<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Y.CH.Y</title><link>/</link><description>Recent content on Y.CH.Y</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Y.CH.Y</copyright><lastBuildDate>Thu, 05 Jan 2023 21:43:40 +0800</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>壬寅年::小寒</title><link>/posts/e39t23/</link><pubDate>Thu, 05 Jan 2023 21:43:40 +0800</pubDate><guid>/posts/e39t23/</guid><description>换组 春节回来后要换个组，把手头的工作结束后，去隔壁组交流访问，能做点稍微偏技术的东西了。
impact 面试当前公司的时候表达了未来能够希望从事基础业务或者基础架构方向发展的意愿，在前司做 2B 业务蛮无聊的，价值感也很低，直接面向客户做开发，千辛万苦做的业务只有几十个撑死上百个人会用，而做基础业务或者基础组件，借由他人的力量，能够影响到更多的人，价值感也会更高。
Obsidian 这两年井喷了一波笔记工具，而这些笔记工具都有些门槛，作为用 Notes 做记录的笔记小白有点望而却步，最近看到了同事用 Obisidan 做笔记，感觉还不错，决定学习了解一下。
Raycast 在推特看到了很多人分享 Raycast 的年度总结，觉得很漂亮，目前使用最多的是剪贴板管理和翻译，但是没有云端同步略遗憾。
拥抱变化 今年的第一场月会，领导说这几年形势多变，他也没办法做长期规划，可能要过苦日子了，最后大家要拥抱变化。
day 1 我想我大概是感染了，中午起床后就感觉喉咙痛，然后就开始头痛了，还有关节痛？，下午看着心率从 80 一路升到 120，后来一直保持在 110 上下，没有失去味觉，没有咳嗽，没有流鼻涕，下午测的抗原阴性。吃了一粒布洛芬，希望能起效。
day 2 早上醒来，看了眼手表，睡觉期间心率 94-110，体温比基础值高了 1.4 度，没有头痛了，看起来布洛芬起效了，喉咙与其说痛不如说是痒，很低频的咳嗽，其他症状依然不明显，不过终于抗原阳性了，感觉新冠的症状很典型也很明显，有点意思。</description></item><item><title>书单</title><link>/books/</link><pubDate>Sun, 01 Jan 2023 17:37:37 +0800</pubDate><guid>/books/</guid><description>2022 领域驱动设计 领域驱动设计::运用领域模型
领域驱动设计::领域驱动设计的构造块
2021 现代操作系统 现代操作系统::引论
现代操作系统::进程与线程
现代操作系统::内存管理
现代操作系统::文件系统
现代操作系统::输入/输出
现代操作系统::死锁
现代操作系统::虚拟化与云
现代操作系统::多处理器系统
现代操作系统::安全
现代操作系统::操作系统设计
深入理解Java虚拟机 深入理解Java虚拟机::走进 Java
深入理解Java虚拟机::自动内存管理
深入理解Java虚拟机::垃圾收集器与内存分配策略
深入理解Java虚拟机::虚拟机性能监控、故障处理工具
深入理解Java虚拟机::调优案例分析与实战
深入理解Java虚拟机::类文件结构
深入理解Java虚拟机::虚拟机类加载机制
深入理解Java虚拟机::虚拟机字节码执行引擎
深入理解Java虚拟机::类加载及执行子系统的案例与实战
深入理解Java虚拟机::前段编译与优化
深入理解Java虚拟机::后端编译与优化
深入理解Java虚拟机::Java 内存模型与线程
深入理解Java虚拟机::线程安全和锁优化
计算机网络自顶向下方法 计算机网络自顶向下方法::计算机网络和因特网
计算机网络自顶向下方法::应用层
计算机网络自顶向下方法::运输层
计算机网络自顶向下方法::网络层::数据平面
计算机网络自顶向下方法::网络层::控制平面
计算机网络自顶向下方法::链路层与局域网
计算机网络自顶向下方法::计算机网络中的安全
系统设计 系统设计::从零到一百万
系统设计::粗略评估
系统设计::系统设计面试框架
系统设计::设计一个限流器
系统设计::设计一致性哈希
系统设计::设计键值存储
系统设计::在分布式系统中设计一个唯一ID生成器
系统设计::设计短链接
系统设计::设计网络爬虫
系统设计::设计一个推送系统
系统设计::设计一个新闻源系统
系统设计::设计一个聊天系统
系统设计::设计一个搜索自动补全系统
系统设计::设计YOUTUBE
系统设计::设计谷歌硬盘</description></item><item><title>2022::书单</title><link>/misc/books_2022/</link><pubDate>Sat, 31 Dec 2022 17:12:59 +0800</pubDate><guid>/misc/books_2022/</guid><description> 书名 分类 Pulsar in Action 编程 第三时效 推理 设计模式之禅（第 2 版） 编程 深入理解 Kafka：核心设计与实践原理 编程 领域驱动设计 编程 UNIX 环境高级编程（第 3 版） 编程 Linux/UNIX 系统编程手册 编程 发布！设计与部署稳定的分布式系统（第 2 版） 编程 是我把你蠢哭了吗 认知 饱食穷民 社会 妻子们的思秋期 社会 流星之绊 推理 你的孩子不是你的孩子 教育</description></item><item><title>壬寅年::冬至</title><link>/posts/e39t22/</link><pubDate>Thu, 22 Dec 2022 20:19:49 +0800</pubDate><guid>/posts/e39t22/</guid><description>跑步 十二月的第一周因为所谓的密接被隔离在家了，打断了我跑一休一的节奏，然后就是防疫政策的变化，不敢到处乱跑了，整个十二月就跑了三次加起来二十多公里，作为一个初阶跑者，还没有到追求成绩的地步，没啥可焦虑的，所以后面天气转好再跑就行了。
新装备 iPhone 14 pro 和 apple watch 8，灵动岛也就新鲜了两天。最大的欣慰就是不用一天 n 充了，用了四年的 xs 和 4 续航尿崩，我每次跑步前都需要给手表充到 50% 以上，不然它连我的 10 公里跑步都坚持不下来了。
四双跑鞋，一双 nimbus24，两双 novablast3，一双 pegasus39。nimbus24 是入手的第一双，考虑到自己是个大体重初跑者，需要比较好的缓震于是便入手了它，它确实很软，在我后面去买鞋的时候到没穿到过比它的中底更软的跑鞋了。缓震的明显缺点就是提速的时候比较卸力，当我可以跑进 530 的配速的时候买了一双 novablast3，中底相对比较弹，也是目前我最喜欢的鞋子，后面又买了一双，换着穿，延长鞋的寿命，这双鞋提供多种楦型，尺码标准，非常的合脚，缺点是雨天不防滑，我在雨后半干的柏油路面跑过一次，全程小心翼翼。最后就是入了 pegasus39，入手这款一来是经典系列，很多人推荐，没有明显缺点，二来我需要一双防滑性能好一点的鞋子，入手了山野版，鞋底做了防滑增强，脚感比 novablast3 更硬一点，另外就是山野版的关系，闷脚，我只穿它跑过一次 10 公里，现在变成了我的雨天通勤鞋。
polar 的心率带，看一些跑步的频道主说冬天的时候手表的心率数据不准确，我还是蛮依赖这个数据的，并不完全看体感跑步，就入手了一个。现在的观点是完全没必要买，因为我冬天根本不出门跑步。
减肥 从三月下半旬开始跑步，体重从 78 公斤减到了 63 公斤，完成了我 65 公斤的目标，比较惊喜的是在十一月的一次跑步中跑完 10 公里后体感还不错突发奇想看看自己能不能坚持到一个半马，最后也顺利完成了。
一年整 在新公司度过了完整的一年，做了一些事情，从 0 开始上线了一个系统，也有一些不足，自我感觉来说还是没有什么亮点。季度自评回顾时，都会想这个需求是只有我能做吗，明显不是，我能做得比别人更好吗，也不见得，于是我每次都给自己打 B。从业务系统中发觉亮点是一件蛮困难的事情，后面还是需要更多思考与总结。
严肃的生产问题 在现在的公司出了一个线上问题后往往要复盘开会，然后会有一些严肃的讨论，比如这个问题是不是应该在开发阶段就被发现，如果发现了应该怎么解决，应该怎么预防，这些问题都是很严肃的。相比我的前司，是一个蛮明显的改变，前司的项目追求小步快跑，在很长时间团队也是保持很小的规模，有 bug 就修，修完就发，有需求就加，需求不对就改，一直到我快要离开的那一年才有比较固定的发版规范。以至于我刚来这里造成第一个线上故障时会觉得，这么点问题，有必要这么严重吗？这种心态是蛮糟糕的，也是不成熟的表现，故障不应该区分大小，都是需要解决的，流程该补的补上，重构该做的就做起来，这样才能让项目更健康，不该因为问题的影响面小就轻视它。
慢下来 从前司还带下来一个比较不好的习惯就是做事情很匆忙，习惯了前司火急火燎的开发节奏后，在这里一切都会被强迫慢下来，有需求初审，有需求终审，有技术方案评审，UI 稿评审，然后进入开发联调，测试验收，UI 验收，产品验收，最后就是上线方案评审，发布预发生产。如果当初毕业的时候能进入一家流程规范的公司对一个行业新人来说或许更好。
技术 说来惭愧，除了工作用到而被动要了解的技术，一整年都没有去主动学习过什么，今年公司要推 Golang，会看一些相关的知识，比如云原生之类的。
学洋文 从国庆后开始背单词了，选择了 COCA20000，用欧陆测了一下词汇量，6000 左右，然后选了 5000 那本来背，后来发现不认识的单词有点多，又选了 4000 的来背，然后 4000 不认得也有点多，又开始背 3000 的，只有 10 个里面有 2 个单词不认识我就认为是难度高了，惭愧，是我太菜了，不怕起点低嘛，贵在坚持。重新开始学习的理由，简单来说就是时局之下，更好的出路，更多的机会，与其在一个赛道上挤破头，不如拓宽自己的赛道。</description></item><item><title>程序员修炼之道摘录</title><link>/misc/the_pragmatic_programmer/</link><pubDate>Sat, 19 Feb 2022 23:43:39 +0800</pubDate><guid>/misc/the_pragmatic_programmer/</guid><description> 关注你的技艺 如果你不关心怎么把软件开发好，那么软件开发领域就再也没什么好谈的事情了 思考！思考你的工作 对每天里每一个项目所做的每一个决定进行的批判性评估 我们，采集的只是石头，却必须始终展望着未来的大教堂 每一天都要努力打磨你的技能，并往技能库里添加新的工具 不断地做出许多小的改进 务实的哲学 你的事业是你自己的，更重要的是，你的人生是你的 务实的程序员的特质是什么 在解决方案中透出的态度、风格及理念 试着将问题放在更宽泛的上下文中综合考虑，从大局着想 为所做的一切负责</description></item><item><title>发布！设计与部署稳定的分布式系统</title><link>/misc/release_it_design_and_deploy_proudction_ready_software/</link><pubDate>Sun, 13 Feb 2022 22:51:56 +0800</pubDate><guid>/misc/release_it_design_and_deploy_proudction_ready_software/</guid><description>生产环境的生存法则 瞄准正确的目标 今天的软件设计在与现实相差甚远的环境中进行，其目标在于通过 QA 部门的验收，不能保证在未来三五年的适用性。另一方面，制造业的产品设计师一直在追求能够让人们以低成本和高质量的方式制造产品的“可制造性设计”。软件行业的“可制造性设计”，就是“为生产环境而设计”。我们既需要设计一个个彼此独立的软件系统，也需要设计由相互依赖的系统所组成的整个生态系统，从而以低成本和高质量的方式进行运维工作。
应对不断扩大的挑战范围 是随着用户触点的增加和系统规模的扩大，系统遭到破坏的方式也会翻新，环境会变得更加恶劣，人们对缺陷的容忍度会变得更低。这个正在不断扩大的挑战范围，即以低成本快速构建和运维对用户有益的软件，要求我们持续改进架构和设计技术。
多花 5 万美元来节省 100 万美元 设计决策和架构决策，也是财务决策。在选择时，必须着眼于实施成本和下游成本。在假设可以投资 5 万美元来创建不停机发布的构建流水线和部署过程。这样做至少可以避免 100 万美元的停机部署损失，而且大有可能提高系统部署频率，占领更多市场份额。
让&amp;quot;原力&amp;quot;与决策同在 早期决策会对系统的最终形态产生巨大的影响。最早做出的决定可能是最难以反悔的。非常具有讽刺意味的是，早期决策恰恰是在信息最不完备的时候做出的。团队在启动项目时，往往最不了解软件的最终架构，却偏偏要在那时必须做出一些最不可能更改的决定。富有远见的决策将会大大减少整个软件声明周期的总成本。
设计务实的架构 务实的架构中，其中每个组件都足以满足的当前的负荷，并且，当符合随着时间发生变化时，架构师知道要替换那些组件。</description></item><item><title>2021::书单</title><link>/misc/books_2021/</link><pubDate>Fri, 31 Dec 2021 17:12:59 +0800</pubDate><guid>/misc/books_2021/</guid><description> 书名 分类 绝叫 推理 软技能 编程 MySQL 技术内幕 编程 Redis 设计与实现 编程 System Design Interview 编程 东方快车谋杀案 推理 凤凰架构 编程 屍人莊殺人事件 推理 白夜行 推理 嫌疑人 X 的献身 推理 字母表谜案 推理 密室收藏家 推理 尸体变化图鉴 科普 深入理解 Java 虚拟机（第 3 版） 编程 心灵侦探城塚翡翠 推理 恶意 推理 操作系统导论 编程 数据密集型应用系统设计 编程 编码 编程 现代操作系统（原书第 4 版） 编程 绝对不在场证明 推理 编程之道 编程 被讨厌的勇气 心理 计算机网络（原书第 7 版） 编程 金色麦田 推理 乌合之众 心理 诡计博物馆 推理 许三观卖血记 文学 活着 文学</description></item><item><title>数据库::高性能MySQL第四版</title><link>/misc/high_performance_mysql_4th/</link><pubDate>Sun, 19 Dec 2021 16:11:52 +0800</pubDate><guid>/misc/high_performance_mysql_4th/</guid><description>MySQL 架构 MySQL 的逻辑架构 MySQL 的架构分为三层
最上面一层是客户端，它们是大多数基于网络的客户/服务器工具或服务器需要的服务：连接处理、认证、安全，等等。
第二层包含 MySQL 的大多数功能，包括提供查询解析、分析、优化的代码，以及所有的内置函数。任何跨存储引擎提供的功能都在这一层：例如，存储过程、触发器和视图。
第三层包含存储引擎。它们负责存储和检索 &amp;ldquo;在 &amp;ldquo;MySQL 中存储的所有数据。像 GNU/Linux 的各种文件系统一样，每个存储引擎都有自己的好处和缺点。服务器通过存储引擎 API 与它们进行通信。
连接管理和安全 默认情况，每个客户端连接都有单独的处理线程，服务器缓存了就绪的线程，避免了每次连接创建和销毁的开销。
当客户端连接到服务器，服务器会进行登录信息鉴权和操作权限校验。
优化和执行 MySQL 解析查询以创建一个内部结构（解析树），然后应用各种优化。这些可能包括重写查询，确定它将读取表的顺序，选择使用哪些索引，等等。你可以通过查询中的特殊关键字向优化器传递提示，影响其决策过程。你还可以要求服务器解释优化的各个环节，以便重新修改查询、模式和设置，使一切尽可能有效地运行。
优化器并不真正关心一个特定的表使用什么存储引擎，但存储引擎确实影响到服务器如何优化查询。例如，一些存储引擎支持索引类型，这对某些查询是有帮助的。
MySQL 的内部缓存随着并发的增加成为了瓶颈，所以在 MySQL8.0 中已经彻底去掉。
并发控制 任何时候，只要有一个以上的查询需要同时改变数据，就会出现并发控制的问题。MySQL 必须在两个层面上做到这一点：服务器层面和存储引擎层面。
读写锁 处理并发读/写访问的系统通常实现一个由两种锁类型组成的锁系统。这些锁通常被称为共享锁和独占锁，或者读锁和写锁。一个资源上的读锁是共享的，或者说是相互不阻塞的：许多客户可以同时从一个资源上读取，而不会相互干扰。另一方面，写锁是排他性的&amp;ndash;也就是说，它们同时阻止读锁和其他写锁&amp;ndash;因为唯一安全的策略是在给定的时间内只有一个客户在向资源写，并且在客户写的时候阻止所有的读。
锁的粒度 每一个锁操作都有开销，包括获取锁、检查锁是否空闲、释放锁，等等。如果系统花费太多的时间来管理锁，而不是存储和检索数据，性能就会受到影响。管理锁是存储引擎设计中的一个非常重要的决定；将粒度固定在某一水平上可以提高某些用途的性能，但使该引擎不适合其他用途。
表锁
MySQL 中最基本的锁策略，也是开销最小的策略，是表锁。当一个客户希望对一个表进行写操作时（插入、删除、更新等），它获得一个写锁。这使得所有其他的读和写操作都无法进行。当没有人写时，读者可以获得读锁，这不会与其他读锁冲突。
表锁在特定情况下有一些变化以提高性能。例如，READ LOCAL 表锁允许某些类型的并发写操作。写和读锁队列是分开的，写队列的优先级完全高于读队列。 行锁
提供最大并发性的锁定方式（也有最大的开销）是使用行锁。这使得服务器可以进行更多的并发写操作，但代价是必须跟踪谁拥有每一个行锁，它们被打开了多长时间，它们是什么样的行锁，以及在不再需要时清理锁的开销。
推荐阅读：MySQL :: MySQL 8.0 Reference Manual :: 15.7.1 InnoDB Locking 事务 事务是一组被原子化处理的 SQL 语句，是一个单一的工作单位。所有操作应该被包裹在一个事务中，这样，如果任何一个步骤失败，任何已完成的步骤都需要回滚。
事务需要满足 ACID 特性。
原子性
事务必须作为一个单一的不可分割的工作单元来运作，这样整个事务要么被应用，要么永远不会提交。当事务是原子性的，就不存在部分完成的事务：要么全部完成，要么什么都没有。 一致性
数据库应该总是从一个一致的状态移动到下一个一致的状态。 隔离性
一个事务的结果通常对其他事务是不可见的，直到该事务完成。 持久性
一旦提交，事务的变化就是永久性的。这意味着这些变化必须被记录下来，以便在系统崩溃时数据不会丢失。 隔离级别 ANSI SQL 标准定义了四个隔离级别。这个标准的目标是定义在事务内部和外部哪些变化是可见的，哪些是不可见的规则。较低的隔离级别通常允许较高的并发性，并具有较低的开销。</description></item><item><title>基础::计算机系统中的时间</title><link>/misc/computer_time/</link><pubDate>Tue, 26 Oct 2021 22:32:54 +0800</pubDate><guid>/misc/computer_time/</guid><description>背景 时间是计算机系统中一个非常重要的概念，很多系统调用与时间有关，很多定时任务依赖时间，甚至内核本身也需要定时器按照一定频率来产生时钟中断来驱动它能够正常运行下去。
硬件时间 操作系统需要在硬件的帮助下才能管理时间，体系结构主要提供了两种硬件设备，一个是时钟源设备，位于主板上的一小块存储空间，有单独的供电，即使断电也可以保持计时。当操作系统启动时，会从这里读取时间，把系统时间与硬件时间设置成一致，此后两个时钟独立，操作系统维护自己的时钟，因为查看硬件既慢又复杂。另一个硬件是时钟事件设备，用于单次或周期性触发系统中断，每次中断，操作系统会进行刷新系统时间，管理进程时间片等操作。
系统时间 计算机科学与计算机编程中, 系统时间表示在计算机系统中的时间与日期。通常用系统时钟从某个时间起点的嘀嗒数。时间起点就是上文提到的在启动时读取的硬件时间，滴答数则是每次中断的累加，定时器是按照一定频率产生中断的，所以系统是可以知道两次中断之间过去了多久的。类 Unix 系统通常采用 Unix Epoch 来表示时间。
时间同步 因为操作系统采用了自己维护时间的方式，所以在运行一段时间后必然会产生硬件时间和软件时间不一致的情况，系统时钟会开始落后。这时候可以使用“hwclock“将两者进行同步，通过指定不同的参数将硬件时间同步到系统时间或者把系统时间同步到硬件时间。
NTP 协议 在单机系统中尚且可以解决时间不一致的问题，但是无法解决时间不准确的问题。于是就有了 NTP 协议，全称网络时间协议（Network Time protocol）。通过与另一台保持准确时间的设备通信来调整自身的系统时间，这就是 NTP 协议所做的事情，协议基于 UDP 实现，通过该协议，可以将时间误差保持在 UTC 时间的毫秒级误差。操作系统会周期性通过 NTP 协议更新系统时间。
UTC 时间 协调世界时是最主要的世界时间标准，其以原子时秒长为基础，在时刻上尽量接近于格林威治标准时间。因为在英国的缩写是 CUT，而法国的缩写是 TUC，所以双方妥协一下，缩写统一成 UTC 时间。协调世界时是世界上调节时钟和时间的主要时间标准，它与 0 度经线的平太阳时相差不超过 1 秒，并不遵守夏令时。协调世界时是最接近格林威治标准时间（GMT）的几个替代时间系统之一。对于大多数用途来说，UTC 时间被认为能与 GMT 时间互换，但 GMT 时间已不再被科学界所确定。这套时间系统被应用于许多互联网和万维网的标准中，例如，网络时间协议（NTP, Network Time Protocol）就是协调世界时在互联网中使用的一种方式。
GMT 时间 格林尼治平均时间（英语：Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台当地的平太阳时，因为本初子午线被定义为通过那里的经线。目前使用的世界时测算标准又称 UT1。在 UT1 之前人们曾使用过 UT0，但由于 UT0 没有考虑极移导致的天文台地理坐标变动的问题，因此测出的世界时不准确，现在已经不再被使用。在 UT1 之后，由于人们发现，因为地球自转本身不均匀的问题，UT1 定义的时间的流逝仍然不均匀，于是人们又发展了一些对 UT1 进行平滑处理后的时间标准，包括 UT1R 和 UT2，但它们都未能彻底解决定义的时间的流逝不均匀的问题，这些时间标准现在都不再被使用。
后来的人们为了解决地球自转产生了时间流逝不均匀的问题，开始采用原子钟定义时间。人们首先用全世界的原子钟共同为地球确立了一个均匀流动的时间，称为国际原子时（International Atomic Time, TAI）。然后，为了使定义的时间与地球自转相配合，人们通过在 TAI 的基础上不定期增减闰秒的方式，使定义的时间与世界时（UT1）保持差异在 0.</description></item><item><title>领域驱动设计::领域驱动设计的构造块</title><link>/notes/ddd_02/</link><pubDate>Mon, 18 Oct 2021 13:24:22 +0800</pubDate><guid>/notes/ddd_02/</guid><description>领域驱动设计的构造快 分离领域 LAYERED ARCHITECTURE 的基本原则是层中的任何元素都仅依赖于本层的其他元素或其下层的元素。分层的价值在于每⼀层都只代表程序中的某⼀特定⽅⾯。这种限制使每个⽅⾯的设计都更具内聚性，更容易解释。分层的价值在于每⼀层都只代表程序中的某⼀特定⽅⾯。 这种限 制使每个⽅⾯的设计都更具内聚性，更容易解释 用户界面层：负责向用户显示信息和解释用户指令。这里指的用户可以是另一个计算机系统，不一定是使用用户界面的人。 用户界面层：定义软件要完成的任务，并且指择表达领域概念的对象来解決问题。这一层所负责的工作对业务来说意义重大，也是与其他系统的应用层进行交互的必要渠道应用层要尽量简单，不包含业务规则或者知识，而只为下一层中的领域对象协调任务，分配工作，使它们互相协作。它没有反映业务情况的状态，但是却可以具有另外一种状态，为用户或程序显示某个任务的进度。 应用层：负责表达业务概念，业务状态信息以及业务规则。尽管保存业务状态的技术细节是由基础设施层实现的，但是反映业务情况的状态是由本层控制并且使用的。领域层是业务软件的核心。 基础设施层：为上面各层提供通用的技术能力，为应用层传递消息，为领域层提供持久化机制，为用户界面层绘制屏慕组件，等等。基础设施层还能够通过架构框架来支持 4 个层次间的交互模式。 给复杂的应⽤程序划分层次。在每⼀层内分别进⾏设计，使其具有内聚性并且只依赖于它的下层。采⽤标准的架构模式，只与上层进⾏松散的耦合。将所有与领域模型相关的代码放在⼀个层中，并把它与⽤户界⾯层、应⽤层以及基础设施层的代码分开。领域对象应该将重点放在如何表达领域模型上，⽽不需要考虑⾃⼰的显⽰和存储问题，也⽆需管理应⽤任务等内容。这使得模型的含义⾜够丰富，结构⾜够清晰，可以捕捉到基本的业务知识，并有效地使⽤这些知识。 各层之间是松散连接的，层与层的依赖关系只能是单向的。 上层可以直接使⽤或操作下层元素，⽅法是通过调⽤下层元素的公共接口，保持对下层元素的引⽤（⾄少是暂时的），以及采⽤常规的交互⼿段。⽽如果下层元素需要与上层元素进⾏通信（不只是回应直接查询），则需要采⽤另⼀种通信机制，使⽤架构模式来连接上下层，如回调模式或 OBSERVERS 模式。 通常，基础设施层不会发起领域层中的操作，它处于领域层“之下”，不包含其所服务的领域中的知识。 事实上这种技术能⼒最常以 SERVICE 的形式提供。例如，如果⼀个应⽤程序需要发送电⼦邮件，那么⼀些消息发送的接⼜可以放在基础设施层中，这样，应⽤层中的元素就可以请求发送消息了。这种解耦使程序的功能更加丰富。消息发送接⼜可以连接到电⼦邮件发送服务、传真发送服务或任何其他可⽤的服务。但是这种⽅式最主要的好处是简化了应⽤层，使其只专注于⾃⼰所负责的⼯作：知道何时该发送消息，⽽不⽤操⼼怎么发送。 应⽤层和领域层可以调⽤基础设施层所提供的 SERVICE。如果 SERVICE 的范围选择合理，接口设计完善，那么通过把详细⾏为封装到服务接⼜中，调⽤程序就可以保持与 SERVICE 的松散连接，并且⾃⾝也会很简单。 不妄求万全之策，只要有选择性地运⽤框架来解决难点问题，就可以避开框架的很多不⾜之处。明智⽽审慎地选择框架中最具价值的功能能够减少程序实现和框架之间的耦合，使随后的设计决策更加灵活。更重要的是，现在许多框架的⽤法都极其复杂，这种简化⽅式有助于保持业务对象的可读性，使其更富有表达⼒。 领域模型是⼀系列概念的集合。“领域层”则是领域模型以及所有与其直接相关的设计元素的表现，它由业务逻辑的设计和实现组成。在 MODEL-DRIVEN DESIGN 中，领域层的软件构造反映出了模型概念。 领域驱动设计只有应⽤在⼤型项⽬上才能产⽣最⼤的收益，⽽这也确实需要⾼超的技巧。不是所有的项⽬都是⼤型项⽬；也不是所有的项⽬团队都能掌握那些技巧。 如果⼀个架构能够把那些与领域相关的代码隔离出来，得到⼀个内聚的领域设计，同时又使领域与系统其他部分保持松散耦合，那么这种架构也许可以⽀持领域驱动设计。 软件中所表示的模型 领域对象的生命周期 使用语言：一个扩展的示例</description></item><item><title>领域驱动设计::运用领域模型</title><link>/notes/ddd_01/</link><pubDate>Sat, 16 Oct 2021 22:19:36 +0800</pubDate><guid>/notes/ddd_01/</guid><description>运用领域模型 每个软件程序是为了执行用户的某项活动，或是满足用户的某种需求。这些用户应用软件的问题区域就是软件的领域。 模型正是解决此类信息超载问题的工具。 模型这种知识形式对知识进行了选择性的简化和有意的结构化。适当的模型可以使人理解信息的意义，并专注于问题。 模型在领域驱动设计中的作用 模型和设计的核心互相影响。 模型是团队所有成员使用的通用语言的中枢。 模型是浓缩的知识。 软件的核心 软件的核心是其为用户解决领域相关的问题的能力。 消化知识 有效建模的要素 模型和实现的绑定。 建立了一种基于模型的语言。 开发一个蕴含丰富知识的模型。 提炼模型。 头脑风暴和实验。 知识消化 高效的领域建模人员是知识的消化者。他们在大量信息中探寻有用的部分。他们不断尝试各种信息组织方式，努力寻找对大量信息有意义的简单视图。很多模型在尝试后被放弃或改造。只有找到一组适用于所有细节的抽象概念后，工作才算成功。这一精华严谨地表示了所发现的最为相关的知识。 知识消化并非一项孤立的活动，它一般是在开发人员的领导下，由开发人员与领域专家组成的团队来共同协作。 持续学习 高效率的团队需要有意识地积累知识，并持续学习。对于开发人员来说，这意味着既要完善技术知识，也要培养一般的领域建模技巧。但这也包括认真学习他们正在从事的特定领域的知识。 那些早期工作还是非常重要的。关键的模型元素被保留下来，而更重要的是，早期工作启动了知识消化的过程，这使得所有后续工作更加高效：团队成员、开发人员和领域专家等都学到了知识，他们开始使用一种公共的语言，而且形成了贯穿整个实现过程的反馈闭环。 知识丰富的设计 业务活动和规则如同所涉及的实体一样，都是领域的核心，任何领域都有各种类别的概念。知识消化所产生的模型能够反映出对知识的深层理解。在模型发生改变的同时，开发人员对实现进行重构，以便反映出模型的变化，这样，新知识就被合并到应用程序中了。 当我们的建模不再局限于寻找实体和值对象时，我们才能充分吸取知识，因为业务规则之间可能会存在不一致。领域专家在反复研究所有规则、解决规则之间的矛盾以及以常识来弥补规则的不足等一系列工作中，往往不会意识到他们的思考过程有多么复杂。软件是无法完成这一工作的。正是通过与软件专家紧密协作来消化知识的过程才使得规则得以澄清和充实，并消除规则之间的矛盾以及删除一些无用规则。 提取一个隐藏的概念 深层模型 有用的模型很少停留在表面。随着对领域和应用程序需求的理解逐步加深，我们往往会丢弃那些最初看起来很重要的表面元素，或者切换它们的角度。这时，一些开始时不可能发现的巧妙抽象就会渐渐浮出水面，而它们恰恰切中问题的要害。 在一个需要团队成员持续学习的真实项目中，要想建立实用且清晰的模型则要求团队成员既精通领域知识，也要精通建模技术。 知识消化是一种探索，它永无止境。 交流与语言的使用 领域模型可成为软件项目通用语言的核心。该模型是一组得自于项目人员头脑中的概念，以及反映了领域深层含义的术语和关系。这些术语和相互关系提供了模型语言的语义，虽然语言是为领域量身定制的，但就技术开发而言，其依然足够精确。正是这条至关重要的纽带，将模型与开发活动结合在一起，并使模型与代码紧密绑定。 这种基于模型的交流并不局限于 UML 图。为了最有效地使用模型，需要充分利用各种交流手段。 模式：UBIQUITOUS LANGUAGE 要想创建一种灵活的、蕴含丰富知识的设计，需要一种通用的、共享的团队语言，以及对语言不断的试验 如果语言支离破碎，项目必将遭遇严重问题。领域专家使用他们自己的术语，而技术团队所使用的语言则经过调整，以便从设计角度讨论领域。日常讨论所使用的术语与代码中使用的术语不一致。甚至同一个人在讲话和写东西时使用的语言也不一致，这导致的后果是，对领域的深刻表述常常稍纵即逝，根本无法记录到代码或文档中。 翻译使得沟通不畅，并削弱了知识消化。 然而任何一方的语言都不能成为公共语言，因为它们无法满足所有的需求。 项目需要一种公共语言，这种语言要比所有语言的最小公分母健壮得多。通过团队的一致努力，领域模型可以成为这种公共语言的核心，同时将团队沟通与软件实现紧密联系到一起。该语言将存在于团队工作中的方方面面。 UBIQUITOUS LANGUAGE（通用语言）的词汇包括类和主要操作的名称。 模型之间的关系成为所有语言都具有的组合规则。词和短语的意义反映了模型的语义。 将模型作为语言的支柱。确保团队在内部的所有交流中以及代码中坚持使用这种语言。在画图、写东西，特别是讲话时也要使用这种语言。通过尝试不同的表示方法（它们反映了备选模型）来消除难点。然后重构代码，重新命名类、方法和模块，以便与新模型保持一致。解决交谈中的术语混淆问题，就像我们对普通词汇形成一致的理解一样。要认识到，UBIQUITOUS LANGUAGE 的更改就是对模型的更改。领域专家应该抵制不合适或无法充分表达领域理解的术语或结构，开发人员应该密切关注那些将会妨碍设计的有歧义和不一致的地方。 讨论系统时要结合模型。使用模型元素及其交互来大声描述场景，并且按照模型允许的方式将各种概念结合到一起。找到更简单的表达方式来讲出你要讲的话，然后将这些新的想法应用到图和代码中。 简单、非正式的 UML 图能够维系整个讨论。绘制一幅包含当前问题最关键的 3 ～ 5 个对象的图，这样每个人都可以集中注意力。所有人就对象关系会达成一致的认识，更重要的是，他们将使用相同的对象名称。 UML 图无法传达模型的两个最重要的方面，一个方面是模型所表示的概念的意义，另一方面是对象应该做哪些事情。 设计的重要细节应该在代码中体现出来。良好的实现应该是透明的，清楚地展示其背后的模型 互为补充的图和文档能够引导人们将注意力放在核心要点上。自然语言的讨论可以填补含义上的细微差别。 文档应作为代码和口头交流的补充 文档应当鲜活并保持最新，避免文档与项目脱节。 绑定模型和实现 领域驱动设计要求模型不仅能够指导早期的分析工作，还应该成为设计的基础。 严格按照基础模型来编写代码，能够使代码更好地表达设计含义，并且使模型与实际的系统相契合。 如果整个程序设计或者其核心部分没有与领域模型相对应，那么这个模型就是没有价值的，软件的正确性也值得怀疑。同时，模型和设计功能之间过于复杂的对应关系也是难于理解的，在实际项目中，当设计改变时也无法维护这种关系。若分析与和设计之间产生严重分歧，那么在分析和设计活动中所获得的知识就无法彼此共享。 软件系统各个部分的设计应该忠实地反映领域模型，以便体现出这二者之间的明确对应关系。我们应该反复检查并修改模型，以便软件可以更加自然地实现模型，即使想让模型反映出更深层次的领域概念时也应如此。我们需要的模型不但应该满足这两种需求，还应该能够支持健壮的 UBIQUITOUS LANGUAGE（通用语言）。从模型中获取用于程序设计和基本职责分配的术语。让程序代码成为模型的表达，代码的改变可能会是模型的改变。而其影响势必要波及接下来相应的项目活动。完全依赖模型的实现通常需要支持建模范式的软件开发工具和语言，比如面向对象的编程。 任何参与建模的技术人员，不管在项目中的主要职责是什么，都必须花时间了解代码。任何负责修改代码的人员则必须学会用代码来表达模型。每一个开发人员都必须不同程度地参与模型讨论并且与领域专家保持联系。参与不同工作的人都必须有意识地通过 UBIQUITOUS LANGUAGE 与接触代码的人及时交换关于模型的想法。</description></item><item><title>翻译::了解Facebook是如何从互联网上消失的</title><link>/misc/understanding_how_facebook_disappeared_from_the_internet/</link><pubDate>Tue, 05 Oct 2021 15:54:34 +0800</pubDate><guid>/misc/understanding_how_facebook_disappeared_from_the_internet/</guid><description>原文: Understanding How Facebook Disappeared from the Internet
翻译: DeepL 翻译 和我
&amp;ldquo;Facebook 不可能瘫痪，对吗？&amp;quot;，让我们思考一秒钟。
今天 16:51UTC，我们开了一个内部事件，题为 &amp;ldquo;Facebook DNS 查询返回 SERVFAIL&amp;rdquo;，因为我们担心我们的 DNS 解析器 1.1.1.1 出了问题。但当我们准备在我们的公共状态页面上发布时，我们意识到发生了其他更严重的事情。
社交媒体迅速爆发，报道了我们的工程师也迅速确认的情况。事实上，Facebook 及其附属服务 WhatsApp 和 Instagram 都已瘫痪。他们的 DNS 名称停止解析，他们的基础设施 IP 也无法访问。这就像有人一下子从他们的数据中心 &amp;ldquo;拔掉了电缆&amp;rdquo;，并将他们与互联网断开连接。
这怎么可能呢？
来自 Facebook 的更新 Facebook 现在发表了一篇博文，介绍了内部发生的一些细节。在外部，我们看到了这篇文章中概述的 BGP 和 DNS 问题，但问题实际上始于一个影响整个内部骨干网的配置变化。这导致了 Facebook 和其他属性的消失，而 Facebook 内部的员工也很难再获得服务。
现在来看看我们从外面看到的情况。
认识 BGP BGP 是边界网关协议的缩写。它是一种在互联网上的自治系统（AS）之间交换路由信息的机制。使互联网运行的大型路由器拥有庞大的、不断更新的可能路由列表，这些路由可用于将每个网络数据包传送到其最终目的地。没有 BGP，互联网路由器就不知道该怎么做，互联网也就无法运行。
互联网实际上是一个网络的网络，它是由 BGP 捆绑在一起的。BGP 允许一个网络（例如 Facebook）向构成互联网的其他网络宣传其存在。当我们写到 Facebook 没有宣传它的存在时，ISP 和其他网络就找不到 Facebook 的网络，因此它就不可用。
各个网络都有一个 ASN：一个自治系统号码。一个自治系统（AS）是一个具有统一的内部路由策略的单独网络。一个 AS 可以发起前缀（说他们控制着一组 IP 地址），以及过境前缀（说他们知道如何到达特定的 IP 地址组）。</description></item><item><title>软技能::代码之外的生存指南</title><link>/misc/soft_skills/</link><pubDate>Tue, 28 Sep 2021 16:13:44 +0800</pubDate><guid>/misc/soft_skills/</guid><description>职业 你所能犯的最大错误就是相信自己是在为别人工作。这样一来你对工作的安全感已然尽失。职业发展的驱动力一定是来自个体本身。记住：工作是属于公司的，而职业生涯却是属于你自己的。 成功的软件开发人员之所以能成功都不是偶然的。他们目标明确，为了达成目标，他们制订了坚实可靠而又深思熟虑的计划。 要做什么，什么时候做，以及如何义无反顾。 从非同凡响开始：绝不要做他人都在做的事 只有你开始把自己当作一个企业去思考时，你才能开始做出良好的商业决策。 软件开发人员售卖的就是他们把一个想法变成一个数字化的现实产品的能力。 专注于你正在提供怎样的服务，以及如何营销这项服务； 想方设法提升你的服务； 思考你可以专注为哪一特定类型的客户或行业提供特定的服务； 集中精力成为一位专家，专门为某一特定类型的客户提供专业的整体服务（记住，作为一个软件开发人员，你只有真正专注于一类客户，才能找到非常好的工作）。 我的服务是管理开发人员，招聘培训人才，建立流程，发现问题，提供解决方案，和其他部门合作，保证结果 大多数成功的公司都会开发出让客户主动上门购买的产品或服务，它们才不会一个接一个地追逐客户。 优秀的人才是被主动挖掘而不是自我寻找 思考未来：你的目标是什么 起步阶段最简单的就是在心中树立一个大目标，然后再建立能帮你达成这个大目标的小目标。 人际交往能力：远比你想象的重要 如果你希望人们接受你的想法，并认可其中的价值，首先你最好先主动给他人相同的礼遇。如果你不能保全他人的自尊，那你永远也不可能赢得他的心。 聚精会神地聆听，当轮到你发言的时候，娓娓道来，一语中的。（实际运用中，你可以提前排练一下这种场景，提前准备好如何进行这种谈话。） 直截了当地告诉老板为什么你喜欢想用某种方式实现某个功能，这并不明智。更好的办法是从对方的心态出发提出建议，阐明为什么采用你建议的方法实现该功能对老板非常有用。理由可能是“让软件更稳定”，或者“能让软件按时交付”。 我们必须要不惜一切代价避免争吵。 在小事情上，任何放弃立场或承认错误的机会对你而言可能没什么大不了的，但对他人却可能是举足轻重的，这么做不仅能为你赢得不可估量的尊重，也能为你的未来积蓄财富，形势逆转时即可兑现使用。 破解面试之道 通过面试的最快捷的方式是让面试官对你怀有好感。 事先就确定我要为这家公司工作的 面试开始之前就思考应对面试的策略。 你必须要突破常规，想尽办法与公司内部人员建立联系。 看看能不能在面试之前得到预面试的机会 能够自发地、无需过问就能做事的员工通常能增加公司的净收入，此外，他们也让老板少操心，只占用少量的管理资源。 与雇用技术高超但需要生拉硬拽才能干活的人相比，我宁愿雇用这样的开发人员：知道的东西可以少一点，但是明确知道要做什么，以及怎样去做。从某种程度上，在你可控的范围之内，面试的时候你要集中精力证明自己就是无需督促也能自动自发做好事情的员工。 集中精力推销自己会对你大有裨益 就业选择：列出你的选择 选择 1：雇员 选择 2：独立咨询师 选择 3：创业者 你是哪类软件开发人员 只要你专业能力雄厚，市场没有过渡饱和，与那些自称为“软件开发人员”的人相比，你能更轻松地找到工作或者赢得客户。 成为这个领域的专家，你就会获得大量业务。 攀登晋升阶梯 在任何公司里能让你脱颖而出的最重要法宝就是承担更多的责任。 没有人愿意涉足的领域是搜寻机会最好的地方。 另一种间接承担责任的方式是成为团队中其他人的导师，自愿帮助新人加速成长，为任何有需要的人提供帮助。 保证“曝光度”——定期与老板会面，确保你经常被注意到。 千万不要忘记分享自己学到的东西。 你要成为那个永远能为各种问题找到解决方案的人，要成为勇于执行这些解决方案以获得成果的人。 你应该对所在组织的政治气候保持警觉。尽管不能完全避开政治，但至少应该知道会发生什么，哪种人需要避开，哪种人永远不要有交集。 确定要自学的最有价值的东西是什么，制订一份下一年的自学计划。 成为专业人士 成为专业人士是一种心态。如果我们总是与恐惧、自毁、拖延和自我怀疑作斗争，那么问题就是：我们正在像外行那样思考问题。外行毫不起眼，外行人废话连篇，外行屈从于逆境。专业人士可不这么想。不管怎样，他引人注目，他恪尽职守，他始终如一。成为专业人士的全部在于：引人注目，恪尽职守，以及不屈服于挫折。成为专业人士，需要你克服自身的缺点，静下心来创作出尽可能最好的作品。 专业人士会坦承自己不知道答案，但是你可以信赖他会找到答案。 每天提前做好计划，就能养成有效管理时间的习惯。专业人士知道每天必须要做什么工作，并且能估算出每项工作大约要花多长时间。 成为自由职业者：开启自己的一片天地 “吸引式营销”基本上就是让潜在的客户主动送上门，而不是你去找他们。你要做的事情就是免费提供有价值的东西。 创建你的第一个产品 在创建产品之前，先筛选出一组特定的受众，他们也是你的解决方案的目标用户。 你打算开始创业吗 很好的创业候选是能够申请专利或受保护的新技术和新方法，而糟糕的创业候选则包括餐厅或其他缺乏独创、很容易被复制的服务。 好的创业项目要有规模扩张的潜力——想想 Twitter、Dropbox 和 Facebook 等。 假装自己能成功 有目的地将自己置于困境，演练一下自己既定的应对策略。 单调乏味的简历——如何修改 beautiful-resumes 上列出了许多漂亮、充满创意的简历，你可以从中得到一些启发。 自我营销 营销就是一场争夺人们注意力的竞赛。 针对“码农”的营销基础课 营销的核心在于将一些人所需要的所期待的产品或者服务与产品或服务本身连接起来。 成功进行自我营销的关键在于：如果想让别人喜欢你，想和你一起工作，你就必须要为他们提供价值。 无论你身在何处都要营销。 自我营销的基本机制是，要想让人们追随你、倾听你，你就要带给他们价值：你能为他们的问题提供答案，甚至是给他们带去欢乐。 打造引人注目的品牌 但品牌不只是商标，更是一项承诺。品牌树立了客户对你的期望，而且这些期望也必须能够实现。 品牌所要传递的信息、品牌的视觉符号、品牌的一致性和品牌的曝光率。 明确要传达的品牌信息。挑选细分市场。创建品牌口号。创建电梯内销售概要。创建视觉符号（即标识）。 接下来，你应该创建所谓“电梯内销售概要”。电梯内销售概要是一段能够快速描述你是谁、能做什么的宣传文字，乘坐电梯的工夫就可以浏览完毕。想想在晚宴上，或者就在电梯里，当有人问起来“你是做什么的”的时候你该怎样回答人家。 创建大获成功的博客 提高你的沟通技巧。组织自己的思想，并将其转化为文字，是一项颇具难度却也极具价值的技能。 持之以恒地坚持写作，坚持不懈地产生高品质的内容，如果你做到了这两点，基本上你就成功了。 你的主要目标：为他人增加价值 不要努力成为一个成功的人，而要努力成为一个有价值的人。——阿尔伯特·爱因斯坦 要想让自我营销的所有努力奏效，基本的方法就是帮助他人获得成功。 你提供的内容应该直接瞄准你所选定的研究领域，为该领域带来价值。 免费内容比付费内容更容易被分享。 最富有创造力的人也是最乐于助人的人。 善于运用社交媒体 发布你认为有用或有趣的。你自己觉得有价值东西，在很大概率上别人也会认同。 演讲、报告和培训：做“说话的极客” 演讲也是一种互动媒介，或者至少你能将其作为媒介使用。 最好从小规模的场合做起，逐渐完善你的演讲技能。要想能在公众面前从容自如地发表演说，需要很长时间的刻苦练习。 作为人类，我们拥有良好的适应能力。只要你把一件事情重复足够多次，你自然就会接纳它。如果你一直坚持在公共场合发表演说，你一定会应对自如，恐惧感终将消散。 著书立说，吸引追随者 要想让自己有机会出书，最好的办法就是明确一个有市场需求的主题，同时也能够充分展示你作为该领域专家的学识。 最后，你应当准备一份翔实的写作提纲（文章摘要），清晰地概括自己的写作目的，明确本书的目标读者，以及你为何认为这本书会成功，为何你是写作这本书的最佳人选。你的提纲写得越好，它被出版商接受的可能性就越大。 百折不挠，越挫越勇 如果你想成功，你必须要学会收起自己脆弱的自尊心，勇敢走出去，别害怕让自己出丑。 学习 教育就是当一个人把在学校所学全部忘光之后剩下的东西。 学习怎样学习：如何自我教育 如果我告诉你该怎么做，你可能会忘掉，但如果你自己动手做一次，你可能就记住了。如果你能将自己所学的东西教给别人，你不仅能记住，还能理解得更深刻。 我的“十步学习法” 要对自己要学的内容有个基本的了解——了解自己不知道什么就足矣。然后，利用这些信息勾勒出学习的范围，即需要学哪些内容，以及学成之后又会获得什么。 第 1 步到第 6 步：这些步骤只做一次 在这一步，你要做的就是了解自己将要学习的主题的全局。这个主题宏观上什么样？你能从中学到足够丰富的知识以了解自己所不知道的吗？以及自己所不知道的有多少？ 研究。通常你可以使用网络搜索来完成大部分研究。如果你碰巧有一本关于该主题的书，那么你就可以只读一下其中的介绍性章节，粗略浏览一下内容，但是不要在这一步上花费太多时间。 了解如何设置和安装 Ubuntu Linux，以及如何使用它的基本特性 为了学习该主题下的不同子主题，你可能会扩张你的学习范围而不够聚焦，但是请务必抵制住这个诱惑，尽可能地保持专注。 最后，在这一步中一定要注意：明确学习范围的时候要考虑时间因素。如果你只有一周时间，你需要本着实事求是的态度确定自己能在这段时间内学到什么。如果你有几个月的时间，你也许能攻克一个更大的主题。你的学习范围务必大小适当，既能符合你的学习理由，又能符合你的时间限制。 在全力以赴启动之前，明确“成功”的含义极为重要。如果不知道成功是什么样子，很难找准目标，也很难知道自己什么时候已经真正达到目标。 在尝试学习任何东西之前，你都应该在自己脑海中清晰地描绘出成功的样子。当你知道自己的目标是什么的时候，你就可以更轻松地使用倒推的方式，明确实现目标所需的步骤。 好的成功标准应该是具体的、无二义性的。不要对自己想要完成的任务进行含糊不清的描述。相反，要列出某一特定的结果，或者一旦实现自己所能达到的目标你应该能够做到的事情。 要尝试收集到多种多样的资源以帮助你学习，而不是只读一本关于这一主题的书。 在这一步中，你会想找到尽可能多的与自己所选主题相关的资源。此时你无需考虑这些资源的质量。这一步与头脑风暴类似。稍后你会对你找到的这些资源进行过滤，去伪存真，但是目前还是想先获得尽可能多的不同类型的资源。 图书博客文章在线视频专家，或者对你所想要学习的内容已经熟知的人播客源代码示例项目在线文档 对于大多数学科而言，学习是一个自然的过程。从 A 开始，前进到 B，最后到达 Z。这个顺序对你掌握随机的碎片化知识价值不大。你需要找出在最短的时间内从 A 到 Z 的正确路径，并且到达沿途的重要地标。 打造自己的学习计划，一个好方法就是观察别人是如何教你感兴趣的主题的。就我自己而言，在这一步我通常会翻看自己在第 4 步中找来的图书的目录。如果五位不同的作者都把内容都分解为相同的模块和顺序，那我就会遵循这样的方法制订自己的学习计划。 把你在第 4 步中收集的全部资源浏览一遍，找出哪些内容能够覆盖你的学习计划。 挑选你想要了解的一项课题，实际经演练一下上述这六个步骤。你可以从一些规模较小的课题开始，以便让自己习惯于这一过程。但是注意，一定要实际运用。如果你只是把这些步骤当作是阅读内容，那么它们对你不会有太大用处。 第 7 步到第 10 步：循环往复 现在开始最有趣的部分。接下来的四个步骤会在你的学习计划所定义的各个模块中循环往复。步骤 7 到步骤 10 的目标是通过“学习—实践—掌握—教授”（LDLT）的方式真正领会知识。 你从掌握恰到好处可以开始的基础知识开始，然后通过操作来学习，同时也通过自我探索收集问题。之后，你掌握了足够多的有用的知识。最后，你能将自己学到的教给他人，以此来弥补自己在学习过程中的不足，同时通过深入思考巩固知识。 在学习过程中通常会犯两类错误：第一类错误是在知之不多的情况下就盲目开始，即行动太快；第二类错误是在行动之前准备过多，即行动太晚。要想在这二者之间取得平衡，你掌握的知识要恰到好处，足以能让你开始学习，但又不会多到让你无力探索，这样你的学习效果最佳。 在第 8 步中，你通过动手操作发现了一些尚未找到答案的问题。现在，是时候来回答这些问题了。在这一步中，你要利用先前收集到的所有资料，进行深入学习。 不过请记住，你依然没有必要把收集到的所有资料全部仔细看一遍。你只需要阅读或观看与当前所学相关的部分。我们很少能有足够的时间把一本书从头读到尾。这些资料只是帮你自学，基本上你可以以解决在动手操作中发现的问题为主要目的。 你告诉我的，我都忘了。你教会我的，我都记得。让我乐在其中，我就一定能学会。 如果你想深入地掌握一门学问，想对这门学问做到融会贯通，那么你必须要做到“好为人师”。除此之外别无他法。 在现实中，你只需要超前别人一步，就可以成为他们的老师。 在这一步中，我会要求你走出自己的舒适区，将自己学到的知识教给别人。 要想确定你确实掌握了某些知识，这是唯一的办法；同时，在你将自己所学介绍给他人时，这也是查缺补漏的好办法。 寻找导师：找到你的尤达 在这一章中，我会教给你一些小窍门，包括寻找怎样的导师，如何找到导师，以及如何说服你的导师让他相信你值得他投入，从而真正实现双赢。 想想我们是怎样学习游泳的。当你第一次学游泳的时候，你的大脑里充斥着关于如何游泳和水很危险的虚假信息。你可能觉得自己不能漂起来，最后会被淹死。你必须要信赖你的游泳教练，对于游泳，他知道的比你多，而你对于游泳的认知都是错的。 学习方法，十步。先了解游戏开发，细化干什么，定目标，准备知识，学习，达成目标，帮助其他人。博客，github，都会觉得自己蠢，离开舒适区。高一点的人适合当老师。写简历，认识公司的人，找一个老师。 他们做到了我想要去做的？他们曾经帮助他人做到了我想做的？他们现在取得了什么可以展示的成就？你能和这个人和睦相处？他充满智慧吗？ 你最好的选择就是去自己认识的人中找，自己的朋友的朋友、家人的朋友等。如果你愿意做一点儿功课，再四处打听一下，无论你努力追求的目标是什么，你极有可能在由家人和朋友组成的关系网中找到适合做你导师的人。 如果你想在一家公司里获得晋升，那么在公司内部给自己寻找一位导师无疑是明智之举。你的老板或者你老板的老板这样的资深人士是导师的不二人选，你很可能会提前接受晋升所需要的各种教育。此外，与高管做朋友对你的职业生涯毫无害处。 我找来一些房地产投资方面最好的书，从这些“虚拟导师”身上我学会很多东西。除了阅读他们所写的内容，我还尝试去理解他们是如何决策的以及为什么做这样的决策的。 可以考虑请他吃午餐或者晚餐，在吃饭的时候让他给你一些建议。 一定要有耐心！大部分人在第一次听到“不”的时候就止步不前。别做这样的人。恰恰相反，要做一个别人用棍子赶才能赶走的人——即便如此，过一会儿也还要回来。你的顽强不会总有回报，但是你可能会惊讶地发现回报来得很频繁。 在寻找导师之前，你必须要明确，你需要导师帮你解决什么问题。坐下来，仔细想想你为什么需要一位导师，你希望从这段师徒经历中获得什么。 列出所有你认识的人中可以做自己的导师的人。请其他人在你的列表上再列出他们认识的人，用好你的人际网络。想一想，为了能够换取导师的帮助，你能给他提供什么？ 开山收徒：成为尤达一样的大师 教授是学习的最佳途径之一。 做导师还会让你感觉良好。这件事情还是值得去了解的——你所做的能够对其他人的生活产生积极的影响，这本身就是一种报偿，特别是当此人无法报答你的时候。指导别人能让你发现人生的新目标和新意义，帮助别人可以给自己带来真正的幸福。 做导师的好处帮助他人时的成就感。深入学习和领悟知识的途径。你的徒弟有朝一日会帮到你。自身的成长。帮助别人成长的过程也就是自己成长的过程。 传道授业：若要学知识，必得为人师 我发现最好的教学方式就是以谦虚的视角来观察问题，以权威的口吻去诠释问题。 你需要一个学位吗，还是可以对此忽略不计 许多计算机科学课程中包含的算法、操作系统、关系型数据库理论和其他主题都是永恒的。 身为软件开发人员，我们所做的大部分工作，都是如何使用新技术，学会如何用它们完成工作。我们很少需要回溯到计算机科学的本源。 学历有用，但是主要还是工作经验。学的过程中的东西很少用 学历教育可以确保你在软件开发方面获得全面的教育。 拥有一个学位也可以帮你即使毫无经验也能踏入职场。 学位还可以给你更多的选择。如果你没有获得过相关学位，有一些职位你是永远不会得到的，尤其是在大公司中。没有学位，做到一定的行政岗位之后就会有一个困难期。 如果没有学历，你就不得不更多地依靠经验来证明自己的能力。学位至少可以让雇主相信你具了解某些软件开发的知识，那么如果你没有学位的话，你就要能够证明自己有这些能力。 证明自己的能力的最好的办法就是以往的工作经验。如果在过去五年中你一直从事软件开发的工作，那么即使没有学位也能说明你会写代码。但是，如果你刚刚踏入职场，那你的求职之路会很艰难，你不得不去证明自己确实能够做到你自己所说的那些。因此准备一份作品集是最好的方法。 不管你是拥有学位还是拥有经验，我都建议你将自己的工作成果总结为作品集。 发现自己的知识短板 我们总是倾向于掩饰自己的短板，而且我们也总是太忙，忙到无暇去填补它们。结果，我们要么不能真正明白自己在做什么，要么为了避开自己的短板而采取低效的方法。 知识短板会阻碍你进步。准确识别它们的最佳方式之一就是看看自己在哪些工作上花费了大量的时间，或者一直进行重复性劳动。 重复性工作也是如此。任何你所做的重复性工作都值得彻查一番，看看是否有自己不理解的地方，如果你这样做了，可能会提高你的工作效率。 另一种识别知识短板的方法就是，时刻都要试图了解自己不理解或不清楚的事物。你可以维护一份清单，列出自己需要去研究或者自己不清楚的所有事物，追踪有哪些主题总是不断出现在这个清单上。你会惊讶地发现这份清单的增长速度有多快。 假如你在准备面试，需要明确自己要学什么，这一方法最管用。尽量找出尽可能多的你在面试中可能会被问到的问题。 知识短板高发区，你的短板在哪些，工作上花费时间最多？可以改进的重复性劳动，自己没有完全理解的东西，你回答不出来的面试题 一切始于专注 生产效率高并不能保证你是高效的。产量多只表明生产效率高，只有完成正确的工作才会成为高效的人。 这一切都源于专注。 但我们所承担的很多任务都有“环境切换”的成本。当我们从一个任务切换到另一个任务时，我们必须要唤醒某些记忆之后才可以重新开始工作。 时不时实践一下专注。选一项大概需要占用你半小时或者更长时间的任务，给完成这项任务分配一个完整的时间段，完全专注于这项任务。迫使自己只集中精力在这一项任务上。当你进入专注状态时，在心里记住是什么感觉。 我的私房“生产力提升计划” 我试过 GTD（GettingThingsDone），也花时间用过“番茄工作法”。我还用过 Seinfeld 的“不要打破链条”（Don’t break the chain）方法的各种版本。（在“不要打破链条”方法中，每天成功完成某项任务，你就在日历上做个标记。这种方法的基本思想就是，让连续工作的势头保持的时间尽可能长。） 我的生产力提升计划的基本思路就是，我把一周的时间分配给一个一个用时不超过两小时的小任务。我使用看板来安排自己的一周活动。看板是一个简单的白板，它有几个列，你可以轻松地在各列之间移动任务项。在敏捷方法的世界里，看板通常还包含展示这些任务项所处的不同状态，典型的状态有“未启动”“进行中”和“已完成”。但是在我的看板中，每一列就是一周中的每一天。 在工作时我会使用番茄工作法来保持专注，并且用番茄工作法估算和衡量每一项任务要花多长时间。 我的计划都是从“季度”开始的。我把我的一年分成 4 个季度，每个季度 3 个月。在做季度计划时，我会尽力列出我想在本季度完成的每一个大项目，我还会制订一些较小的目标。 我也会创建一个宏观计划，将本季度我想要完成的工作列入其中。这让我清楚地了解自己的主要目标是什么，也知道该如何实现它。同时，它还会让我保持专注。 每个月的第一天我会打印出当月的月历，并且规划出每天要完成的工作。 每周一的早晨，我会做我的周计划。我原来使用名为 Trello 的工具作为看板来组织我一周的工作，但最近我一直在用 Kanbanflow 创建自己的看板，因为 Kanban flow 有一个内置的番茄钟定时器。 每天，在坐下来工作之前，我都会做一些健身活动。之所以这样做，是因为我不希望中途有事情打断我专注的状态。一旦我做好准备坐下来工作，我做的第一件事就是计划我的这一天。 要计划好这一天，我首先要把对应日期里的卡片移到“今天”这一栏，并把它们按照重要性排序。我要保证自己优先完成最重要的事情。我也会对当天的任务进行调整，如果卡片上对该项任务的描述不够细致，我还会添加细节。我要确保自己在开始工作之前就确切地知道 知道自己在做什么，这项任务完成的标准又是什么。 为了免受干扰，另一件大事就是，在白天我基本上会忽略电子邮件。我只在休息的时候检查电子邮件，这也只是为了确保不会耽搁必须要马上处理的紧急邮件。但是，除非一些事情确实紧急，否则我一般只在晚上统一回复电子邮件。通过在集中的时间段内统一回复邮件，我可以大幅提升邮件回复效率。（如果能彻底摆脱检查电子邮件的习惯，我可能会生产效率更高。但可惜，我只是个普通人。） 要确保自己有一些休息时间，或者有那么几周我会称之为“无工作周”，基本上在这几周里，我不会使用番茄钟，也不会把整周都排满。在无工作周里，我只做一些我喜欢的工作。 番茄工作法 它的基本思路是：你规划出打算一天之内完成的工作，然后设置一个时长 25 分钟的定时器，去完成计划中的第一项任务；在这 25 分钟之内，你只专注于这一项任务，心无旁骛。一旦有干扰，可以用各种方法屏蔽掉干扰，但是通常你要努力保证自己完全不被打扰。总之，你不希望自己的专注的工作状态被打断。 在 25 分钟结束的时候，设置一个 5 分钟的定时器，休息一下。这就是所谓的一个“番茄钟”。每 4 个番茄钟后，你都需要休息一会儿，通常为 15 分钟。 番茄工作法只有被当作估算和评估工作的工具使用时，才能发挥它的真正威力。 通过计算自己完成的番茄钟的数量，可以确切知道自己一周完成了多少任务，也就不会觉得自己没完成足够量的任务。如果你没能完成自己设定的任务，但是却用完了足够数量的番茄钟，那么问题就不是工作量是否饱满，而是给某个任务项设置的优先级是否正确。 正确使用番茄工作法教会我“设置优先级”的真正价值。当每周我只有这么多番茄钟可分配的时候，我必须小心翼翼地使用这些宝贵的番茄钟。 我的“定额工作法”：我是如何做到超额完成工作的 确立一个明确的目标，规定自己要在预先确定的时间段内需要取得多大的进展。 完成自己承诺的定额。我非常严肃地对待这些定额。 挑选一些需要重复去做的任务，设定的一个定额，即明确自己在一个给定的时间段内完成该项任务的频率。 承诺是“定额工作法”的核心。除了想方设法完成自己的工作，不给自己留下任何其他的选择。 选择可实现、可持续的定额。 挑选一项重复性任务。明确有效时限，在此期间该任务被重复执行。明确在给定的有效时限内该任务应该完成的次数的定额。给自己承诺：一定要达成定额。调整。调高或者调低定额，但是不能在有效时间段之内调整。 以缓慢但稳定的节奏工作，要优于快速但缺乏持久和坚持的工作方式。 我们中的大多数人在长期高生产效率地工作中时都会面临如何保持始终如一的节奏的问题。随着时间的推移，只要每天都能保证完全落实到位，小砖头终会筑成高墙。只关注高墙（手边的大任务）很容易让人泄气，如果每天只是砌砖（小任务）就会容易很多。关键是要保证将方法落实到位，保证自己每天、每周、每月都在“砌砖”。 定额工作法还可以帮你克服意志力薄弱的问题，通过预先设定好的必须要遵循的过程，消除需要做出决策的部分。因为已经预先承诺在规定时间段内完成同一任务很多次，所以就不需要再判断要不要做某事——你知道必须要做。 对自己负责 让人们完成工作主要有两大动机——内部动机（来自内心的动机）和外部动机（来自外部奖励或惩罚的动机）。 内部动机要比外部动机有效得多。在内部动机的激励下工作时，我们能完成更多的工作，也更倾向于把工作做得更好。所以，秘诀是让你的主要动机来自内心而非外部。 我们中大多数人之所以会每天按时上下班，至少在某种程度上是因为我们要对自己的雇主负责。拥有一份工作的责任感会促使我们去做一些如果我们可以自主决定是绝对不会做的事情。 培养出在没有人监督自己的时候也能高效工作的自我责任感非常重要。你也可以把这称为是具有一种性格或者具有一种素质， 要培养“对自己负责”的精神，首先要让自己的生活井然有序。如果不知道应该做的事情是什么，就不能真正为自己所做的任何事情承担责任。 你必须通过为自己设定规则，将这种条理性自愿地应用于自己的生活中。你需要创建自己的规则来管理自己的生活，并且要在自己思维清晰、大脑尚未被错误的判断蒙蔽的时候，提前制订好这些规则。 你可以告诉他你给自己制订的规则，或者你想达成的目标，通过定期互相汇报进度（不论成败），可以互相帮助对方强化责任感。 通常，想到要告诉自己的责任监督伙伴自己没能完成设定的目标，就足以阻止自己不够自律的行为。在关键点作出正确的选择还是错误的选择会有极大的区别。 我自己就加入了一个智囊团，它的功能就像一个责任监督小组。我们小组每周都会开例会，每个人都要讲讲自己在这周做了什么和计划做什么。通过在小组内部讨论每个人各自的计划，我们互相监督计划的落实情况。没人希望因为自己不遵守计划而令组员失望。自从我加入了这个小组，工作效率大幅提升。 公开自己的日常活动也是一个好主意。 最重要的是要确保自己对自己的行为带有某种责任感。坚守自己设定的标准时，生产效率会高很多。 抉择一下：你想如何度过自己的一生。花点儿时间创建一些自己的规则，确保自己朝着正确的方向前进。创建自己的责任制度，帮助自己严格执行规则。 要不要多任务并行 多任务导致效率低下的根本原因似乎在于，我们根本没有能力真正去践行多任务并行。 是的，如果你每天都因为有多个任务要完成就深陷多任务并行的泥潭，最好学会如何批量处理这些任务，一次性完成一系列互相关联的任务，而不是将它们拆分完成。批量处理电子邮件就是非常好的起点，任何在短时间可以完成的任务也都适合批量处理。 潜在的适合批量处理的领域处理电子邮件。打电话。修复 bug。开短会。 比起在不同时间段分别处理相关任务，批量处理相关任务拥有两大优点。第一，你不会打破自己对正在处理的大任务的专注。第二，你会更专注于自己平常没有足够的时间进入专注状态去处理的任务。 最有可能的就是，将一项不费脑筋的任务和一项一定程度上需要精神专注才能完成的任务组合起来。 停止任何并非真正的多任务并行的多任务并行。每天力争在一个时间段内只做一件事。番茄工作法对此有很大帮助。一次性批量处理小任务，而不是每天或每周里做许多次。找出能够真正实现多任务并行的领域。任何不需要耗费脑力的活动都可以跟其他活动结合起来。只要进行任何需要耗费脑力的活动，就将其与体育运动结合起来。 职业倦怠：我已找到解药 提高生产力的最大障碍之一就是身体和心理上的倦怠。 你越是努力工作，完成的工作就越多，这种倦怠感来得就会越快。这就是难以取得工作成效的原因。工作效率越高，你从中体会到的愉悦感就越少。 为自己设定了一个时间表，并且坚决执行。 你可以采用类似的方法来帮自己突破阻挡了你的那堵围墙。想学会弹夏威夷四弦琴？每天留出一定的时间练习。在上第一堂课之前就制订好这样的计划——那时你的兴趣和动机都处于最高点。当你不可避免地撞到这样一堵墙的时候，这个计划能帮助你穿过它。 时间是怎样被浪费掉的 看电视 召开会议 一些常见的时间杀手看电视。社交媒体。新闻网站。不必要的会议。烹饪。玩电子游戏（尤其是网络游戏）。工间喝咖啡休息。 要想消灭时间杀手，最好的方法就是先找出它们。在找回被浪费的时间之前，你需要了解自己的时间都浪费在哪儿了。 下一周，精心地跟踪一下自己的时间花费情况。获取精确的数字，了解每天的每小时你都是怎样花掉的。 形成惯例的重要性 生产力的真正秘诀在于：长期坚持做一些小事。 一个好的惯例始于一个大的目标。你想要达成的目标是什么？通常你一次只能专注于实现一个大目标，因此选择当下对你最重要的目标。你知道，为了这个目标你已经准备了好久，但你从来没有时间着手去实现它。 一旦挑选好了大目标，接下来就要弄清楚怎样才能每天或每周前进，最终实现目标。如果你想写一本书，每天要写多少字才能在一年内完成？如果你想减肥，每周要减掉几斤才能达到目标？ 我建议你把每天最开始的一两个小时投入到最重要的目标上。你可能需要早起一两个小时，但是通过有效利用每天最开始的一两个小时，你不仅更容易坚持想要做的事情，还会精力更充沛。 强烈建议你安排好每个工作日的时间，以便自己知道每天、每周要做什么。 刚开始工作的时候你就要决定好自己打算做什么。它可能会是查看和回复电子邮件，但也许更好的选择是从每天必须要做的最重要的事情开始。（电子邮件可以晚点儿处理。）选出每天或每周都要重复的几个任务（ 当我在办公室工作的时候，每天我会抽出 30 分钟时间学习自己工作中会用到的技术，我习惯将其称为“研究时间”。 你还应该安排自己的食谱，甚至围绕着每天吃什么来形成惯例。我知道这听起来有点儿不可思议，但我们的确为了决定吃什么和做什么饭浪费了大量的时间，如果这些事情不能提前计划，最终我们就会吃得很差。 培养习惯：刷新你的代码 成就我们的恰恰就是那些不断重复做的事情。因此，优秀不是一种行为，而是一种习惯。 习惯主要由三个要素构成：暗示，惯例和奖励。 暗示是导致习惯被触发的某样东西。它可能是某一天的某个特定时刻、某种形式的社交场合、某个特定的环境或者其他任何东西。例如，只要我们进入电影院，我们就获得了买爆米花的暗示。 接下来是惯例。惯例就是你做的事情，也就是习惯的本质。惯例可能是抽烟、跑步，也可能是在检查代码之前运行所有的单元测试。 最后，还有奖励。奖励就是让习惯真正保持下去的“锚”。这是一种你从执行习惯中获得的良好感觉。 我们会根据周围的事物自发地养成习惯。一件事情做的越多，越可能形成习惯。习惯的力量往往基于奖励的价值。 如果我早起之后的第一件事情不再是浏览网站，我会制订当日计划，并挑出当天自己最喜欢的事情。这样我就可以完成更多的工作，我也可以从自己最喜欢的工作开始，而不是从最不喜欢的工作开始。 习惯。要找出坏习惯，最好的办法就是设法找到日常生活中令你感到内疚的事情或惯例。 选一个你找出来的坏习惯，不要试图马上就改变它。相反，尽量找出这个习惯被什么触发，你这么做有什么表现，以及是什么奖励激励你产生冲动要这样做。 最后也是最困难的部分是，强迫自己坚持足够长的时间，以使新习惯取代旧习惯。只要你能在新的习惯上坚持足够长的时间，新习惯最终一定会变得很轻松且是自发的。 养成习惯的方法与形成惯例的过程很相似。试想，你要完成的大目标是什么，看看你是否能养成某种习惯，推动你在奔向大目标的方向上前进。你的习惯越积极，你向着自己的目标前进的过程就越轻松。 接下来，为你的新习惯找出暗示。是什么触发了你的这个习惯？让暗示固定不变，让你可以依赖。一天中某一个特定时间，或者一周中特定的某一天，都是很好的暗示， 它将确保你不会把行动推迟到另一个时间。 跟踪你的习惯。哪些习惯对你目前的生活影响最大？你认为其中有多少是好习惯，又有多少是坏习惯？挑选一项你的坏习惯，试着把它转变为好习惯。在开始做之前，先在自己脑海中设想一下从现在起一周之后、一个月之后、乃至于一年之后你会有什么成果。 分解任务：如何吃掉一头大象 分解任务。通过将大任务分解为小任务，你会发现自己更有动力去完成它们，也更加稳妥地向着目标前进。 任务越大，越难明确定义。任务容易，你正确完成任务的概率也很高。 大型任务是一种智力挑战，与小任务相比，大任务更可能导致拖延，通常描述也更少，更容易出错，也更难估算完成时间。 你首先需要明确完成这项任务需要哪些步骤。 把大任务分解为小任务的关键步骤就是确定出因为缺失了哪些信息而导致你无法创建更小、更明确的任务。如果你在把大任务拆分成小任务的时候遇到问题，很可能是由于缺少信息。 单独一行代码的复杂度绝对不会超过任何一位程序员的理解能力和编码水平，所以，如果你愿意将问题分解得足够小，只凭借写出单行代码的能力你就能写好任何应用程序。 努力工作的价值，以及为什么你总是逃避努力工作 被我们认为困难的事情，实际上都是我们不想做的事情，因为它们不那么激动人心，也不那么光彩照人。 成功会带来更多的成功。越成功就越容易获得成功。 养成雷厉风行的习惯，并且立即在需要做的工作中付诸行动。 任何行动都比不采取行动好 任何行动往往都比没有行动好，特别是当你一直停滞在不愉快的情势下很长时间的时候。如果这是一个错误，至少你学到了一些东西。这样一来，它就不再是一个错误。如果你仍然选择停滞不前，那么你就学不到任何东西。</description></item><item><title>经济::经济机器是怎样运行的</title><link>/misc/how_the_economic_machine_works/</link><pubDate>Thu, 23 Sep 2021 07:17:30 +0800</pubDate><guid>/misc/how_the_economic_machine_works/</guid><description>经济机器是怎样运行的 经济就像一部简单的机器那样运行，但很多人不懂得这一点，或是对经济的运行方式持有不同观点，于是导致很多不必要的经济损失，我深感有责任与大家分享，我的简单但是实用的经济分析模式。这个模式虽然不符合常规传统经济学，但是已经帮助我预测和躲避了全球金融危机，30 多年来对我一直很有用，我们开始吧！
经济虽然可能看起来复杂，但其实是以简单和机械的方式运行。经济由几个简单的零部件和无数次重复的简单交易组成，这些交易首先是由人的天性所驱动的，因而形成三股主要的经济动力。
1、生产率的提高
2、短期债务周期
3、长期债务周期
下面我们谈一下这三股动力，并介绍如何把他们组合在一起得出一个良好的模型，便于我们跟踪经济走势，并理解当前正在发生的事情。我们先来说一下经济中最简单的部分 — — 交易。
交易 经济不过是无数交易的总和，而交易是一件非常简单的事情，交易时刻都在发生，你每次买东西都是进行一笔交易。在每次交易中，买方使用货币或信用向卖方交换商品、服务或金融资产。信用在使用时和货币一样，因此把花费的货币和信用加在一起就可以得出支出总额。
支出总额是经济的驱动力，如果用支出金额除以销量就得出价格，就是这么简单，这就是交易。交易是经济机器的最基本零件，所有的经济周期和动力都是交易造成的，所以理解了交易就理解了整个经济。
一个市场由买卖同一种商品的所有买方和卖方组成，例如小麦市场、汽车市场、股票市场和千百万种其他市场，经济就是由所有市场内的全部交易构成。把全部市场的总支出和销量加在一起就得到了了解经济运行所需要的全部信息，就这么简单。
个人、企业、银行和政府都在以上述方式从事交易，用货币和信用交换商品、服务和金融资产。政府是最大的买方和卖方，而政府有两个组成部分，即收税和花钱的中央政府和中央银行。央行控制着经济中的货币和信贷数量，因此不同于其他买方和卖方，央行通过影响利率和发行更多货币来实行这种控制。我们在下面会看到，正因如此，央行在信贷流通当中发挥着重要作用。
信贷 请诸位注意信贷，信贷是经济中最重要的组成部分，但也许是人们最不了解的部分，它之所以最重要是因为它是经济中最大且最为变幻莫测的一部分，贷款人和借款人与在市场中进行交易的买方和卖方没有两样。通常贷款人希望自己的钱生出更多的钱，而借款人则想购买当前无法负担的某种东西，比如房子、汽车或是进行投资，比如开办企业，借贷可以同时满足贷款人和借款人的需要。
借款人保证偿还借款称为本金，并支付额外的款额称为利息。利率高时借贷就会减少，因为贷款变得昂贵，当利率低时借贷就会增加，因为贷款变得便宜。如果借款人保证偿还债务而且贷款人相信这一承诺，信贷就产生了。任何两个人都可以通过协定凭空创造出信贷，信贷看似简单实则复杂，因为信贷还有其它名称，信贷一旦产生，立即成为债务。债务是贷款人的资产，是借款人的负债，等到借款人今后偿还了贷款并支付了利息，这些资产和负债将消失，交易得以完成。
那么为什么信贷如此重要？这是因为，借款人一旦获得信贷，便可以增加自己的支出。不要忘记，支出是经济的驱动力，这是因为一个人的支出是另一个人的收入。想想看，你每花一块钱另一个人就挣了一块钱，而你每挣一块钱，必定有别人花了一块钱，所以你花的越多，别人挣的就越多。如果某人收入增加，其信用度就会提高，贷款人就更愿意把钱借给他。信用良好的借款人具备两个条件，偿还能力和抵押物。收入债务比率高，借款人就具备偿还能力，如果无法偿还，借款人还可以用有价值可以出售的资产作为抵押物，这样贷款人可以放心的把钱借给他们。所以收入增加使得借贷也增加，从而能够增加支出。由于一个人的支出是另一个人的收入，这将导致借贷进一步增加，并不断循环，这一自我驱动的模式导致经济增长，也正是因为如此才产生了经济周期。
经济周期 在一项交易中，为了获得某样东西，你必须付出另一样东西，长期来看你得到多少取决于你生产多少。我们的知识随时间而逐渐增多，知识的积累会提高我们的生活水平，我们将此称为生产率的提高。一个善于创新和勤奋的人，将比那些自满和懒惰的人，更快的提高生产率和生活水平，但在短期内不一定体现出来，生产率在长期内最关键，但信贷在短期内最重要。这是因为生产率的提高不会剧烈波动，因此不是经济起伏的一个重要动力，但是债务是这种动力。因为我们能够通过借贷让消费超过产出，但是在还贷时不得不让消费低于产出。
债务量的波动有两大周期，其中一个周期持续大约 5–8 年，另一个持续大约 75–100 年。大部分人虽然能够感受到波动，但由于离波动太近，每天每周都身临其境，通常比不认为这是周期，我们将在本章考察这三股主要动力，并观察它们如何相互作用，以及它们在日常经济中的表现。
如上所述，经济的上下起伏，不是取决于人们多么善于创新或是勤奋工作，而是主要看信贷的总量。
我们先想象一下一个没有信贷的经济运行。在这样的经济运行中，增加支出的唯一办法是增加收入。因此，需要提高生产率和工作量，提高生产率是经济增长的唯一途径，由于我的支出是另一个人的收入，当我或者另一个人提高生产率的时候，经济就会增长。我们如果观察各种交易加以总结，就会发现一条类似于生产率增长轨迹的渐进线，但是由于我们借贷于是产生了周期。原因并不是任何法规，而是人的天性和信贷的运作方式。
借债不过是提前消费，为了购买现在买不起的东西，你的支出必然超过收入，因此你需要借钱，实质上是向未来的自己借钱。你给自己设定了一个未来的时间，到那个时候你的支出必须少于收入，以便偿还债务，这样马上就形成了一个周期。通常一旦你借钱就制造了一个周期，对于个人是这样，对于整个经济运行也是这样。这就是为什么必须理解信贷，因为信贷触发了一系列机械和可以预料的将在未来发生的事件。这就是信贷不同于货币的地方。
完成交易需要使用货币，当在酒吧用货币买一瓶啤酒时，交易立即完成。但是如果你用信用来买一瓶啤酒，比如赊账，你相当于承诺今后为这瓶啤酒付钱，你和酒吧一起创造了一笔资产和一笔负债，你们凭空制造出了信贷。只有在你今后清偿了这笔赊账之后，上述资产和负债才会消失，债务才会还清，交易才会了结。
现实生活中大部分所谓钱实际上是信贷，美国国内的信贷总额大约 50 万亿美元，而货币总额只有大约 3 万亿美元。不要忘记，在没有信贷的经济运行中，增加支出的唯一办法是增加生产，但是在有信贷的经济运行中，还可以通过借债来增加支出。因此，有信贷的经济运行能增加支出，使得收入的增长速度在短期内超过生产率的增长，但在长期内并非如此。但是请不要误解我的意思，信贷不一定是坏事，只是会导致周期性变化。
信贷如果造成超过偿还能力的过度消费就是不良信贷，但是信贷如果高效率的分配资源和产生收入，让你能偿还债务就是良性信贷。
例如如果你借钱买一台大彩电，电视机不会带来任何收入让你偿还债务，但是你如果借钱买一台拖拉机，用它来收获更多的庄稼，赚更多的钱，你就能偿还债务，提高生活水平。
在有信贷的经济运行中，我们可以跟踪各种交易，观察信贷如何带来经济增长。
我举一个例子，假设你每年挣 10 万美元，没有任何债务，你有不错的信用可以借 1 万美元，比如用信用卡借。因此你每年可以花 11 万美元，即时你的收入只有 10 万美元。由于你的支出是别人的收入，另一个人因此挣了 11 万美元，这个挣了 11 万美元的人如果没有任何债务，可以借 1.1 万美元，他可以消费 12.1 万美元，即使他的年收入只有 11 万美元。由于他的支出是另一个人的收入，而我们通过跟踪个人的交易可以看到这个过程不断自我强化。但不要忘记借债形成，周期会上升最终也会下降。
短期债务周期 下面我们谈谈短期债务周期，随着经济活动的增加，出现了扩张，这是短期债务周期的第一阶段。支出继续增加，价格开始上涨，原因是导致支出增加的是信贷，而信贷可以即刻凭空产生。如果支出和收入的增长速度超过所出售商品的生产速度，价格就会上涨，我们把价格的上涨称为通货膨胀。
央行不希望通货膨胀过高，因为这会导致许多问题。央行在看到价格上涨时就会提高利率，随着利率上升，有能力借钱的人就会减少，同时现有的债务成本也会上升，就等于你每个月的信用卡还款额会增加。由于人们减少借债，还款额度增长，剩下来用于支出的资金就减少，因此支出速度放慢，而由于一个人的支出是另一个人的收入，环环相扣，人们的收入将下降。由于支出减少价格将下跌，我们称之为通货紧缩，经济活动减少，经济便进入衰退。
如果衰退过于严重，而且通货膨胀不再成为问题，央行将降低利率，使经济活动重新加速。随着利率降低，偿债成本下降，借债和支出增加，出现另一次经济扩张。可见经济像一部机器一样运行，在短期债务周期中，限制支出的唯一因素是贷款人和借款人的贷款和借款意愿。如果信贷易于获得，经济就会扩张，如果信贷不易获得，经济就会衰退。请注意这个周期主要由央行控制，短期债务周期通常持续 5–8 年，在几十年里不断重复。
但是请注意在每个周期的低谷和高峰后，经济增长和债务都超过前一个周期。为什么会这样，这是人促成的，人具有借更多钱和花更多钱的倾向，而不喜欢偿还债务。这是人的天性，因此在长期内债务增加的速度超过收入，从而形成长期债务周期。
长期债务周期 尽管人们的债务增加，但贷款人会提供更宽松的信贷条件，这是为什么？这是因为，大家都以为形式一片大好，人们仅注意最近出现的情况，最近的情况是什么呢？收入一直在增加，资产价值不断上升，股票市场欣欣向荣，现在是繁荣时期，用借来的钱购买商品、服务和金融资产很划算，当人们过度借贷消费时，泡沫便产生了。因此尽管债务一直增加，但收入也以相近的速度增加，从而抵消了债务。我们把债务与收入比例称为债务负担，只要收入继续上升，债务负担就可以承受。
与此同时，资产价值迅猛上升，人们大量借钱来购买资产，因为投资促使资产价格日益升高。人们感觉自己很富有，因此尽管积累了大量债务，收入和资产价值的上升帮助借贷人在长期内保持良好的信用度。
但是这种情况显然无法永久持续下去，也确实没有持续下去，几十年来债务负担缓慢增加使偿债成本越来越高，到了一定的时候，偿债成本的增加速度超过收入，迫使人们削减支出。由于一个人的支出是另一个人的收入，收入开始下降。人们的信用因此降低，致使借贷减少，偿债成本继续增加，使得支出进一步减少。周期开始逆转，这时到达长期债务的顶峰，债务负担变得过重。
美国、欧洲和世界上很多其他地区在 2008 年发生了这一情况，日本在 1989 年和美国在 1929 年因同样原因发生这一情况，现在经济进入去杠杆化时期。</description></item><item><title>CMU::15-445/645::Tree Indexes 笔记</title><link>/notes/cmu_15_445_06_note/</link><pubDate>Wed, 22 Sep 2021 08:41:54 +0800</pubDate><guid>/notes/cmu_15_445_06_note/</guid><description>树形索引第一部分 表索引 在数据库系统中，有许多不同的数据结构，可以用于内部元数据、核心数据存储、临时数据结构或表索引等目的。对于表索引，可能涉及到带有范围扫描的查询。
表索引是一个表的列的子集的副本，它被组织和(或)排序，以使用这些属性的子集进行有效的访问。因此，DBMS 可以查询表索引的辅助数据结构，而不是进行顺序扫描，以更快地找到 Tuple 。DBMS 确保表和索引的内容在逻辑上总是同步的。
在每个数据库要创建的索引数量之间存在着一个权衡。尽管更多的索引使得查询速度更快，但索引也会使用存储空间并需要维护。DBMS 的工作是找出用于执行查询的最佳索引。
B+树 B+Tree 是一种自平衡的树形数据结构，它可以保持数据的分类，并允许在 O(log(n))中进行搜索、顺序访问、插入和删除。它为面向磁盘的 DBMS 的读/写大型数据块而优化。
几乎所有支持保序索引的现代 DBMS 都使用 B+Tree。有一种特定的数据结构叫做 B-Tree，但是人们也用这个词来泛指一类数据结构。原始的 B-Tree 和 B+Tree 之间的主要区别是，B-Tree 在所有节点中存储键和值，而 B+Tree 只在叶节点中存储值。现代 B+Tree 的实现结合了其他 B-Tree 变体的特征，例如 B\(^{link}\)-Tree 中使用的兄弟姐妹指针。
从形式上看，B+树是一棵具有以下特性的 M-way 搜索树。
它是完全平衡的（即，每个叶子节点都在相同的深度）。 除根以外的每个内部节点至少有一半是满的（M/2 - 1 &amp;lt;= 键的数量 &amp;lt;= M - 1）。 每个有 k 个键的内部节点都有 k+1 个非空子节点。 B+Tree 中的每个节点都包含一个键/值对数组。这些对中的键是由索引所基于的属性派生的。这些值将根据一个节点是内部节点还是叶子节点而有所不同。对于内部节点，值数组将包含指向其他节点的指针。叶子节点值的两种方法是记录 ID 和 Tuple 数据。记录 ID 指的是一个指向 Tuple 位置的指针。有 Tuple 数据的叶子节点在每个节点中存储 Tuple 的实际内容。
每个节点的数组都（几乎）是按键排序的。
实践中节点中键和值是分开存储的
插入 要在 B+树中插入一个新的条目，必须沿着树向下遍历，并使用内部节点来确定将值插入哪个叶子节点。</description></item><item><title>Linux/UNIX系统编程手册::基础</title><link>/misc/tlpi_basic/</link><pubDate>Tue, 21 Sep 2021 18:04:51 +0800</pubDate><guid>/misc/tlpi_basic/</guid><description>第 1 章：历史与标准 UNIX 和 C 语言简史 1969 年，在 AT&amp;amp;T 电话公司下辖的 bell 实验室中， Ken Thompson 开发出了首个 UNIX 实现。 1970 年， AT&amp;amp;T 的工程师们又在刚购进的 Digital PDP-11 小型机上，以汇编语言重写了 UNIX。 1972 年，Dennis Ritchie（Thompson 在 bell 实验室的同事， UNIX 开发的早期合作者） 设计并实现出了 C 编程语言。 1973 年， C 语言步入了成熟期，人们能够使用这一新语言重写几乎整个 UNIX 内核。 1974 年的 UNIX 第五版开始， AT&amp;amp;T 准许高校在支付象征性的发布费用后使用 UNIX 系统，UNIX 开始在高校流行。 1979 年 1 月的 UNIX 第七版改善了系统的可靠性，配备了增强型的文件系统。从该版本起， UNIX 分裂为了两 大分支：BSD 和 System V。 1979 年 12 月，诞生了首个完整的 UNIX 发布版 3BSD。 1983 年，加州大学伯克利分校的计算机系统研究组（Computer Systems Research Group）发布 了 4.</description></item><item><title>CMU::15-445/645::Hash Tables 笔记</title><link>/notes/cmu_15_445_05_note/</link><pubDate>Mon, 20 Sep 2021 16:20:16 +0800</pubDate><guid>/notes/cmu_15_445_05_note/</guid><description>散列表 数据结构 DBMS 为系统内部的许多不同部分使用各种数据结构。一些例子包括。
内部元数据。这是对数据库和系统状态信息进行跟踪的数据。 核心数据存储。数据结构被用来作为数据库中 Tuple 的基础存储。 临时数据结构。DBMS 可以在处理查询的过程中即时建立数据结构，以加快执行速度（例如，用于连接的哈希表）。 表索引。可以使用辅助数据结构来使其更容易找到特定的 Tuple 。 在实现 DBMS 的数据结构时，有两个主要的设计决定需要考虑。
数据组织。我们需要弄清楚如何布局内存，以及在数据结构内存储哪些信息以支持有效的访问。 并发。我们还需要考虑如何使多个线程访问数据结构而不造成问题。 散列表 Hash Tables 哈希表实现了一个关联数组的抽象数据类型，它将键映射到值。它提供了平均 O(1) 的操作复杂度（最坏情况下为 O(n)）和 O(n)的存储复杂度。请注意，即使平均操作复杂度为 O(1)，也有一些常数系数的优化这在现实实践中需要考虑，这些很重要的。
哈希函数 这告诉我们如何将一个大的键空间映射到一个较小的领域。它被用来计算进入一个桶或槽阵列的索引。我们需要考虑快速执行和碰撞率之间的权衡。在一个极端，我们有一个总是返回一个常数的哈希函数（非常快，但一切都会发生碰撞）。在另一个极端，我们有一个&amp;quot;完美&amp;quot;的散列函数，其中没有碰撞，但需要极长的时间来计算。理想的设计是介于两者之间。
散列方案 这告诉我们如何处理散列后的键值冲突。在这里，我们需要考虑分配一个大的哈希表以减少碰撞和在发生碰撞时必须执行额外的指令之间的权衡。
散列函数 散列函数接受任何键作为其输入。然后它返回该键的整数表示（即&amp;quot;哈希&amp;quot;）。该函数的输出是确定的（即，相同的键值应该总是产生相同的哈希输出）。
DBMS 不需要使用加密安全的哈希函数（例如 SHA-256），因为我们不需要担心保护键值的内容。这些哈希函数主要由 DBMS 内部使用，因此信息不会被泄露。
一般来说，我们只关心哈希函数的速度和碰撞率。 目前最先进的哈希函数是 Facebook XXHash3。
静态散列方案 静态散列方案是指散列表的大小是固定的。这意味着如果 DBMS 在哈希表中的存储空间用完了，那么它就必须从头开始重建一个更大的哈希表，这非常昂贵。通常，新的哈希表是原始哈希表的两倍。
为了减少浪费的比较次数，避免哈希键的碰撞很重要。通常情况下，我们使用两倍于预期元素数量的槽位。
以下假设在现实中通常是不成立的。
元素的数量是提前知道的。 键值是唯一的。 存在一个完美的哈希函数。 因此，我们需要适当地选择散列函数和散列模式。
线性探测散列 这是最基本的散列方案。它通常也是最快的。它使用一个数组槽的循环缓冲区。 散列函数将键映射到槽。当发生碰撞时，我们线性地搜索相邻的槽，直到找到一个开放的槽。对于查找，我们可以检查键的哈希值，然后线性搜索，直到找到所需的条目（或一个空槽，在这种情况下，键不在表中）。请注意，这意味着我们必须在槽中存储密钥，以便我们能够检查一个条目是否是所需的。删除是比较棘手的。我们必须小心翼翼地从槽中删除条目，因为这可能会阻止未来的查询找到被放在现在空槽下面的条目。这个问题有两个解决方案。
最常见的方法是使用 &amp;ldquo;墓碑&amp;rdquo;。我们不删除这个条目，而是用一个 &amp;ldquo;墓碑 &amp;ldquo;条目取代它，告诉未来的查找要继续扫描。 另一种方法是在删除一个条目后移动相邻的数据以填补现在的空槽。然而，我们必须注意只移动最初被移位的条目。 非唯一键。在同一个键可能与多个不同的值或 Tuple 相关的情况下，有两种方法。
单独的链表。我们不将数值与键一起存储，而是将一个指针指向一个单独的存储区域，该区域包含所有数值的链接列表。 冗余的键。更常见的方法是简单地在表中多次存储相同的键。即使我们这样做，所有具有线性探测功能的东西仍然可以工作。 插入 有 A B C D E F 六个值和一个缓冲区</description></item><item><title>CMU::15-445/645::Buffer Pools 笔记</title><link>/notes/cmu_15_445_04_note/</link><pubDate>Mon, 13 Sep 2021 23:17:58 +0800</pubDate><guid>/notes/cmu_15_445_04_note/</guid><description>缓冲池和内存管理 介绍 DBMS 负责管理其内存并从磁盘上来回移动数据。由于在大多数情况下，数据不能直接在磁盘上操作，任何数据库都必须能够有效地将其磁盘上以文件形式表示的数据移动到内存中，以便能够使用。DBMS 面临的一个障碍是尽量减少移动数据的速度问题。理想情况下，数据应该&amp;quot;看起来&amp;quot;是已经在内存中了。
从空间控制和时间控制的角度来思考这个问题。
空间控制是指页面在磁盘上的物理写入位置，目标是使经常一起使用的页面在磁盘上尽可能地保持物理上的接近。
时间控制是指何时将页面读入内存，何时将其写入磁盘，目的是尽量减少从磁盘上读取数据的停顿次数。
Locks vs. Latches Locks: Locks 是一个更高层次的逻辑元语，它保护数据库的内容（如 Tuple 、表、数据库）不受其他事务的影响。事务将在整个持续时间内持有一个 Locks。数据库系统可以在运行查询时向用户披露哪些 Locks 正在被持有。Locks 需要能够回滚。概念上接近于操作系统中的 Latches。
Latches: Latches 是一种底层的保护元语，DBMS 将其用于内部数据结构的关键部分（例如，哈希表，内存区域）。Latches 只在所进行的操作的时间内保持。Latches 不需要支持回滚。概念上接近与操作系统的 Mutex。
缓冲池 缓冲池是一个从磁盘上读取页面的内存缓存。它本质上是在数据库内部分配的一个大的内存区域，用来存储从磁盘获取的页面。
缓冲池的内存区域被组织成一个固定大小的页面阵列。每个数组条目被称为一个帧。当 DBMS 请求一个页面时，一个精确的副本被放置到缓冲池的一个帧中。然后，当一个页面被请求时，数据库系统可以首先搜索缓冲池。如果没有找到该页，那么系统就会从磁盘上获取该页的副本。
缓冲池元数据 缓冲池必须维护某些元数据，以便有效和正确地使用。首先，页表是一个内存中的哈希表，用于跟踪当前内存中的页面。它将页面 ID 映射到缓冲池中的帧位置。由于缓冲池中的页面顺序不一定反映磁盘上的顺序，这个额外的中介层允许识别缓冲池中的页面位置。请注意，页面表不能与页面目录混淆，后者是从页面 ID 到数据库文件中的页面位置的映射。
页面表还维护着每个页面的额外元数据，一个脏页标志和一个固定/引用计数器。
每当一个线程修改一个页面时，就会设置脏页标记。这表明存储管理程序必须将该页写回磁盘。
固定/引用计数器跟踪当前访问该页的线程数量（无论是读取还是修改）。一个线程在访问该页之前必须递增该计数器。如果一个页面的计数大于零，那么存储管理器就不允许将该页面从内存中替换出去。
内存分配策略 数据库中的内存是根据两个策略分配给缓冲池的。
全局策略处理 DBMS 应该做出的决定，以有利于正在执行的整个工作负载。 它考虑所有活动的事务，以找到分配内存的最佳决策。
另一个选择是局部策略，它做出的决定将使单个查询或事务运行得更快，即使它对整个工作负载不利。对整个工作负载有利。局部策略将帧分配给特定的事务，而不考虑并发事务的行为。并发事务的行为。但是需要考虑共享页面。
大多数系统使用全局策略和局部策略的组合。
缓冲池优化 多个缓冲池 DBMS 可以为不同的目的维护多个缓冲池（即每个数据库缓冲池、每个页面类型的缓冲池）。然后，每个缓冲池可以采用为其内部存储的数据定制的本地策略。这种方法可以帮助减少锁的竞争，并提高定位性。
将所需页面映射到缓冲池的两种方法是对象 ID 和散列。
对象 ID 涉及到扩展记录 ID，以包括关于每个缓冲池管理的数据库对象的元数据。然后通过对象标识符，可以维护对象到特定缓冲池的映射。
另一种方法是散列，DBMS 对页面 ID 进行散列，以选择访问哪个缓冲池。
预取 DBMS 也可以通过基于查询计划的预取页面来进行优化。然后，当第一组页面被处理时，第二组可以被预取到缓冲池中。这种方法是 DBMS 在连续访问许多页面时常用的。</description></item><item><title>MySQL技术内幕::InnoDB存储引擎</title><link>/misc/inside_mysql/</link><pubDate>Sat, 11 Sep 2021 10:03:18 +0800</pubDate><guid>/misc/inside_mysql/</guid><description>MySQL 体系结构和存储引擎 定义数据库和实例 数据库 物理操作系统文件和其他形式文件类型的集合 frm、MYD、MYI、ibd 结尾的文件 实例 MySQL 数据库由后台线程和一个共享内存组成 数据库实例才是真正用来操作数据库的 实例与数据库一一对应 MySQL 数据库实例在系统上的表现就是一个进程 配置加载顺序 /etc/my.cnf =&amp;gt; /etc/mysql/my.cnf =&amp;gt; /usr/local/mysql/etc/my.cnf =&amp;gt; $HOME/.my.cnf MySQL 体系结构 组成 连接池组建 管理服务和工具组建 SQL 接口组件 查询分析器组件 优化器组件 缓冲组件 插件式存储引擎 物理文件 存储引擎是基于表的，而不是数据库 存储引擎 InnoDB 存储引擎 支持事务，面向 OLTP 应用 行锁，外键 支持裸设备 多版本并发控制，四种隔离级别 next-key locking 避免幻读 插入缓冲、二次写、自适应哈希索引、预读 采用索引组织表，每张表的存储都是按照转的顺序存放的 MyISAM 存储引擎 不支持事务 表锁设计 支持全文索引 面向 OLAP 只缓存索引文件 MyISAM 存储引擎表由 MYD 和 MYI 组成 MYD 存放数据文件 MYI 存放索引文件 NDB 存储引擎 集群存储引擎 share nothing 架构 Memory 存储引擎 表数据放在内存 使用哈希索引 用于存放临时结果集 Archive 存储引擎 只支持 INSERT 和 SELECT 使用 zlib 压缩数据，有较好的压缩率 适合归档数据 Federated 存储引擎 指向一台远程 MySQL 数据库服务器上的表 Maria 存储引擎 目标取代 MyISAM 特性同 InnoDB 存储引擎 其他存储引擎 Merge CSV Sphinx Infobright 存储引擎比较 MySQL :: 16 Alternative Storage Engines 连接 MySQL TCP/IP 不同机器之间 在客户端和服务器端连接 命名管道和共享内存 在同一台机器上 通过 &amp;ndash;enable-named-pipe 启用 UNIX 域套接字 同一台机器上使用 通过 &amp;ndash;socket=/etc/mysql.</description></item><item><title>大纲::分布式系统</title><link>/misc/distsys_outline/</link><pubDate>Fri, 10 Sep 2021 03:39:50 +0800</pubDate><guid>/misc/distsys_outline/</guid><description>分布式系统大纲 介绍分布式系统基础。直观地了解关键的分布式系统术语，概述算法领域，并探索生产环境的问题。
转载 分布式系统大纲 - iswade&amp;rsquo;s blog，补充了落后的部分以及部分翻译和格式修正
分布式系统大纲 - XMind
为什么需要分布式? Lamport, 1987:
分布式系统是：你不知道存在计算机故障会导致您自己的计算机无法使用的系统。
首先，在托管中心运行*nix 的盒子，进程通过 TCP 或者 UDP 通信。 或者 EC2, Rackspace 的盒子等等 也许通过 InfiniBand 通信 以短距离的局域网分割 或者以数千公里互联网分割 许多移动应用也参与分布式系统 通过糟糕的网络进行通信 桌面 Web 浏览器也是如此 这不仅仅是服务器 —— 它也是客户端 更一般地说，分布式系统具有如下特征 由交互的组件构成 很慢 不可靠 无论那些对你意味着什么 还有： 飞机上的冗余 CPU ATM 和销售点终端 太空探测器 支付账单 医生进行推荐 醉酒的朋友试图通过短信制定计划 每次商务会议 节点和网络 我们将分布式系统中的每个部分叫做 节点 也称之为 进程，代理，参与者 节点 延迟特征 在一个节点内部的操作很快 节点之间的操作很慢 快和慢取决于系统的目的 节点是可靠的 作为一个故障单元 你知道什么时候发生问题 状态是连贯的 状态转换以优雅有序的方式进行 典型的模型是某种类型的单线程状态机 节点可以自己组成一个分布式系统 但只要该系统作为一个整体提供“快速，连贯”的操作，我们就可以将其视为单个节点。 进程模型 顺序进程通信模型 Pi-演算 Ambient 演算 Actor 模型 节点故障模型 故障停止 Crash-stop 故障恢复 Crash-recover 故障遗忘 Crash-amnesia 拜占庭 Byzantine 消息流通的网络 节点通过网络交互 人类通过口头语言进行交互 粒子通过磁场交互 计算机通过 IP，TCP，UDP，SCTP 或者其它协议交互 在节点之间发送的离散 消息 消息需要 时间 来传播 这是分布式系统中比较慢的部分 我们称之为 延迟 消息可能会丢失 这是分布式系统中另一个不可靠的部分。 网络几乎不会是同构的 一些连接比其它的连接速度更慢、带宽更小、更容易出错 因果关系图 我们可以将节点和网络交互表示为图表 时间从左到右或者从上到下表示 节点是时间方向上的线（因为它们保持不动） 消息通过倾斜的路径 连接 节点 同步网络 节点以锁步方式执行：节点步骤之间的时间始终为 1 消息延迟有限 有效的完美的全球时钟 易于证明的 你可能没有 半同步网络 像同步一样，但时钟只是近似的，例如在 [c，1] 异步网络 独立执行，无论何时：步进时间在[0,1]中的任何位置 无限制的消息延迟 没有全球时钟 比半同步或同步网络弱 意味着某些算法效率不高 意味着某些算法是 不可能的 参见例如 Attiya＆Mavronicolas，“半同步与异步网络的效率“ IP 网络肯定是异步的 但 在实践中 真正的病态事情不会发生 大多数网络在几秒到几周内恢复，而不是“从不” 相反，人类的时间尺度大约为几秒到几周 所以我们不能臆想不存在的问题 当网络出错时 异步网络允许 重复 延迟 丢失 重排 丢失和延迟是很难区分的 拜占庭网络被允许随意乱序 包括重写内容 在真实的网络中几乎不会出现 大多数情况 https://www.</description></item><item><title>CMU::15-445/645::Database Storage 笔记</title><link>/notes/cmu_15_445_03_note/</link><pubDate>Wed, 08 Sep 2021 09:07:42 +0800</pubDate><guid>/notes/cmu_15_445_03_note/</guid><description>数据库存储第一部分 存储 我们将关注一个 &amp;ldquo;面向磁盘 &amp;ldquo;的 DBMS 架构，它假定数据库的主要存储位置是在非易失性磁盘上。
数据库的主要存储位置是在非易失性磁盘上。
在存储层次结构的顶端，最接近 CPU 的位置，这是最快的但它也是容量小和最昂贵的存储。离 CPU 越远，存储设备的容量就越大。设备有更大的容量，但速度更慢，离 CPU 更远。这些设备每 GB 的价格也越来越便宜。
易失性设备。 易失性意味着如果你从机器上拔掉电源，那么数据就会丢失。 易失性存储支持快速的随机访问，具有字节寻址的位置。这意味着程序可以跳转到任何字节地址，并获得其中的数据。 为了我们的目的，我们将始终把这种存储类别称为 &amp;ldquo;存储器&amp;rdquo;。 非易失性设备。 非易失性意味着存储设备不需要持续供电，以便以保留它所存储的比特。 它也是块/页可寻址的。这意味着，为了读取一个特定偏移量的数值，程序首先要加载 4KB 的页面加载到内存中，以提供程序想要读取的值。 非易失性存储在传统上更擅长顺序访问（同时读取多块数据）。 我们将把它称为 &amp;ldquo;磁盘&amp;rdquo;。我们将不对固态硬盘或机械硬盘进行区分。 (SSD)或旋转式硬盘(HDD)。 还有一类新的存储设备即将问世，称为非易失存储器，定位介于 DRAM 于 SSD 之间。它几乎和 DRAM 一样快，但具有磁盘的持久性。(英特尔傲腾)
对非易失性存储的随机访问通常比顺序访问要慢得多。 算法试图减少对随机页的写入次数，以便将数据存储在连续的块中。 程序在再一次调用中分配多个页面。 由于系统假设数据库存储在磁盘上，DBMS 的组件负责找出如何在非易失性磁盘和易失性存储器之间来回移动数据。DBMS 的组件负责找出如何在非易失性磁盘和易失性存储器之间来回移动数据，因为系统不能直接对磁盘上的数据进行操作。
数据库存储在磁盘上，系统不能直接在磁盘上操作数据，DBMS 的组件负责找出如何在非易失性磁盘和易失性存储器之间来回移动数据。
我们将专注于如何隐藏磁盘的延迟，而不是专注于用寄存器和缓存进行优化，因为从磁盘获取数据的速度非常慢。如果从 L1 缓存引用中读取数据需要半秒，那么从 SSD 中读取数据需要 1.7 天，从 HDD 中读取需要 16.5 周。
面向磁盘的 DBMS 总览 数据库都在磁盘上，数据库文件中的数据被组织成页，第一页是目录页。为了对数据进行操作，DBMS 需要将数据带入内存。它通过拥有一个缓冲池来管理磁盘和内存之间的来回移动。DBMS 也有一个执行引擎，可以执行查询。执行引擎将要求缓冲池提供一个特定的页面，而缓冲池将负责把该页面带入内存，并给执行引擎一个指向内存中该页面的指针。缓冲池管理器将确保在执行引擎对该内存进行操作时，该页是存在的。
DBMS 对比 OS DBMS 的一个高层次设计目标是支持超过可用内存量的数据库。由于对磁盘的读/写是昂贵的，所以必须小心管理。我们不希望在从磁盘上获取东西时出现大的停顿，从而拖慢其他一切。因此，我们希望 DBMS 能够在等待从磁盘获取数据时处理其他查询。它就像虚拟内存一样，有一个大的地址空间和一个供操作系统从磁盘引入页面的地方。</description></item><item><title>CMU::15-445/645::Advanced SQL 笔记</title><link>/notes/cmu_15_445_02_note/</link><pubDate>Wed, 01 Sep 2021 09:07:42 +0800</pubDate><guid>/notes/cmu_15_445_02_note/</guid><description>高级 SQL 关系语言 Edgar Codd 在 20 世纪 70 年代初发表了关于关系模型的主要论文。他最初只定义了 DBMS 如何在关系模型 DBMS 上执行查询的数学符号。
用户只需要使用声明性语言（即 SQL）来指定他们想要的结果。DBMS 负责通过使用查询优化器重新组合操作确定产生该答案的最有效计划。
关系代数是基于 sets（无序的，没有重复的）。SQL 是基于 bags（无序的，允许重复）
SQL 历史 SQL。结构化查询语言
IBM 最初称其为 SEQUEL (Structured English Query Language)
由不同类别的命令组成。
数据操作语言（DML）。SELECT,INSERT,UPDATE,DELETE 数据定义语言（DDL）。模式定义。 数据控制语言（DCL）。安全，访问控制。 目前的 SQL 标准是 SQL:2016
各阶段引入的特性
SQL:2016 → JSON, Polymorphic tables SQL:2011 → Temporal DBs, Pipelined DML SQL:2008 → TRUNCATE, Fancy sorting SQL:2003 → XML, windows, sequences, auto-gen IDs. SQL:1999 → Regex, triggers, OO SQL 并没有死。它每隔几年就会有新的功能被更新。SQL-92 是一个 DBMS 必须支持的最低版本，以便声称他们支持 SQL。每个供应商都在一定程度上遵循该标准，但也有许多专有的扩展。</description></item><item><title>论文::如何阅读一篇论文</title><link>/misc/how_to_read_a_paper/</link><pubDate>Wed, 01 Sep 2021 04:45:33 +0800</pubDate><guid>/misc/how_to_read_a_paper/</guid><description>原始论文 HowtoReadPaper.pdf
摘要 研究人员花了大量的时间阅读研究论文。然而，这种技能很少被传授，导致了浪费了很多精力。本文概述了一种实用而有效的阅读研究论文的三段式方法。我还描述了如何使用这种方法来进行文献调查。
类别和主题描述符。A.1 [介绍性和调查]。
一般术语。文档。
关键词: 论文，阅读，提示。
1 介绍 研究人员必须阅读论文的原因有几个：为会议或课程审阅论文，在他们的领域保持领先，或对一个新领域进行文献调查。一个典型的研究人员每年可能要花数百个小时来阅读论文。
学会有效地阅读论文是一项重要的技能，但却很少有人教。因此，初学的研究生必须通过试验和错误来自学。在这个过程中，学生们浪费了大量的精力，而且经常被逼得灰心丧气。
多年来，我一直使用一种简单的方法来有效地阅读论文。本文介绍了 &amp;ldquo;三段式 &amp;ldquo;方法及其在进行文献调查时的应用。
2 三段式方法 关键的想法是，你应该最多分三遍来阅读论文，而不是从头开始，一路耕耘到最后。每一遍都要达到特定的目标，并在前一遍的基础上进行。第一遍让你对这篇论文有一个大致的了解。第二遍让你掌握论文的内容，但不是其细节。第三遍帮助你深入了解该论文。
2.1 第一遍 第一遍是快速扫描，以获得纸张的一个概览。你也可以决定是否需要做更多的扫描。这一遍应该需要大约 5 到 10 分钟，包括以下步骤。
仔细阅读标题、摘要和导言 阅读章节和分节的标题，但忽略其他内容 阅读结论 扫一眼参考资料，在心里勾出你已经读过的资料 在第一遍结束时，你应该能够回答这五个问题
类别。这是什么类型的论文？一份测量论文？对一个现有系统的分析？对一个研究原型的描述？ 背景。它与哪些其他论文有关？使用了哪些理论基础来分析问题？ 正确性。假设是有效的吗？ 贡献。该论文的主要贡献是什么？ 清晰度。论文写得好吗？ 利用这些信息，你可以选择不再继续阅读。这可能是因为你对该论文不感兴趣，或者你对该领域的了解不足以理解该论文，或者作者做出了无效的假设。对于那些不属于你的研究领域，但有一天可能被证明是相关的论文，第一遍就足够了。
顺便提一下，当你写一篇论文时，你可以期望大多数审稿人（和读者）只看一遍。请注意选择连贯的章节和分节标题，并写出简明而全面的摘要。如果审稿人在看完一遍后不能理解要点，论文很可能会被拒绝；如果读者在五分钟后不能理解论文的重点，论文很可能永远不会被阅读。
2.2 第二遍 在第二遍时，要更仔细地阅读论文，但忽略诸如证明等细节。在阅读过程中，记下关键点，或在空白处做评论，会有帮助。
仔细观察论文中的数字、图表和其他插图。要特别注意图表。轴的标记是否正确？显示的结果是否有误差条，从而使结论具有统计学意义？诸如此类的常见错误会将仓促的、低劣的工作与真正优秀的工作区分开来。 记得标记相关的未读参考文献以便进一步阅读（这是了解论文背景的一个好方法） 第二遍应该花上一个小时。经过这一关，你应该能够掌握论文的内容。 你应该能够向别人总结论文的主旨，并提供支持性证据。这种详细程度适合于你感兴趣的论文，但不属于你的研究专长。
有时，即使在第二遍结束时，你也无法理解一篇论文。这可能是因为该主题对你来说是新的，有不熟悉的术语和缩略语。或者作者可能使用了你不理解的证明或实验技术，因此，论文的大部分内容是无法理解的。论文可能写得很差，没有事实依据的断言和大量的参考文献。也可能只是因为现在是深夜，你很累。你现在可以选择。(a)把论文放在一边，希望你不需要理解这些材料就能在事业上取得成功，(b)以后再回来看这篇论文，也许是在阅读背景材料之后，或者(c)坚持下去，进入第三关。
2.3 第三遍 要完全理解一篇论文，特别是如果你是审稿人，需要第三遍。第三遍的关键是试图重现该论文：也就是说，在与作者相同的假设下，重新创造该工作。通过比较这种再创造和实际的论文，你不仅可以很容易地发现论文的创新，还可以发现其隐藏的失败和假设。
这一关需要非常注意细节。你应该找出并挑战每一个陈述中的假设。此外，你应该思考你自己会如何陈述一个特定的想法。这种实际与虚拟的比较使你对论文中的证明和表述技巧有了敏锐的洞察力，你很可能将其加入你的工具库。在这个过程中，你还应该记下对未来工作的想法。
这一关对于初学者来说可能需要四五个小时，而对于有经验的读者来说则需要一个小时左右。在这一阶段结束时，你应该能够根据记忆重建论文的整个结构，并能够确定其强点和弱点。特别是，你应该能够指出隐含的假设、缺少对相关工作的引用，以及实验或分析技术的潜在问题。
3 进行文献调查 在做文献调查时，论文阅读能力受到考验。这将要求你阅读数十篇论文，也许是在一个不熟悉的领域。你应该阅读哪些论文？以下是你如何使用三段式方法来帮助。
首先，使用学术搜索引擎，如 Google Scholar 或 CiteSeer 和一些精心选择的关键词，找到该领域的三到五篇最新论文。对每篇论文进行一次检索以了解其工作情况，然后阅读其相关工作部分。你会发现最近工作的缩略图，如果你幸运的话，也许会有一个指向最近的调查报告的指针。如果你能找到这样一份调查报告，你就完成了。阅读调查报告，祝贺自己的好运气。
否则，在第二步，在书目中找到共同的引文和重复的作者名字。这些是该领域的关键论文和研究人员。下载关键论文并将其放在一边。然后进入关键研究人员的网站，看看他们最近在哪里发表过文章。这将帮助你确定该领域的顶级会议，因为最好的研究人员通常在顶级会议上发表文章。
第三步是进入这些顶级会议的网站，查看他们最近的会议记录。快速扫描通常会发现最近的高质量相关工作。这些论文，连同你之前搁置的论文，构成了你调查的第一个版本。对这些论文进行两次扫描。如果他们都引用了你之前没有发现的关键论文，那么就获取并阅读它，必要时进行迭代。
4 经验之谈 在过去的 15 年里，我一直使用这种方法来阅读会议记录，写评论，做背景研究，以及在讨论前快速审查论文。这种有规律的方法可以防止我在得到一个概览之前迷失在细节中。它使我能够估计审查一组论文所需的时间。此外，我可以根据自己的需要和时间的多少来调整论文评估的深度。
5 相关工作 如果你阅读论文是为了做评论，你还应该阅读 Timothy Roscoe 关于 &amp;ldquo;为系统会议撰写评论 &amp;ldquo;的论文[2]。如果你打算写一篇技术论文，你应该同时参考 Henning Schulzrinne 的综合网站[3]和 George Whitesides 对这个过程的出色概述[4]。最后，Simon Peyton Jones 有一个涵盖整个研究技能的网站 [1]。</description></item><item><title>CMU::15-445/645::Relational Model 笔记</title><link>/notes/cmu_15_445_01_note/</link><pubDate>Mon, 30 Aug 2021 01:51:13 +0800</pubDate><guid>/notes/cmu_15_445_01_note/</guid><description>关系模型和关系代数 数据库 数据库是一个有组织的相互关联的数据集合，它对现实世界的某些方面进行建模。数据库是很多计算机应用的核心部分。人们经常将数据库与数据库管理系统(比如 MyQSL，Oracle，MongoDB)相混淆，数据库管理系统是指管理数据库的软件。
文本文件稻草人 数据库被存储为 DBMS 管理的逗号分隔值（CSV）文件。每个实体将被存储在它自己的文件中。应用程序每次要读取或更新记录时，都必须解析文件。每个每个实体都有自己的属性集，所以在每个文件中，不同的记录都用新的行来分隔，而记录中的每个而记录中的每个相应的属性都用逗号隔开。继续沿用数字音乐商店的例子，会有两个文件：一个是艺术家文件，另一个是专辑。一个艺术家可以有一个名字、年份和国家属性，而一张专辑有名字、艺术家和年份属性
查询 Ice Cube 解散的年份
无格式文件的问题 数据完整性 我们如何确保每个专辑条目中的艺术家是相同的？ 如果有人用一个无效的字符串覆盖了专辑年份怎么办？ 我们如何存储一张专辑中有多个艺术家的情况？ 如果我们删除了一个有专辑的艺术家会发生什么？ 实现 你如何找到一个特定的记录？ 如果我们现在想创建一个使用相同数据库的新应用程序，该怎么办？ 如果两个线程试图同时写到同一个文件怎么办？ 持久性 如果我们的程序在更新一条记录时机器崩溃了怎么办？ 如果我们想在多台机器上复制数据库以获得高可用性怎么办？ 数据库管理系统 DBMS 是一种允许应用程序在数据库中存储和分析信息的软件 通用的 DBMS 被能够定义、创建、查询、更新和管理数据库 早期数据库 数据库应用很难建立和维护，因为逻辑层和物理层之间存在着紧密的耦合。
逻辑层是指数据库有哪些实体和属性，而物理层是指这些实体和属性是如何被存储的。
早期，物理层是在应用程序代码中定义的，所以如果我们想改变应用程序正在使用的物理层，我们就必须改变所有的代码来匹配新的物理层。
随着人工成本超过物理成本，这种做法逐渐不可接受，Codd 发布了关于数据关系模型的论文。
关系模型 关系模型三个关键点 以简单的数据结构（关系）存储数据库 通过高级语言访问数据 物理存储由实现决定 数据模型是描述数据库中数据的概念的集合。关系模型是一个数据模型的例子
模式是对一个特定的数据集合的描述，使用一个给定的数据模型
关系型数据库定了三个概念
结构。关系的定义和它们的内容。这就是关系所具有的属性和这些属性可以持有的值 完整性。确保数据库的内容满足约束。一个约束的例子是年份属性的任何值都必须是一个数字 操作性。如何访问和修改数据库的内容 关系是一个无序的集合，包含代表实体的属性关系。由于关系是无序的，DBMS 可以以任何方式存储它们，允许进行优化
Tuple是关系中的一组属性值（也被称为它的域）。最初，值必须是原子或标量，现在值也可以是列表或嵌套数据结构。每个属性都可以是一个特殊的值 NULL，即属性是未定义的
一个有 n 个属性的关系被称为 n-ary 关系
键值 一个关系的主键唯一地标识了一个单一的 Tuple 。如果你没有定义一个主键，一些 DBMS 会自动创建一个内部主键。很多 DBMS 都支持自动生成的键，所以应用程序不必手动增加键
外键指定了一个关系中的属性必须映射到另一个关系中的 Tuple
数据操作语言 DML 一种从数据库中存储和检索信息的语言。在这方面有两类语言可选择</description></item><item><title>编程::编程之道</title><link>/misc/tao_of_programming/</link><pubDate>Sun, 22 Aug 2021 21:58:06 +0800</pubDate><guid>/misc/tao_of_programming/</guid><description>第 1 册 - 寂静的虚空 主程序员如是说：
“当你学会了从陷阱帧中抓取错误代码时，你就该离开了。“
1.1 某种神秘的东西形成，在寂静的虚空中诞生。独自等待，一动不动，它既静止又不断运动。它是所有程序的来源。我不知道它的名字，所以我称之为编程之道。
如果道是美好的，那么操作系统是美好的。如果操作系统是美好的，那么编译器也是美好的。如果编译器是美好的，那么应用程序也是美好的。用户满意，世界和谐。
编程之道远流归于晨风。
1.2 道催生了机器语言。机器语言催生了汇编程序。
汇编器催生了编译器。现在有一万种语言。
每种语言都有其目的，无论多么卑微。每种语言都表达了软件的阴阳。每种语言在道中都有它的位置。
但是，如果可以避免，请不要在 COBOL 中编程。
1.3 起初是道。道催生出了空间和时间。所以空间和时间是编程的阴阳。
不懂道的程序员总是没有时间和空间来编写他们的程序。懂道的程序员总有足够的时间和空间来实现他们的目标。
不然呢？
1.4 聪明的程序员被告知道并遵循它。普通程序员被告知道并搜索它。愚蠢的程序员被告知道并嘲笑它。
若非欢笑，便无道。
曲高和寡。
进亦是退。
大器晚成。
即使是完美的程序仍然存在错误。
第 2 册 - 古代大师 主程序员如是说：
&amp;ldquo;三天没有编程，生活变得毫无意义。&amp;rdquo;
2.1 古代的程序员是神秘而深刻的。我们无法揣摩他们的想法，所以我们所做的只是描述他们的外表。
谨觉，就像一只过水的狐狸。机警，就像战场上的将军。亲切，就像一位女大师迎接她的客人。简单，就像未雕刻的木块。浑浊，就像黑暗洞穴中的黑色水池。
谁能说出他们内心深处的秘密？
答案只存在于道中。
2.2 图灵大师曾经梦想自己是一台机器。当他醒来时，他惊呼道：
&amp;ldquo;我不知道我是图灵在梦想我是机器，还是机器在梦想我是图灵！&amp;rdquo;
2.3 一个很大的电脑公司的程序员去参加了一个软件会议，然后回来向他的经理汇报，他说：“什么样的程序员在其他公司工作？他们行为恶劣，对外表漠不关心。他们的头发又长又乱，衣服又皱又旧。他们毁了我们的招待大厅，并在我的演讲中发出粗鲁的声音。”
经理说：“我不应该派你去参加会议。那些程序员生活在物理世界之外。他们认为生活是荒谬的，是偶然的巧合。他们来来去去，不受限制。毫无顾虑，他们只为自己的程序而活。他们为什么要为社会习俗而烦恼？
&amp;ldquo;他们活在道中。&amp;rdquo;
2.4 一个新手问大师：“这是一个从不设计、记录或测试他的程序的程序员。然而，所有认识他的人都认为他是世界上最好的程序员之一。这是为什么？&amp;quot;
师父回答：“那个程序员已经掌握了道。他已经超越了设计的需要；当系统崩溃时，他不会生气，而是毫无顾虑地接受宇宙。他已经超越了对文件的需求；他不再关心其他人是否看到他的代码。他已经超越了测试的需要；他的每一个程序都是完美的，宁静而优雅，其目的不言而喻。的确，他进入了道的奥秘。”
第 3 册 - 设计 主程序员如是说：
&amp;ldquo;当程序正在测试时，进行设计更改为时已晚。&amp;rdquo;
3.1 从前有一个人参加了一个电脑贸易展。每天他一进门，就对门口的守卫说：
“我是个大盗，以入店行窃闻名。预先警告，因为这个贸易展不会逃脱不受掠夺。”
这番话让守卫大为不安，因为里面有数百万美元的电脑设备，所以他小心翼翼地看着那人。但那人只是在一个摊位间徘徊，自言自语地低声哼唱着。
男人走后，守卫把他拉到一边，搜了遍他的衣服，却一无所获。
交易会的第二天，那个人回来责备看守说：“我昨天带着一大笔赃物逃了出来，但今天会更好。”于是看守更密切地看着他，但无济于事.
展销会的最后一天，守卫再也抑制不住好奇了。“小偷先生，”他说，“我很困惑，我无法平静地生活。请赐教。你偷的是什么？”
男人笑了。“我在窃取想法，”他说。
3.2 曾经有一位编写非结构化程序的大师级程序员。一个想模仿他的新手程序员也开始编写非结构化程序。当新手要求大师评价他的进步时，大师批评他编写非结构化程序，说：“适合大师的东西不适合新手。在超越结构之前，您必须了解道。”
3.3 从前有一个程序员，隶属于吴军的朝廷。军阀问程序员：“哪个更容易设计：会计软件包还是操作系统？”</description></item><item><title>APUE::Threads</title><link>/misc/advanced_programming_in_the_unix_environment_threads/</link><pubDate>Wed, 11 Aug 2021 00:43:37 +0800</pubDate><guid>/misc/advanced_programming_in_the_unix_environment_threads/</guid><description>Threads Thread Concepts simplify code that deals with asynchronous events by assigning a separate thread to handle each event type Threads automatically have access to the same memory address space and file descriptors Some problems can be partitioned so that overall program throughput can be improved interactive programs can realize improved response time by using multiple threads The benefits of a multithreaded programming model can be realized even if your program is running on a uniprocessor A thread consists of the information necessary to represent an execution context within a process a thread ID that identifies the thread within a process a set of register values a stack a scheduling priority and policy a signal mask an errno variable thread-specific data Everything within a process is sharable among the threads in a process text of the executable program the program’s global and heap memory, the stacks the file descriptors Thread Identification every thread has a thread ID the thread ID has significance only within the context of the process to which it belongs A thread ID is represented by the pthread_t data type Thread Creation When a thread is created, there is no guarantee which will run first: the newly created thread or the calling thread The memory location pointed to by tidp is set to the thread ID of the newly created thread when pthread_create returns successfully pthread functions usually return an error code when they fail.</description></item><item><title>APUE::UNIX System Overview</title><link>/misc/advanced_programming_in_the_unix_environment_overview/</link><pubDate>Sun, 01 Aug 2021 00:43:37 +0800</pubDate><guid>/misc/advanced_programming_in_the_unix_environment_overview/</guid><description>UNIX System Overview an operating system can be defined as the software that controls the hardware resources of the computer and provides an environment under which programs can run Kernel is relatively small and resides at the core of the environment The interface to the kernel is a layer of software called the system calls Libraries of common functions are built on top of the system call interface, but applications are free to use both The shell is a special application that provides an interface for running other applications In a broad sense, an operating system consists of the kernel and all the other software that makes a computer useful and gives the computer its personality.</description></item><item><title>现代操作系统::操作系统设计</title><link>/notes/modern_operating_systems_operating_system_design/</link><pubDate>Fri, 23 Jul 2021 02:11:01 +0800</pubDate><guid>/notes/modern_operating_systems_operating_system_design/</guid><description>操作系统设计 设计问题的本质 目标 定义抽象概念 进程、文件、线程、信号量 提供基本操作 每一个抽象概念可以通过具体数据结构的形式来实例化。用户可以创建进程、文件、信号量等。基本操作则处理这些数据结构。例如，用户可以读写文件。基本操作以系统调用的形式实现。从用户的观点来看，操作系统的核心是由抽象概念与其上的基本操作所构成的，而基本操作则可通过系统调用加以利用。 确保隔离 用户之间的隔离 虚拟机之间的隔离 进程之间的隔离 故障隔离 资源共享 管理硬件 提供一个框架，统一管理不同型号的硬件资源 难点 已经发展成了极其复杂的程序 必须处理并发和并发导致竞争条件、死锁等问题。 必须处理可能有敌意的用户 需要提供在不同用户之间共享资源的能力 设计人员需要思考未来的操作系统设计方向 需要提供想当程度的通用性 可移植性 需要保持向后兼容 接口设计 指导原则 简单：一个简单的接口更加易于理解并且更加易于以无差错的方式实现 完备：接口必须能够做用户需要做的一切事情，也就是说，它必须是完备的 效率：如果一个功能特性或者系统调用不能够有效地实现，或许就不值得包含它。 范型 用户界面范型：不管选择什么范型，重要的是所有应用程序都要使用它。因此，系统设计者需要提供库和工具包给应用程序开发人员，使他们能够访问产生一致的外观与感觉的程序。没有工具，应用开发者做出来的东西可能完全不同。 执行范型： 算法范型：启动一个程序是为了执行某个功能，而该功能是事先知道的或者是从其参数获知的。 事件驱动范型：在这里程序执行某种初始化（例如通过显示某个屏幕），然后等待操作系统告诉它第一个事件。事件经常是键盘敲击或鼠标移动。这一设计对干高度交互式的程序是十分有益的。 数据范型： 一切皆磁带：在早期的 FORTRAN 批处理系统中，所有一切都是作为连续的磁带来建立模型。用于读入的卡片组被看作输入磁带，用于穿孔的卡片组被看作输出磁带，井且打印机给出被看作输出磁带。磁盘文件也被看作磁带 一切皆文件：UNIX 用”所有一切都是文件”的模型一步发展了这一思想。使用这一范型，所有 I/O 设备都被看作文件，井且可以像普通文件一样打开和操作。 一切皆对象：Windows 试图使所有一切看起来像是一个对象。一旦一个进程获得了一个指向文件、进程、信号量、 邮箱或者其他内核对象的有效句柄，它就可以在其上执行操作。这一范型甚至比 UNIX 更加一般化，井且比 FORTRAN 要一般化得多。 一切皆文档：Web 背后的范型是充满了文档的超空间，每一个文档具有一个 URL。通过键人一个 URL 或者点击被 URL 所支持的条目，你就可以得到该文档。 系统调用接口 操作系统应该提供恰好够用的系统调用，井且每个系统调用都应该尽可能简单 在某些情况下，系统调用可能需要若干变体，但是通常比较好的实现是具有处理一般情况的一个系统调用，而由不同的库过程向程序员隐藏这一事实。 添加更多的代码就是添加更多的程序错误 不要隐藏能力，如果硬件具有极其高效的方法做某事，它就应该以简单的方法展露给程序员 任何面向连接的机制与无连接的机制之间的权衡在于建立连接的机制（例如打开文件）要求的额外开销， 与系统调用接口有关的另一个问题是接口的可见性。 POSIX 强制的系统调用列表很容易找到。Microsoft 从未将 Windows 系统调用列表公开。作为替代，Win API 和其他 API 被公开了，但是这些 API 包含大量的库调用（超过 10000 个），只有很少数是其正的系统调用 实现 系统结构 分层系统：对于一个新系统，选择走这一路线的设计人员应该首先非常仔细地选择各个层次，井且定义每个层次的功能。底层应该总是试图隐藏硬件最糟糕的特异性 外内核：他们的观点基干端到端问题，某件事情必须由用户程序本身去完成，在一个较低的层次做同样的事情就是浪费。端到端问题可以扩展到几乎所有操作系统。它主张不要让操作系统做用户程序本身可以做的任何事情。 在让操作系统做每件事情和让操作系统什么也不做之间的折衷是让操作系统做一点事情。这一设计导致微内核的出现，它让操作系统的大部分作为用户级的服务器进程而运行，在所有设计中这是最模块化和最灵活的。在灵活性上的极限是让每个设备驱动程序也作为一个用户进程而运行，从而完全保护内核和其他驱动程序，但是让设备驱动程序运行在内核会增加模块化程度。 可扩展的系统：将更多的模块放到内核中，但是以一种“受保护的”方式。可扩展的系统自身井不是构造一个操作系统的方法。然而，通过以一个只是包含保护机制的 朵小系统为开端，然后每次将受保护的模块添加到内核中，直到达到期望的功能，对千手边的应用而言一个最小的系统就建立起来了 。 内核线程：无论选择哪种结构模型，允许存在与任何用户进程相隔离的内核线程是很方便的。这些线程可以在后台运行，将脏页面写入磁盘，在内存和磁盘之间交换进程，如此等等。实际上，内核本身可以完全由这样的线程构成，所以当一个用户发出系统调用时，用户的线程并不是在内核模式中运行，而是阻塞井且将控制传给一个内核线程，该内核线程接管控制以完成工作。 机制与策略 另一个有助于体系结构一致性的原理是机制与策略的分离，该原理同时还有助于使系统保持小型和良好的结构。通过将机制放入操作系统而将策略留给用户进程，即使存在改变策略的需要，系统本身也可以保持不变。即使策略模块必须保留在内核中，它也应该尽可能地与机制相隔离，这样策略模块中的变化就不会影响机制模块。 对于线程调度，机制负责从高优先级到低优先级调度线程，策略负责制定线程优先级 对于内存分页，机制负责把页面在内存和磁盘之间换入换出，策略绝地交换是局部的还是全局的，是 LRU 还是 FIFO 正交性 良好的系统设计在于单独的概念可以独立地组合。 命名 操作系统大多数较长使用的数据结构都具有某种名字或标识符，通过这些名字或标识符就可以引用这些数据结构。显而易见的例子有注册名、文件名、设备名、进程 ID 等。 绑定的时机 操作系统使用多种类型的名字来引用对象。有时在名字和对象之间的映射是固定的，但是有时不是。在后一种情况下，何时将名字与对象绑定可能是很重要的。一般而言，早期绑定(early binding) 是简单的，但是不灵活，而晚期绑定(late binding) 则比较复杂，但是通常更加灵活。 操作系统对大多数数据结构通常使用早期绑定，但是偶尔为了灵活性也使用晚期绑定。内存分配是一个相关的案例。在缺乏地址重定位硬件的机器上，早期的多道程序设计系统不得不在某个内存地址装载一个程序，井且对其重定位以便在此处运行。如果它曾经被交换出去，那么它就必须装回到相同的内存地址，否则就会出错。相反，页式虚拟内存是晚期绑定的一种形式。在页面被访问并且实际装入内存之前，与一个给定的虚拟地址相对应的实际物理地址是不知道的。 静态与动态结构 操作系统设计人员经常被迫在静态与动态数据结构之间进行选择。静态结构总是简单易懂，更加容易编程井且用起来更快，动态结构则更加灵活。一个显而易见的例子是进程表。早期的系统只是分配一个固定的数组，存放每个进程结构。如果进程表由 256 项组成，那么在任意时刻只能存在 256 个进程。试图创建第 257 个进程将会失败，因为缺乏表空间。类似的考虑对于打开的文件表以及许多其他内核表格也是有效的。 自顶向下与自底向上的实现 虽然最好是自顶向下地设计系统，但是在理论上系统可以自顶向下或者自底向上地实现。在自顶向下的实现中，实现者以系统调用处理程序为开端，并且探究需要什么机制和数据结构来支持它们。接着写这些过程等，直到触及硬件。 这种方法的问题是，由于只有顶层过程可用，任何事情都难于测试。出于这样的原因，许多开发入员发现实际上自底向上地构建系统更加可行。这一方法需要首先编写隐藏底层硬件的代码。中断处理程序和时钟驱动程序也是早期就需要的。 同步通信与异步通信 对干系统设计者，在正确编程模型的决定上是一个艰难但是很重要的问题。这场论战没有冠军。像 apache 这样的 Web 服务器坚决拥护异步通信，但是 lighnpd 等其他服务器则基干事件驱动模式。两者都非常受欢迎。在我们看来，事件相比于线程更加容易理解和调试。只要没有多核并发的需要，事件很可能是一个好的选择。 实用技术 隐藏硬件：许多硬件是十分麻烦的，所以只好尽早将其隐藏起来 引用：通过一个索引来找到另一个实体 可重用性：在略微不同的上下文中重用相同的代码通常是可行的。 重入：重入指的是代码同时被执行两次或多次的能力。 蛮力法：在一些代码上不值得优化或优化代价很大，就不必优化 首先检查错误：系统调用可能由千各种各样的原因而执行失败：要打开的文件属于他人、因为进程表满而创建进程失败、或者因为目标进程不存在而使信号不能被发送。操作系统在执行调用之前必须无微不至地检查每一个可能的错误。 性能 操作系统为什么运行缓慢 硬件检查、初始化、功能多 什么应该优化 唯一的优化应该是那些显而易见要成为不可避免的问题的事情 性能一旦达到一个合理的水平，榨出最后一点百分比的努力和复杂性或许并不值得 空间-时间的权衡 改进性能的一种一般性的方法是权衡时间与空间。在一个使用很少内存但是速度比较慢的莽法与一个使用很多内存但是速度更快的算法之间进行选择，这在计算机科学中是经常发生的事情。在做出重要的优化时，值得寻找通过使用更多内存加快了速度的算法，或者反过来通过做更多的计算节省了宝贵的内存的算法。 缓存 用于改进性能的一项众所周知的技术是缓存。在任何相同的结果可能需要被获取多次的情况下，缓存都是适用的。一般的方法是首先做完整的工作，然后将结果保存在缓存中。对于后来的获取结果的工作，首先要检查缓存。如果结果在缓存中，就使用它。否则、再做完整的工作。 线索 缓存项总是正确的。缓存搜索可能失败，但是如果找到了一项，那么这一项保证是正确的井且无需再费周折就可以使用。在某些系统中，包含线索(hint)的表是十分便利的。这些线索是关于答案的提示，但是它们并不保证是正确的。调用者必须自行对结果进行验证。 利用局部性 进程和程序的行为井不是随机的，它们在时间上和空间上展现出相当程度的局部性，并且可以以各种方式利用该信息来改进性能。空间局部性的一个常见例子是：进程并不是在其地址空间内部随机地到处跳转的。在一个给定的时间间隔内．它们倾向于使用数目比较少的页面。进程正在有效地使用的页面可以被标记为它的工作集，井且操作系统能够确保当进程被允许运行时，它的工作集在内存中，这样就减少了缺页的次数。 局部性起作用的另一个领域是多处理器系统中的线程调度，在多处理器上一种调度线程的方法是试图在最后一次用过的 CPU 上运行每个线程，期望它的某些内存块依然还在内存的缓存中。 优化常见的情况 区分最常见的情况和最坏可能的情况井且分别处理它们，这通常是一个好主意。针对这两者的代码常常是相当不同的。重要的是要使常见的情况速度快。对于最坏的情况，如果它很少发生，使其正确就足够了。 项目管理 人月神话： 工作不可能完全并行化 为了完全利用数目众多的程序员，工作必须划分成数目众多的模块，这样每个人才能有事情做。由于每个模块可能潜在地与每个其他模块相互作用，需要将模块－模块相互作用的数目看成随着模块数目的平方而培长， 调试工作是高度序列化的 团队结构 任何大型项目都需要组织成层次结构。底层是许多小的团队，每个团队由首席程序员领导。在下一层，必须由一名经理人对一组团队进行协调。经验表明，你所管理的每一个人将花费你 10% 的时间，所以每组 10 个团队需要一个全职经理。这些经理也必须被管理。 经验的作用 拥有丰富经验的设计人员对于一个操作系统项目来说至关重要。Brooks 指出，大多数错误不是在代码中，而是在设计中。程序员正确地做了吩咐他们要做的事情，而吩咐他们要做的事情是错误的。再多测试软件都无法弥补糟糕的设计说明书。 没有银弹 或许在下一个十年将会看到一颗银弹，或许我们将只好满足于逐步的、渐进的改进。 操作系统设计的趋势 虚拟化与云 众核芯片 大型地址空间操作系统 无缝的数据访问 电池供电的计算机 嵌入式系统</description></item><item><title>现代操作系统::安全</title><link>/notes/modern_operating_systems_security/</link><pubDate>Thu, 22 Jul 2021 02:11:01 +0800</pubDate><guid>/notes/modern_operating_systems_security/</guid><description>安全 环境安全 威胁 很多安全方面的文章将信息系统的安全分解为三个部分：机密性，完整性和可用性。 机密性：指的是将机密的数据置于保密状态。更确切地说，如果数据所有者决定这些数据仅用于特定的人，那么系统就应该保证数据绝对不会发布给未经授权的人。 完整性：指未经授权的用户没有得到许可就擅自改动数据 可用性：没哟人可以扰乱系统使之瘫痪 后来，人们认为三个基本属性不能满足所有场景，因此又增添了一些额外属性，例如真实性、可审 计性、不可否认性、隐私性以及一些其他诸如此类的属性 安全工具对于攻击和防守都是有用的，具有双重用途这一属性 有时候攻击的影响会超越计算计机系统本身，对现实世界也会有影响。 网络战，大型组织之间发动的攻击行为 安全问题的另一个与保密性相关的重要方面是隐私 (privacy). 即保证私人的信息不披滥用 入侵者 从安全性的角度来说，那些喜欢闯入与自已毫不相干区域的人叫作攻击者(anacker)、入侵者(intruder) 或敌人(adversary) 攻击者的范围从技术不是很精湛的黑客爱好者（也称为脚本爱好者），到极其精通技术的黑客。他们可能专门为了罪犯、政府（如警察、军队或者情技部门）或者安全公司工作，或者只是在业余时间开展“黑客”行为的业余爱好者。 操作系统安全 攻击分为被动攻击与主动攻击。被动攻击试图窃取信息，而主动攻击会使计算机程序行为异常。 我们也将加密和程序加固区分开来。加密是将一个消息或者文件进行转码，除非获得密的密钥，否则很难恢复出原信息。程序加固是指在程序中加入保护机制从而使得攻击者很难破坏程序。操作系统在很多地方使用加密：在网络上安全传输据，在硬盘上安全存储文件，将密码存储在密码文件中等。 可信系统 为什么不去做一个安全的操作系统 现代系统虽然不安全但是用户不愿抛弃它们 现在已知的建立安全系统仅有的办法是保持系统的简单性。特性是安全的大敌。 邮件的多媒体文件 HTML 中的可执行脚本 可信计算基 在安全领域中，人们通常讨论可信系统而不是安全系统．这些系统在形式上申明了安全要求并满足了这些安全要求。每一个可信系统的核心是最小的可信计算基,其中包含了实施所有安全规则所必需的硬件和软件。如果这些可信计算基根据系统规约工作，那么，无论发生了什么错误，系统安全性都不会受到威胁。 典型的 TCB 包括了大多数的硬件（除了不影响安全性的 I/O 设备）、操作系统核心中的一部分、大多数或所有掌握超级用户权限的用户程序（如 UNIX 中的 SETUID 根程序）等。必须包含在 TCB 中的操作系统功能有：进程创建、进程切换、内存面管理以及部分的文件和 I/O 管理。在安全设计中、为了减少空间以及纠正错误，TCB 通常完全独立于操作系统的其他部分。 保护机制 保护域 域(domain)是（对象，权限）对的集合。每一对组合指定一个对象和一些可在其上运行的操作子集。这里权限 (right) 是指对某个操作的执行许可。通常域相当于单个用户，告诉用户可以做什么不可以做什么，当然有时域的范围比用户要更广。 任何时间，每个进程会在某个保护域中运行。换句话说，进程可以访问某些对象的集合，每个对象都有一个权限集。进程运行时也可以在不同的域之间切换。 在 UNIX 系统中，使用相同(UID, GID)组合的两个进程访问的是完全一致的对象集合。使用不同(UID, GID)值的进程访问的是不同的文件集合，虽然这些文件有大量的重叠。 而且，每个 UNIX 的进程有两个部分：用户部分和核心部分。当执行系统调用时，进程从用户部分切换到核心部分。核心部分可以访问与用户部分不同的对象集。 访问控制列表 每一个文件关联一个列表，列表里包含了所有可访问对象的域以及这些域如何访问这些对象的方法。这一列表叫作访问控制列表 每个文件对他特定用户和特定组拥有不同的权限 权能字 每一个权能字赋予所有者针对特定对象的权限。一个权能字通常包含了文件（或者更一般的情况下是对象）的标识符和用于不同权限的位图。在类似 UNIX 的系统中，文件标识符可能是 i 节点号。权能字列表本身也是对象，也可以从其他权能字列表处指定，这样就有助于共享子域。ACL 和权能字具有一些彼此互补的特性。在部分操作系统中应用。 安全系统的形式化模型 Harrison 等人 (1976) 在保护矩阵上确定了 6 种最基本的操作，这些操作可用作任何安全系统模型的基准。这些最基本的操作是 create object、delete object、create domain、delete domain、insert right 和 remove right。合并称为保护命令 多级安全 大多数操作系统允许个人用户来决定谁可以读写他们的文件和其他对象。这一策略称为可自由支配的访问控制 部分场景需要强制性的访问控制来确保所阐明的安全策峈被系统强制执行，而不是可自由支配的访问控制。这些强制性的访问控制管理整个信息流，确保不会泄漏那些不应该泄漏的信息。 Bell-LaPadula 模型 简易安全规则：在密级 k 上面运行的进程只能读取同一密级或更低密级的对象。例如，将军可以读取中尉的文档，但中尉却不可以读取将军的文档。 *规则： 在密级 k 上面运行的进程只能写同一密级或更高密级的对象。例如，中尉只能在将军的信箱添加信息告知自己所知的全部，但是将军不能在中尉的信箱里添加信息告知自己所知的全部，因为将军拥有绝密的文档，这些文档不能泄露给中尉。 Biba 模型： 简单完整性规则 ：在安全等级 k 上运行的进程只能写同一等级或更低等级的对象（没有往上写）。 完整性＊规则：在安全等级 k 上运行的进程只能读同一等级或更高等级的对象（不能向下读）。 隐蔽信道 系统通过精心设计的方式来通信，而不被察觉 隐写术：将信息编码到其他的文件中，用于隐蔽地泄漏信息 密码学原理 加密的目的是将明文一也就是原始信息或文件，通过某种手段变为密文，通过这种手段，只有经过授权的人才知道如何将密文恢复为明文。对无关的人来说，密文是一段无法理解的编码 在算法中使用的加密参数叫作密钥 (key) 。如果 P 代表明文，从代表加密密钥，C 代表密文，E 代表加密算法法（即，函数），那么 \(C=E(P,K_E)\) 。这就是加密的定义 私钥加密技术 对于给定了加密密钥就能够较为容易地找到解密密钥，反之亦然。这样的系统采用了私钥加密技术或对称密钥加密技术 公钥加密技术 这一体系的特点是加密密钥和解密密钥是不同的，并且当给出了一个筛选过的加密密钥后不可能推出对应的解密密钥。在这种特性下，加密密钥可被公开而只有解密密钥处于秘密状态。 一种叫作 RSA 的公钥机制表明：对计算机来说，大数乘法比对大数进行因式分解要容易得多，特别是在使用取换算法进行运算且每个数字都有上百位时 。这种机制广泛应用干密码领域。其他广泛使用的还有离散对数 。公钥机制的主要问题在于运算速度要比对称密钥机制慢数千倍。 当我们使用公钥密码体系时，每个人都拥有一对密钥（公钥和私钥）井把其中的公钥公开．公钥是加密密钥，私钥是解密密钥。通常密钥的运算是自动进行的，有时候用户可以自选密码作为算法的种子．在发送机密信息时，用接收方的公钥将明文加密。由于只有接收方拥有私钥，所以也只有接收方可以解密信息。 单向函数，我们将看到有些函数 f, 其特性是给定 f 和参数 x, 很容易计算出 y =f(x).</description></item><item><title>现代操作系统::多处理器系统</title><link>/notes/modern_operating_systems_multiple_processor_systems/</link><pubDate>Wed, 21 Jul 2021 02:11:01 +0800</pubDate><guid>/notes/modern_operating_systems_multiple_processor_systems/</guid><description>多处理器系统 多处理机 共享存储器多处理机是这样一种计算机系统，其两个或更多的 CPU 全部共享访问一个公用的 RAM。 CPU 可对存储器的某个字写入某个值，然后读回该字，并得到一个不同的值。在进行恰当组织时，这种性质构成了处理器间通信的基础:一个 CPU 向存储器写人某些数据而另一个读取这些数据。 多处理器硬件 所有的多处理机都具有每个 CPUi 可访问全部存储器的性质 UMA 多处理器读出每个存储器字的速度是一样快的，NUMA 没有这种特性 基于总线的 UMA 多处理器结构 两个或更多的 CPU 以及一个或多个存储器模块都使用同一个总线进行通信 当一个 CPU 需要读一个存储器字 (memory word) 时，它首先检查总线忙否。 如果总线空闲，该 CPU 把所需字的地址放到总线上，发出若干控制信号，然后等待存储器把所需的字放到总线上。当 CPU 核数上升时，效率下降严重。 解决方案是为每个 CPU 添加一个高速缓存 高速缓存可以位于 CPU 芯片的内部、 CPU 附近、在处理器板上或所有这三种方式的组合 高速缓存 不以单个字为基础，而是以 32 字节或 64 字节块为基础 高速缓存一致性协议 CPU 试图在一个或多个远程高速缓存中写入一个字，总线硬件检测到写，并把一个信号放到总线上通知所有其他的高速缓存。如果其他高速缓存有个“干净&amp;quot;的副本，也就是同存储器内容完全一样的副本，那么它们可以丢弃该副本井让写者在修改之前从存储器取出高速缓存块。如果某些其他高速缓存有&amp;quot;脏&amp;quot;(被修改过)副本，它必须在处理写之前把数据写回存储器或者把它通过总线直接传送到写者上。 基于交叉开关的 UMA 多处理机 连接 n 个 CPU 到 K 个存储器的最简单的电路是交叉开关 水平线(进线)和垂直线(出线)的每个相交位咒上是一个交叉点 (crosspoint)。交叉点是一个小 的电子开关，具体取决千水平线和垂直线是否偕要连接。 非阻塞网络 使用多级交换网络的 UMA 多处理机 有一种完全不同的、基于简单 2 x 2 开关的多处理机设计。 这个开关有两个输入和两个输出。到达任意一个输入线的消息可以被交换至任意一个输出线上。就我们的目标而言，消息可由四个部分组成。Module (模块)域指明使用哪个存储器。Address (地址)域指定在模块中的地址。Opcode (操作码)给定了操作，如 READ 或 WRITE。最后，在可选的 Value (值)域中可包含一个操作数，比如一个要被 WRITE 写入的 32 位字。该开关检查 Module 域并利用它确定消息是应该送给 X 还是发送给 Y。 这个 2 x 2 开关可有多种使用方式，用以构建大型的多级交换网络。 有一种是简单经济的 omega 网络， Omega 网络的接线模式常被称作全混洗(perfect shuffle)。 接着看看 Omega 网络是如何工作的，假设 CPU 011 打算从存储器模块 110 读取一个字。CPU 发送 READ 消息给开关 1D, 它在 Module 域包含 110。ID 开关取 110 的首位(最左位)并用它进行路由处理。0 路由到上端输出，而 1 的路由到下端，由于该位为 1, 所以消息通过低端输出被路由到 2D。 所有的第二级开关，包括 2D,取用第二个比特位进行路由。这.</description></item><item><title>现代操作系统::虚拟化与云</title><link>/notes/modern_operating_systems_virtualization_and_the_cloud/</link><pubDate>Tue, 20 Jul 2021 02:11:01 +0800</pubDate><guid>/notes/modern_operating_systems_virtualization_and_the_cloud/</guid><description>虚拟化与云 介绍 在一个虚拟化系统中，不同的服务器可以运行在不同的虚拟机上，从而以更低的开销和更好的可维护性保留多计算机系统具有的局部故障模型。而且，可以在同一硬件上运行多个不同的操作系统，并享受虚拟机隔离带来的安全性和其他好处。 虚拟化技术有效的前提是绝大多数服务中断不是硬件缺陷造成的，而是由与软件设计不周、不可靠、有缺陷、配置不当造成的，特别是操作系统。 物理机数址的减少节省了硬件和电力开销以及机架空间的占用。 虚拟化技术还能在尝试新想法时提供帮助 虚拟机的另一个优势是设置检查点和虚拟机迁移(例如跨多台胀务器进行负载均衡)比在普通操作系统上运行的迁移要容易得多 在已停止支持或无法工作于当前硬件的操作系统(或操作系统版本)上运行遗留应用程序。 协助软件开发。程序员不需要在多台机器上安装不同操作系统来保证软件能在不同系统上运行。 虚拟化技术目前最重要最时髦的用途是云。云的核心思想很直接:将你的计箕或存储需求外包给一个管理良好的数据中心。 历史 20 世纪 60 年代，IBM 开发了 SIMMON 和 CP-40，运行在 System/360，重新实现成 CP-67 1974 年，加拿大的两位计算机科学家发表论文定义了一个计算机体系结构有效支持虚拟化所需满足的条件 20 世纪 90 年代，VMware 成立，后续 Xen，KVM，VirtualBox，Hyper-V，Parallels 也相继出现。 虚拟化的必要条件 虚拟机管理程序需要实现良好的表现 安全性: 虚拟机管理程序应完全掌控虚拟资源。 保真性: 程序在虚拟机上执行的行为应与在裸机上相同. 高效性: 虚拟机中运行的大部分代码应不受虚拟机管理程序的干涉。 安全性 解释器(例如 Bochs)中逐条考虑指令井准确执行其行为是一种安全执行指令的方式。 保真性 每个包含内核态和用户态的 CPU 都有一个特殊的指令集合，其中的指令在内核态和用户态执行的行为不同。这些指令包括进行 I/O 操作和修改 MMU 设置的指令，Popek 和 Goldberg 称之为敏感指令 (sensitive instruction)。 还有另一个指令集合，其中的指令在用户态执行时会导致陷人，Popek 和 Goldberg 称之为特权指令 他们的论文首次指出机器可虚拟化的一个必要条件是敏感指令为特权指令的子集 Intel 和 AMD 在 CPU 中引入虚拟化支持 VT，使问题得以解决。VM 技术的基本思想是创建可以运行虚拟机的容器。客户操作系统在容器中启动井持续运行，直到触发异常并陷入虚拟机管理程序 半虚拟化 半虚拟化提供一层类似物理机器的软件接口，显式暴露出自身是一个虚拟化的环境.例如，它提供一组虚拟化调用 (hypercall), 允许客户机向虚拟机管理程序发送显式的请求，就像系统调用为应用程序提供服务那样。客户机使用虚拟化调用执行特权操作，如修改页表等，但由于操作是客户机和虚拟机管理程序协作完成的，因此整个系统更加简单快速。 第一类和第二类虚拟机管理程序 第一类虚拟机管理程序就像一个操作系统，因为它是唯一一个运行在最高特权级的程序。 它的工作是支持真实硬件的多个虚拟机 (virtual machine) 拷贝，类似千普通操作系统支持的进程。 第二类虚拟机管理程序则不同。它是一个依赖于 Windows、 Linux 等操作系统分配和调度资源的程序，很像一个普通的进程。寄托于宿主操作系统提供大量的功能。 高效虚拟化技术 在不支持虚拟化的平台上实现虚拟化 虚拟机上的操作系统认为自己运行在内核态(实际上不是)。我们称之为虚拟内核态。 在不支持 VT 的 CPU 上，执行内核态才能执行指令会失败井导致操作系统崩溃。在支持 VT 的 CPU 上， 客户操作系统执行敏感指令时，会陷入虚拟机管理程序，虚拟机管理程序可以检查这条指令是由虚拟机中的客户操作系统执行的还是用户程序执行的。如果是前者，虚拟机管理程序将安排这条指令功能的正确执行。否则，虚拟机管理程序将换拟其实硬件面对用户态执行敏感指令时的行为。 在不支持 VT 的平台上，软件工程师们利用二进制翻译和 x86 平台确实存在的硬件特性(如处理器的特权级)构建出了虚拟机系统。 进制翻译器改写运行在第 1 级的客户操作系统，虚拟机管理程序运行在第 0 级 直接运行客户机代码井使用完全相同的技术需要第二类虚拟机管理程序能在最底层操纵硬件，这在用户态无法实现，因此，大多数现代的第二类虚拟机管理程序有一个在第 0 级运行的内核模块，能够使用特权指令操纵硬件。 虚拟化的开销 VT 硬件使用的陷入井模拟方法会产生大量陷入，而陷入在现代硬件上开销很大，因为 CPU 高速缓存、 TLB、转移预测都会受到不利影响。 使用二进制翻译后，代码既有可能变快，也有可能变慢。替换了部分需要陷入的指令。 虚拟机管理程序是真正的微内核吗 第一类和第二类虚拟机管理程序都支持未修改的客户操作系统，但需要费尽于辛万苦才能取得较好 的性能 半虚拟化 采取了不同的方法，要求修改客户操作系统的諒代码。半虚拟化的客户机执行虚拟化调用而不是敏感指令，这套调用接口实际上构成了应用编程接口 (Application Programming Interface, API), 虽然接口由客户操作系统而非应用程序使用。 移除客户操作系统中的所有敏感指令，只让它通过虚拟化调用访问 I/O 等系统服务，就将虚拟机管理程序变成了微内核 内存虚拟化 对每台虚拟机，虚拟机管理程序都需要创建一个影子页表, 将虚拟机使用的虚拟页映射到它分配给虚拟机的实际物理页上。 嵌套页表的硬件支持 使用影子页表会造成巨大的开销。 芯片生产商添加了嵌套页表 (nested page table) 的硬件支持。在无需陷入的悄况下由硬件处理虚拟化引发的额外页表操作，以降低开销。 回收内存 一个小的气球模块作为伪设备驱动程序加载到每个虚拟机中，与虚拟机管理程序通信。气球模块在虚拟机管理程序的请求下可以通过申请锁定页面来膨胀，也可以通过释放这些页面而紧缩。气球膨胀，客户机的实际可用物理内存减少，客户操作系统将以换出最不重要页面的方式响应这一变化，正如期望的那样。反过来，气球紧缩，客户机可用内存增加。虚拟机管理程序让操作系统来帮它作决定，通俗地讲这叫踢皮球。 I/O 虚拟化 I/O MMU 设备隔离 设备域 单根 I/O 虚拟化 虚拟应用 软件开发人员可以精心构造一个虚拟机.</description></item><item><title>现代操作系统::死锁</title><link>/notes/modern_operating_systems_deadlock/</link><pubDate>Mon, 19 Jul 2021 02:11:01 +0800</pubDate><guid>/notes/modern_operating_systems_deadlock/</guid><description>死锁 资源 需要排他性使用的对象称为资源 硬件资源，打印机，蓝牙驱动器 一组信息，数据库中加锁的数据 可抢占资源 可以从拥有它的进程中抢占而不会产生任何副作用，存储器就是一类可抢占的资源 不可抢占资源 在不引起相关的计算失败的情况下，无法把它从占有它的进程处抢占过来 某个资源是否可抢占取决干上下文环境。在一台标准的 PC 中，内存中的页面总是可以置换到磁盘中并置换回来，故内存是可抢占的。但是在一部不支持交换和页面调度的智能机上，仅通过将内存消耗大户交换出来是不能避免死锁的。 总的来说，死锁与不可抢占资源有关，有关可抢占资源的潜在死锁通常可以通过在进程之间重新分配资源而化解。 若请求时资源不可用，则请求进程被迫等待。某些进程会自动阻塞，有一些会发挥错误代码并在稍后重试。 资源获取 对于数据库系统中的记录这类资源，应该由用户进程来管理其使用. 一种允许用户管理资源的可能方法是为每一个资源配置一个信号量。 死锁简介 如果一个进在集合中的每个进在都在等持只能由该进在集合中的其他进程才能引发的事件，那么，该进在集合就是死锁的. 资源死锁的条件，同时满足以下四个条件 互斥条件.每个资源要么已经分配给了一个进程，要么就是可用的 占有和等待条件。已经得到了某个资源的进程可以再请求新的资源。 不可抢占条件。已经分配给一个进程的资源不能强制性地被抢占，它只能披占有它的进程显式地释放。 环路等待条件。死锁发生时，系统中一定有由两个或两个以上的进程组成的一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 死锁建模 Holt 指出如何用有向图建立上述四个条件的模型。在有向图中有两类节点:用圆形表示的进程，用方形表示的资源。从资源节点到进程节点的有向边代表该资源已被请求、授权井被进程占用。由进程节点到资源节点的有向边表明当前进程正在请求该资源，并且该进程已被阻塞，处于等待该资源的状态。 有四种处理死锁的策眳 忽略该问题。也许如果你忽略它，它也会忽略你。 检测死锁井恢复。让死锁发生，检测它们是否发生，一旦发生死锁，采取行动解决问题。 仔细对资源进行分配，动态地避免死锁。 通过破坏引起死锁的四个必要条件之一，防止死锁的产生。 鸵鸟算法 假装根本没有问题发生 死锁检测和死锁恢复 每种类型一个资源的死锁检测 构造一张资源分配图，从中检测有向环图 每种类型多个资源的死锁检测 现在我们提供一种基于矩阵的算法来检测从 p1 到 pn 这 n 个进程中的死锁。 假设资源的类型数为 m, E1 代表资源类型 1, E2 代表资源类型 2, Ei 代表资源类型 i。E 是现有资源向量 (existing resource vector) , 现在我们需要两个数组:C 代表当前分配矩阵 (current allocation matrix), R 代表请求矩阵 (request matrix)。 C 的第 i 行代表 Pi 当前所持有的每一种类型资源的资源数。所以，Cij 代表进程 i 所持有的资源 j 的数量。同理，Rij 代表 Pi 所需要的资源 j 的数量。 每个进程起初都是没有标记过的。算法开始会对进程做标记，进程被标记后就表明它们能够被执行，不会进入死锁。当算法结束时，任何没有标记的进程都是死锁进程。该算法假定了一个最坏悄形:所有的进程在退出以前都会不停地获取资源。 死锁检测算法如下: 寻找一个没有标记的进程 Pi, 对于它而言 R 矩阵的第 i 行向让小于或等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转到第 1 步。 如果没有这样的进程，那么算法终止。 从死锁中恢复 利用抢占恢复：在不通知原进程的情况下，将某一资源从一个进程强行取走给另一个进程使用，接着又送回，这种做法是否可行主要取决于该资源本身的特性。用这种方法恢复通常比较困难或者说不太可能。若选择挂起某个进程，则在很大程度上取决干哪一个进程拥有比较容易收回的资源。 利用回滚恢复：周期性地对进程进行检查点检查，进程检查点检查查就是将进程的状态写入一个文件以备以后重启。该检查点中不仅包括存储映像，还包括了资源状态，即哪些资源分配给了该进程。一旦检测到死锁，就很容易发现需要哪些资源。为了进行恢复，要从一个较早的检查点上开始，这样拥有所需要资源的进程会回滚到一个时间点，在此时间点之前该进程获得了一些其他的资源。在该检查点后所做的所有工作都丢失。 通过杀死进程恢复：最直接也是最简单的解决死锁的方法是杀死一个或若干个进程。一种方法是杀掉环中的一个进程。如果走运的话，其他进程将可以继续。如果这样做行不通的话，就需要继续杀死别的进程直到打破死锁环。另一种方法是选一个环外的进程作为牺牲品以释放该进程的资源。在使用这种方法时，选择一个要被杀死的进程要特别小心，它应该正好持有环中某些进程所需的资源.</description></item><item><title>现代操作系统::输入/输出</title><link>/notes/modern_operating_systems_input_output/</link><pubDate>Sun, 18 Jul 2021 02:11:01 +0800</pubDate><guid>/notes/modern_operating_systems_input_output/</guid><description>输入/输出 I/O 硬件原理 I/O 设备 分类 块设备，块设备把信息存储在固定大小的块中.每个块有自己的地址。通常块的大小在 512 字节至 65536 字节之间。所有传输以一个或多个完整的(连续的)块为单位。块设备的基本特征是每个块都能独立干其他块而读写。硬盘、蓝光光盘和 USB 盘是最常见的块设备。 字符设备，字符设备以字符为单位发送或接收一个字符流，而不考虑任何块结构。字符设备是不可寻址的，也没有任何寻道操作。打印机、鼠标、键盘以及大多数与磁盘不同的设备都可以看作字符设备。 设备控制器 I/O 设备一般由机械部件和电子部件两部分组成。通常可以将这两部分分开处理，以提供更加模块化和更加通用的设计。电子部件称作设备控制器 (device controller) 或适配器 (adapter)。在个人计算机上，它经常以主板上的芯片的形式出现，或者以插入 (PCI) 扩展槽中的印刷电路板的形式出现。机械部件则是设备本身。 控制器与设备之间的接口通常是一个很低层次的接口。 控制器的任务是把串行的位流转换为字节块，井进行必要的错误校正工作。 内存映射 I/O 每个控制器有几个寄存器用来与 CPU 进行通信。通过写人这些寄存器，操作系统可以命令设备发送数据接收数据、开启或关闭，或者执行某些其他操作。通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等。 除了这些控制寄存器以外，许多设备还有一个操作系统可以读写的数据缓冲区。 每个控制寄存器被分配一个 I/O 端口 (I/O port) 号，这是一个 8 位或 16 位的整数。所 有 I/O 端口形成 I/O 端口空间 (I/O port space), 井且受到保护使得普通的用户程序不能对其进行访问(只有操作系统可以访问)。CPU 通过这个 I/O 端口和控制器通信。 另一种方式是将所有控制寄存器映射到内存空间中，每个控制寄存器被分配唯一的一个内存地址，井且不会有内存被分配这一地址。这样的系统称为内存映射 I/O 直接存储器存取 CPU 从 I/O 控制器请求数据浪费 CPU 时间，所以经常用到一种称为直接存储器存取的方案。 DMA 的工作过程 CPU 通过设置 DMA 控制器的寄存器对它进行编程，所以 DMA 控制器知道将什么数据传送到什么地方。 DMA 控制器通过在总线上发出一个读请求到磁盘控制器而发起 DMA 传送 磁盘控制器从其内部缓冲区读取内容后，写到内存中。 当写操作完成时，磁盘控制器在总线上发出一个应答信号到 DMA 控制器 DMA 控制器步增要使用的内存地址，井且步减字节计数。如果字节计数仍然大于 O, 则重复第 2 步到第 4 步，直到字节计数到达 0。此时，DMA 控制器将中断 CPU 以便让 CPU 知道传送现在已经完成了。当操作系统开始工作时，用不着将磁盘块复制到内存中，因为它已经在内存中了。 总线操作模式 字模式：DMA 控制器请求传送一个字并且得到这个字。如果 CPU 也想使用总线，它必须等待。这一机制称为周期窃取(cycle stealing),因为设备控制器偶尔偷偷溜入并且从 CPU 偷走一个临时的总线周期，从而轻微地延迟 CPU。 块模式：在块模式中，DMA 控制器通知设备获得总线，发起一连串的传送，然后释放总线。这一操作形式称为突发模式 (burst mode)。它比周期窃取效率更高，因为获得总线占用了时间，井且以一次总线获得的代价能够传送多个字。突发模式的缺点是，如果正在进行的是长时间突发传送，有可能将 CPU 和其他设备阻塞相当长的周期。 飞跃模式：DMA 控制器通知设备控制器直接将数据传送到主存。某些 DMA 控制器使用的其他校式是让设备控制器将字发送给 DMA 控制器.</description></item><item><title>现代操作系统::文件系统</title><link>/notes/modern_operating_systems_file_system/</link><pubDate>Sat, 17 Jul 2021 11:01:25 +0800</pubDate><guid>/notes/modern_operating_systems_file_system/</guid><description>文件系统 文件 文件命名 文件是一种抽象机制，它提供了一种在磁盘上保存信息而且方便以后读取的方法。这种方法可以使用户不必了解存储信息的方法、位置和实际磁盘工作方式等有关细节。 文件的具体命名规则在各个系统中是不同的，不过所有的现代操作系统都允许用 1 至 8 个字母组成的字符串作为合法的文件名。 有些文件系统区分大小写字母，有些则不区分。 UNIX 属于前一类，老的文件系统 MS-DOS 则属于后一类。 许多操作系统支持文件名用圆点隔开分为两部分，如文件名 prog.c。圆点后面的部分称为 文件扩展 名 (file extension) 在某些系统中(如所有 UNIX 版本)，文件扩展名只是一种约定，操作系统井不强迫采用它。Windows 关注扩展名且对其赋予了含义。 文件结构 字节序列，一种无结构的字节序列，只对特定程序有意义，目前主流操作系统采取的方案。 记录序列，文件是具有固定长度记录的序列，每个记录都有其内部结构。把文件作为记录序列的中心思想是:读操作返回一个记录，而写操作重写或追加一个记录。穿孔卡片采用的方案。 树，这种结构中由一棵记录树构成，每个记录不必具有相同的长度，记录的固定位置上有一个键字段。可以根据特定字段找到记录的位置，在一些处理商业数据的服务器上采用。 文件类型 普通文件，含有包含用户信息的文件。 ASCII 文件，有多行正文组成，可以显示打印和用编辑器编辑。 二进制文件，有特定结构，只对使用该结构的程序有意义。 目录，管理文件系统结构的系统文件。 字符特殊文件，与输入/输出有关，用于串行 I/O 类设备，如终端、打印机、网络等 块特殊文件用于磁盘类设备 文件访问 顺序访问，从头按顺序读取文件的全部字节或记录，但不能跳过某一些内容，也不能不按顺序读取。 随机访问文件，能够以任何次序读取其中字节或记录。 文件属性 名字 权限 创建时间 加锁标记 等等 文件操作 create。创建不包含任何数据的文件。该调用的目的是表明文件即将建立，井设置文件的一些属性。 delete。当不再需要某个文件时，必须删除该文件以释放磁盘空间。任何文件系统总有一个系统调用用来删除文件。 open。在使用文件之前，必须先打开文件。open 调用的目的是:把文件属性和磁盘地址表装入内存，便于后续调用的快速访问。 close。访问结束后，不再需要文件属性和磁盘地址，这时应该关闭文件以释放内部表空间。很多系统限制进程打开文件的个数，以鼓励用户关闭不再使用的文件。磁盘以块为单位写入，关闭文件时，写入该文件的最后一块，即使这个块还没有满。 read。在文件中读取数据。 一般地，读取的数据来自文件的当前位置。调用者必须指明需要读取多少数据，并且提供存放这些数据的缓冲区。 write。向文件写数据，写操作一般也是从文件当前位置开始。如果当前位置是文件末尾，文件长度增加。如果当前位置在文件中间，则现有数据被覆盖，并且永远丢失。 append。此调用是 write 的限制形式，它只能在文件末尾添加数据。若系统只提供最小系统调用集合，则通常没有 append。很多系统对同一操作提供了多种实现方法，这些系统中有时有 append 调用. seek。对干随机访问文件，要指定从何处开始获取数据，通常的方法是用 seek 系统调用把当前位置指针指向文件中特定位置。 seek 调用结束后，就可以从该位置开始读写数据了。 get attributes。进程运行常需要读取文件属性。例如， UNIX 中 make 程序通常用于管理由多个源文件组成的软件开发项目。在调用 make 时，它会检查全部源文件和目标文件的修改时间，实现最小编译，使得全部文件都为最新版本。为达到此目的，需要查找文件的某一些属性，即修改时间。 set attributes。某些属性是可由用户设置的，甚至是在文件创建之后，实现该功能的是 set attributes 系统调用。保护模式信息是一个典型的例子，大多数标志也属于此类属性。 rename。用户常常要改变已有文件的名字， rename 系统调用用于这一目的。严格地说， rename 系统调用不是必需的，因为先把文件复制到一个新文件中，然后删除原来的文件，就可以达到同样的目的。 目录 一级目录系统 目录系统的最简单形式是在一个目录中包含所有的文件。这有时称为根目录 层次目录系统 用户可以创建任意数量的子目录，每个目录又可以继续创建子目录。 路径名 绝对路径名，路径名从根目录开始，不同路径之间用&amp;rsquo;/&amp;lsquo;分割 相对路径名，从当前工作目录开始，‘.</description></item><item><title>现代操作系统::内存管理</title><link>/notes/modern_operating_systems_memory_manage/</link><pubDate>Fri, 16 Jul 2021 09:39:03 +0800</pubDate><guid>/notes/modern_operating_systems_memory_manage/</guid><description>内存管理 操作系统中管理分层存储器体系的部分称为存储管理器 (memory manager)。它的任务是有效地管理内存，即记录哪些内存是正在使用的，哪些内存是空闲的，在进程需要时为其分配内存，在进程使用完后释放内存。 无存储器抽象 最简单的存储器抽象就是根本没有抽象。 每一个程序都直接访问物理内存。在这种情况下，要想在内存中同时运行两个程序是不可能的。 在不使用存储器抽象的情况下运行多个程序 操作系统只需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入到内存中再运行即可。只要在某一个时间内存中只有一个程序，那么就不会发生冲突。 在特殊硬件的帮助下，即使没有交换功能，井发地运行多个程序也是可能的。 IBM 360 的早期模型是这样解决的:内存被划分为 2KB 的块，每个块被分配一个 4 位的保护键，保护键存储在 CPU 的特殊寄存器中。一个内存为 1MB 的机器只需要 512 个这样的 4 位寄存器，容量总共为 256 字节。PSW (Program Status Word, 程序状态字)中存有一个 4 位码。一个运行中的进程如果访问保护键与其 PSW 码不同的内存，360 的硬件会捕获到这一事件。因为只有操作系统可以修改保护键，这样就可以防止用户进程之间、用户进程和操作系统之间的互相干扰。引用了绝对物理地址会导致出错。 一种存储器抽象：地址空间 使用绝对物理地址的问题 用户可以访问每个地址，容易造成破坏 运行多个程序很困难 地址空间的概念 需要解决的问题 保护 重定向 地址空间是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址空间，井且这个地址空间独立于其他进程的地址空间 基址寄存器和界限寄存器 使用动态重定位，简单地把每个进程的地址空间映射到物理内存的不同部分。 经典办法是给每个 CPU 配置两个特殊硬件寄存器，通常叫作基址寄存器和界限寄存器。当使用基址寄存器和界限寄存器时，程序装载到内存中连续的空闲位置且装载期间无须重定位，每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前，自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。如果访问的地址超过了界限，会产生错误并中止访问。 对基址寄存器和界限寄存器会以一定的方式加以保护，使得只有操作系统可以修改它们。 使用基址寄存器和界限寄存器重定位的缺点是，每次访问内存都需要进行加法和比较运算。比较运算可以做得很快，但是加法运算由于进位传递时间的问题，在没有使用特殊电路的情况下会显得很慢。 交换技术 内存容量优先，多进程存在内存超载的问题。 交换 即把一个进程完整调入内存，使该进程运行一段时间，然后把它存回磁盘。空闲进程主要存储在磁盘上，所以当它们不运行时就不会占用内存。 交换在内存中产生了多个空闲区 (hole, 也称为空洞)，通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块。该技术称为内存紧缩 (memory compaction)。通常不进行这个操作，因为它要耗费大量的 CPU 时间。 进程的数据段可以增长，系统如何分配内存。一种可用的方法是，当换入或移动进程时为它分配一些额外的内存。 空闲内存管理 使用位图的存储管理 使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲， 1 表示占用(或者相反) 分配单元的大小是一个重要的设计因素。分配单元越小，位图越大。 这种方法的主要问题是，在决定把一个占 k 个分配单元的进程调人内存时，存储管理器必须搜索位图，在位图中找出有 k 个连续 0 的串。查找位图中指定长度的连续 0 串是耗时的操作(因为在位图中该串可能跨越字的边界)，这是位图的缺点。 使用链表的存储管理 维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个结点或者包含一个进程，或者是两个进程间的一块空闲区。 分配算法 首次适配 存储管理器沿若段链表进行搜索，直到找到一个足够大的空闲区，除非空闲区大小和要分配的空间大小正好一样，否则将该空闲区分为两部分，一部分供进程使用，另一部分形成新的空闲区。首次适配算法是一种速度很快的算法，因为它尽可能少地搜索链表结点。 下次适配 它的工作方式和首次适配算法法相同，不同点是每次找到合适的空闲区时都记录当时的位置，以便在下次寻找空闲区时从上次结束的地方开始搜索，而不是像首次适配算法那样每次都从头开始。 最佳适配 最佳适配算法搜索整个链表，找出能够容纳进程的最小的空闲区。最佳适配算法试图找出最接近实际需要的空闲区，以最好地匹配请求和可用空闲区，而不是先拆分一个以后可能会用到的大的空闲区。 因为每次调用最佳适配算法时都要搜索整个链表，所以它要比首次适配算法慢。让人感到有点意外的是，它比首次适配算法或下次适配算法浪费更多的内存，因为它会产生大址无用的小空闲区。 最差适配 总是分配最大的可用空闲区，使新的空闲区比较大从而可以继续使用。仿真程序表明最差适配算法也不是一个好主意。 快速适配 它为那些常用大小的空闲区维护单独的链表。 虚拟内存 每个程序拥有自己的地址空间，这个空间被分割成多个块，每一块称作一页或页面(page)。每一页有连续的地址范围。这些页被映射到物理内存，但井不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把 CPU 交给另一个进程使用.</description></item><item><title>现代操作系统::进程与线程</title><link>/notes/modern_operating_systems_process_and_thread/</link><pubDate>Thu, 15 Jul 2021 09:39:03 +0800</pubDate><guid>/notes/modern_operating_systems_process_and_thread/</guid><description>进程与线程 进程 一个进程就是一个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值。 进程的创建 4 种主要事件会导致进程的创建: 系统初始化 正在运行的程序执行了创建进程的系统调用 用户请求创建一个新进程 一个批处理作业的初始化 前台进程，与用户交互完成工作的进程 后台进程，与特定的用户没有关系，完成专门功能的进程，守护进程 在 UNIX 系统中，只有一个系统调用可以用来创建新进程:fork。这个系统调用会创建一个与调用进程相同的副本。在调用了 fork 后，这两个进程(父进程和子进程)拥有相同的内存映像、同样的环境字符串和同样的打开文件。这就是全部情形。通常 ，子进程接着执行 execve 或一个类似的系统调用，以修改其内存映像并运行一个新的程序。之所以要安排两步建立进程，是为了在 fork 之后但在 execve 之前允许该子进程处理其文件描述符，这样可以完成对标准输入文件、标准输出文件和标准错误文件的重定向。 在 UNIX 中，子进程的初始地址空间是父进程的一个副本，但是这里涉及两个不同的地址空间，不可写的内存区是共享的。某些 UNIX 的实现使程序正文在两者间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但这种情况下内存通过写时复制 (copy-on-write) 共享，这意味着一且两者之一想要修改部分内存，则这块内存首先被明确地复制，以确保修改发生在私有内存区域。 进程的终止 通常有以下几种情况会导致进程的终止 正常退出(自愿的)。 出错退出(自愿的). 严重错误(非自愿)。 被其他进程杀死(非自愿). 进程的层次结构 某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。 在 UNIX 中，进程和它的所有子进程以及后裔共同组成一个进程组。 进程的状态 运行态(该时刻进程实际占用 CPU)。 就绪态(可运行，但因为其他进程正在运行而暂时停止)。 阻塞态(除非某种外部事件发生，否则进程不能运行). 进程的实现 操作系统维护进程表 每个进程占用一个表项目，称为进程控制块，里面有程序运行的必要信息。 所有的中断都从保存寄存器开始，对于当前进程而言，通常是保存在进程表项中。 当一个 I/O 中断发生时，中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。 中断发生后操作系统最底层的工作步骤 硬件压人堆栈程序计数器等 硬件从中断向量装人新的程序计数器 汇编语言过程保存寄存器值 汇编语言过程设置新的堆栈 C 中断服务例程运行 (典型地读和缓冲输入) 调度程序决定下一 个将运行的进程 C 过程返回至汇编代码 汇编语言过程开始运行新的当前进程 一个进程在执行过程中可能被中断数千次，但关键是每次中断后被中断的进程都返回到与中断发生前完全相同的状态。 多道程序设计模型 采用多道程序设计可以提高 CPU 的利用率。 假设一个进程等待 I/O 操作的时间与其停留在内存中时间的比为 p。当内存中同时有 n 个进程时、则所有 n 个进程都在等待 I/O (此时 CPU 空转)的概率是\( p^n \)。CPU 的利用率由下面的公式给出: \(CPU 利用率=1-p^n\) 线程 线程的使用 人们需要多线程的主要原因是，在许多应用中同时发生若多种活动。其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准井行运行的多个顺序线程，程序设计校型会变得更简单。 在有了多线程概念之后，我们才加入了一种新的元素: 并行实体拥有共享同一个地址空间和所有可用数据的能力 线程比进程更轻量级，所以它们比进程更容易(即更快)创建，也更容易撤销。许多系统中，创建一个线程较创建一个进程要快 1~100 倍 如果存在着大量的计算和大量的 I/O 处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。 在多 CPU 系统中，多线程是有益的，在这样的系统中，真正的并行有了实现的可能 经典的线程模型 进程模型基于两种独立的概念:资源分组处理与执行。 进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。 进程拥有一个执行的线程，通常简写为线程 (thread)。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行.</description></item><item><title>现代操作系统::引论</title><link>/notes/modern_operating_systems_introduction/</link><pubDate>Wed, 14 Jul 2021 09:39:03 +0800</pubDate><guid>/notes/modern_operating_systems_introduction/</guid><description>引论 什么是操作系统 操作系统是一种运行在内核态的软件 为应用程序提供一个资源集的清晰抽象，并管理这些硬件资源，而不仅仅是一堆硬件 作为扩展机器的操作系统，创建好的抽象，并实现和管理它所创建的抽象对象。 作为资源管理者的操作系统，在相互竞争的程序之间有序地控制对处理器、存储器以及其他 I/O 接口设备的分配。 操作系统的历史 第一代 (1945 ~ 1955) : 真空管和穿孔卡片 第二代 (1955 ~ 1965) : 晶体管和批处理系统 第三代 (1965 ~ 1980) : 集成电路和多道程序设计 第四代 (1980 ~ ) :个人计算机 第五代 (1990 ~ ): 移动计算机 计算机硬件简介 处理器 专门的指令集 寄存器 程序计数器 保存了将要取出的下一条指令的内存地址 堆栈指针 指向内存中当前栈的顶端 程序状态字 这个寄存器包含了条件码位、CPU 优先级、模式(用户态或内核态)，以及各种其他控制位 通用寄存器 流水线 个 CPU 可以有单独的取指单元、解码单元和执行单元，于是当它执行指令 n 时，还可以对指令 n + 1 解码，井且读取指令 n + 2 超标量 CPU 两个或更多的指令被同时取出、解码并装入暂存缓冲区中，直至它们执行完毕.只要有一个执行单元空闲.就检查保持缓冲区中是否还有可处理的指令，如果有，就把指令从缓冲区中移出并执行之. 两种模式 内核态 用户态 系统调用 为了从操作系统中获得服务，用户程序必须使用系统调用(system call)以陷入内核井调用操作系统。TRAP 指令把用户态切换成内核态，并启用操作系统。 多线程和多核芯片 多线程允许 CPU 保持两个不同的线程状态，然后在纳秒级的时间尺度内来回切换。 多线程不提供其正的并行处理。在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级。 存储器 寄存器，纳秒数量级时间 高速缓存 个位数纳秒数量级时间 高速缓存命中 多级缓存 不同的缓存位置的影响 主存 易失性与非易失性存储介质 十位数纳秒数量级时间 闪存 电可擦除可编程内存 CMOS 存储器 磁盘 毫秒数量级时间 磁道 柱面 固态硬盘 虚拟内存机制 MMU 上下文切换 I/O 设备 设备控制器 插在电路板上的一块芯片或一组芯片 这块电路板物理地控制设备。它从操作系统接收命令 控制器的任务是为操作系统提供一个简单的接口 读写过程很复杂，控制器中经常安装一个小的嵌入式计算机，该嵌入式计算机运行为执行这些工作而专门编好的程序。 设备本身 本身有个相对简单的标准化接口 SATA 串行高级技术附件(Serial Advanced Technology Attachment) 由于实际的设备接口隐藏在控制器中，所以，操作系统看到的是对控制器的接口 设备驱动程序 将内核与设备驱动程序重新链接，然后重启动系统。 在一个操作系统文件中设置一个入口，并通知该文件需要一个设备驱动程序，然后重新启动系统。在系统启动时，操作系统去找寻所需的设备驱动程序井装载之。 操作系统能够在运行时接受新的设备驱动程序并且立即将其安装好，无须重启动系统。 每个设备控制器都有少址用千通信的寄存器 一个最小的磁盘控制器也会有用干指定磁盘地址、内存地址、扇区计数和方向(读或写)的寄存器。 要激活控制器，设备驱动程序从操作系统获得一条命令，然后翻译成对应的值，并写进设备寄存器中。所有设备寄存器的集合构成了 I/O 端口空间， 通信方式 在有些计算机中，设备寄存器被映射到操作系统的地址空间，不需要专门的 I/O 指令，用户程序可以被硬件阻挡在外，防止其接触这些存储器地址 另一些机器中，设备寄存器被放入一个专门的 I/O 端口空间中，每个寄存器都有一个端口地址。在这些机器中，提供在内核态中可使用的专门 IN 和 OUT 指令，供设备驱动程序读写这些寄存器用。 实现输入输出的方式 用户程序发出一个系统调用，内核将其翻译成一个对应设备驱动程序的过程调用。然后设备驱动程序启动 I/O 并在一个连续不断的循环中检查该设备，看该设备是否完成了工作(一般有一些二进制位用来指示设备仍在忙碌中)。当 I/O 结束后，设备驱动程序把数据送到指定的地方(若有此需要)，井返回。然后操作系统将控制返回给调用者。这种方式称为忙等待(busywaiting), 其缺点是要占据 CPU, CPU 一直轮询设备直到对应的 I/O 操作完成。 设备驱动程序启动设备并且让该设备在操作完成时发出一个中断。设备驱动程序在这个时刻返回。操作系统接若在需要时阻塞调用者井安排其他工作进行。当设备驱动程序检查到该设备的操作完毕时，它发出一个中断通知操作完成。 为 I/O 使用一种特殊的直接存储器访问 (Direct Memory Access, DMA) 芯片，它可以控制在内存和某些控制器之间的位流，而无须持续的 CPU 干预。 CPU 对 DMA 芯片进行设置，说明需要传送的字节数、有关的设备和内存地址以及操作方向，接着启动 DMA。当 DMA 芯片完成时，它引发一个中断，其处理方式如前所述。 总线 主板上有很多不同作用的总线 PCIe 总线是 PCI 总线的继承者，PCI 总线是为了取代原来的 ISA 总线，速度快 USB，将所有慢速 I/O 设备与计算机连接，是一种集中式总线 SCSI，是一种高速总线，用在高速硬盘、扫描仪和其他需要较大带宽的设备上。 启动计算机 主板上有一块称为 BIOS 的程序，存储在非易失性存储介质中 主板加电，BIOS 开始运行，检查设备 根据 CMOS 存储的设备清单启动设备，从启动分区读入操作系统，启动它 操作系统访问 BIOS，获取设备信息，加载设备驱动程序，初始化相关程序。 操作系统大观园 大型机操作系统 用于大型机的操作系统主要面向多个作业的同时处理，多数这样的作业需要巨大的 I/O 能力。系统主要提供三类服务:批处理、事务处理和分时。 服务器操作系统 它们在服务器上运行，服务器可以是大型的个人计算机、工作站，甚至是大型机。它们通过网络同时为若干个用户服务，并且允许用户共享硬件和软件资源。 多处理器操作系统 获得大量联合计算能力的常用方式是将多个 CPU 连接成单个的系统。依据连接和共享方式的不同，这些系统称为并行计算机、多计算机或多处理器。它们需要专门的操作系统，不过通常采用的操作系统是配有通信、连接和一致性等专门功能的服务器操作系统的变体。 个人计算机操作系统 现代个人计算机操作系统都支持多道程序处理，在启动时，通常有几十个程序开始运行 。它们的功能是为单个用户提供良好的支持。 掌上计算机操作系统 大多数设备基于的是多核 CPU、GPS、摄像头及其他的传感器、大量内存和精密的操作系统。 嵌入式操作系统 嵌入式系统在用来控制设备的计算机中运行，这种设备不是一般意义上的计算机，井且不允许用户安装软件 。 传感器节点操作系统 每个传感器节点是一个配有 CPU、RAM、ROM 以及一个或多个环境传感器的实实在在的计算机。节点上运行一个小型但是真实的操作系统，通常这个操作系统是事件驱动的，可以响应外部事件，或者基于内部时钟进行周期性的测量。 实时操作系统 这些系统的特征是将时间作为关键参数。工控系统，民航，军事用途。硬实时操作系统。 多媒体，数字音频，软实时操作系统，允许一定延迟。 智能卡操作系统 智能卡是一种包含一块 CPU 芯片的信用卡。它有非常严格的运行能耗和存储空间的限制。其中，有些智能卡只具有单项功能，如电子支付，但是其他的智能卡则拥有多项功能.</description></item><item><title>计算机网络自顶向下方法::计算机网络中的安全</title><link>/notes/computer_network_a_topdown_approach_08/</link><pubDate>Sat, 19 Jun 2021 20:28:06 +0800</pubDate><guid>/notes/computer_network_a_topdown_approach_08/</guid><description>什么是网络中的安全 机密性 (confidentiality)。仅有发送方和希望的接收方能够理解传输报文的内容因为窃听者可以截获报文，这必须要求报文在一定程度上进行加密(encrypted),使截取的报文无法被截获者所理解。机密性的这个方面大概就是通常意义上对于术语安全通信的理解。 报文完整性 (message integrity)。Alice 和 Bob 希望确保其通信的内容在传输过程中未被改变——或者恶意篡改或者意外改动。我们在可靠传输和数据链路协议中遇到的检验和技术在扩展后能够用于提供这种报文完整性。 端点鉴别(end-point authentication)。发送方和接收方都应该能证实通信过程所涉及的另一方，以确信通信的另一方确实具有其所声称的身份。人类的面对面通信可以通过视觉识别轻易地解决这个问题。当通信实体在不能看到对方的媒体上交换报文时，鉴别就不是那么简单了。当某用户要访问一个邮箱时，邮件服务器如何证实该用户就是他所声称的那个人呢。 运行安全性(operational security)。几乎所有的机构（公司、大学等）今天都有了与公共因特网相连接的网络。这些网络都因此潜在地能够被危及安全。攻击者能够试图在网络主机中安放蠕虫，获取公司秘密，勘察内部网络配置并发起 DoS 攻击。我们将看到诸如防火墙和入侵检测系统等运行设备正被用于反制对机构网络的攻击。防火墙位于机构网络和公共网络之间，控制接入和来自网络的分组。入侵检测系统执行“深度分组检查“任务，向网络管理员发出有关可疑活动的警告。 密码学的原则 对称密钥密码体制 历史上的单密码 凯撒密码 单密码替换 多码代替密码 块密码 该密码用在多种因特网协议的加密中，包括 PGP (用于安全电子邮件）、SSL(用于使 TCP 连接更安全）和 IPsec(用于使网络层传输更安全）。 在块密码中，要加密的报文被处理为 K 比特的块。每块被独立加密。为了加密一个块，该密码采用了一对一映射，将 K 比特块的明文映射为 K 比特块的密文。 目前有一些流行的块密码，包括 DES (Data Encryption Standard, 数据加密标准）3DES 和 AES (Advanced Encryption Standard, 高级加密标准）。 密码块链接 在计算机网络应用中，通常需要加密长报文（或长数据流）。如果使用前面描述的块密码，通过直接将报文切割成 K 比特块并独立地加密每块，将出现一个微妙而重要的问题。为了理解这个问题，注意到两个或更多个明文块可能是相同的。例如，两个或更多块中的明文可能是 HHTTP/1.1 。对于这些相同的块，块密码当然将产生相同的密文。当攻击者看到相同的密文块时，它可能潜在地猜出其明文，并且通过识别相同的密文块和利用支撑协议结构的知识，甚至能够解密整个报文。为了解决这个问题，可以在密文中混合某些随机性，使得相同的明文块产生不同的密文块。 公开密钥加密 公开密钥密码学（英语：Public-key cryptography）也称非对称式密码学（英语：Asymmetric cryptography）是密码学的一种算法，它需要两个密钥，一个是公开密钥，另一个是私有密钥；公钥用作加密，私钥则用作解密。使用公钥把明文加密后所得的密文，只能用相对应的私钥才能解密并得到原本的明文，最初用来加密的公钥不能用作解密。由于加密和解密需要两个不同的密钥，故被称为非对称加密；不同于加密和解密都使用同一个密钥的对称加密。公钥可以公开，可任意向外发布；私钥不可以公开，必须由用户自行严格秘密保管，绝不透过任何途径向任何人提供，也不会透露给被信任的要通信的另一方。 RSA 报文完整性和数字签名 密码散列函数 MD5，SHA-1，SHA-256 报文鉴别码 发送发送方使用一个密钥和特定算法对明文产生一个短小的定长数据分组，即 MAC（报文鉴别码），并将它附加在报文中。在接收方，使用相同密钥的和算法对明文计算 MAC，如果新的 MAC 与报文中的 MAC 匹配，那么接受者确信报文未被修改过，接受者确信报文来自所期望的发送方。 数字签名 在数字领域，人们通常需要指出一个文件的所有者或创作者，或者表明某人认可一个文件内容。数字签名(digital signature) 就是一种在数字领域实现这些目标的密码技术。 Bob 让他的初始长报文通过一个散列函数。然后他用自己的私钥对得到的散列进行数字签名。明文形式的初始报文连同已经数字签名的报文摘要（从此以后可称为数字签名）一道被发送给 Alice。 Alice 先把发送方的公钥应用于报文获得一个散列结果。然后她再把该散列函数应用于明文报文以得到第二个散列结果。如果这两个散列匹配，则 Alice 可以确信报文的完整性及其发送方 。 公钥认证 数字签名的一个重要应用是公钥认证 (public key certification),即证实一个公钥属于某个特定的实体。公钥认证用在许多流行的安全网络协议中，包括 IPsec 和 SSL。 CA 证实一个实体（ 一个人 、一台路由器等）的真实身份。如何进行认证并没有强制的过程。当与一个 CA 打交道时，一方必须信任这个 CA 能够执行适当的严格身份验证。 一旦 CA 验证了某个实体的身份，这个 CA 会生成一个将其身份和实体的公钥绑定起来的证书(certificate)。这个证书包含这个公钥和公钥所有者全局唯一的身份标识信息（例如，一个人的名字或一个 IP 地址）。由 CA 对这个证书进行数字签名。 端点鉴别 当经网络进行鉴别时，通信各方不能依靠生物信息比如外表、声波纹等进行身份鉴别。的确，我们会在后面的实例研究中看到，诸如路由器、客户／服务器进程等网络元素通常必须相互鉴别。此处，鉴别应当在报文和数据交换的基础上，作为某鉴别协议 (authentication protocol)的一部分独立完成。鉴别协议通常在两个通信实体运行其他协议（例如，可靠数据传输协议、路由选择信息交换协议或电子邮件协议）之前运行。鉴别协议首先建立相互满意的各方的标识；仅当鉴别完成之后，各方才继续下面的工作。 不重数和对称密钥密码体制 Alice 向 Bob 发送报文“我是 Alice&amp;quot; 。 Bob 选择一个不重数 R , 然后把这个值发送给 Alice 。 Alice 使用她与 Bob 共享的对称秘密密钥 \(K_{A-B}\) 来加密这个不重数，然后把加密的不 重数 \(K_{A-B}(R)\) 发回给 Bob。与在协议 ap3.</description></item><item><title>计算机网络自顶向下方法::链路层与局域网</title><link>/notes/computer_network_a_topdown_approach_06/</link><pubDate>Fri, 18 Jun 2021 20:28:06 +0800</pubDate><guid>/notes/computer_network_a_topdown_approach_06/</guid><description>链路层概述 在本章中为方便讨论，将运行链路层协议协议的任何设备均称为节点。节点包括主机、路由器、交换机和 WiFi 接入点 。我们也把沿着通信路径连接相邻节点的通信信道称为链路。为了将一个数据报从源主机传输到目的主机，数据报必须通过沿端到端路径上的各段链路传输。 链路层提供的服务 成帧(framing).在每个网络层数据报经链路传送之前，几乎所有的链路层协议都要将其用链路层帧封装起来。一个帧由一个数据字段和若干首部字段组成，其中网络层数据报就插在数据字段中。帧的结构由链路层协议规定。 链路接入。媒体访问控制(Medium Access Control, MAC)协议规定了帧在链路上传输的规则。 可靠交付。当链路层协议提供可靠交付服务时。它保证无差错地经链路层移动每个网络层数据报 差错检测和纠正。当帧中的一个比特作为 1 传输时，接收方节点中的链路层硬件可能不正确地将其判断为 0,反之亦然。这种比特差错是由信号衰减和电磁噪声导致的。因为没有必要转发一个有差错的数据报，所以许多链路层协议提供一种机制来检测这样的比特差错。通过让发送节点在帧中包括差错检测比特，让接收节点进行差错检查，以此来完成这项工作。 链路层在何处实现 链路层的主体部分是在网络适配器(network adapter)中实现的，网络适配器有时也称为网络接口卡(Nehvork Interface Card, NIC)。位于网络适配器核心的是链路层控制器，该控制器通常是一个实现了许多链路层服务（成帧、链路接入、差错检测等）的专用片。因此，链路层控制器的许多功能是用硬件实现的。 在发送端，控制器取得了由协议栈较高层生成并存储在主机内存中的数据报，在链路层帧中封装该数据报（填写该帧的各个字段），然后遵循链路接入协议将该帧传进通信链路中。在接收端，控制器接收了整个帧，抽取出网络层数据报。如果链路层执行差错检 测，则需要发送控制器在该帧的首部设置差错检测比特，由接收控制器执行差错检测。 链路层的软件组件实现了高层链路层功能，如组装链路层寻址信息和激活控制器硬件。在接收端，链路层软件响应控制器中断，处理差错条件和将数据报向上传递给网络层。所以，链路层是硬件和软件的结合体。 差错检测和纠正技术 奇偶位校验 假设要发送的信息 D 有 d 比特。在偶校验方案中，发送方只需包含一个附加的比特，选择它的值，使得这 d+1 比特中 1 的总数是偶数。对于奇校验方案，选择校验比特值使得有奇数个 1。单个校验比特被存放在一个单独的字段中。 采用单个奇偶校验位方式。接收方的操作也很简单。接收方只需要数一数接收的 d + 1 比特中 1 的数目即可。如果在采用偶校验方案中发现了奇数个值为 1 的比特，接收方知道至少出现了一个比特差错。更精确的说法是，出现了奇数个比特差错。 二维奇偶校验 单比特奇偶校验方案的二维一般化方案。这里 D 中的 d 个比特被划分为 i 行 j 列。对每行和每列计算奇偶值。产生的 i+j+1 奇偶比特构成了链路层帧的差错检测比特。现在假设在初始 d 比特信息中出现了列单个比特差错。使用这种二维奇偶校验方案，包含比特值改变的列和行的校验值都将会出现差错。因此接收方不仅可以检测到出现了单个比特差错的事实，而且还可以利用存在奇偶校验差错的列和行的索引来实际识别发生差错的比特并纠正它！ 接收方检测和纠正差错的能力被称为前向纠错，FEC 技术很有价值，因为它们可以减少所需的发送方重发的次数。也许更为重要的是，它们允许在接收方立即纠正差错。FEC 避免了不得不等待的往返时延，而这些时延是发送方收到 NAK 分组并向接收方重传分组所需要的，这对于实时网络应用或者具有长传播时延的链路（如深空间链路）可能是一种非常重要的优点。 检验和方法 因特网检验和(Internet checksum)就基于这种方法，即数据的字节作为 16 比特的整数对待并求和。这个和的反码形成了携带在报文段首部的因特网检验和。接收方通过对接收的数据（包括检验和）的和取反码，并且检测其结果是否为全 1 比特来检测检验和。如果这些比特中有任何比特是 0, 就可以指示出差错。检验和方法需要相对小的分组开销。例如，TCP 和 UDP 中的检验和只用了 16 比特。然而，与常用于链路层的 CRC 相比，它们提供相对弱的差错保护。 循环冗余检测 现今的计算机网络中广泛应用的差错检测技术基于循环冗余检测编码 CRC 编码也称为多项式编码，因为该编码能够将要发送的比特串看作为系数是 0 和 1 一个多项式，对比特串的操作被解释为多项式算术。 多路访问链路和协议 有两种类型的网络链路：点对点链路和广播链路。 点对点链路(point-to-point link)由链路一端的单个发送方和链路另一端的单个接收方组成。许多链路层协议都是为点对点链路设计的，如点对点协议 (point-to-point protocol, PPP)和高级数据链路控制(high-level data link control HDLC)就是两种这样的协议。 广播链路(broadcast link),它能够让多个发送和接收节点都连接到相同的、单一的、共享的广播信道上。广播信道通常用于局域网中，局域网是一个地理上集中在一座建筑物中的网络。 多路访问协议 信道划分协议 时分多路复用(TDM)和频分多路复用(FDM)是两种能够用于在所有共享信道节点之间划分广播信道带宽的技术。假设一个支持 N 个节点的信道且信道的传输速率为 Rbps。TDM 将时间划分为时间帧(time frame),并进一步划分每个时间帧为 N 个时隙(slot)。然后把每个时隙分配给 N 个节点中的一个。无论何时某个节点在有分组要发送的时候，它在循环的 TDM 帧中指派给它的时隙内传输分组比特。通常，选择的时隙长度应使一个时隙内能够传输单个分组。TDM 是有吸引力的，因为它消除了碰撞而且非常公平：每个节点在每个帧时间内得到了专用的传输速率 R/N bps。然而它有两个主要缺陷。首先，节点被限制于 R/N bps 的平均速率，即使当它是唯一有分组要发送的节点时。其次，节点必须总是等待它在传输序列中的轮次，即我们再次看到，即使它是唯一一个有帧要发送的节点。 FDM 将 R bps 信道划分为不同的频段（每个频段具有 R/N 带宽），并把每个频率分配给 N 个节点中的一个。因此 FDM 在单个较大的 R bps 信道中创建了 N 个较小的 R/N bps 信道。FDM 也有 TDM 同样的优点和缺点。它避免了碰撞．在 N 个节点之间公平地划分了带宽，然而，FDM 也有 TDM 所具有的主要缺点，也就是限制一个节点只能使用 R/N 的带宽，即使当它是唯一一个有分组要发送的节点时。 CDMA 对每个节点分配一种不同的编码。然后每个节点用它唯一的编码来对它发送的数据进行编码。如果精心选择这些编码，CDMA 网络具有一种奇妙的特性，即不同的节点能够同时传输，并且它们各自相应的接收方仍能正确接收发送方编码的数据比特，而不在乎其他节点的干扰传输 CDMA 已经在军用系统中使用了一段时间，目前已经广泛地用于民用，尤其是蜂窝电话中。 随机接入协议 在随机接入协议中，一个传输节点总是以信道的全部速率（即 R bps ) 进行发送，当有碰撞时，涉及碰撞的每个节点反复地重发它的帧（也就是分组），到该帧无碰撞地通过为止。但是当一个节点经历一次碰撞时，它不必立刻重发该帧。相反，它在重发该帧之前等待一个随机时延。涉及碰撞的每个节点独立地选择随机时延。因为该随机时延是独立地选择的，所以下述现象是有可能的：这些节点之一所选择的时延充分小于其他碰撞节点的时延，并因此能够无碰撞地将它的帧在信道中发出。 时隙 ALOHA 所有帧由 L 比特组成 时间被划分成长度为 L/R 秒的时隙。 节点只在时隙起点开始传输帧。 节点是同步的。每个节点都知道时隙何时开始。 如果在一个时隙中有两个或者更多个帧碰撞。则所有节点在该时隙结束之前检测到该碰撞事件。令 p 是一个概率，即一个在 0 和 1 之间的数。在每个节点中，时隙 ALOHA 的操作是简单的。 当节点有一个新帧要发送时，它等到下一个时隙开始并在该时隙传输整个帧。 如果没有碰撞，该节点成功地传输它的帧，从而不需要考虑重传该帧。 如果有碰撞，该节点在时隙结束之前检测到这次碰撞。每个时隙中重传它的帧，直到该帧被无碰撞地传输出去 时隙多路访问协议的效率定义为：当有大量的活跃节点且每个节点总有大量的帧要发送时，长期运行中成功时隙的份额。注意到如果不使用某种形式的访问控制，而且每个节点都在每次碰撞之后立即重传，这个效率将为零。时隙 ALOHA 显然增加了它的效率，使之大于零 载波侦听多路访问 (CSMA) 说话之前先听。如果其他人正在说话，等到他们说完话为止。在网络领域中，这被称为载波侦听(carrier sensing) 即一个节点在传输前先听信道。如果来自另一个节点的帧正向信道上发送，节点则等待直到检测到一小段时间没有传输，然后开始传输 。 如果与他人同时开始说话，停止说话。在网络领域中，这被称为碰撞检测(colliion detection),即当一个传输节点在传输时一直在侦听此信道户。如果它检测到另一个节点正在传输干扰帧，它就停止传输，在重复＂侦听－当空闲时传输＂循环之前等待一段随机时间。 这两个规则包含在载波侦听多路访问(Carrier Sense Multiple Access, CSMA) 和具有碰撞检测的 CSMA。 具有碰撞检测的载波侦听多路访问 (CSMA/CD) 适配器从网络层一条获得数据报，准备链路层帧，并将其放入帧适配器缓存中。 如果适配器侦听到信道空闲（即无信号能量从信道进入适配器），它开始传输帧。在另一方面，如果适配器侦听到信道正在忙，它将等待，直到侦听到没有信号能批时才开始传输帧。 在传输过程中，适配器监视来自其他使用该广播信道的适配器的信号能量的存在。 如果适配器传输整个帧而未检测到来自其他适配器的信号能量，该适配器就完成了该帧。在另一方面，如果适配器在传输时检测到来自其他适配器的信号能量，它中止传输（即它停止了传输帧）。 中止传输后，适配器等待一个随机时间量、然后返回步骤 2 轮流协议 轮询协议 轮询协议要求这些节点之一要被指定为主节点。主节点以循环的方式轮询(poll)每个节点。特别是，主节点首先向节点 1 发送一个报文，告诉它（节点 1)能够传输的帧的最多数量。在节点 1 传输了某些帧后，主节点告诉节点 2 它（节点 2)能够传输的帧的最多数量。上述过程以这种方式继续进行，主节点以循环的方式轮询了每个节点。轮询协议消除了困扰随机接入协议的碰撞和空时隙，这使得轮询取得高得多的效率。但是它也有一些缺点。第一个缺点是该协议引入了轮询时延，即通知一个节点”它可以传输”所需的时间。例如，如果只有一个节点是活跃的，那么这个节点将以小于 R bps 的速率传输，因为每次活跃节点发送了它最多数量的帧时，主节点必须依次轮询每一个非活跃的节点。第二个缺点可能更为严重，就是如果主节点有故障，整个信道都变得不可操作。 令牌传递协议 在这种协议中没有主节点。一个称为令牌(token)的小的特殊帧在节点之间以某种固定的次序进行交换。例如，节点 1 可能总是把令牌发送给节点 2,节点 2 可能总是把令牌发送给节点 3，而节点 N 可能总是把令牌发送给节点 1。当一个节点收到令牌时，仅当它有一些帧要发送时，它才持有这个令牌；否则，它立即向下一个节点转发该令牌。当一个节点收到令牌时，如果它确实有帧要传输，它发送最大数目的帧数，然后把令牌转发给下一个节点。令牌传递是分散的，并有很高的效率。但是它也有自己的一些问题。例如，一个节点的故障可能会使整个信道崩溃。或者如果一个节点偶然忘记了释放令牌，则必须调用某些恢复步骤使令牌返回到循环中来。 DOCSIS: 用于电缆因特网接入的链路层协议 一个电缆接入网通常在电缆网头端将几千个住宅电缆调制解调器与一个电缆调制解调器端接系统 CMTS 连接。CMTS 规范定义了电缆数据网络体系结构及其协议。DOCSIS 使用 FDM 将下行和上行（调制解调器到 CMTS) 网络段划分为多个频率信道。CMTS 在下行信道中传输的帧被所有在信道上做接收的电缆调制解调器接收到；然而因为仅有单一的 CMTS 在下行信道上传输，不存在多路访问问题。但在上行方向，存在着多个有趣的技术挑战，因为多个电缆调制解调器共享到 CMTS 的相同上行信道（频率），因此能够潜在地出现碰撞）。电缆调制解调器既不能侦听上行信道是否忙，也不能检测碰撞。相反，该电缆调制解调器如果没有在下一个下行控制报文中收到对请求分配的响应的话，就推断出它的微时隙请求帧经历了一次碰撞。当推断出一次碰撞，电缆调制解调器使用二进制指数回退将其微时隙请求帧延缓到以后的时隙重新发送。当在上行信道上有很少的流量，电缆调制解调器可能在名义上分配给微时隙请求帧的时隙内实际传输数据帧（因此避免不得不等待微时隙分配）。 交换局域网 链路层寻址和 ARP (ARP)该协议提供了将 IP 地址转换为链路层地址的机制。 MAC 地址 并不是主机或路由器具有链路层地址，而是它们的适配器（即网络接口）具有链路层地址。 链路层地址有各种不同的称呼：LAN 地址(LAN address)、物理地址(physical address)或 MAC 地址(MAC address)。因为 MAC 地址似乎是最为流行的术语，所以我们此后就将链路层地址称为 MAC 地址。 MAC 地址的一个有趣性质是没有两块适配器具有相同的地址。IEEE 在管理着该 MAC 地址空间。特别是，当一个公司要生产适配器时，它支付象征性的费用购买组成 2^24 个地址的一块地址空间。IEEE 分配这块 2^24 个地址的方式是：固定一个 MAC 地址的前 24 比特，让公司自已为每个适配器生成后 24 比特的唯一组合。 当某适配器要向某些目的适配器发送一个帧时、发送适配器将目的适配器的 MAC 地址插入到该帧中，并将该帧发送到局域网 上。 地址解析协议 因为存在网络层地址（例如，因特网的 IP 地址）和链路层地址（即 MAC 地址），所以需要在它们之间进行转换。对于因特网而言、这是地址解析协议(Address Resolution Protocol,ARP)的任务。 为了发送数据报，该源必须要向它的适配器不仅提供 IP 数据报，而且要提供目的主机 222.</description></item><item><title>计算机网络自顶向下方法::网络层::控制平面</title><link>/notes/computer_network_a_topdown_approach_05/</link><pubDate>Thu, 17 Jun 2021 20:28:06 +0800</pubDate><guid>/notes/computer_network_a_topdown_approach_05/</guid><description>概述 转发表和流表计算、维护和安装的两种方法 每路由器控制。每台路由器中都包含转发和路由选择功能。每台路由器有一个路由选择组件，用于与其他路由器中的路由选择组件通信，以计算其转发表的值。这种每路由器控制的方法在因特网中已经使用了几十年。OSPF 和 BGP 协议都是基于这种每路由器的方法进行控制的。 逻辑集中式控制。通用的&amp;quot;匹配加动作“抽象允许执行传统的 IP 转发以及其他功能（负载共享、防火墙功能和 NAT)的丰富集合，而这些功能先前是在单独的中间盒中实现的。该控制器经一种定义良好的协议与每台路由器中的一个控制代理(CA)进行交互，以配置和管理该路由器的转发表。CA 一般具有最少的功能，其任务是与控制器通信并且按控制器命令行事。这些 CA 既不能直接相互交互，也不能主动参与计算转发表。这是每路由器控制和逻辑集中式控制之间的关键差异。 &amp;ldquo;逻辑集中式＂控制意味着就像路由选择控制服务位于单一的集中服务点那样获取它们，即使该服务出于容错和性能扩展性的原因，很可能经由多个服务器实现。 SDN 采用了逻辑集中式控制器的概念，而这种方法在生产部署中得到了越来越多的应用。 路由选择算法 其目的是从发送方到接收方的过程中确定一条通过路由器网络的好的路径（等价于路由）。通常，一条好路径指具有最低开销的路径。 第一种分类方式：根据该算法是集中式还是分散式来划分 集中式路由选择算法 用完整的、全局性的网络知识计算出从源到目的地之间的最低开销路径。具有全局状态信息的算法常被称作链路状态(Link State,LS) 算法，因为该算法必须知道网络中每条链路的开销。 分散式路由选择算法 路由器以迭代、分布式的方式计算出最低开销路径。没有节点拥有关于所有网络链路开销的完整信息。相反，每个节点仅有与其直接相连链路的开销知识即可开始工作。然后，通过迭代计算过程以及与相邻节点的信息交换，一个节点逐渐计算出到达某目的节点或一组目的节点的最低开销路径。 第二种分类方式：根据算法是静态的还是动态的进行分类 静态路由选择算法 路由随时间的变化非常缓慢，通常是人工进行调整如人为手工编辑一条链路开销） 动态路由选择算法 随着网络流量负载或拓扑发生变化而改变路由选择路径。一个动态算法可周期性地运行或直接响应拓扑或链路开销的变化而运行。虽然动态算法易于对网络的变化做出反应，但也更容易受诸如路由选择循环、路由振荡之类问题的影响。 第三种分类方式：根据它是负载敏感的还是负载迟钝的进行划分 负载敏感算法 链路开销会动态地变化以反映出底层链路的当前拥塞水平。如果当前拥塞的一条链路与高开销相联系，则路由选择算法趋向于绕开该拥塞链路来选择路由。 负载迟钝 当今的因特网路由选择算法（如 RIP、OSPF 和 BGP)都是负载迟钝的(load-insensitive),因为某条链路的开销不明确地反映其当前或最近的拥塞水平。 链路状态路由选择算法 在链路状态算法中，网络拓扑和所有的链路开销都是已知的。实践中这是通过让每个节点向网络中所有其他节点广播链路状态分组来完成的，其中每个链路状态分组包含它所连接的链路的标识和开销。在实践中，这经常由链路状态广播算法来完成。节点广播的结果是所有节点都具有该网络的统一、完整的视图。于是每个节点都能够像其他节点一样，运行 LS 算法并计算出相同的最低开销路径集合。 距离向量路由选择算法 距离向量(Distance-Vector,DV)算法是一种迭代的、异步的和分布式的算法。说它是分布式的，是因为每个节点都要从一个或多个直接相连邻居接收某些信息，执行计算，然后将其计算结果分发给邻居。说它是迭代的，是因为此过程一直要持续到邻居之间无更多信息要交换为止。说它是异步的，是因为它不要求所有节点相互之间步伐一致地操作。 链路开销改变与链路故障 当一个运行 DV 算法的节点检测到从它自己到邻居的链路开销发生变化时，它就更新其距离向量，并且如果最低开销路径的开销发生了变化，向邻居通知其新的距离向量。 LS 与 DV 路由选择算法的比较 报文复杂性。我们已经看到 LS 算法要求每个节点都知道网络中每条链路的开销。这就要求要发送 O(|N||E|）个报文 。而且无论何时一条链路的开销改变时，必须向所有节点发送新的链路开销。DV 算法要求在每次迭代时，在两个直接相连邻居之间交换报文。我们已经看到，算法收敛所需时间依赖于许多因素。当链路开销改变时，DV 算法仅当在新的链路开销导致与该链路相连节点的最低开销路径发生改变时，才传播已改变的链路开销。 收敛速度。我们已经看到 LS 算法的实现是一个要求 O(|N||E|)个报文的 O(|N|^2)算法。DV 算法收敛较慢，且在收敛时会遇到路由选择环路。DV 算法还会遭遇无穷计数的问题。 健壮性。对于 LS 算法，路由器能够向其连接的链路广播不正确的开销。作为 LS 广播的一部分，一个节点也可损坏或丢弃它收到的任何区广播分组。但是一个 LS 节点仅计算自己的转发表；其他节点也自行执行类似的计算。这就意味着在 LS 算法下，路由计算在某种程度上是分离的，提供了一定程度的健壮性。在 DV 算法下，一个节点可向任意或所有目的节点通告其不正确的最低开销路径。更一般地，我们会注意到每次迭代时，在 DV 算法中一个节点的计算会传递给它的邻居，然后在下次迭代时再间接地传递给邻居的邻居。在此情况下，DV 算法中一个不正确的节点计算值会扩散到整个网络 。 因特网中自治系统内部的路由选择：OSPF 规模。随着路由器数目变得很大，涉及路由选择信息的通信、计算和存储的开销将高得不可实现。当今的因特网由数亿台主机组成。在这些主机中存储的路由选择信息显然需要巨大容量的内存。在所有路由器之间广播连通性和链路开销更新所要求的负担将是 巨大的！在如此大量的路由器中迭代的距离向量算法将肯定永远无法收敛！显然，必须采取一些措施以减少像因特网这种大型网络中的路由计算的复杂性 。 管理自治。因特网是 ISP 的网络，其中每个 ISP 都有它自己的路由器网络。ISP 通常希望按自己的意愿运行路由器，或对外部隐藏其网络的内部组织面貌。在理想情况下，一个组织应当能够按自己的愿望运行和管理其网络，还要能将其网络与其他外部网络连接起来。 在相同 AS 中的路由器都运行相同的路由选择算法并且有彼此的信息。在一个自治系统内运行的路由选择算法叫作自治系统内部路由选择协议。 开放最短路优先 (OSPF) OSPF 路由选择及其关系密切的协议 IS-IS 都被广泛用千因特网的 AS 内部路由选择。 OSPF 是一种链路状态协议，它使用洪泛链路状态信息和 Dijkstra 最低开销路径算法。使用 OSPF, 一台路由器构建了一 幅关于整个自治系统的完整拓扑图（即一幅图）。于是，每台路由器在本地运行 Dijkstra 的最短路径算法，以确定一个以自身为根节点到所有子网的最短路径树。各条链路开销是由网络管理员配置的管理员也许会选择将所有链路开销设为 1, 因而实现了最少跳数路由选择，或者可能会选择将链路权值按与链路容量成反比来设置，从而不鼓励流量使用低带宽链路。OSPF 不强制使用设置链路权值的策略（那是网络管理员的任务），而是提供了一种机制（协议），为给定链路权值集合确定最低开销路径的路由选择。 使用 OSPF 时，路由器向自治系统内所有其他路由器广播路由选择信息，而不仅仅是向其相邻路由器广播。每当一条链路的状态发生变化时（如开销的变化或连接／中断状态的变化），路由器就会广播链路状态信息。即使链路状态未发生变化，它也要周期性地（至少每隔 30 min 一次）广播链路状态。OSPF 协议还要检查链路正在运行（通过向相连的邻居发送 HELLO 报文 ），并允许 OSPF 路由器获得相邻路由器的网络范围链路状态的数据库 。 优点 安全。能够鉴别 OSPF 路由器之间的交换（如链路状态更新）。 多条相同开销的路径。当到达某目的地的多条路径具有相同的开销时，OSPF 允许使用多条路径。 对单播与多播路由选择的综合支持。 支持在单个 AS 中的层次结构。一个 OSPF 自治系统能够层次化地配置多个区域每个区域都运行自己的 OSPF 链路状态路由选择算法，区域内的每台路由器都向该区域内的所有其他路由器广播其链路状态。 ISP 之间的路由选择：BGP 在因特网中，所有的 AS 运行相同的 AS 间路由选择协议，称为边界网关协议(Broder Gateway Protocol, BGP)。正是这个协议将因特网中数以千计的 ISP 黏合起来。 BGP 的作用 从邻居 AS 荻得前缀的可达性信息。特别是，BGP 允许每个子网向因特网的其余部分通告它的存在。一个子网高声宣布“我存在，我在这里”，而 BGP 确保在因特网中的所有 AS 知道该子网。如果没有 BGP 的话，每个子网将是隔离的孤岛，即它们孤独地存在，不为因特网其余部分所知和所达。 确定到该前缀的“最好的“路由。一台路由器可能知道两条或更多条到特定前缀的不同路由。为了确定最好的路由，该路由器将本地运行一个 BGP 路由选择过程（使用它经过相邻的路由器获得的前缀可达性信息）。该最好的路由将基于策略以及可达性信息来确定 。 通告 BGP 路由信息 对于每个 AS, 每台路由器要么是一台网关路由器(gateway router)要么是一台内部路由器(internal router)。网关路由器是一台位于 AS 边缘的路由器，它直接连接到在其他 AS 中的一台或多台路由器。内部路由器仅连接在它自己 AS 中的主机和路由器 。 在 BGP 中，每对路由器通过使用 179 端口的半永久 TCP 连接交换路由选择信息。每条直接连接以及所有通过该连接发送的 BGP 报文，称为 BGP 连接 (BGP connection)。此外，跨越两个 AS 的 BGP 连接称为外部 BGP (eBGP) 连接，而在相同 AS 中的两台路由器之间的 BGP 会话称为内部 BGP (iBGP) 连接 。在真实的网络中，从某个给定的路由器到某个给定的目的地可能有多条不同的路径，每条通过了不同的 AS 序列 。 确定最好的路由 当路由器通过 BGP 连接通告前缀时，它在前缀中包括一些 BGP 属性 (BGP attribute)。用 BGP 术语来说，前缀及其属性称为路由 (route)。两个较为重要的属性是 AS-PATH 和 NEXT-HOP。AS-PATH 属性包含了通告已经通过的 AS 的列表，如我们在前面的例子中所见。为了生成 AS-PATH 的值，当一个前缀通过某 AS 时，该 AS 将其 ASN 加入 AS-PATH 中的现有列表。 IP 任播 BGP 还常被用于实现 IP 任播(anycast) 服务，该服务通常用于 DNS 中。 动机 在许多分散的不同地理位置，替换不同服务器上的相同内容 让每个用户从最靠近的服务器访问内容。 CDN 使用 IP 任波的方式 在 IP 任播配置阶段，CDN 公司为它的多台服务器指派相同的 IP 地址，并且使用标准的 BGP 从这些服务器的每台来通告该 IP 地址。当某台 BGP 路由器收到对于该 IP 地址的多个路由通告，它将这些通告处理为对相同的物理位置提供不同的路径当配置其路由选择表时，每台路由器将本地化地使用 BGP 路由选择算法来挑选到该 IP 地址的最好的路由。 路由选择策略 在路由选择算法中，实际上首先根据本地偏好属性选择路由，本地偏好值由本地 AS 的策略所确定。 为什么会有不同的 AS 间和 AS 内部路由选择协议？ 策略。在 AS 之间，策略问题起主导作用。一个给定 AS 产生的流量不能穿过另一个特定的 AS, 这可能非常重要。类似地，一个给定 AS 也许想很好地控制它承栽的其他 AS 之间穿越的流量。我们已看到，BGP 承栽了路径属性，并提供路由选择信息的受控分布，以便能做出这种基于策略的路由选择决策。在一个 AS 内部，一切都是在相同的管理控制名义下进行的，因此策略问题在 AS 内部选择路由中起着微不足道的作用。 规模。扩展一个路由选择算法及其数据结构以处理到大量网络或大量网络之间的路由选择的这种能力，是 AS 间路由选择的一个关键问题。在一个 AS 内，可扩展性不是关注的焦点。首先，如果单个 ISP 变得太大时，总是能将其分成两个 AS, 并在这两个新的 AS 之间执行 AS 间路由选择。 性能。由于 AS 间路由选择是面向策略的，因此所用路由的质量通常是次要关心的问题。 我们的确看到了在 AS 之间，甚至没有与路由相关的开销概念。然而在一个 AS 内部，这种对策略的关心就不重要了，可以使路由选择更多地关注一条路由实现的性能级别。 SDN 控制平面 SDN 体系结构具有 4 个关键特征 基于流的转发：SDN 控制的交换机的分组转发工作，能够基于运输层、 网络层或链路层首部中任意数量的首部字段值进行。 数据平面与控制平面分离：数据平面由网络交换机组成，交换机是相对简单（但快速）的设备，该设备在它们的流表中执行“匹配加动作”的规则。控制平面由服务器以及决定和管理交换机流表的软件组成。 网络控制功能：位于数据平面交换机外部。然而，与传统的路由器不同，这个软件在服务器上执行，该服务器与网络交换机截然分开且与之远离。控制平面自身由两个组件组成： 一个 SDN 控制器, 以及若干网络控制应用程序。控制器维护准确的网络状态信息机和主机的状态；为运行在控制平面中的网络控制应用程序提供这些信息；提供方法，这些应用程序通过这些方法能够监视、 编程和控制下面的网络设备。 可编程的网络。通过运行在控制平面中的网络控制应用程序、该网络是可编程的。这些应用程序代表了控制平面的“智力”，使用了由 SDN 控制器提供的 API 来定义和控制网络设备中的数据平面。 SDN 控制平面：SDN 控制器和 SDN 网络控制应用程序 通信层：SDN 控制器和受控网络设备之间的通信。显然，如果 SDN 控制器要控制远程 SDN 使能的交换机、主机或其他设备的运行，需要一个协议来传送控制器与这些设备之间的信息。 网络范围状态管理层。由 SDN 控制平面所做出的最终控制决定换机的流表以取得所希望的端到端转发，实现负载均衡，或实现一种特定的防火墙能力，将要求控制器具有有关网络的主机、链路、交换机和其他 SDN 控制设备的最新状态信息。 对于网络控制应用程序层的接口。控制器通过它的“北向“接口与网络控制应用程序交互。该 API 允许网络控制应用程序在状态管理层之间读／写网络状态和流表。当状态改变事件出现时，应用程序能够注册进行通告。可以提供不同类型的 API, 我们将看到两种流行 SDN 控制器使用 REST 请求响应接口与它们的应用程序进行通信。 OpenFlow 协议 OpenFlow 协议运行在 SDN 控制器和 SDN 控制的交换机或其他实现 OpenFlow API 的设备之间。OpenFlow 协议运行在 TCP 之上，使用 6653 的默认端口号。从控制器到受控交换机流动的重要报文有下列这些： 配置。该报文允许控制器查询并设置交换机的配置参数 。 修改状态。该报文由控制器所使用，以增加／删除或修改交换机流表中的表项，且设置交换机端口特性。 读状态。该报文被控制器用于从交换机的流表和端口收集统计数据和计数器值。 发送分组。该报文被控制器用于在受控交换机从特定的端口发送出 一个特定的报文。 流删除。该报文通知控制器已删除一个流表项，例如由于超时，或作为收到“修改状态＂报文的结果。 端口状态。交换机用该报文向控制器通知端口状态的变化。 分组入。一个分组到达交换机端口，并且不能与任何流表项匹配，那么这个分组将被发送给控制器进行额外处理。匹配的分组也被发送给控制器，作为匹配时所采取的一个动作。“分组入“报文被用于将分组发送给控制器。 ICMP: 因特网控制报文协议 ICMP 被主机和路由器用来彼此沟通网络层的信息。ICMP 最典型的用途是差错报告。 在某个位置，IP 路由器不能找到一条通往 HTTP 请求中所指定的主机的路径、该路由器就会向你的主机生成并发出一个 ICMP 报文以指示该错误。 另一个有趣的 ICMP 报文是源抑制报文。这种报文在实践中很少使用 。其最初目的是执行拥塞控制，即使得拥塞的路由器向一台主机发送一个 ICMP 源抑制报文，以强制该主机减小其发送速率。 网络管理和 SNMP 网络管理框架 管理服务器(managing server)是一个应用程序，通常有人的参与，并运行在网络运营中心 (NOC) 的集中式网络管理工作站上。管理服务器是执行网络管理活动的地方，它控制网络管理信息的收集、处理、分析和／或显示。 被管设备 (managed deyjce) 是网络装备的一部分（包括它的软件），位于被管理的网络中。在一个被管设备中，有几个所谓被管对象 (managed object)。这些被管对象是被管设备中硬件的实际部分（例如，一块网络接口卡只是一台主机或路由器的一个组件）和用于这些硬件及软件组件的配置参数（例如，像 OSPF 这样的 AS 内部路由选择协议）。 一个被管设备中的每个被管对象的关联信息收集在管理信息库(Management Information Base, MIB) 中，我们将看到这些信息的值可供管理服务器所用 在每个被管设备中还驻留有网络管理代理 (network management agent),它是运行在被管设备中的一个进程，该进程与管理服务器通信，在管理服务器的命令和控制下在被管设备中采取本地动作。 网络管理框架的最后组件是网络管理协议 (network management protocol )。该协议运行在管理服务器和被管设备之间，允许管理服务器查询被管设备的状态，并经过其代理间接地在这些设备上采取行动。代理能够使用网络管理协议向管理服务器通知异常事件（如组件故障或超过了性能阙值）。重要的是注意到网络管理协议自己不能管理网络。恰恰相反，它为网络管理员提供了一种能力，使他们能够管理网络。 简单网络管理协议 SNMP 是一个应用层协议，用于在管理服务器和代表管理服务器执行的代理之间传递网络管理控制和信息报文。SNMP 最常使用的是请求响应模式，其中 SNMP 管理服务器向 SNMP 代理发送一个请求，代理接收到该请求后，执行某些动作，然后对该请求发送一个回答。请求通常用于查询（检索）或修改（设置）与某被管设备关联的 MIB 对象值。 SNMP 第二个常被使用的是代理向管理服务器发送的一种非请求报文，该报文称为陷阱报文(trap message)。陷阱报文用于通知管理服务器，一个异常情况（例如一个链路接口启动或关闭）已经导致了 MIB 对象值的改变。</description></item><item><title>计算机网络自顶向下方法::网络层::数据平面</title><link>/notes/computer_network_a_topdown_approach_04/</link><pubDate>Thu, 17 Jun 2021 20:27:06 +0800</pubDate><guid>/notes/computer_network_a_topdown_approach_04/</guid><description>网络层概述 路由器的数据平面的主要作用是从其输入链路向其输出链路转发数据报；控制平面的主要作用是协调这些本地的每路由器转发动作，使得数据报沿着源和目的地主机之间的路由器路径最终进行端到端传送。 转发和路由选择：数据平面和控制平面 转发：当一个分组到达某路由器的一条输入链路时，该路由器必须将该分组移动到适当的输出链路 路由选择：当分组从发送方流向接收方时，网络层必须决定这些分组所采用的路由或路径。计算这些路径的算法被称为路由选择算法 每台网络路由器中有一个关键元素是它的转发表(fonvarding table)。路由器检查到达分组首部的一个或多个字段值，进而使用这些首部值在其转发表中索引，通过这种方法来转发分组。这些值对应存储在转发表项中的值，指出了该分组将被转发的路由器的输出链路接口。 控制平面：传统的方法 路由选择算法运行在每台路由器中，并且在每台路由器中都包含转发和路由选择两种功能。在一台路由器中的路由选择算法与在其他路由器中的路由选择算法通信，以计算出它的转发表的值。 控制平面：SDN 方法 SDN 方法显示了从路由器物理上分离的另一种方法，远程控制器计算和分发转发表以供每台路由器所使用，路由选择设备仅执行转发。远程控制器可能实现在具有高可靠性和冗余的远程数据中心中，并可能由 ISP 或某些第三方管理。路由器和远程控制器通过交换包含转发表和其他路由选择信息的报文实现通信。 网络服务模型 网络层能提供的某些可能的服务 确保交付。该服务确保分组将最终到达目的地。 具有时延上界的确保交付。该服务不仅确保分组的交付，而且在特定的主机到主机时延上界内（例如在 1OOms 内）交付 。 有序分组交付。该服务确保分组以它们发送的顺序到达目的地。 确保最小带宽。这种网络层服务模仿在发送和接收主机之间一条特定比特率（例如 1Mbps) 的传输链路的行为。只要发送主机以低于特定比特率的速率传输比特（作为分组的组成部分），则所有分组最终会交付到目的主机。 安全性。网络层能够在源加密所有数据报并在目的地解密这些分组，从而对所有运输层报文段提供机密性。 因特网的网络层提供了单一的服务，称为尽力而为服务，使用尽力而为服务，传送的分组既不能保证以它们发送的顺序被接收，也不能保证它们最终交付；既不能保证端到端时延，也不能保证有最小的带宽。尽力而为服务看起来是根本无服务的一种委婉说法，即一个没有向目的地交付分组的网络也符合尽力而为交付服务的定义 路由器工作原理 通用路由器结构 输入端口 它在路由器中执行终结入物理链路的物理层功能 与位于入链路远端的数据链路层交互来执行数据链路层功能 执行查找功能，通过查询转发表决定路由器的输出端口，到达的分组通过路由器的交换结构转发到输出端口 交换结构 交换结构将路由器的输入端口连接到它的输出端口 输出端口 输出端口存储从交换结构接收的分组，并通过执行必要的链路层和物理层功能在输出链路上传输这些分组 路由选择处理器 路由选择处理器执行控制平面功能 在传统的路由器中，它执行路由选择协议，维护路由选择表与关联链路状态信息，并为该路由器计算转发表 在 SDN 路由器中，路由选择处理器负责与远程控制器通信，目的是接收由远程控制器计算的转发表项，并在该路由器的输入端口安装这些表项 输入端口处理和基于目的地转发 输入端口的线路端接功能与链路层处理实现了用于各个输入链路的物理层和链路层。在输入端口中执行的查找对于路由器运行是至关重要的。正是在这个地方，路由器使用转发表来查找输出端口，使得到达的分组能经过交换结构转发到该输出端口。 转发表是由路由选择处理器计算和更新的，或者转发表接收来自远程 SDN 控制器的内容 最长前缀匹配规则 路由器用分组目的地址的前缀(prefix)与该表中的表项进行匹配；如果存在一个匹配项，则路由器向与该匹配项相关联的链路转发分组，当有多个匹配时，在该表中寻找最长的匹配项，并向与最长前缀匹配相关联的链路接口转发分组。 执行转发表匹配不仅必须要用硬件执行查找，而且需要对大型转发表使用超出简单线性搜索的技术 一旦通过查找确定了某分组的输出端口，则该分组就能够发送进入交换结构。在某些设计中，如果来自其他输入端口的分组当前正在使用该交换结构，一个分组可能会在进入交换结构时被暂时阻塞。因此，一个被阻塞的分组必须要在输入端口处排队，并等待稍后被及时调度以通过交换结构。 其他需要执行的动作 必须出现物理层和链路层处理 必须检查分组的版本号、检验和以及寿命字段，并且重写后两个字段 必须更新用于网络管理的计数器 可选防火墙过滤分组 可选 NAT 重写端口号 交换 交换结构位于一台路由器的核心部位，因为正是通过这种交换结构，分组才能实际地从一个输入端口交换（即转发）到一个输出端口中。交换可以用许多方式完成。 经内存交换。最简单、最早的路由器是传统的计算机，在输入端口与输出端口之间的交换是在 CPU (路由选择处理器）的直接控制下完成的。输入与输出端口的功能就像在传统操作系统中的 I/O 设备一样。一个分组到达一个输入端口时。该端口会先通过中断方式向路由选择处理器发出信号。于是，该分组从输入端口处被复制到处理器内存中。路由选择处理器则从其首部中提取目的地址，在转发表中找出适当的输出端口，并将该分组复制到输出端口的缓存中。 经总线交换。在这种方法中、输入端口经一根共享总线将分组直接传送到输出端口。不需要路由选择处理器的干预。 经互联网络交换。克服单一、共享式总线带宽限制的一种方法是，使用一个更复杂的互联网络，例如过去在多处理器计算机体系结构中用来互联多个处理器的网络。纵横交换机是非阻塞的。更为复杂的互联网络使用多级交换元素，以使来自不同输入端口的分组通过交换结构同时朝着相同的输出端口前行。 输出端口处理 输出端口处理取出已经存放在输出端口内存中的分组并将其发送到输出链路上。这包括选择和取出排队的分组进行传输，执行所需的链路层和物理层传输功能。 何时出现排队 输入排队 如果交换结构不能快得（相对于输入线路速度而言）使所有到达分组无时延地通过它传送，在这种情况下，在输入端口也将出现分组排队，因为到达的分组必须加入输入端口队列中，以等待通过交换结构传送到输出端口。 队头阻塞 一个输入队列中的排队分组必须等待通过交换结构发送，因为它被位于线路前部的另一个分组所阻塞，即使这个分组所前往的端口是空闲的。 输出排队 端口的发送速率小于交换机交换分组的速率，排队的分组耗尽了端口的可用内存，将会采取一定策略丢弃排队的分组 弃尾策略，丢弃刚到达排队的分组 删除一个或多个巳排队的分组为新来的分组腾出空间 分组调度 先进先出 调度规则按照分组到达输出链路队列的相同次序来选择分组在链路上传输，如果没有足够的缓存空间来容纳到达的分组，队列的分组丢弃策略则确定该分组是否将被队列中去除其他分组以便为到达的分组腾出空间， 优先权排队 到达输出链路的分组被分类放人输出队列中的优先权类，实践中，网络操作员可以配置一个队列，这样携带网络管理信息的分组获得超过用户流量的优先权，非抢占式优先权排队规则下，一旦分组开始传输，就不能打断。 循环和加权公平排队 其中，到达的分组被分类并在合适的每个类的等待区域排队。于是用循环调度一样，WFQ 调度器也以循环的方式为各个类提供服务，即首先服务第一类，然后第二类，接着第三类，然后重复这种服务模式。 网际协议：IPv4、寻址、 IPv6 及其他 IPv4 数据报格式 版本（号）。这 4 比特规定了数据报的 IP 协议版本。通过查看版本号，路由器能够确定如何解释 IP 数据报的剩余部分 。不同的 IP 版本使用不同的数据报格式。 首部长度。因为一个 IPv4 数据报可包含一些可变数量的选项，故需要用这 4 比特来确定 IP 数据报中载荷实际开始的地方。大多数 IP 数据报不包含选项，所以一般的 IP 数据报具有 20 字节的首部。 服务类型。服务类型(TOS)比特包含在 IPv4 首部中，以便使不同类型的 IP 数据报能相互区别开来 数据报长度。这是 IP 数据报的总长度（首部加上数据），以字节计。因为该字段长为 16 比特，所以 IP 数据报的理论最大长度为 65535 字节。 标识、标志、片偏移。这个字段与所谓 IP 分片有关。 寿命。寿命字段用来确保数据报不会永远（如由于长时间的路由选择环路）在网络中循环。每当一台路由器处理数据报时，该字段 的值减 1。若 TTL 字段减为 0, 则该数据报必须丢弃。 协议。该字段通常仅当一个 IP 数据报到达其最终目的地时才会有用。该字段值指示了 IP 数据报的数据部分应交给哪个特定的运输层协议。 首部检验和，首部检验和用于帮助路由器检测收到的 IP 数据报中的比特错误 源和目的 IP 地址。当某源生成一个数据报时，它在源 IP 字段中插入它的 IP 地址，在目的 IP 地址字段中插入其最终目的地的地址。 选项。选项字段允许 IP 首部被扩展。 数据（有效栽荷）。IP 数据报中的数据字段包含要交付给目的地的运输层报文段 ( TCP 或 UDP)。然而，该数据字段也可承载其他类型的数据，如 ICMP 报文。 IPv4 数据报分片 一个链路层帧能承载的最大数据量叫作最大传送单元(Maximum Transmission Unit, MTU)，不同的链路有不同的 MTU 片在其到达目的地运输层以前需要重新组装。 当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时贴上标识号。发送主机通常将它发送的每个数据报的标识号加 1。当某路由器需要对一个数据报分片时，形成的每个数据报（即片）具有初始数据报的源地址、目的地址与标识号。当目的地从同一发送主机收到一系列数据报时，它能够检查数据报的标识号以确定哪些数据报实际上是同一较大数据报的片。为了让目的主机绝对地相信它已收到了初始数据报的最后一个片，最后一个片的标志比特被设为 0、而所有其他片的标志比特被设为 1。为了让目的主机确定是否丢失了一个片（且能按正础的顺序重新组装片），使用偏移字段指定该片应放在初始 IP 数据报的哪个位置。 IPv4 编址 一台主机通常只有一条链路连接到网络；当主机中的 IP 想发送一个数据报时，它就在该链路上发送。主机与物理链路之间的边界叫作接口(interface)。 因为路由器的任务是从链路上接收数据报并从某些其他链路转发出去，路由器必须拥有两条或更多条链路与它连接。路由器与它的任意一条链路之间的边界也叫作接口。一台路由器因此有多个接口．每个接口有其链路。因为每台主机与路由器都能发送和接收 IP 数据报，IP 要求每台主机和路由器接口拥有自己的 IP 地址。因此、从技术上讲，一个 IP 地址与一个接口相关联，而不是与包括该接口的主机或路由器相关联。 每个 IP 地址长度为 32 比特（等价为 4 字节），因此总共有 2^32 大约 40 亿个可能的 IP 地址 。 在全球因特网中的每台主机和路由器上的每个接口，都必须有一个全球唯一的 IP 地址，这些地址不能随意地自由选择。一个接口的 IP 地址的一部分需要由其连接的子网来决定。 IP 编址为这个子网分配一个地址 223.</description></item><item><title>计算机网络自顶向下方法::运输层</title><link>/notes/computer_network_a_topdown_approach_03/</link><pubDate>Wed, 16 Jun 2021 20:27:06 +0800</pubDate><guid>/notes/computer_network_a_topdown_approach_03/</guid><description>概述和运输层服务 运输层协议为运行在不同主机上的应用进程之间提供了逻辑通信。应用进程使用运输层提供的逻辑通信功能彼此发送报文，而无须考虑承载这些报文的物理基础设施的细节。 运输层协议是在端系统中而不是在路由器中实现的。在发送端，运输层将从发送应用程序进程接收到的报文转换成运输层分组，用因特网术语来讲该分组称为运输层报文段（segment）。在接收端，网络层从数据报中提取运输层报文段，并将该报文段向上交给运输层 。运输层则处理接收到的报文段，使该报文段中的数据为接收应用进程使用。 网络应用程序可以使用多种的运输层协议。例如，因特网有两种协议，即 TCP 和 UDP。每种协议都能为调用的应用程序提供一组不同的运输层服务。 运输层和网络层的关系 在协议栈中，运输层刚好位于网络层之上。网络层提供了主机之间的逻辑通信，而运输层为运行在不同主机上的进程之间提供了逻辑通信 计算机网络中可以安排多种运输层协议，每种协议为应用程序提供不同的服务模型。 运输协议能够提供的服务常常受制于底层网络层协议的服务模型。如果网络层协议无法为主机之间发送的运输层报文段提供时延或带宽保证的话，运输层协议也就无法为进程之间发送的应用程序报文提供时延或带宽保证。 即使底层网络协议不能在网络层提供相应的服务，运输层协议也能提供某些服务。例如可靠运输。 因特网运输层概述 UDP：它为调用它的应用程序提供了一种不可靠、无连接的服务 TCP：它为调用它的应用程序提供了一种可靠的、面向连接的服务 当设计一个网络应用程序时，该应用程序的开发人员必须指定使用这两种运输协议中的一种 因特网网络层协议有一个名字叫 IP, 即网际协议。IP 为主机之间提供了逻辑通信。IP 的服务模型是尽力而为交付服务，是不可靠的 我们总结一下 UDP 和 TCP 所提供的服务模型。UDP 和 TCP 最基本的责任是，将两个端系统间 IP 的交付服务扩展为运行在端系统上的两个进程之间的交付服务。将主机间交付扩展到进程间交付被称为运输层的多路复用 (transport-layer multiplexing) 与 多路分解 (demultiplexing) 进程到进程的数据交付和差错检查是两种最低限度的运输层服务，也就是 UDP 所提供的服务 TCP 额外供了可靠数据运输和拥塞控制 多路复用和多路分解 一个进程有一个或多个套接字，它相当于从网络向进程传递数据和从进程向网络传递数据的门户。在接收主机中的运输层实际上并没有直接将数据交付给进程，而是将数据交给了一个中间的套接字。由于在任一时刻，在接收主机上可能有不止一个套接字，所以每个套接字都有唯一的标识符。标识符的格式取决于它是 UDP 还是 TCP 套接字。 主机为了将一个到达的运输层报文段定向到适当的套接字，每个运输层报文段中具有几个字段。在接收端，运输层检查这些字段，标识出接收套接字，进而将报文段定向到该套接字。将运输层报文段中的数据交付到正确的套接字的工作称为多路分解(demulti plexing)。在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息（这将在以后用于分解）从而生成报文段，然后将报文段传递到网络层，所有这些工作称为多路复用(multiplexing) 运输层多路复用要求 套接字有唯一标识 每个报文段有特殊字段来指示该报文段所要交付到的套接字 这些特殊字段是源端口号字段和目的端口号字段 在主机上的每个套接字能够分配一个端口号，当报文段到达主机时，运输层检查报文段中的目的端口号，并将其定向到相应的套接字。然后报文段中的数据通过套接字进入其所连接的进程 无连接的多路复用与多路分解 一个 UDP 套接字是由一个二元组全面标识的，该二元组包含一个目的 IP 地址和一个目的端口号。因此，如果两个 UDP 报文段有不同的源 IP 地址和／或源端口号，但具有相同的目的 IP 地址和目的端口号，那么这两个报文段将通过相同的目的套接字被定向到相同的目的进程。 面向连接的多路复用与多路分解 TCP 套接字是由一个四元组（源 IP 地址，源端口号，目的 IP 地址，目的端口号）来标识的 两个具有不同源 IP 地址或源端口号的到达 TCP 报文段将被定向到两个不同的套接字 Web 服务器与 TCP 如果客户与服务器使用持续 HTTP,则在整条连接持续期间 ，客户与服务器之间经由同一个服务器套接字交换 HTTP 报文 。然而，如果客户与服务器使用非持续 HTTP, 则对每一对请求／响应都创建一个新的 TCP 连接并在随后关闭、因此对每一对请求／响应创建一个新的套接字并在随后关闭。这种套接字的频繁创建和关闭会严重地影响一个繁忙的 Web 服务器的性能 无连接运输：UDP UDP 只是做了运输协议能够做的最少工作。除了复用／分解功能及少量的差错检测外，它几乎没有对 IP 增加别的东西。 使用 UDP 时，在发送报文段之前，发送方和接收方的运输层实体之间没有握手 使用 UDP 的理由 关于发送什么数据以及何时发送的应用层控制更为精细 无须连接建立 无连接状态 分组首部开销小 UDP 中缺乏拥塞控制能够导致 UDP 发送方和接收方之间的高丢包率，并挤垮了 TCP 会话，这是一个潜在的严重问题。很多研究人员已经提出了一些新的机制，使得 UDP 执行自适应的拥塞控制 使用 UDP 的应用是可能实现可靠数据传输的。这可通过在应用程序自身中建立可靠性机制来完成。例如 Google 的 QUIC。 UDP 报文段结构 源端口，发送方的端口号 目的端口，接收方的端口号 报文长度，即整个 UDP 报文的长度，包括头部和数据，单位为字节 检验和。 应用数据，也就是报文 UDP 检验和 检验和用千确定当 UDP 报文段从源到达目的地移动时，其中的比特是否发生了改变 发送方的 UDP 对报文段中的所有 16 比特字的和进行反码运算，求和时遇到的任何溢出都被回卷。 得到的结果被放在 UDP 报文段中的检验和字段，在接收方，全部的 4 个 16 比特字（包括检验和）没有引入差错 ，则显然在接收方处该和将是 1111111111111111 UDP 提供差错检测是因为不能保证源和目的之间的所有链路都提供差错检测；这就是说，也许这些链路中的一条可能使用没有差错检测的协议 可靠数据传输原理 构造可靠数据传输协议 经完全可靠信道的可靠数据传输: rdt1.</description></item><item><title>计算机网络自顶向下方法::应用层</title><link>/notes/computer_network_a_topdown_approach_02/</link><pubDate>Wed, 16 Jun 2021 20:26:06 +0800</pubDate><guid>/notes/computer_network_a_topdown_approach_02/</guid><description>应用层协议原理 应用层协议原理 研发网络应用程序的核心是写出能够运行在不同的端系统和通过网络彼此通信的程序 当研发新应用程序时，你需要编写将在多台端系统上运行的软件 网络应用体系结构 从应用程序研发者的角度看，网络体系结构是固定的，并为应用程序提供了特定的服务集合 应用程序体系结构 (application architecture) 由应用程序研发者设计，规定了如何在各种端系统上组织该应用程序。 客户-服务器体系结构 有一个总是打开的主机称为服务器，它服务于来自许多其他称为客户的主机的请求 客户-服务器体系结构，客户相互之间不直接通信 服务器具有固定的、周知的地址，该地址称为 IP 地址 具有客户-服务器体系结构的非常著名的应用程序包括 Web、FTP、Telnet 和电子邮件 一个流行的社交网络站点如果仅有一台服务器来处理所有请求，将很快变得不堪重负。为此，配备大量主机的数据中心(data center)常被用于创建强大的虚拟服务器。 P2P 体系结构 对数据中心服务器有最小的依赖 应用程序在间断连接的主机对之间使用直接通信，这些主机对被称为对等方 具有自扩展性，成本效率高，不需要庞大的基础设施 具有 P2P 体系结构的应用包括 BitTorrent、因特网电话和视频会议(例如 Skype) 进程通信 客户与服务器通信 网络应用程序由成对的进程组成，这些进程通过网络相互发送报文 对每对通信进程，我们通常将这两个进程之一标识为客户(client) , 而另一个进程标识为服务器 在 P2P 文件共享的某些应用中，一个进程能够既是客户又是服务器 我们定义客户和服务器进程如下: 在一对进程之间的通信会话场景中，发起通信(即在该会话开始时发起与其他进程的联系)的进程被标识为客户，在会话开始时等待联系的进程是服务器 进程与计算机网络之问的接口 进程通过一个称为套接字(socket)的软件接口向网络发送报文和从网络接收报文 套接字是同一台主机内应用层与运输层之间的接口。由于该套接字是建立网络应用程序的可编程接口，因此套接字也称为应用程序和网络之间的应用程序编程接口 进程寻址 为了标识该接收进程，需要定义两种信息 主机的地址 目的主机中指定接受进程的标识符 在因特网中，主机由其 IP 地址 (IP adress) 标识 目的地端口号 (port number) 用于指定运行在接收主机上的接收进程(更具体地说，接收套接字) 可供应用程序使用的运输服务 可靠数据传输 确保由应用程序的一端发送的数据正确、完全地交付给该应用程序的另一端 吞吐量 运输层协议能够以某种特定的速率提供确保的可用吞吐量 带宽敏感的应用具有特定的吞吐量要求，而弹性应用 (elastic application) 能够根据当时可用的带宽或多或少地利用可供使用的吞吐量 定时 运输层协议也能提供定时保证，能够以多种形式实现。这种服务将对交互式实时应用程序有吸引力。 安全性 在发送和接收进程之间提供机密性，以防该数据以某种方式在这两个进程之间被观察到。运输协议还能提供除了机密性以外的其他安全性服务，包括数据完整性和端点鉴别 因特网的提供的运输服务 TCP 服务 面向连接服务和可靠数据传输服务 在应用层数据报文开始流动之前，TCP 让客户端和服务器互相交换运输层控制信息。在握手后，一个全双工 TCP 连接就在两者之间建立了。当应用程序结束报文发送时，必须拆除该连接。 通信进程能够依靠 TCP, 无差错、按适当顺序交付所有发送的数据。当应用程序的一端将字节流传进套接字时，它能够依靠 TCP 将相同的字节流交付给接收方的套接字，而没有字节的丢失和冗余。 TCP 也提供拥塞控制机制，当发送方和接收方之间的网络出现拥塞时，TCP 的拥塞控制机制会抑制发送进程，TCP 拥塞控制也试图限制每个 TCP 连接，使它们达到公平共享网络带宽的目的。 UDP 服务 UDP 是一种不提供不必要服务的轻量级运输协议，它仅提供最小服务。UDP 是无连接的，因此在两个进程通信前没有握手过程。 UDP 协议提供一种不可靠数据传送服务，不保证报文能到达接受进程，也不保证顺序。 UDP 没有拥塞控制机制，可以以任意速率向下层注入数据。 运输协议不提供的服务 吞吐量和定时保证 应用层协议 交换的报文类型，例如请求报文和响应报文。 各种报文类型的语法，如报文中的各个字段及这些字段是如何描述的。 字段的语义，即这些字段中的信息的含义。 确定一个进程何时以及如何发送报文，对报文进行响应的规则。 Web 和 HTTP HTTP 概况</description></item><item><title>计算机网络自顶向下方法::计算机网络和因特网</title><link>/notes/computer_network_a_topdown_approach_01/</link><pubDate>Tue, 15 Jun 2021 20:26:06 +0800</pubDate><guid>/notes/computer_network_a_topdown_approach_01/</guid><description>计算机网络和因特网 什么是因特网 具体构成描述 因特网是一个世界范围的计算机网络，即它是一个互联了遍及全世界数十亿计算设备的网络。 传统 PC、Linux 工作站、服务器、智能手机、平板电脑、电视机、游戏机、家用电器、手表正在与互联网相连，这些设备称为主机或者端系统。 端系统通过通信链路 (communication link) 和分组交换机 (packet switch) 连接到一起 不同的链路能够以不同的速率传输数据，链路的传输速率 (transmission rate) 以比特/秒 (bills, 或 bps) 度量 。 当一台端系统要向另一台端系统发送数据时，发送端系统将数据分段，并为每段加上首部字节。由此形成的信息包用计算机网络的术语来说称为分组(packet)。这些分组通过网络发送到目的端系统，在那里被装配成初始数据。 分组交换器 从它的一条入通信链路接收到达的分组，并从它的一条出通信链路转发该分组 在当今的因特网中，两种最著名的类型是路由器(router)和链路层交换机(link-layer switch) 链路层交换机通常用于接入网中，而路由器通常用于网络核心中。 从发送端系统到接收端系统，一个分组所经历的一系列通信链路和分组交换机称为通过该网络的路径(route 或 path) ISP 端系统通过因特网服务提供商 (Internet Service Provider, ISP) 接入因特网 每个 ISP 自身就是一个由多台分组交换机和多段通信链路组成的网络。 协议 端系统、分组交换机和其他因特网部件都要运行一系列协议 (protocol), 这些协议控制因特网中信息的接收和发送。 TCP、IP、HTTP、SMTP 协议标准由因特网工程任务组研发，IETF 的标准文档称为请求评论(Request For Comment, RFC) 服务描述 为应用程序提供服务的基础设施 因特网相连的端系统提供了一个套接字接口(socket interface), 该接口规定了运行在一个端系统上的程序请求因特网基础设施向运行在另一个端系统上的特定目的地程序交付数据的方式。 什么是协议 定义了在两个或多个通信实体之间交换的报文的格式和顺序，以及报文发送和/或接收一条报文或其他事件所采取的动作。 因特网中协议无处不在快，不同的协议用于完成不同的通信任务。 网络边缘 与因特网相连的计算机和其他设备称为端系统，它们位于因特网的边缘，因特网的端系统包括了桌面计算机、服务器和移动计算机和非传统联网设备。 端系统被称为主机 运行应用程序，提供服务 主机有时又被进一步划分为两类 :客户(client)和服务器(server) 接入网 将端系统物理连接到其边缘路由器(edge router)的网络。边缘路由器是端系统到任何其他远程端系统的路径上的第一台路由器。 家庭接入: DSL、电缆、 FTTH、拨号和卫星 企业(和家庭)接人: 以太网和 WiFi 广域无线接入: 3/4/5G 和 LTE 物理媒介 双绞铜线 同轴电缆 光线 陆地无线电信道 卫星无线电信号 网络核心 分组交换 在各种网络应用中, 端系统彼此交换报文(message), 报文能够包含协议设计者需要的任何东西,报文可以执行一种控制功能，也可以包含数据， 为了从源端系统向目的端系统发送一个报文, 源将长报文划分为较小的数据块，称之为分组(packet)。 在源和目的地之间，每个分组都通过通信链路和分组交换机(packet switch)传送。 如果某源端系统或分组交换机经过一条链路发送一个 L 比特的分组，链路的传输速率为 R 比特/秒，则传输该分组的时间为 L/R 秒 。 存储转发传输 存储转发传输是指在交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。 排队时延和分组丢失 如果到达的分组需要传输到某条链路，但发现该链路正忙于传输其他分组，该到达分组必须在输出缓存中等待。因此，除了存储转发时延以外，分组还要承受输出缓存的排队时延。 因为缓存空间的大小是有限的，一个到达的分组可能发现该缓存巳被其他等待传输的分组完全充满了。在此情况下，将出现分组丢失(丢包)(packet loss), 到达的分组或已经排队的分组之一将被丢弃 。 转发表和路由选择协议 每台路由器具有一个转发表(forwarding table),用于将目的地址(或目的地址的一部分)映射成为输出链路。当某分组到达一台路由器时，路由器检查该地址，并用这个目的地址搜索其转发表，以发现适当的出链路。路由器则将分组导向该出链路 。 因特网具有一些特殊的路由选择协议，(routing protocol) ,用于自动地设置这些转发表。 电路交换 在电路交换网络中，在端系统间通信会话期间，预留了端系统间沿路径通信所需要的资源(缓存，链路传输速率) 在分组交换网络中.</description></item><item><title>深入理解Java虚拟机::线程安全和锁优化</title><link>/notes/understand_the_jvm_13/</link><pubDate>Mon, 12 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_13/</guid><description>线程安全和锁优化 线程安全 当多个线程同时访问一个对象时，如果不用考虑这些线程在运行时环境下 的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那就称这个对象是线程安全的。 代码本身封装了所有必要的正确性保障手段(如互斥同步等)，令调用者无须关心多线程下的调用问题，更无须自己实现任何措施来保证多线程环境下的正确调用 Java 语言中的线程安全 不可变 不可变(Immutable)的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再进行任何线程安全保障措施。 最简单的一种就是把对象里面带有状态的变量都声明为 final 常见不可变类型 String 枚举类 java.lang.Number 的部分子类 Long Double BigInteger BigDecimal 绝对线程安全 不管运行时环境如何，调用者都不需要任何额外的同步措施 相对线程安全 需要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。 线程兼容 线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用 线程对立 线程对立是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码 线程安全的实现方法 互斥同步 同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一条(或者是一些，当使用信号量的时候)线程使用。 互斥是实现同步的一种手段，临界区(Critical Section)、互斥量 (Mutex)和号量(Semaphore)都是常见的互斥实现方式 synchronized synchronized 关键字经过 Javac 编译之后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这两个字节码指令 。 这两个字节码指令都需要一个 reference 类型的参数来指明要锁定和解锁的对象 被 synchronized 修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。 被 synchronized 修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁;也无法强制正在等待锁的线程中断等待或超时退出。 持有锁是一个重量级 ReentrantLock 等待可中断:是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。 公平锁:是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁;而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized 中的锁是非公平的，ReentrantLock 在默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。不过一旦使用了公平锁，将会导致 ReentrantLock 的性能急剧下降，会明显影响吞吐量。 锁绑定多个条件:是指一个 ReentrantLock 对象可以同时绑定多个 Condition 对象。在 synchronized 中，锁对象的 wait()跟它的 notify()或者 notifyAll()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁;而 ReentrantLock 则无须这样做，多次调用 newCondition()方法即可。 比较 性能接近 只需要基础的同步功能时，更推荐 synchronized。 Lock 应该确保在 finally 块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不 会释放持有的锁。这一点必须由程序员自己来保证，而使用 synchronized 的话则可以由 Java 虚拟机来确保即使出现异常，锁也能被自动释放。 非同步阻塞 基于冲突检测的乐观并发策略 如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为非阻塞同步(Non-Blocking Synchronization)，使用这种措施的代码也常被称为无锁(Lock-Free) 编程。 硬件指令保证原子性 测试并设置(Test-and-Set) ; 获取并增加(Fetch-and-Increment) ; 交换(Swap); 比较并交换(Compare-and-Swap，下文称 CAS); 加载链接/条件储存(Load-Linked/Store-Conditional，下文称 LL/SC)。 无同步方案 可重入代码 可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误，也不会对结果有所影响。 不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等。 线程本地存储(Thread Local Storage):如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 锁优化 自旋锁与自适应自旋 自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。 锁消除 锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。 锁粗化 如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展(粗化)到整个操作序列的外部 轻量级锁 在代码即将进入同步块的时候，如果此同步对象没有被锁定(锁标志位为“01”状态)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的 Mark Word 的拷贝，然后，虚拟机将使用 CAS 操作尝试把对象的 Mark Word 更新为指向 Lock Record 的指针。如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象 Mark Word 的锁标志位(Mark Word 的最后两个比特)将转变为“ 00”，表示此对象处于轻量级锁定状态.</description></item><item><title>深入理解Java虚拟机::Java 内存模型与线程</title><link>/notes/understand_the_jvm_12/</link><pubDate>Sun, 11 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_12/</guid><description>Java 内存模型与线程 Amdahl 定律通过系统中并行化与串行化的比重来描述多处理器系统能获得的运算加速能力，摩尔定律则用于描述处理器晶体管数量与运行效率之间的发展关系。这两个定律的更替代表了近年来硬件发展从追求处理器频率到追求多核心并行处理的发展过程。 硬件的效率与一致性 缓存一致性 在多路处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存 当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致 为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有 MSI、MESI(Illinois Protocol)、MOSI、 Synapse、Firefly 及 Dragon Protocol 等 内存模型 在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象 Java 内存模型 主内存与工作内存 Java 内存模型的主要目的是定义程序中各种变量的访问规则，即关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节。 变量 包括实例字段、静态字段和构成数组对象的元素 不包括局部变量与方法参数，线程私有的 Java 内存模型规定了所有的变量都存储在主内存(Main Memory)中 每条线程还有自己的工作内存 线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的数据。 内存之间的交互操作 8 个原子操作 lock(锁定):作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock(解锁):作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read(读取):作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用。 load(载入):作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。 use(使用):作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign(赋值):作用于工作内存的变量，它把一个从执行引擎接收的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store(存储):作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write 操作使用。 write(写入):作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中。 需要满足的规则 不允许 read 和 load、store 和 write 操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起回写了但主内存不接受的情况出现。 不允许一个线程丢弃它最近的 assign 操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。 不允许一个线程无原因地(没有发生过任何 assign 操作)把数据从线程的工作内存同步回主内存中。 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化(load 或 assign)的变量，换句话说就是对一个变量实施 use、store 操作之前，必须先执行 assign 和 load 操作 。 一个变量在同一个时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。 如果对一个变量执行 lock 操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行 load 或 assign 操作以初始化变量的值。 如果一个变量事先没有被 lock 操作锁定，那就不允许对它执行 unlock 操作，也不允许去 unlock 一个被其他线程锁定的变量。 对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中(执行 store、write 操作)。 对于 volatile 型变量的特殊规则 两项特性 第一项是保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的 保证原子性 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。 变量不需要与其他的状态变量共同参与不变约束。 禁止指令重排序优化 volatile 变量读操作的性能消耗与普通变量几乎没有什么差别，但是写操作则可能会慢上一些，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。 volatile 屏蔽指令重排序的语义在 JDK 5 中才被完全修复，此前的 JDK 中即使将变量声明为 volatile 也仍然不能完全避免重排序所导致的问题(主要是 volatile 变量前后的代码仍然存在重排序问题)，这一点也是在 JDK5 之前的 Java 中无法安全地使用 DCL(双锁检测)来实现单例模式的原因。 双重锁定检查是一种在许多语言中都广泛流传的单例构造模式。 针对 long 和 double 型变量的特殊规则 long 和 double 的非原子性协定 在实际开发中，除非该数据有明确可知的线程竞争，否则我们在编写代码时一般不需要因为这个原因刻意把用到的 long 和 double 变量专门声明为 volatile。 原子性、可见性与有序性 原子性(Atomicity) 由 Java 内存模型来直接保证的原子性变量操作包括 read、load、assign、use、store 和 write 这六个 更大范围的原子性保证(经常会遇到)，Java 内存模型提供了 lock 和 unlock 字节码指令 monitorenter 和 monitorexit 来隐式地使用这两个操作。这两个字节码指令反映到 Java 代码中就是同步块——synchronized 关键字，因此在 synchronized 块之间的操作也具备原子性。 可见性(Visibility) 可见性就是指当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改 Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是 volatile 变量都是如此。普通变量与 volatile 变量的区别是，volat ile 的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。 除了 volatile 之外，Java 还有两个关键字能实现可见性，它们是 synchronized 和 final 同步块的可见性是由&amp;quot;对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中&amp;quot; 而 final 关键字的可见性是指:被 final 修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去，那么在其他线程中就能看见 final 字段的值。 有序性(Ordering) Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性，volatile 关键字本 身就包含了禁止指令重排序的语义，而 synchronized 则是由“一个变量在同一个时刻只允许一条线程对其进行 lock 操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入。 先行发生原则 先行发生是 Java 内存模型中定义的两项操作之间的偏序关系，比如说操作 A 先行发生于操作 B，其实就是说在发生操作 B 之前，操作 A 产生的影响能被操作 B 观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 程序次序规则(Program Order Rule):在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 管程锁定规则(Monitor Lock Rule):一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这 里必须强调的是“同一个锁”，而“后面”是指时间上的先后。 volatile 变量规则(Volatile Variable Rule):对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后。 线程启动规则(Thread Start Rule):Thread 对象的 start() 方法先行发生于此线程的每一个动作。 线程终止规则(Thread Termination Rule):线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过 Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。 线程中断规则(Thread Interruption Rule):对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread::interrupted()方法检测到是否有中断发生。 对象终结规则(Finalizer Rule):一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize()方法的开始。 传递性(Transitivity):如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那就可以得出操作 A 先行发生于操作 C 的结论。 Java 与线程 线程的实现 内核线程实现 内核线程(Kernel-Level Thread，KLT)就是直接由操作系统内核(Kernel，下称内核)支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器(Scheduler)对线程进行调度，并负责将线程的任务映射到各个处理器上。 用户线程实现 完全建立在用户空间的线程库上，系统内核不能感知到用户线程的存在及如何实现的。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也能够支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。 混合实现 这种混合实现下，既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级进程来完成，这大大降低了整个进程被完全阻塞的风险。 Java 线程的实现 Java 线程在 早期的 Classic 虚拟机上(JDK 1.</description></item><item><title>深入理解Java虚拟机::后端编译与优化</title><link>/notes/understand_the_jvm_11/</link><pubDate>Sat, 10 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_11/</guid><description>后端编译与优化 Java 世界里，虽然提前编译(Ahead Of Time，AOT)早已有所应用，但相对而言，即时编译(Just In Time，JIT)才是占绝对主流的编译形式
解释器与编译器
主流的商用 Java 虚拟机，内部都同时包含解释器与编译器 解释器与编译器两者各有优势 当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即运行 当程序启动后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码，这样可以减少解释器的中间损耗，获得更高的执行效率 解释器还可以作为编译器激进优化时后备的“逃生门”,当激进优化的假设不成立，如加载了新类以后，类型继承结构出现变化、出现“罕见陷阱”(Uncommon Trap)时可以通过逆优化(Deoptimization)退回到解释状态继续执行 内置即时编译器 客户端编译器 服务端编辑器 实验性 Graal 编译器 解释器与编译器搭配使用的方式在虚拟机中被称为“混合模式”(Mixed Mode) 分层编译 第 0 层。程序纯解释执行，并且解释器不开启性能监控功能(Profiling)。 第 1 层。使用客户端编译器将字节码编译为本地代码来运行，进行简单可靠的稳定优化，不开启性能监控功能。 第 2 层。仍然使用客户端编译器执行，仅开启方法及回边次数统计等有限的性能监控功能。 第 3 层。仍然使用客户端编译器执行，开启全部性能监控，除了第 2 层的统计信息外，还会收集如分支跳转、虚方法调用版本等全部的统计信息。 第 4 层。使用服务端编译器将字节码编译为本地代码，相比起客户端编译器，服务端编译器会启用更多编译耗时更长的优化，还会根据性能监控信息进行一些不可靠的激进优化。 热点代码 被多次调用的方法。 被多次执行的循环体。 编译器依然必须以整个方法作为编译对象 热点探测 周期性地检查各个线程的调用栈顶，如果发现某个(或某些)方法经常出现在栈顶，那这个方法就是“热点方法” 基于计数器的热点探测(Counter Based Hot Spot Code Detection)。采用这种方法的虚拟机会为每个方法(甚至是代码块)建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是“热点方法”。 回边计数器 统计一个方法中循环体代码执行的次数 当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否有已经编译好的版本，如果有的话，它将会优先执行已编译的代码，否则就把回边计数器的值加一，然后判断方法调用计数器与回边计数器值之和是否超过回边计数器的阈值。当超过阈值的时候，将会提交一个栈上替换编译请求，并且把回边计数器的值稍微降低一些，以便继续在解释器中执行循环，等待编译器输出编译结果 编译过程 在第一个阶段，一个平台独立的前端将字节码构造成一种高级中间代码表 在第二个阶段，一个平台相关的后端从 HIR 中产生低级中间代码表示 最后的阶段是在平台相关的后端使用线性扫描算法在 LIR 上分配寄存器，并在 LIR 上做窥孔优化，然后产生机器代码 经典优化手段 无用代码消除(Dead Code Elimination) 循环展开 (Loop Unrolling) 循环表达式外提(Loop Expression Hoisting) 消除公共子表达式(Common Subexpression Elimination) 常量传播(Constant Propagation) 基本块重排序(Basic Block Reordering) 范围检查消除(Range Check Elimination) 空值检查消除(Null Check Elimination) 如守护内联(Guarded Inlining) 分支频率预测 (Branch Frequency Prediction) 提前编译器</description></item><item><title>深入理解Java虚拟机::前段编译与优化</title><link>/notes/understand_the_jvm_10/</link><pubDate>Fri, 09 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_10/</guid><description>前段编译与优化 前端编译器：把 *.java 文件转变成 *.class 文件 即时编译器：运行期把字节码转变成本地机器码 静态的提前编译器：直接把程序编译成与目标机器指令集相关的二进制代码 Javac 编译器 Java 语言实现 编译过程 准备过程:初始化插入式注解处理器。 提前至编译期对代码中的特定注解进行处理，从而影响到前端编译器的工作过程 我们可以把插入式注解处理器看作是一组编译器的插件，当这些插件工作时，允许读取、修改、添加抽象语法树中的任意元素。如果这些插件在处理注解期间对语法树进行过修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止 解析与填充符号表 词法、语法分析。将源代码的字符流转变为标记集合，构造出抽象语法树 词法分析是将源代码的字符流转变为标记(Token)集合的过程，单个字符是程序编写时的最小元素 词法分析过程由 com.sun.tools.javac.parser.Scanner 类来实现。 填充符号表。产生符号地址和符号信息 符号表(Symbol Table)是由一组符号地址和符号信息构成的数据结构 符号表中所登记的信息在编译的不同阶段都要被用到。 在 Javac 源代码中，填充符号表的过程由 com.sun.tools.javac.comp.Enter 类实现 该过程的产出物是一个待处理列表，其中包含了每一个编译单元的抽象语法树的顶级节点， 分析与字节码生成过程 标注检查。对语法的静态信息进行检查。 标注检查步骤要检查的内容包括诸如变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配 顺便进行一个称为常量折叠的代码优化 数据流及控制流分析。对程序动态运行过程进行检查。 数据流分析和控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题。 解语法糖。将简化代码编写的语法糖还原为原有的形式。 计算机语言中添加的某种语法，这种语法对语言的编译结果和功能并没有实际影响，但是却能更方便程序员使用该语言 Java 中最常见的语法糖包括了前面提到过的泛型、变长参数、自动装箱拆箱，等等 字节码生成。将前面各个步骤所生成的信息转化成字节码。 在 Javac 源码里面由 com.sun.tools.javac.jvm.Gen 类来完成。字节码生成阶段不仅仅是把前面各个步骤所生成的信息(语法树、符号表)转化成字节码指令写到磁盘中，编译器还进行了少量的代码添加和转换工作。 完成了对语法树的遍历和调整之后，就会把填充了所有所需信息的符号表交到 com.sun.tools.javac.jvm.ClassWriter 类手上，由这个类的 writeClass()方法输出字节码，生成最终的 Class 文件，到此，整个编译过程宣告结束。 语法糖 泛型 泛型的本质是参数化类型(Parameterized Type)或者参数化多态(Parametric Polymorphism)的应用，即可以将操作的数据类型指定为方法签名中的一种特殊参数，这种参数类型能够用在类、接口 和方法的创建中，分别构成泛型类、泛型接口和泛型方法。泛型让程序员能够针对泛化的数据类型编写相同的算法，这极大地增强了编程语言的类型系统及抽象能力。 类型擦除式泛型 Java 语言中的泛型只在程序源码中存在，在编译后的字节码文件中，全部泛型都被替换为原来的裸类型了，并且在相应的地方插入了强制 转型代码，因此对于运行期的 Java 语言来说，ArrayList与 ArrayList其实是同一个类型 擦除式泛型的实现几乎只需要在 Javac 编译器上做出改进即可，不需要改动字节码、不需要改动 Java 虚拟机，也保证了以前没有使用泛型的库可以直接运行在 Java 5.</description></item><item><title>深入理解Java虚拟机::类加载及执行子系统的案例与实战</title><link>/notes/understand_the_jvm_09/</link><pubDate>Thu, 08 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_09/</guid><description>类加载及执行子系统的案例与实战 Tomcat:正统的类加载器架构 必要的服务器功能 部署在同一个服务器上的两个 Web 应用程序所使用的 Java 类库可以实现相互隔离 部署在同一个服务器上的两个 Web 应用程序所使用的 Java 类库可以互相共享。 服务器需要尽可能地保证自身的安全不受部署的 Web 应用程序影响 支持 JSP 应用的 Web 服务器，十有八九都需要支持 HotSwap 功能。 为了满足上述需求，在部署 Web 应用时，单独的一个 ClassPath 就不能满足需求了，所以各种 Web 服务器都不约而同地提供了好几个有着不同含义的 ClassPath 路径供用户存放第三方类库，这些路径一般 会以“lib”或“classes”命名。被放置到不同路径中的类库，具备不同的访问范围和服务对象，通常每一个目录都会有一个相应的自定义类加载器去加载放置在里面的 Java 类库。 OSGi:灵活的类加载器架构 OSGi 中的每个模块(称为 Bundle)与普通的 Java 类库区别并不太大，两者一般都以 JAR 格式进行封装，并且内部存储的都是 Java 的 Package 和 Class。但是一个 Bundle 可以声明它所依赖的 Package(通过 Import-Package 描述)，也可以声明它允许导出发布的 Package(通过 Export-Package 描述)。在 OSGi 里面，Bundle 之间的依赖关系从传统的上层模块依赖底层模块转变为平级模块之间的依赖，而且类库的可见性能得到非常精确的控制，一个模块里只有被 Export 过的 Package 才可能被外界访问，其他的 Package 和 Class 将会被隐藏起来。 加载规则 以 java.*开头的类，委派给父类加载器加载。 否则，委派列表名单内的类，委派给父类加载器加载。 否则，Import 列表中的类，委派给 Export 这个类的 Bundle 的类加载器加载。 否则，查找当前 Bundle 的 Classpath，使用自己的类加载器加载。 否则，查找是否在自己的 Fragment Bundle 中，如果是则委派给 Fragment Bundle 的类加载器加载。 否则，查找 Dynamic Import 列表的 Bundle，委派给对应 Bundle 的类加载器加载。 否则，类查找失败。 字节码生成技术与动态代理的实现 省去了编写代理类那一点编码工作量， 实现了可以在原始类和接口还未知的时候，就确定代理类的代理行为，当代理类与原始类脱离直接联系后，就可以很灵活地重用于不同的应用场景之中。 Backport 工具:Java 的时光机器 ASM 框架直接对字节码进行处理，把高版本的字节码编译到更低版本的字节码</description></item><item><title>深入理解Java虚拟机::虚拟机字节码执行引擎</title><link>/notes/understand_the_jvm_08/</link><pubDate>Wed, 07 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_08/</guid><description>虚拟机字节码执行引擎 概述 执行引擎是 Java 虚拟机核心的组成部分之一 虚拟机的执行引擎则是由软件自行实现的，因此可以不受物理条件制约地定制指令集与执行引擎的结构体系，能够执行那些不被硬件直接支持的指令集格式。 运行时栈帧结构 Java 虚拟机以方法作为最基本的执行单元 栈帧是用于支持虚拟机进行方法调用和方法执行背后的数据结构 虚拟机运行时数据区中的虚拟机栈的栈元素 栈帧 局部变量表、操作数栈、动态连接和方法返回地址等信息 每一个方法从调用开始至执行结束的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程 一个栈帧需要分配多少内存，并不会受到程序运行期变量数据的影响，而仅仅取决于程序源码和具体的虚拟机实现的栈内存布局形式 局部变量表 局部变量表是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量 局部变量表的容量以变量槽为最小单位 64 位或者 32 位 每个变量槽都应该能存放一个 boolean、 byte、char、short、int、float、reference 或 returnAddress 类型的数据 局部变量表是建立在线程堆栈中的，属于线程私有的数据，无论读写两个连续的变量槽是否为原子操作，都不会引起数据竞争和线程安全问题。 当一个方法被调用时，Java 虚拟机会使用局部变量表来完成参数值到参数变量列表的传递过程，即实参到形参的传递, 实例方法, 那局部变量表中第 0 位索引的变量槽默认是用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问到这个隐含的参数。其余参数则按照参数表顺序排列，占用从 1 开始的局部变量槽，参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域分配其余的变量槽。 变量槽可以复用，但是会影响垃圾回收 把占用了大量内存但是已经用不到的变量设为 null 有助于 gc 的回收，因为在局部变量表中不再有引用 操作数栈 后入先出栈 动态连接 支持方法调用过程中的动态连接 Class 文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池里指向方法的符号引用作为参数 这些符号引用一部分会在类加载阶段或者第一次使用的时候就被转化为直接引用，这种转化被称为静态解析。 另外一部分将在每一次运行期间都转化为直接引用，这部分就称为动态连接 方法返回地址 当一个方法开始执行后，只有两种方式退出这个方法 遇到任意一个方法返回的字节码指令 代码中使用 athrow 字节码指令产生的异常 方法退出的过程实际上等同于把当前栈帧出栈 恢复上层方法的局部变量表和操作数栈 把返回值压入调用者栈帧的操作数栈中 调整 PC 计数器的值以指向方法调用指令后面的一条指令等 方法调用 方法调用阶段唯一的任务就是确定被调用方法的版本，暂时还未涉及方法内部的具体运行过程 某些调用需要在类加载期间，甚至到运行期间才能确定目标方法的直接引用。 解析 方法调用的目标方法在 Class 文件里面都是一个常量池中的符号引用 方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的 在 Java 虚拟机支持以下 5 条方法调用字节码指令，分别是: invokestatic。用于调用静态方法。 invokespecial。用于调用实例构造器()方法、私有方法和父类中的方法。 invokevirtual。用于调用所有的虚方法。 invokeinterface。用于调用接口方法，会在运行时再确定一个实现该接口的对象。 invokedynamic。先在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法。前面 4 条调用指令，分派逻辑都固化在 Java 虚拟机内部，而 invokedynamic 指令的分派逻辑是由用户设定的引导方法来决定的。 final 方法无法被覆盖 分派 静态分派 编译器在重载时是通过参数的静态类型而不是实际类型作为判定依据的 静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的，这点也是为何一些资料选择把它归入“解析”而不是“分派”的原因。 自动转型按照 char &amp;gt; int &amp;gt; long &amp;gt; float &amp;gt; double 的顺序转型进行匹配 动态分配 重写 invokevirtual 指令的运行时解析过程 找到操作数栈顶的第一个元素所指向的对象的实际类型，记作 C。 如果在类型 C 中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束;不通过则返回 java.</description></item><item><title>深入理解Java虚拟机::虚拟机类加载机制</title><link>/notes/understand_the_jvm_07/</link><pubDate>Tue, 06 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_07/</guid><description>虚拟机类加载机制 概述 Java 虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的 Java 类型，这个过程被称作虚拟机的类加载机制 类加载的时机 一个类型从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期将会经历加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unload ing)七个阶段，其中验证、准备、解析三个部分统称为连接(Linking) 加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的 解析在某些情况下可以在初始化阶段之后再开始 为了支持 Java 语言的运行时绑定特性 JVM 规范严格规定了有且只有六种情况必须立即对类进行初始化 遇到 new、getstatic、putstatic 或 invokestatic 这四条字节码指令时，如果类型没有进行过初始化，则需要先触发其初始化阶段 使用 new 关键字实例化对象的时候 读取或设置一个类型的静态字段(被 final 修饰、已在编译期把结果放入常量池的静态字段除外)的时候。 调用一个类型的静态方法的时候 使用 java.lang.reflect 包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化 当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类(包含 main()方法的那个类)，虚拟机会先初始化这个主类。 当使用 JDK 7 新加入的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial 四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。 当一个接口中定义了 JDK 8 新加入的默认方法(被 default 关键字修饰的接口方法)时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。 这六种场景中的行为称为对一个类型进行主动引用。除此之外，所有引用类型的方式都不会触发初始化，称为被动引用。 类加载的过程 加载 在加载阶段，Java 虚拟机需要完成以下三件事情: 通过一个类的全限定名来获取定义此类的二进制字节流。 从 ZIP 压缩包中读取，这很常见，最终成为日后 JAR、EAR、WAR 格式的基础 从网络中获取，这种场景最典型的应用就是 Web Applet。 运行时计算生成，这种场景使用得最多的就是动态代理技术，在 java.lang.reflect.Proxy 中，就是用了 ProxyGenerator.generateProxyClass()来为特定接口生成形式为“*$Proxy”的代理类的二进制字节流。 由其他文件生成，典型场景是 JSP 应用，由 JSP 文件生成对应的 Class 文件。 从数据库中读取，这种场景相对少见些，例如有些中间件服务器(如 SAP Netweaver)可以选择把程序安装到数据库中来完成程序代码在集群间的分发。 可以从加密文件中获取，这是典型的防 Class 文件被反编译的保护措施，通过加载时解密 Class 文件来保障程序运行逻辑不被窥探。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的 java.</description></item><item><title>深入理解Java虚拟机::类文件结构</title><link>/notes/understand_the_jvm_06/</link><pubDate>Mon, 05 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_06/</guid><description>类文件结构 实现语言无关性的基础是虚拟机和字节码存储格式 Class 类文件的结构 Class 文件格式采用一种类似于 C 语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型无符号数和表 无符号数属于基本的数据类型，以 u1、u2、u4、u8 来分别代表 1 个字节、2 个字节、4 个字节和 8 个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照 UTF-8 编码构成字符串值 表是由多个无符号数或者其他表作为数据项构成的复合数据类型，为了便于区分，所有表的命名都习惯性地以“_info”结尾。表用于描述有层次关系的复合结构的数据，整个 Class 文件本质上也可以视作是一张表， ClassFile { u4 magic; //0xCAFEBABE u2 minor_version; //class file minor version u2 major_version; //class file major version u2 constant_pool_count; //count of entries in next item cp_info constant_pool[constant_pool_count-1]; //constants u2 access_flags; //class assess flags u2 this_class; //index of this class to const pool u2 super_class; //index of super class to const pool u2 interfaces_count; //number of interfaces implemented u2 interfaces[interfaces_count];//indices of interfaces u2 fields_count; //number of fields in the class field_info fields[fields_count];//fields descriptions u2 methods_count; //number of methods in the class method_info methods[methods_count]; //methods descriptions u2 attributes_count; //number of attributes of the class attribute_info attributes[attributes_count]; //attributes } 魔数与 Class 文件的版本 魔数 每个 Class 文件的头 4 个字节被称为魔数(Magic Number)，它的唯一作用是确定这个文件是否为一个能被虚拟机接受的 Class 文件。 Class 文件的版本号 第 5 和第 6 个字节是次版本号(Minor Version)，第 7 和第 8 个字节是主版本号(Major Version)。 高版本需要向下兼容以前版本的 Class 文件，但不能运行以后版本的 Class 文件。 常量池 常量池的入口放置一项 u2 类型的数据，代表常量池容量计数值(constant_pool_count) Class 文件结构中只有常量池的容量计数是从 1 开始, 0 用于表示无常量池引用 常量池中主要存放两大类常量: 字面量(Literal)和符号引用(Symbolic References) 字面量 文本字符串 声明为 final 的常量值 符号引用 被模块导出或者开放的包 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 方法句柄和方法类型 动态调用点和动态常量 常量池中的每一项常量都是一个表，互相之间的结构都不相同 JVM 规范中关于 Class 文件格式的章节 访问标志 识别一些类或者接口层次的访问信息 有 16 个标志位可以使用，当前只定义了其中 9 个 类索引、父类索引与接口索引集合 类索引用于确定这个类的全限定名 父类索引用于确定这个类的父类的全限定名 接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按 implements 关键字后的接口顺序从左到右排列在接口索引集合中。 字段表集合 字段表用于描述接口或者类中声明的变量 类级变量以及实例级变量，但不包括在方法内部声明的局部变量 字段表集合中不会列出从父类或者父接口中继承而来的字段 方法表集合 volatile 关键字和 transient 关键字不能修饰方法 Java 语言中，重载方法需要签名不同 Class 文件格式中，允许方法签名相同，返回值不同的方法存在 属性表集合 Code 属性 Java 程序方法体里面的代码经过 Javac 编译器处理之后，最终变为字节码指令存储在 Code 属性内。 接口和抽象方法没有 Code 属性 《Java 虚拟机规范》中明确限制了一个方法不允许超过 65535 条字节码指令 Exceptions 属性 Exceptions 属性的作用是列举出方法中可能抛出的受查异常 LineNumberTable 属性 LineNumberTable 属性用于描述 Java 源码行号与字节码行号(字节码的偏移量)之间的对应关系 非必需，对程序运行产生的最主要影响就是当抛出异常时，堆栈中将不会显示出错的行号 LocalVariableTable 及 LocalVariableTypeTable 属性 LocalVariableTable 属性用于描述栈帧中局部变量表的变量与 Java 源码中定义的变量之间的关系 非必需，影响是当其他人引用这个方法时，所有的参数名称都将会丢失 SourceFile 及 SourceDebugExtension 属性 SourceFile 属性用于记录生成这个 Class 文件的源码文件名称 非必需，当抛出异常时，堆栈中将不会显示出错代码所属的文件名 ConstantValue 属性 ConstantValue 属性的作用是通知虚拟机自动为静态变量赋值。只有被 static 关键字修饰的变量(类变量)才可以使用这项属性。 InnerClasses 属性 InnerClasses 属性用于记录内部类与宿主类之间的关联。 如果一个类中定义了内部类，那编译器将会为它以及它所包含的内部类生成 InnerClasses 属性。 Deprecated 及 Synthetic 属性 Deprecated 和 Synthetic 两个属性都属于标志类型的布尔属性，只存在有和没有的区别，没有属性值的概念。 Deprecated 属性用于表示某个类、字段或者方法，已经被程序作者定为不再推荐使用，它可以通过代码中使用@deprecated注解进行设置。 StackMapTable 属性 目的在于代替以前比较消耗性能的基于数据流分析的类型推导验证器。 Signature 属性 它是一个可选的定长属性，可以出现于类、字段表和方法表结构的属性表中 Signature 属性会为记录泛型签名信息。之所以要专门使用这样一个属性去记录泛型类型，是因为 Java 语言的泛型采用的是擦除法实现的伪泛型，字节码(Code 属性)中所有的泛型信息编译(类型变量、参数化类型)在编译之后都通通被擦除掉 BootstrapMethods 属性 用于保存 invokedynamic 指令引用的引导方法限定符。 MethodParameters 属性 MethodParameters 的作用是记录方法的各个形参名称和信息。 模块化相关属性 Module 属性是一个非常复杂的变长属性，除了表示该模块的名称、版本、标志信息以外，还存储了这个模块 requires、exports、opens、uses 和 provides 定义的全部内容 运行时注解相关属性 RuntimeVisibleAnnotations 是一个变长属性，它记录了类、字段或方法的声明上记录运行时可见注解，当我们使用反射 API 来获取类、字段或方法上的注解时，返回值就是通过这个属性来取到的 字节码指令简介 Java 虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字以及跟随其后的零至多个代表此操作所需的参数构成 加载和存储指令 加载和存储指令用于将数据在栈帧中的局部变量表和操作数栈之间来回传输 运算指令 算术指令用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入到操作栈顶 大体上运算指令可以分为两种: 对整型数据进行运算的指令与对浮点型数据进行运算的指令。 类型转换指令 类型转换指令可以将两种不同的数值类型相互转换，这些转换操作一般用于实现用户代码中的显式类型转换操作 对象创建与访问指令 虽然类实例和数组都是对象，但 Java 虚拟机对类实例和数组的创建与操作使用了不同的字节码指令(在下一章会讲到数组和普通类的类型创建过程是不同的)。对象创建后，就可以通过对象访问指令获取对象实例或者数组实例中的字段或者数组元素 操作数栈管理指令 用于直接操作操作数栈的指令 控制转移指令 控制转移指令可以让 Java 虚拟机有条件或无条件地从指定位置指令的下 一条指令继续执行程序，从概念模型上理解，可以认为控制指令就是在有条件或无条件地修改 PC 寄存器的值 方法调用和返回指令 用于方法调用 异常处理指令 显式抛出异常的操作都由 athrow 指令来实现 同步指令 Java 虚拟机可以支持方法级的同步和方法内部一段指令序列的同步，这两种同步结构都是使用管程来实现 公有设计，私有实现 《Java 虚拟机规范》描绘了 Java 虚拟机应有的共同程序存储格式:Class 文件格式以及字节码指令集。这些内容与硬件、操作系统和具体的 Java 虚拟机实现之间是完全独立的，虚拟机实现者可能更愿意把它们看作程序在各种 Java 平台实现之间互相安全地交互的手段。 一个优秀的虚拟机实现，在满足《Java 虚拟机规范》的约束下对具体实现做出修改和优化也是完全可行的，并且《Java 虚拟机规范》中明确鼓励实现者这样去做。只要优化以后 Class 文件依然可以被正确读取，并且包含在其中的语义能得到完整保持，那实现者就可以选择以任何方式去实现这些语义，虚拟机在后台如何处理 Class 文件完全是实现者自己的事情，只要它在外部接口上看起来与规范描述的一致即可 Class 文件结构的发展 Class 文件结构一直处于一个相对比较稳定的状态，Class 文件的主体结构、字节码指令的语义和数量几乎没有出现过变动，所有对 Class 文件格式的改进，都集中在访问标志、属性表这些设计上原本就是可扩展的数据结构中添加新内容。 二十余年间，字节码的数量和语义只发生过屈指可数的几次变动，例如 JDK 1.</description></item><item><title>深入理解Java虚拟机::调优案例分析与实战</title><link>/notes/understand_the_jvm_05/</link><pubDate>Sun, 04 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_05/</guid><description>调优案例分析与实战 大内存硬件上的程序部署策略 目前单体应用在较大内存的硬件上主要的部署方式有两种: 通过一个单独的 Java 虚拟机实例来管理大量的 Java 堆内存。 同时使用若干个 Java 虚拟机，建立逻辑集群来利用硬件资源。 面临的问题 回收大块堆内存而导致的长时间停顿，自从 G1 收集器的出现，增量回收得到比较好的应用 大内存必须有 64 位 Java 虚拟机的支持，但由于压缩指针、处理器缓存行容量(Cache Line)等因素，64 位虚拟机的性能测试结果普遍略低于相同版本的 32 位虚拟机。 必须保证应用程序足够稳定，因为这种大型单体应用要是发生了堆内存溢出，几乎无法产生堆转 储快照，哪怕成功生成了快照也难以进行分析;如果确实出了问题要进行诊断，可能就必须应用 JM C 这种能够在生产环境中进行的运维工具。 相同的程序在 64 位虚拟机中消耗的内存一般比 32 位虚拟机要大，这是由于指针膨胀，以及数据类 型对齐补白等因素导致的，可以开启压缩指针功能来缓解。 集群间同步导致的内存溢出 集群同步软件的问题导致了内存泄漏 -XX:+HeapDumpOnOutOfMemoryError 堆外内存导致的溢出错误 直接内存:可通过-XX:MaxDirectMemorySize 调整大小，内存不足时抛出 OutOfMemoryError 或者 OutOfMemoryError:Direct buffer memory。 线程堆栈:可通过-Xss 调整大小，内存不足时抛出 StackOverflowError(如果线程请求的栈深度大 于虚拟机所允许的深度)或者 OutOfMemoryError(如果 Java 虚拟机栈容量可以动态扩展，当栈扩展时 无法申请到足够的内存)。 Socket 缓存区:每个 Socket 连接都 Receive 和 Send 两个缓存区，分别占大约 37KB 和 25KB 内存，连接 多的话这块内存占用也比较可观。如果无法分配，可能会抛出 IOException:Too many open files 异常。 JNI 代码:如果代码中使用了 JNI 调用本地库，那本地库使用的内存也不在堆中，而是占用 Java 虚 拟机的本地方法栈和本地内存的。 虚拟机和垃圾收集器:虚拟机、垃圾收集器的工作也是要消耗一定数量的内存的。 外部命令导致系统缓慢 执行这个 Shell 脚本是通过 Java 的 Runtime.</description></item><item><title>深入理解Java虚拟机::虚拟机性能监控、故障处理工具</title><link>/notes/understand_the_jvm_04/</link><pubDate>Sat, 03 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_04/</guid><description>虚拟机性能监控、故障处理工具 jps 虚拟机进程状况工具 可以列出正在运行的虚拟机进程，并显示虚拟机执行主类(Main Class，main()函数所在的类)名称以及这些进程的本地虚拟机唯一 ID(LVMID，Local Virtual Machine Identifier) jstat 虚拟机统计信息监视工具 显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据 jinfo 是实时查看和调整虚拟机各项参数 System.getProperties() jmap 生成堆转储快照 查询 finalize 执行队列 Java 堆和方法区的详细信息 如空间使用率 当前用的是哪种收集器 jhat 与 jmap 搭配使用，来分析 jmap 生成的堆转储快照 jstack 用于生成虚拟机当前时刻的线程快照</description></item><item><title>深入理解Java虚拟机::垃圾收集器与内存分配策略</title><link>/notes/understand_the_jvm_03/</link><pubDate>Fri, 02 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_03/</guid><description>垃圾收集器与内存分配策略 垃圾回收需要完成的三件事 那些内存需要回收 什么时候回收 如何回收 当垃圾回收成为性能瓶颈时，对垃圾回收进行必要的监控和调整 需要回收的区域 方法区 内存堆 对象已死 引用计数法 在对象中添加一个引用计数器 每当有一个地方引用它时，计数器值就加一 当引用失效时，计数器值就减一 任何时刻计数器为零的对象就是不可能再被使用的 优点 原理简单，判定效率也很高 缺点 有很多例外情况要考虑，必须要配合大量额外处理才能保证正确地工作 如单纯的引用计数就很难解决对象之间相互循环引用的问题 可达性分析 通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain），如果某个对象到 GC Roots 间没有任何引用链相连，或者用图论的话来说就是从 GC Roots 到这个对象不可达时，则证明此对象是不可能再被使用的 GC Roots 在虚拟机栈（栈帧中的本地变量表）中引用的对象 在方法区中类静态属性引用的对象，譬如 Java 类的引用类型静态变量 方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用 在本地方法栈中 JNI（即通常所说的 Native 方法）引用的对象 Java 虚拟机内部的引用，如基本数据类型对应的 Class 对象，一些常驻的异常对象（比如 NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器 所有被同步锁（synchronized 关键字）持有的对象 反映 Java 虚拟机内部情况的 JMXBean、JVMTI 中注册的回调、本地代码缓存等。 其他临时性加入的对象 引用 强引用是程序代码之中普遍存在的引用赋值 软引用是用来描述一些还有用，但非必须的对象 弱引用也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止 虚引用也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。 回收方法区 废弃的常量和不再使用的类型 判断一个类不再被使用 该类所有的实例都已经被回收 加载该类的类加载器已经被回收 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法 垃圾回收算法 分代收集理论 绝大多数对象都是朝生夕灭的 熬过越多次垃圾收集过程的对象就越难以消亡 跨代引用相对于同代引用来说仅占极少数 标记清除算法 首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象 主要缺点 执行效率不稳定，标记和清除两个过程的执行效率都随对象数量增长而降低 标记、清除之后会产生大量不连续的内存碎片 标记复制算法 它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块 当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉 空间浪费 优化 新生代中的对象有 98%熬不过第一轮收集 把新生代分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次分配内存只使用 Eden 和其中一块 Survivor。发生垃圾搜集时，将 Eden 和 Survivor 中仍然存活的对象一次性复制到另外一块 Survivor 空间上，然后直接清理掉 Eden 和已用过的那块 Survivor 空间 HotSpot 虚拟机默认 Eden 和 Survivor 的大小比例是 8∶1 当 Survivor 空间不足以容纳一次 Minor GC 之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行分配担保 标记整理算法 用于老年代回收 标记过程仍然与标记清除算法一样 整理时让所有存活的对象都向内存空间一端移动 STW 的影响 是否移动对象需要考虑延迟和吞吐 优化 平时采用标记清除，当内存碎片化到影响对象分配的时候采用标记整理 HotSpot 的算法实现细节 根节点枚举 根节点枚举始终必须在一个能保障一致性的快照中进行 枚举根节点时是必须要停顿的, STW 准确式垃圾收集 用 OopMap 的数据结构来直接得到哪些地方存放着对象引用的 一旦类加载动作完成，HotSpot 会把对象偏移量上的数据类型计算出来 安全点 只是在“特定的位置”记录了这些信息 强制要求必须执行到达安全点后才能够暂停 安全点位置的选取基本上是以“是否具有让程序长时间执行的特征”为标准进行选定的 抢先式中断 在垃圾收集发生时，系统首先把所有用户线程全部中断，如果发现有用户线程中断的地方不在安全点上，就恢复这条线程执行，让它一会再重新中断，直到跑到安全点上 主动式中断 当垃圾收集需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志位，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起 安全区域 安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点 当用户线程执行到安全区域里面的代码时，首先会标识自己已经进入了安全区域，那样当这段时间里虚拟机要发起垃圾收集时就不必去管这些已声明自己在安全区域内的线程了。当线程要离开安全区域时，它要检查虚拟机是否已经完成了根节点枚举(或者垃圾收集过程中其他需要暂停用户线程的阶段)，如果完成了，那线程就当作没事发生过，继续执行;否则它就必须一直等待，直到收到可以离开安全区域的信号为止。 记忆集与卡表 解决对象跨代引用所带来的问题 记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构 卡表 字节数组 CARD_TABLE 的每一个元素都对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称作“卡页”(Card Page) 一个卡页的内存中通常包含不止一个对象，只要卡页内有一个(或更多)对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为 1，称为这个元素变脏(Dirty)，没有则标识为 0。在垃圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把它们加入 GC Roots 中一并扫描。 写屏障 解决卡表元素如何维护的问题 写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的 AOP 切面，在引用对象赋值时会产生一个环形(Around)通知，供程序执行额外的动作，也就是说赋值的前后都在写屏障的覆盖范畴内 应用写屏障后，虚拟机就会为所有赋值操作生成相应的指令 伪共享问题 并发的可达性问题 从 GC Roots 再继续往下遍历对象图，这一步骤的停顿时间就必定会与 Java 堆容量直接成正比例关系了 三色标记 白色:表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达。 黑色:表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接(不经过灰色对象)指向某个白色对象。 灰色:表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过 对象消失的问题 赋值器插入了一条或多条从黑色对象到白色对象的新引用 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用 增量更新 当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。这可以简化理解为，黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了。 原始快照 当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索。 经典垃圾回收器 Serial 收集器 使用一个处理器或一条收集线程去完成垃圾收集工作 额外内存消耗最小 简单而高效 Serial 收集器对于运行在客户端模式下的虚拟机来说是一个很好的选择 ParNew 收集器 Serial 收集器的多线程并行版本 Parallel Scavenge 收集器及 G1 收集器等都没有使用 HotSpot 中原本设计的垃圾收集器的分代框架，而选择另外独立实现,CMS 只能和 ParNew 搭配使用 Parallel Scavenge 收集器 基于标记-复制算法实现的收集器 达到一个可控制的吞吐量(Throughput)。所谓吞吐量就是处理器用于运行用户代码的时间与处理器总消耗时间的比值 最高效率地利用处理器资源 Serial Old 收集器 Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器 使用标记-整理算法 供客户端模式下的 HotSpot 虚拟机使用 Parallel Old 收集器 Parallel Old 是 Parallel Scavenge 收集器的老年代版本，支持多线程并发收集 基于标记-整理算法实现 注重吞吐量或者处理器资源较为稀缺的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器这个组合 CMS 收集器 获取最短回收停顿时间为目标的收集器 标记-清除算法 初始标记(CMS initial mark) 仅仅只是标记一下 GC Roots 能直接关联到的对象 并发标记(CMS concurrent mark) 从 GC Roots 的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程 重新标记(CMS remark) 修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录 并发清除(CMS concurrent sweep) 清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的 其中初始标记、重新标记这两个步骤仍然需要“Stop The World” 缺点 对处理器资源非常敏感 CMS 默认启动的回收线程数是(处理器核心数量 +3)/4 CMS 收集器无法处理“浮动垃圾” CMS 的并发标记和并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS 无法在当次收集中处理掉它们，只好留待下一次垃圾收集时再清理掉 空间碎片 G1 收集器 开创了收集器面向局部收集的设计思路和基于 Region 的内存布局形式 提供并发的类卸载的支持 主要面向服务端应用的垃圾收集器 JDK9 的默认收集器 面向堆内存任何部分来组成回收集(Collection Set，一般简称 CSet)进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是 G1 收集器的 Mixed GC 模式 基于 Region 的堆内存布局 G1 不再坚持固定大小以及固定数量的分代区域划分，而是把连续的 Java 堆划分为多个大小相等的独立区域(Region)，每一个 Region 都可以根据需要，扮演新生代的 Eden 空间、Survivor 空间，或者老年代空间。收集器能够对扮演不同角色的 Region 采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果 Region 中还有一类特殊的 Humongous 区域，专门用来存储大对象。G1 认为只要大小超过了一个 Region 容量一半的对象即可判定为大对象 对于那些超过了整个 Region 容量的超级大对象， 将会被存放在 N 个连续的 Humongous Region 之中 使用 Region 划分内存空间，以及具有优先级的区域回收方式，保证了 G1 收集器在有限的时间内获取尽可能高的收集效率 Region 里面存在的跨 Region 引用对象如何解决 使用记忆集避免全堆作为 GC Roots 扫描，但在 G1 收集器上记忆集的应用其实要复杂很多，它的每个 Region 都维护有自己的记忆集，这些记忆集会记录下别的 Region 指向自己的指针，并标记这些指针分别在哪些卡页的范围之内 根据经验，G1 至少要耗费大约相当于 Java 堆容量 10%至 20%的额外内存来维持收集器工作 并发标记阶段如何保证收集线程与用户线程互不干扰地运行 原始快照算法 如果内存回收的速度赶不上内存分配的速度， G1 收集器也要被迫冻结用户线程执行，导致 Full GC 而产生长时间“Stop The World” 怎样建立起可靠的停顿预测模型 G1 收集器的停顿预测模型是以衰减均值(Decaying Average)为理论基础来实现的，在垃圾收集过程中，G1 收集器会记录每个 Region 的回收耗时、每个 Region 记忆集里的脏卡数量等各个可测量的步骤花费的成本，并分析得出平均值、标准偏差、置信度等统计信息 收集过程 初始标记(Initial Marking):仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS 指针的值，让下一阶段用户线程并发运行时，能正确地在可用的 Region 中分配新对象。这个阶段需要停顿线程，但耗时很短，而且是借用进行 Minor GC 的时候同步完成的，所以 G1 收集器在这个阶段实际并没有额外的停顿。 并发标记(Concurrent Marking):从 GC Root 开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以后，还要重新处理 SATB 记录下的在并发时有引用变动的对象。 最终标记(Final Marking):对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的 SATB 记录。 筛选回收(Live Data Counting and Evacuation):负责更新 Region 的统计数据，对各个 Region 的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个 Region 构成回收集，然后把决定回收的那一部分 Region 的存活对象复制到空的 Region 中，再清理掉整个旧 Region 的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。 G1 收集器除了并发标记外，其余阶段也是要完全暂停用户线程的 最先进的垃圾收集器的设计导向都不约而同地变为追求能够应付应用的内存分配速率 (Allocation Rate)，而不追求一次把整个 Java 堆全部清理干净 G1 垃圾收集产生的内存占用(Footprint)和程序运行时的额外执行负载 (Overload)都要比 CMS 要高 G1 的记忆集(和其他内存消耗)可能会占整个堆容量的 20%乃至更多的内存空间 G1 对写屏障的复杂操作要比 CMS 消耗更多的运算资源 目前在小内存应用上 CMS 的表现大概率仍然要会优于 G1，而在大内存应用上 G1 则大多能发挥其优势，这个优劣势的 Java 堆容量平衡点通常在 6GB 至 8GB 之间 低延迟垃圾收集器 ZGC 收集器 在尽可能对吞吐量影响不太大的前提下，把垃圾收集的停顿时间限制在十毫秒以内的低延迟 ZGC 收集器是一款基于 Region 内存布局的，(暂时) 不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的，以低延迟为首要目标的一款垃圾收集器 ZGC 的 Region 具有动态性——动态创建和销毁，以及动态的区域容量大小 小型 Region(Small Region):容量固定为 2MB，用于放置小于 256KB 的小对象。 中型 Region(Medium Region):容量固定为 32MB，用于放置大于等于 256KB 但小于 4MB 的对象。 大型 Region(Large Region):容量不固定，可以动态变化，但必须为 2MB 的整数倍，用于放置 4MB 或以上的大对象 ZGC 收集器有一个标志性的设计是它采用的染色指针技术 染色指针是一种直接将少量额外的信息存储在指针上的技术 ZGC 用地址的高 4 位提取出来存储四个标志信息 其引用对象的三色标记状态 是否进入了重分配集(即被移动过) 是否只能通过 finalize()方法才能被访问到 染色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量，设置内存屏障，尤其是写屏障的目的通常是为了记录对象引用的变动情况，如果将这些信息直接维护在指针中，显然就可以省去一些专门的记录操作 ZGC 只使用了读屏障 ZGC 使用了多重映射(Multi-Mapping)将多个不同的虚拟内存地址映射到同一个物理内存地址上 收集过程 并发标记：标记阶段会更新染色指针中的 Marked0、Marked1 标志位 并发预备重分配: 根据特定的查询条件统计得出本次收集过程要清理哪些 Region，将这些 Region 组成重分配集(Relocation Set) 并发重分配(Concurrent Relocate):重分配是 ZGC 执行过程中的核心阶段，这个过程要把重分配集中的存活对象复制到新的 Region 上，并为重分配集中的每个 Region 维护一个转发表(Forward Table)，记录从旧对象到新对象的转向关系 并发重映射(Concurrent Remap):重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用 选择合适的垃圾收集器 如果是数据分析、科学计算类的任务，目标是能尽快算出结果，那吞吐量就是主要关注点 如果是 SLA 应用，那停顿时间直接影响服务质量，严重的甚至会导致事务超时，这样延迟就是主要关注点 如果是客户端应用或者嵌入式应用，那垃圾收集的内存占用则是不可忽视的</description></item><item><title>深入理解Java虚拟机::自动内存管理</title><link>/notes/understand_the_jvm_02/</link><pubDate>Thu, 01 Apr 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_02/</guid><description>自动内存管理 程序计数器 程序计数器(Program Counter Register)是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器 每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存 如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址 如果正在执行的是本地(Native)方法，这个计数器值则应为空(Undefined) Java 虚拟机栈 线程私有的 生命周期与线程相同 每个方法被执行的时候，Java 虚拟机都会同步创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态连接、方法出口等信息 局部变量表存放了编译期可知的各种 Java 虚拟机基本数据类型、对象引用和 returnAddress 类型 StackOverflowError OutOfMemoryError 本地方法栈 虚拟机栈所发挥的作用是非常相似的，其区别只是虚拟机栈为虚拟机执行 Java 方法(也就是字节码)服务，而本地方法栈则是为虚拟机使用到的本地(Native)方法服务 StackOverflowError OutOfMemoryError Java 堆 Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建 此内存区域的唯一目的就是存放对象实例，Java 世界里“几乎”所有的对象实例都在这里分配内存 逃逸分析，栈上分配，标量替换 垃圾收集器管理的内存区域 分代收集理论 所有线程共享的 Java 堆中可以划分出多个线程私有的分配缓冲区 TLAB 以提升对象分配时的效率 Java 堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的 OutOfMemoryError 方法区 线程共享 存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据 可以选择不实现垃圾收集 内存回收目标主要是针对常量池的回收和对类型的卸载 运行时常量池 方法区的一部分 存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中 具备动态性 OutOfMemoryError 直接内存 不是虚拟机运行时数据区的一部分 在 JDK 1.4 中新加入了 NIO(New Input/Output)类，引入了一种基于通道(Channel)与缓冲区 (Buffer)的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作 不会受到 Java 堆大小的限制 OutOfMemoryError 对象的创建 当 Java 虚拟机遇到一条字节码 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程 对象所需内存的大小在类加载完成后便可完全确定 对象分配空间的任务实际上便等同于把一块确定大小的内存块从 Java 堆中划分出来 假设 Java 堆中内存是绝对规整的&amp;ndash;指针碰撞 如果 Java 堆中的内存并不是规整的&amp;ndash;空闲列表 选择哪种分配方式由 Java 堆是否规整决定 Java 堆是否规整又由所采用的垃圾收集器是否带有空间压缩整理(Compact)的能力决定 指针碰撞 Serial、ParNew 等带压缩整理过程的收集器 空闲列表 使用 CMS 这种基于清除(Sweep)算法的收集器 在虚拟机中对象创建的线程安全 对分配内存空间的动作进行同步处理 内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在 Java 堆中预先分配一小块内存，称为本地线程分配缓冲(Thread Local Allocation Buffer，TLAB)，哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，分配新的缓存区时才需要同步锁定 内存分配完成之后虚拟机必须将分配到的内存空间(但不包括对象头)都初始化为零值 对对象进行必要的设置 new 指令之后会接着执行()方法，按照程序员的意愿对对象进行初始化，这样一个真正可用的对象才算完全被构造出来 对象的内存布局 对象头(Header) 对象自身的运行时数据 哈希码(HashCode) GC 分代年龄 锁状态标志 线程持有的锁 偏向线程 ID 偏向时间戳 类型指针 指向它的类型元数据的指针 记录数组长度的数据 实例数据(Instance Data) 程序代码里面所定义的各种类型的字段内容 父类继承下来的 子类中定义的字段 对齐填充(Padding) 不是必然存在的 HotSpot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍 对象的访问定位 使用句柄访问 Java 堆中将可能会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息 使用直接指针访问 考虑如何放置访问类型数据的相关信息 reference 中存储的直接就是对象地址 速度更快，它节省了一次指针定位的时间开销</description></item><item><title>深入理解Java虚拟机::走进 Java</title><link>/notes/understand_the_jvm_01/</link><pubDate>Wed, 31 Mar 2021 22:10:56 +0800</pubDate><guid>/notes/understand_the_jvm_01/</guid><description>走进 Java 发展史 1996.01.23 JDK 1.0 发布 JVM Applet AWT 1996.02.19 JDK 1.1 发布 JAR 文件格式 JDBC JavaBeans RMI 内部类 反射 1998.12.04 JDK 1.2 发布 J2SE J2EE J2ME EJB Java Plug-in Java IDL Swing JIT VM Classic VM HotSpot VM Exact VM strictfp 关键字 2000.05.08 JDK 1.3 发布 JNDI Java 2D API JavaSound 2002.02.13 JDK 1.4 发布 正则表达式 异常链 NIO 日志类 XML 解析器和 XSLT 转换器 2004.09.30 JDK 5 发布 自动装箱 范型 动态注解 枚举 可变长参数 遍历循环 JMM JUC 2006.</description></item><item><title>心理学::被讨厌的勇气</title><link>/misc/the_courage_to_be_disliked/</link><pubDate>Sun, 28 Mar 2021 17:14:37 +0800</pubDate><guid>/misc/the_courage_to_be_disliked/</guid><description>被讨厌的勇气 我们的不幸是谁的错 如果我们一直依赖原因论，就会永远止步不前。
任何经历本身并不是成功或者失败的原因。我们并非因为自身经历中的刺激——所谓的心理创伤——而痛苦，事实上我们会从经历中发现符合自己目的的因素。决定我们自身的不是过去的经历，而是我们自己赋予经历的意义。
我们大家都是在为了某种“目的”而活着。这就是目的论。
所谓愤怒其实只是可放可收的一种“手段”而已。
答案不应该是从别人那里得到，而应该是自己亲自找出来。
重要的不是被给予了什么，而是如何去利用被给予的东西。
无视现实的是你。一味执著于“被给予了什么”，现实就会改变？我们不是可以更换的机械。我们需要的不是更换而是更新。
比如现在你感觉不到幸福。有时还会觉得活得很痛苦，甚至想要变成别人。但是，现在的你之所以不幸正是因为你自己亲手选择了“不幸”，而不是因为生来就不幸。
行为之恶的确有很多。但无论什么样的犯罪者，都没有因为纯粹想要作恶而去干坏事的，所有的犯罪者都有其犯罪的内在的“相应理由”。假设有人因为金钱纠纷而杀了人。即使如此，对其本人来说也是有“相应理由”的行为，换句话说就是“善”的行动。当然，这不是指道德意义上的善，而是指“利己”这一意义上的善。
你在人生的某个阶段里选择了“不幸”。这既不是因为你生在了不幸的环境中，也不是因为你陷入了不幸的境地中，而是因为你认为“不幸”对你自身而言是一种“善”。
人时常在选择着自己的生活方式，即使像现在这样促膝而谈的瞬间也在进行着选择。你把自己说成不幸的人，还说想要马上改变，甚至说想要变成别人。尽管如此还是没能改变，这是为什么呢？那是因为你在不断地下着不改变自己生活方式的决心。
如果选择新的生活方式，那就既不知道新的自己会遇到什么问题，也不知道应该如何应对眼前的事情。未来难以预测，生活就会充满不安，也可能有更加痛苦、更加不幸的生活在等着自己。也就是说，即使人们有各种不满，但还是认为保持现状更加轻松、更能安心。
阿德勒心理学就是勇气心理学。你之所以不幸并不是因为过去或者环境，更不是因为能力不足，你只不过是缺乏“勇气”，可以说是缺乏“获得幸福的勇气”。
的确。你现在首先应该做的是什么呢？那就是要有“摈弃现在的生活方式”的决心。
无论之前的人生发生过什么，都对今后的人生如何度过没有影响。”决定自己人生的是活在“此时此刻”的你自己。
一切烦恼都来自人际关系 你为什么讨厌自己呢？为什么只盯着缺点就是不肯去喜欢自己呢？那是因为你太害怕被他人讨厌、害怕在人际关系中受伤。
那么，如何实现这种目的呢？答案很简单。只要变成一个只看自己的缺点、极其厌恶自我、尽量不涉入人际关系的人就可以了。如此一来，只要躲在自己的壳里就可以不与任何人发生关联，而且万一遭到别人的拒绝，还可以以此为理由来安慰自己。心里就会想：因为我有这样的缺点才会遭人拒绝，只要我没有这个缺点也会很讨人喜欢。
但是，请你不要忘记，在人际关系中根本不可能不受伤。只要涉入人际关系就会或大或小地受伤，也会伤害别人。
一切烦恼都是人际关系的烦恼
困扰我们的自卑感不是“客观性的事实”而是“主观性的解释”？
我们无法改变客观事实，但可以任意改变主观解释。并且，我们都活在主观世界中。
也就是说，价值必须建立在社会意义之上。即使 1 美元纸币所承载的价值是一种常识（共通感觉），那它也不是客观意义上的价值。如果从印刷成本考虑的话，它根本不等于 1 美元。
自卑感本身并不是坏事。这一点你能够理解吧？就像阿德勒说过的那样，自卑感也可以成为促成努力和进步的契机。例如，虽然对学历抱有自卑感，但若是正因为如此，才下定“我学历低所以更要付出加倍的努力”之类的决心，那反而成了好事。而另一方面，自卑情结是指把自己的自卑感当作某种借口使用的状态。具体就像“我因为学历低所以无法成功”或者“我因为长得不漂亮所以结不了婚”之类的想法。像这样在日常生活中大肆宣扬“因为有 A 所以才做不到 B”这样的理论，这已经超出了自卑感的范畴，它是一种自卑情结。
简单地说就是害怕向前迈进或者是不想真正地努力。不愿意为了改变自我而牺牲目前所享受的乐趣——比如玩乐或休闲时间。也就是拿不出改变生活方式的“勇气”，即使有些不满或者不自由，也还是更愿意维持现状。
如果真正地拥有自信，就不会自大。正因为有强烈的自卑感才会骄傲自大，那其实是想要故意炫耀自己很优秀。担心如果不那么做的话，就会得不到周围的认可。这完全是一种优越情结。这是一种通过把自卑感尖锐化来实现异常优越感的模式。具体就是指夸耀不幸。
以自己的不幸为武器来支配对方。通过诉说自己如何不幸、如何痛苦来让周围的人——比如家人或朋友——担心或束缚支配其言行。刚开始提到的那些闭门不出者就常常沉浸在以不幸为武器的优越感中。阿德勒甚至指出：“在我们的文化中，弱势其实非常强大而且具有特权。
不与任何人竞争，只要自己不断前进即可
健全的自卑感不是来自与别人的比较，而是来自与“理想的自己”的比较。
好吧，我们都不一样。性别、年龄、知识、经验、外貌，没有完全一样的人。我们应该积极地看待自己与别人的差异。但是，我们“虽然不同但是平等”。
不是。无论是走在前面还是走在后面都没有关系，我们都走在一个并不存在纵轴的水平面上，我们不断向前迈进并不是为了与谁竞争。价值在于不断超越自我。
这与竞争有关。请你记住。如果在人际关系中存在“竞争”，那人就不可能摆脱人际关系带来的烦恼，也就不可能摆脱不幸。
竞争的可怕之处就在于此。即便不是败者、即便一直立于不败之地，处于竞争之中的人也会一刻不得安心、不想成为败者。而为了不成为败者就必须一直获胜、不能相信他人。之所以有很多人虽然取得了社会性的成功，但却感觉不到幸福，就是因为他们活在竞争之中。因为他们眼中的世界是敌人遍布的危险所在。
把他人的幸福看作“我的失败”，所以才无法给予祝福。
如果能够体会到“人人都是我的伙伴”，那么对世界的看法也会截然不同。不再把世界当成危险的所在，也不再活在不必要的猜忌之中，你眼中的世界就会成为一个安全舒适的地方。人际关系的烦恼也会大大减少。
这种情况下，对方的目的是什么呢？是纯粹想要讨论政治吗？不是。对方只是想要责难挑衅你，通过权力之争来达到让不顺眼的你屈服的目的。这个时候你如果发怒的话，那就是正中其下怀，关系会急剧转入权力之争。所以，我们不能上任何挑衅的当。
不是不能发怒，而是“没必要依赖发怒这一工具”。
那就是无论认为自己多么正确，也不要以此为理由去责难对方。这是很多人都容易陷落进去的人际关系圈套。
原本主张的对错与胜负毫无关系。如果你认为自己正确的话，那么无论对方持什么意见都应该无所谓。但是，很多人都会陷入权力之争，试图让对方屈服。正因为如此，才会认为“承认自己的错误”就等于“承认失败”。
承认错误、赔礼道歉、退出权力之争，这些都不是“失败”。
那么你为什么把别人看成是“敌人”而不能认为是“伙伴”呢？那是因为勇气受挫的你在逃避“人生的课题”。
行为方面的目标有以下两点：
自立。 与社会和谐共处。 而且，支撑这种行为的心理方面的目标也有以下两点：
“我有能力”的意识。 “人人都是我的伙伴”的意识。 阿德勒心理学不是改变他人的心理学，而是追求自我改变的心理学。不能等着别人发生变化，也不要等着状况有所改变，而是由你自己勇敢迈出第一步。
当人能够感觉到“与这个人在一起可以无拘无束”的时候，才能够体会到爱。既没有自卑感也不必炫耀优越性，能够保持一种平静而自然的状态。真正的爱应该是这样的。
现阶段能说的就是不能够逃避。无论多么困难的关系都不可以选择逃避，必须勇敢去面对。即使最终发展成用剪刀剪断，也要首先选择面对。最不可取的就是在“这样”的状态下止步不前。
人就是这么任性而自私的生物，一旦产生这种想法，无论怎样都能发现对方的缺点。即使对方是圣人君子一样的人物，也能够轻而易举地找到对方值得讨厌的理由。正因为如此，世界才随时可能变成危险的所在，人们也就有可能把所有他人都看成“敌人”。
让干涉你生活的人见鬼去 阿德勒心理学否定寻求他人的认可。
你不是为了满足别人的期待而活着，我也不是为了满足别人的期待而活着。我们没必要去满足别人的期待。
如果一味寻求别人的认可、在意别人的评价，那最终就会活在别人的人生中。
基本上，一切人际关系矛盾都起因于对别人的课题妄加干涉或者自己的课题被别人妄加干涉。
辨别究竟是谁的课题的方法非常简单，只需要考虑一下“某种选择所带来的结果最终要由谁来承担？”
这一点需要注意。阿德勒心理学并不是推崇放任主义。放任是一种不知道也不想知道孩子在做什么的态度。而阿德勒心理学的主张不是如此，而是在了解孩子干什么的基础上对其加以守护。如果就学习而言，告诉孩子这是他自己的课题，在他想学习的时候父母要随时准备给予帮助，但绝不对孩子的课题妄加干涉。在孩子没有向你求助的时候不可以指手画脚。
接受心理咨询辅导之后，被辅导者下什么样的决心、是否改变生活方式，这都是被辅导者本人的课题，辅导顾问不能干涉。
可以把马带到水边，但不能强迫其喝水
能够改变自己的只有自己。</description></item><item><title>数据密集型应用系统设计::派生数据</title><link>/notes/designing_data_intensive_application_derived_data/</link><pubDate>Mon, 22 Mar 2021 21:57:43 +0800</pubDate><guid>/notes/designing_data_intensive_application_derived_data/</guid><description>派生数据 记录系统 一个记录系统也被称为真实数据系统，拥有数据的权威版本 如果另一个系统与记录系统之间存在任何差异，那么以记录系统中的数据值为准 派生数据系统 派生数据系统中的数据则是从另一个系统中获取已有数据并以某种方式进行转换或处理的结果 如果派生数据丢失，用户可以从原始数据源进行重建 例如缓存 批处理系统 在线服务 服务等待客户请求或指令的到达。当收到请求或指令时，服务试图尽可能快地处理它，并发回一个响应。 响应时间通常是服务性能的主要衡量指标，而可用性同样非常重要 批处理系统 批处理系统接收大量的输入数据，运行一个作业来处理数据，并产生输出数据 批处理作业的主要性能衡量标准通常是吞吐量 流处理系统 流处理介于在线与离线/批处理之间(所以有时称为近实时或近线处理)。与批处理系统类似，流处理系统处理输入并产生输出 流式作业在事件发生后不久即可对事件进行处理，而批处理作业则使用固定的一组输入数据进行操作。这种差异使得流处理系统比批处理系统具有更低的延迟。 使用 UNIX 工具进行批处理 使用 awk, sed， grep, sort , uniq 和 xargs 的组合 ，可以在几分钟内完成许多数据分析任务 UNIX 设计哲学 每个程序做好一件事。如果要做新的工作，则建立一个全新的程序，而不是通过增加新“特征”使旧程序变得更加复杂。 期待每个程序的输出成为另一个尚未确定的程序的输入。不要将输出与无关信息混淆在一起。避免使用严格的表格状或二进制输入格式。不要使用交互式输入 尽早尝试设计和构建软件，甚至是操作系统，最好在几周内完成。需要扔掉那些笨拙的部分时不要犹豫，并立即进行重建 优先使用工具来减轻编程任务，即使你不得不额外花费时间去构建工具，并且预期在使用完成后会将其中一些工具扔掉 统一接口 如果希望某个程序的输出成为另一个程序的输入，也就意味着这些程序必须使用相同的数据格式，换句话说，需要兼容的接口，在 UNIX 中，这个接口就是文件(更准确地出，是文件描述符) 逻辑与布线分离 UNIX 工具的另一个特点是使用标准输入(stdin)和标准输出(stdout) 这允许 shell 用户以任何他们想要的方式连接输入和输出:程序并不知道也不关心输入来自哪里以及输出到哪里。 将输入/输出的布线连接与程序逻辑分开，可以更容易地将小工具组合成更大的系统 透明与测试 UNIX 命令的输入文件通常被视为是不可变的。这意味着可以随意运行命令，尝试各种命令行选项，而不会损坏输入文件。 可以在任何时候结束流水线，将输出管道输送到 less ，然后查看它是否具有预期的形式。这种检查能力对调试非常有用。 可以将流水线某个阶段的输出写入文件，并将该文件用作下一阶段的输入。这使得用户可以重新启动后面的阶段，而无需重新运行整个流水线。 MapReduce 与分布式文件系统 MapReduce 有点像分布在数千台机器上的 UNIX 工具 不修改输入，无副作用，在分布式文件系统上读写文件 分布式文件系统 GFS HDFS Amazon S3 Azure Blob OpenStack Swift HDFS 包含一个在每台机器上运行的守护进程，并会开放一个网络服务以允许其他节点访问存储在该机器上的文件 容错 多个机器上的相同数据的多个副本 纠错码方案 MapReduce 作业执行 MapReduce 是一个编程框架，可以使用它编写代码来处理 HDFS 等分布式文件系统中的大型数据集 处理模式 读取一组输入文件，并将其分解成记录 调用 mapper 函数从每个输入记录中提取一个键值对 按关键字将所有的键值对排序 调用 reducer 函数遍历排序后的键值对 Mapper 每个输入记录都会调用一次 mapper 程序，其任务是从输入记录中提取关键字和值。对于每个输入，它可以生成任意数量的健值对(包括空记录)。它不会保留从一个输入记录到下一个记录的任何状态，因此每个记录都是独立处理的。 Reducer MapReduce 框架使用由 mapper 生成的键值对，收集属于同一个关键字的所有值，并使用迭代器调用 reducer 以使用该值的集合。Reducer 可以生成输出记录 MapReduce 的分布式执行 作业的输入通常是 HDFS 中的一个目录，且输入目录中的每个文件或文件块都被视为一个单独的分区，可以由一个单独的 map 任务来处理 让靠近数据的机器就近执行 mapper 任务，减少网络传输的负载，提高了访问局部性 map 任务的数量与 reduce 任务的数量不需要一致 为了使相同值的 mapper 输出交给同一个 reduce 处理，采用了关键字哈希分区 键值对必须排序。map 任务基于关键字哈希，按照 reducer 对输出进行分块。每个分区都被写入 mapper 程序所在文件磁盘上的已排序文件。 当 mapper 完成文件输出后，MP 调度器通知 reducer 从 mapper 中获取输出文件。reduce 从 mapper 中获取文件后把他们合并在一起，同时保持数据的排序。 Reduce 端的 join 与分组 在批处理的背景下讨论 join 时，我们主要是解决数据集内存在关联的所有事件 join 最简单的实现是遍历所有记录，并在远程服务器中查找对应的记录。 更好的方法是获取用户数据库的副本，并将其放入与用户活动事件日志相同的分布式文件系统。然后，可以将用户数据库放在 HDFS 中的一组文件中，并将用户活动记录放在另一组文件中，使用 MapReduce 将所有相关记录集中到一起，从而有效地处理它们。 排序-合并 join mapper 和排序过程确保将执行特定用户 ID join 操作的所有必要数据都放在一起，这样就只需要一次 reducer 调用。因为所有需要的数据已经预先排列好，所以 reducer 是一段相当简单的单线程代码，以高吞吐量和低内存开销来处理记录。 分组 在 mapper 阶段，使其生成的键值对使用所需的分组关键字。然后，分区和排序过程将相同 reducer 中所有具有相同关键字的记录集合在一起 处理数据倾斜 如果 join 输入中存在热键，则可以使用算法进行补偿。在真正开始执行 join 时，mapper 将任何与热键有关的记录发送到随机选择的若干个 reducer 中的一个，对于 join 的其他输入，与热键相关的记录需要被复制到所有处理该关键字的 reducer 中，这种技术将处理热键的工作分散到多个 reducer 上，可以更好地实现并行处理，代价是不得不将 join 的其他输入复制到多个 reducer 使用热键对记录进行分组并汇总时，可以分两个阶段进行分组。第一个 MapReduce 阶段将记录随机发送到 reducer，以便每个 reducer 对热键的记录子集执行分组，并为每个键输出更紧凑的聚合值。然后第二个 MapReduce 作业将来自所有第一阶段 reducer 的值合并为每个键的单一值 Map 端的 join 操作 广播哈希 join 实现 map 端 join 的最简单方住特别适合大数据集与小数据集 join，尤其是小数据集能够全部加载到每个 mapper 的内存中 当 mapper 程序执行时，它可以首先将用户数据库从分布式文件系统读取到内存的哈希表中。然后，mapper 程序扫描用户活动事件，并简单地查找哈希表中每个事件的用户 ID Map 任务依然可以有多个: 大数据集的每个文件块对应一个 mapper。每个 mapper 还负责将小数据集全部加载到内存中。 也可以存在磁盘中，由于缓存和索引的原因，和内存查找差不多快。 分区哈希 join 如果以相同方式对 map 端 join 的输入进行分区，则哈希 join 方法可以独立作用于每个分区 批处理工作流的输出 生成搜索索引 批处理输出键值 批处理输出的哲学 如果在代码中引入了漏洞，输出错误或者损坏，那么可以简单地回读到先前版本，然后重新运行该作业，将再次生成正确的输出; 或者更简单的办法是将旧的输出保存在不同的目录中，然后切换回原来的目录 与发生错误即意味着不可挽回的损害相比 ，易于回滚的特性更有利于快速开发新功能。这种使不可逆性最小化的原则对于敏捷开发是有益的 如果 map 或 reduce 任务失败， MapReduce 框架会自动重新安排作业并在同一个输入上再次运行，失败任务的输出则被 MapReduce 框架丢弃 对比 Hadoop 与分布式数据库 存储多样性 分布式文件系统中的文件只是字节序列，可以使用任何数据模型和编码来编写 来自事务处理 系统的数据以某种原始形式转储到分布式文件系统中，然后编写 MapReduce 作业进行数据清理，将其转换为关系表单，并将其导入 MPP 数据仓库以进行分析。数据建模仍然会发生，但它位于一个单独步骤中，与数据收集是分离的。由于分布式文件系统支持以任何格式编码的数据，所以这种解相是可行的。 处理模型多样性 并非所有类型的处理都可以合理地表达为 SQL 查询 由于 Hadoop 平台的开放性，可以在上面实施更多的处理模型 针对频繁故障的设计 MapReduce 可以容忍 map 或者 reduce 任务失败，单个失败可以重试。 MapReduce 容忍任意失败是为了更好的利用集群资源，允许高优先级任务抢占资源 超越 MapReduce MapReduce 很强大，但依然有些问题 对于某些类型的任务，其他工具可能要快几个数量级 中间状态实体化 MapReduce 会把中间结果写入文件，这个过程称为实体化 UNIX 管道不存在实体化，输出可以立即成为下一个的输入 几个问题 输出不会立马被利用，任务耗时会比预计的久 mapper 冗余，它们只是读取刚刚由 reducer 写入的同一个文件，并为下一个分区和排序阶段做准备。在许多情况下，mapper 代码可能是之前 reducer 的一部分:如果 reducer 的输出被分区和排序的方式与 mapper 输出相同，那么不同阶段的 reducer 可以直接链接在一起，而不需要与 mapper 阶段交错。 把中间状态文件存储在分布式系统中意味着这些文件被复制都多个节点了，对于这样的临时数据来说通常是大材小用了 数据流引擎 为了解决 MapReduce 的这些问题，开发了用于分布式批处理的新的执行引擎 Spark，Tez，Flink 它们把整个工作流作为一个作业来处理，而不是把它分解成独立的子作业 通过若干个处理阶段明确地建模数据流，所以这些系统被称为数据流引擎。像 MapReduce 一样，它们通过反复调用用户定义的函数来在单个线程上一次处理一条记录。它们通过对输入进行分区来并行工作，并将一个功能的输出复制到网络上，成为另一个功能的输入 。 流处理引擎可以以更加灵活的方式组装各种函数 对比 MapReduce 模型的几个优点 排序等计算代价昂贵的任务只在实际需要的地方进行，而不是在每个 map 和 reduce 阶段之间默认发生 没有不必要的 map 任务，因为 mapper 所做的工作通常可以合并到前面的 reduce 运算符中 由于工作流中的所有 join 和数据依赖性都是明确声明的，因此调度器知道哪些数据在哪里是必需的，因此它可以进行本地优化 将运算符之间的中间状态保存在内存中或写入本地磁盘通常就足够了 运算符可以在输入准备就绪后立即开始执行，在下一个开始之前不需要等待前个阶段全部完成。 现有的 Java 虚拟机进程可以被重用来运行新的运算符，从而减少启动开销。 容错 将中间状态完全实体化到分布式文件系统的一个优点是持久化，这使得在 MapReduce 中实现容错变得相当容易 Spark, Flink 和 Tez 避免将中间状态写入 HDFS，所以它们采用不同的方法来容忍错误: 如果机器发生故障，并且该机器上的中间状态、丢失，则利用其他可用的数据重新计算 为了实现重新计算，框架必须追踪给定数据是如何计算的，使用了哪个输入分区，以及应用了哪个运算符。 关于实体化的讨论 数据流对 MapReduce 的改进是，不需要自己将所有中间状态写入文件系统。 图与迭代处理 在批处理环境中查看图也很有趣，其目标是在整个图上执行某种离线处理或分析。这种需求经常出现在机器学习应用程序或排名系统中 Pregel 处理模型 作为对图数据的批处理优化，计算的批量同步并行模型 一个顶点可以“发送消息”到另一个顶点，通常这些消息沿着图的边被发送。 顶点状态和顶点之间的消息具有容错性和持久性，并且通信以固定的方式进行:每一轮迭代中，框架会将前一次迭代中的所有消息都发送出去。 Actor model 通常没有这样的时序保证。 容错 由于 Pregel 集型保证在一次迭代中发送的所有消息都会在下一次迭代中被发送，所以先前的迭代必须全部完成，而且所有的消息必须在下一次迭代 开始之前复制到网络中。 即使底层网络可能会丢弃、重复或任意延迟消息，但 Pregel 的实现可以保证在后续迭代中消息在目标顶点只会被处理一次。像 MapReduce 一样，该框架透明地从故障中恢复，以简化 Pregel 顶层算陆的编程模型。 这种容错方式是通过在迭代结束时定期快照所有顶点的状态来实现的，即将其全部状态写入持久存储。如果某个节点发生故障并且其内存中状态丢失，则最简单的解决方也是将整个图计算回攘到上一个检查点，然后重新开始计算。如果算法是确定性的， 并且记录了消息，那么也可以选择性地只恢复丢失的分区 并行执行 顶点不需要知道它运行在哪台物理机器上。当它发送消息到其他顶点时，只需要将消息发送至一个顶点 ID。框架对图进行分区，即确定哪个顶点运行在哪个机器上，以及如何通过网络路由消息，以便它们都能到达正确的位置。 高级 API 与语言 由于手工编写 MapReduc 巳作业太过耗时费力，因此 Hive、Pig、Cascading 和 Crunch 等高级语言和 API 变得非常流行。随着 Tez 的出现， 这些高级语言还能够移植到新的数据流执行引擎，而无需重写作业代码。Spark 和 Flink 也包含他们自己的高级数据流 API 这些高级接口不仅使提高了系统利用率，而且提高了机器级别的作业执行效率。 转向声明式查询语言 通过将声明式特征与高级 API 结合，使查询优化器在执行期间可以利用这些优化方法，批处理框架看起来就更像 MPP 数据库了,井且能够实现性能相当。同时，通过具有运行任意代码和读取任意格式数据的可扩展性，它们依然保持了灵活性的优势。 不同领域的专业化 要实现可重用的通用构建模块 可重复使用统计和数值算法 流处理系统 我们将把事件流视为一种数据管理机制: 一种无界的、持续增量处理的方式 发送事件流 在流处理的上下文中，记录通常被称为事件 本质上是一回事:一个小的、独立的、不可变的对象，该对象包含某个时间点发生的事情的细节。每个事件通常包含一个时间戳，用于指示事件发生的墙上时间 案例 服务器的每一行日志 用户的下单或者浏览 格式 文本 JSON 二进制 生成一次，读取多次 在流系统中，相关的时间通常被组合成主题或流 传统数据库无法支持实时的消息通知 消息系统 向消费者通知新事件的常见方法是使用消息系统:生产者发送包含事件的消息，然后该消息被推送给一个或多个消费者 当生产者发送消息比消费者处理快 系统丢弃消息 将消息存储在队列中 激活背压，也称流量控制，组织生产者发送过多消息 如果节点崩溃或者离线，是否会有消息丢失 持久化需要写入磁盘，需要成本，在可以接收消息丢失的系统上，在同样的硬件上可以将获得更高的吞吐量和更低的延迟 是否接收消息丢失取决于应用程序 生产者与消费者之间的直接消息传递 UDP 组播广泛应用与金融行业，例如股票市场等低延迟场景 无代理的消息库，过 TCP 或 IP 多播实现发布/订阅消息传递。 使用不可靠的 UDP 消息传递 消费者在网络上公开服务，则生产者可以直接发出 HTTP 或 RPC 请求以将消息推送给消费者 缺点 有限容错，消息丢失 生产者和消费者都需要保持在线 消息代理 它作为服务器运行，生产者和消费者作为客户端连接到它。 生产者将消息写入代理，消费者通过从消息代理那里读取消息来接收消息 消息代理与数据库对比 而大多数消息代理在消息成功传递给消费者时就自动删除消息。这样的消息代理不适合长期的数据存储。 消息代理的工作集很小，如果消费慢了就会占用很多内存，整体吞吐降低 数据库支持二级索引和各种搜索数据的方式，消息代理采用订阅匹配特定模式的主题 数据库查询基于数据快照，消息代理不支持查询 多个消费者 负载均衡式 每一条消息都只被传递给其中一个消费者，所以消费者可以共享主题中处理消息的工作。代理可以任意分配消息给消费者。 扇出式 每条消息都被传递给所有的消费者。扇出允许几个独立的消费者各自“收听”相同的消息广播，而不会相互影响，流相当于多个读取相同输入文件的不同批处理作业 确认和重新传递 消费者随时可能崩溃，消费者消费完事件后需要显式告知消息代理，消息代理才会从队列中删除 消息代理重试时间导致事件发生顺序改变，如果消息之间存在因果关系会导致问题。 分区日志 将数据库的持久存储方居与消息传递的低延迟功能相结合 基于日志的消息存储 日志是磁盘上一个仅支持追加式修改记录的序列，我们可以使用相同的结构来实现消息代理:生产者通过将消息追加到日志的末尾来发消息，消费者通过依次读取日志来接收消息。如果消费者读到日志的末尾，它就开始等待新消息被追加的通知。 为了突破单个磁盘所能提供的带宽吞吐的上限，可以对日志进行分区。不同的节点负责不同的分区，使每个分区成为一个单独的日志，并且可以独立于其他分区读取和写入。然后可以将主题定义为一组分区，他们都携带相同类型的消息 在每个分区中，代理为每个消息分配一个单调递增的序列号或偏移量。这样的序列号是非常有意义，因为分区只能追加，所以分区内的消息是完全有序的。不同分区之间则没有顺序保证。 对比日志与传统消息系统 都支持扇出式消息传递 因为同一分区内的消息将被传递到同一节点，所以消费一个主题的节点数最多等于该主题中的日志分区数 如果单个消息处理缓慢，则会阻碍该分区中的后续消息的处理 消费者偏移量 顺序读取一个分区可以很容易地判断哪些消息已经被处理，代理不需要跟踪每条消息的确认，只需要定期记录消费者的偏移量 磁盘空间使用 如果持续不断地追加日志，磁盘空间最终将被耗尽。为了回收磁盘空间，日志实际上是被分割成段，并且不时地将旧段删除或归档保存。 如果一个消费者的速度慢到难以跟上消息产生的速度，并且远远落后以至于消费者偏移量指向了已经被删除的片段，那么消费者将会错过一些消息。实际上，日志实现了一个有限大小的缓冲区，当缓冲区变搞时，旧的消息就被丢弃，该缓冲区也被称为循环缓冲区或环形 缓冲区。由于该缓冲区在磁盘上，因此它可以非常大。 当消费者跟不上生产者时 基于日志的方法是一种缓冲形式，它具有比较大的缓冲区 当消费者明显落后消息时发出警报，让操作员有时间修复 重新处理信息 可以用旧的偏移量重新开启一个消费队列，并将输出写到不同的位置，以便重新处理最后一段时间的消息，通过改变处理代码可以多次重复此操作。 数据库与流 保持数据同步 多数据系统数据一致性 变更数据捕获 捕获数据库中的更改并不断将相同的更改应用于搜索索引。如果以相同顺序应用于更改日志，那么可以预期搜索索引中的数据与数据库中的数据匹配。搜索索引和任何其他派生的数据系统只是变更流的消费者 实现变更数据捕获 我们可以调用日志消费者的派生数据，变更数据捕获机制可以确保对记录系统所做的所有更改都反映在派生数据系统中，以便派生系统具有数据的准确副本，从本质上讲，变更数据捕获使得一个数据库成为主节点，井将其他变成从节点。由于基于日志的消息代理保留了消息的排序，因此它非常适合从原数据库传输更改事件 原始快照 如果有了数据库所有更改的日志，就可以通过 replay 日志来重建数据库的整个状态。构建新的全文索引需要整个数据库的完整副本，仅仅应用最近更改的日志还不够，因为它会丢失最近未更新的项目。因此，如果没有完整的日志历史记录，则需要从一致的快照开始，数据库的快照必须与更改日志中的已知位置或偏移量相对应，以便在快照处理完成后，知道在哪一点开始应用更改。 日志压缩 存储引擎定期查找具有相同 key 的日志记录，丢弃所有的重复项，井且只保留每个 key 的最新的更新。这个压缩和合并的过程是在后台运行的。 对变更流的 API 支持 数据库将关系数据模型中的输出流表示为表，该表支持事务插入元组，但不支持查询。输出流包含了向该特殊表提交写事务的元组日志，并严格按照事务提交顺序排序。外部消费者可以异步使用此日志并使用它来更新派生数据系统。 时间溯源 在变更捕获中，CDC 记录了操作发生的顺序 时间溯源中，应用程序逻辑基于写入事件日志的不可变事件构成。 从事件日志导出当前状态 使用事件溯源的应用程序需要记录事件的日志，井将其转换为适合向用户显示的状态 。这种转换可以使用任意的逻辑，但它应该是确定性的，以便可以再次运行它并从事件日志中派生相同的应用程序状态。 用于更新记录的 CDC 事件通常包含记录的全部新版本，因此 key 的当前值完全由该 key 的最近事件确定，井且日志压缩可以丢弃相同 key 之前的事件 使用事件溯源在更高的层次上对事件建模: 事件通常用来表达用户行为的意图，而不是一种对行为结果进行相应状态更新的机制 命令和事件 事件溯源的哲学是小心的区分事件和命令。当来自用户的请求第一次到达时，它最初是一个命令:此时它可能仍然会失败，例如因为违反了某些完整性条件。应用程序必须首先验证它是否可以执行该命令。如果验证成功并且命令被接受，它将变成一个持久且不可变的事件。 状态，流与不可变 事务日志记录了对数据库所做的所有更改。高速追加是更改日志的唯一方位。从这个角度来看，数据库的内容保存了日志中最新记录值的缓存。日志是事实。数据库是日志子集的缓存。该缓存子集恰好是来自日志的每个记录和索引值的最新值。 日志压缩则是链接日志与数据库区别的一种方式。它仅保留每条记录的最新版本，井丢弃被覆盖的版本。 不变事件的优势 恢复历史数据 记录历史操作 相同的事件日志中派生出多个视图 通过从不变事件日志中分离可变状态，可以从相同的事件日志派生出多个面向读取的表示方式 并发控制 事件捕获和变更数据捕获的最大缺点是事件日志的消费者通常是异步的，所以用户可能会写入日志，然后从日志派生的视图中读取，却发现这些写操作还没有反映在读取视图中 一种解决方案是同步执行读取视图的更新，并将事件追加到日志中。这需要一个事务来将写入操作合并到一个原子单元中，所以要么需要将事件日志和读取视图保存在同一个存储系统中，要么需要跨不同系统的分布式事务。 另一方面，从事件日志导出当前状态也简化了并发控制。对于多对象事务的大部分需求源自单个用户需要在不同地方改变数据的操作。通过事件溯源，可以设计一个事件，使其成为用户操作的独立描述。用户操作只需要在一个地方进行一次写操作，即将事件追加到日志中，这很容易使其原子化。 不变形的限制 隐私，彻底删除数据 流处理 三种处理 可以将事件中的数据写入数据库、缓存、搜索索引或者类似的存储系统，然后被其他客户端查询 可以通过某种方式将事件推送给用户 可以处理一个或多个输入流以产生一个或多个输出流。数据流可能会先经过由几个这样的处理阶段组成的流水线，最终在输出端结束 流处理的适用场景 监控目的的流应用 信用风控 金融交易监控 机器状态监控 军事情报系统报警 复杂事件处理 在流中搜索特定模式的事件 流分析 测量某种类型事件的速率 计算一段时间内某个值的波动平均值 将当前的统计数据与以前的时间间隔进行比较 维护物化视图 使用数据库更改流来保持派生数据系统与源数据库之间的同步，可以将这些示例视为一种维护物化视图的例子: 对某个数据集导出一个特定的试图以便高效查询，并在底层数据更改时自动更新该导出视图。 在流上搜索 需要基于一些复杂条件来搜索单个事件, 搜索流是把查询条件先保存下来，所有文档流过查询条件，筛选出结果。 消息传递和 RPC 流的时间问题 流处理系统经常需要和时间打交道，尤其是在用于分析目的时，这些分析通常使用时间窗口 事件延迟处理会引发流处理各种问题，需要有介入处理这种问题 混淆事件时间与处理时间会导致错误的结果，重启流处理系统倒是的事件积压，出现处理高峰 什么时候准备就绪 无法确定是否完全收到特定窗口内所有的事件 忽略滞后的事件，丢失大量数据时报警 发布一个更新，针对滞后事件的一个更新值。可能还需要收回以前的输出 用一个特殊值来触发窗口处理 你用谁的钟 为了调整不正确的设备时钟，一种是方法是记录三个时间戳 根据设备的时钟，记录事件发生的时间。 根据设备的时钟，记录将事件发送到服务器的时间。 根据服务器时钟，记录服务器收到事件的时间。 窗口类型 轮转窗口 翻滚窗口长度固定，每个事件都属于一个窗口 跳跃窗口 窗口长度固定，窗口之间有重叠以提供平滑过渡 滑动窗口 滑动窗口包含在彼此的某个间隔内发生的所有事件, 滑动窗口可以通过保留按时间排序的事件缓冲区井且在从窗口过期时移除旧事件来实现 会话窗口 与其他窗口类型不同，会话窗口没有固定的持续时间。相反，它是通过将同一用户在时间上紧密相关的所有事件分组在一起而定义的，一旦用户在一段时间内处于非活动状态，则窗口结束。会话分析是网站分析中常见的一种需求 流式 join 流和流 join 搜索事件和点击事件 流和表 join 流处理提前加载表的内容，在流处理时匹配相关 ID 表和表 join 流视图和流视图的 join，每当视图更新刷新 join 结果 join 的时间依赖性 不同流和分区之间的事件，顺序是如何确定的 通常的做法是，当数据发生变化后赋予一个新的关联 ID 流处理的容错 批处理容错方法可以确保批处理作业的输出与没有出错时的最终结果相同 微批处理和校验点 将流分解成多个小块，并像小型批处理一样处理每个块。这种方法被称为微批处理 Apache Flink 中使用了该方法的一个变体，它定期生成状态滚动检查点并将其写入持久化存储。如果流操作发生崩溃，它可以从最近的检查点重新启动，并丢弃在上一个检查点和崩溃之间生成的所有输出 重新审视原子提交 在出现故障时，为了看起来实现恰好处理了一次，我们需要确保当且仅当处理成功时，所有输出和副作用才会生效.</description></item><item><title>数据密集型应用系统设计::分布式数据系统</title><link>/notes/designing_data_intensive_application_distributed_data/</link><pubDate>Sun, 21 Mar 2021 21:57:43 +0800</pubDate><guid>/notes/designing_data_intensive_application_distributed_data/</guid><description>分布式数据系统 扩展性 容错与高性能 延迟考虑 系统扩展能力 共享内存架构 成本增长过快 无异地容错能力 共享磁盘架构 适用于数仓 资源竞争和锁开销限制扩展 无共享结构 水平扩展 扩展更加简单 复制与分区 复制 在多个节点保存相同的数据 分区 将一个大块头的数据库拆分成多个较小的子集 数据复制 目的 使数据在地理位置上更接近用户，从而降低访问延迟 当部分组件出现位障，系统依然可以继续工作，从而提高可用性 扩展至多台机器以同时提供数据访问服务，从而提高读吞吐量 三种复制方案 主从复制 工作原理 指定某一个副本为主副本(或称为主节点)。当客户写数据库时，必须将写请求首先发送给主副本，主副本首先将新数据写入本地存储 其他副本全部称为从副本或称为从节点。主副本把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从副本。每个从副本获得更改日志之后将其应用到本地，且严格保持与主副本相同的写入顺序。 客户端从数据库中读数据时，可以在主副本或者从副本上执行查询。再次强调，只有主副本才可以接受写请求,从客户端的角度来看，从副本都是只读的。 同步复制与异步复制 同步复制数据强一致性，但是会阻塞后续的写操作 异步响应速度快 实践中把一个副节点设置为同步复制，其他副节点设置为异步复制，当主节点不可用时，提升另一个副节点到主节点 全异步复制吞吐高，存在数据丢失问题，复制滞后问题 配置新的从节点 在某个时间点对主节点的数据副本产生一个一致性快照，这样避免长时间锁定整个数据库 将此快照拷贝到新的从节点 从节点连接到主节点并请求快照点之后所发生的数据更改日志 获得日志之后，从节点来应用这些快照点之后所有数据变更，这个过程称之为追赶。接下来，它可以继续处理主节点上新的数据变化 处理节点失效 从节点失效 从节点根据复制日志，知道故障之前最后一笔事务，然后连接到主节点，请求那笔事务后面所有的数据变更。 主节点失效 确认主节点失效，心跳检测 选举出新的主节点，共识算法 重新配置系统使得新节点生效，原主节点重新上线后要降级成从节点 变数 使用异步复制丢失数据，主从切换过程中丢失数据 其他依赖数据库的内容在一起使用 集群脑裂 不合适的超时检测 复制日志的实现 基于语句的复制 主节点记录所执行的每个写请求(操作语句)并将该操作语句作为日志发送给从节点 问题 调用 date()，rand()等函数会在从节点产生不一样的值 并发事务限制 有副作用的语句会在不同的节点产生不同的副作用 基于 WAL 传输 从节点收到日志进行处理，建立与主节点内容完全相同的数据副本 问题 复制方案和存储引擎紧密耦合 基于行的逻辑日志复制 关系数据库的逻辑日志通常是指一系列记录来描述数据表行级别的写请求 对于行插入，日志包含所有相关列的新值。 对于行删除，日志里有足够的信息来唯一标识已删除的行，通常是靠主键，但如果表上没有定义主键，就需要记录所有列的旧值。 对于行更新，日志包含足够的信息来唯一标识更新的行，以及所有列的新值(或至少包含所有已更新列的新值)。 优势 与存储引擎结耦，更容易向后兼容 容易解析，可以发送到外部数据源 基于触发器的复制 触发器支持注册自己的应用层代码，使得当数据库系统发生数据更改(写事务)时自动执行上述自定义代码。通过触发器技术，可以将数据更改记录到一个单独的表中，然后外部处理逻辑访问该表，实施必要的自定义应用层逻辑，例如将数据更改复制到另一个系统。 问题 开销大 容易出错，有很多限制 复制滞后问题 主从复制要求所有写请求经过主节点，而任何副节点只能接收只读查询。 当从节点变多时，可以提高读请求的服务吞吐量，但是写请求吞吐变低 副节点落后与主节点，读到过期数据，一段时间后达成最终一致性 解决复制滞后的问题 写后读一致性 如果用户访问可能会被修改的内容，从主节点读取;否则，在从节点读取 客户端还可以记住最近更新时的时间戳 ，并附带在读请求中，据此信息，系统可以确保对该用户提供读服务时都应该至少包含了该时间戳的更新 。如果不够新，要么交由另一个副本来处理，要么等待直到副本接收到了最近的更新。 时间戳可以是逻辑时间戳或实际系统时钟 如果副本分布在多数据中心，情况会更复杂些。必须先把请求路由到主节点所在的数据中心 跟踪最近更新的时间，如果更新后一分钟之内，则总是在主节点读取;并监控从节点的复制滞后程度，避免从那些滞后时 间超过一分钟的从节点读取 需要考虑的问题 记住用户上次更新时间戳的方法实现起来会比较困难，因为在一台设备上运行的代码完全无法知道在其他设备上发生了什么。此时，元数据必须做到全局共享 如果副本分布在多数据中心, 无法保证来自不同设备的连接经过路由之后都到达同一个数据中心，需要想办法确保将来自不同设备的请求路由到同一个数据中心 单调读 一个比强一致性弱，但比最终一致性强的保证。当读取数据时，单调读保证，如果某个用户依次进行多次读取，则他绝 不会看到回滚现象，即在读取较新值之后又发生读旧值的情况 一种实现方法是每个用户总是从同一副本执行读取 前缀一致读 保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时也会按照当时写入的顺序 一个解决方案是确保任何具有因果顺序关系的写入都交给一个分区来完成 多主节点复制 单节点单点失败问题 适用场景 多数据中心 在每个数据中心都配置主节点 每个数据中心内，采用常规的主从复制方案 数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新 与单节点的主从复制方案的区别 就近访问，降低写入延迟，异步同步到其他数据中心 容忍数据中心失效，每个数据中心的主节点独立运行，失效主节点恢复后可以重新从其他主节点获取最新数据 容忍网络问题，主从模式写入是同步操作，需要更可靠的网络性能，多主节点是异步复制，可以更好容忍不可靠的网络 离线客户端操作 应用在离线后还需要继续工作的 日历，笔记 协作编辑 当一个用户编辑文档时，所做的更改会立即应用到本地副本，然后异步复制到服务器以及编辑同一文档的其他用户。 如果要确保不会发生编辑冲突，则应用程序必须先将文档锁定，然后才能对其进行编辑。如果另一个用户想要编辑同一个文档，首先必须等到第一个用户提交修改并释放锁。这种协作模式相当于主从复制模型下在主节点上执行事务操作。 为了加快协作编辑的效率，可编辑的粒度需要非常小。 处理写冲突 在不同的数据中心修改统一记录，在数据中心内部完成写入，在跨数据中心同步的时候出现写冲突 同步与异步冲突检测 同步冲突检测 等待写请求完成对所有副本的同步 丧失多主的优势 避免冲突 在应用层保证对同一记录的写请求只通过同一个主节点 由于主节点失效或者客户端漫游因为转到其他数据中心，此方法不再有效 收敛于一致状态的几个方案 给每个写入分配唯一的 ID，例如，一个时间戳，二个足够长的随机数，一个 UUID 或者一个基于键-值的哈希，挑选最高 ID 的写入作为胜利者，并将其他写入丢弃。如果基于时间戳，这种技术被称为最后写入者获胜。虽然这种方法很流行，但是很容易造成数据丢失。 为每个副本分配一个唯一的 ID，并制定规则，例如序号高的副本写入始终优先于序号低的副本 。这种方法也可能会导致数据丢失。 以某种方式将这些值合并在一起 利用预定义好的格式来记录和保留冲突相关的所有信息，然后依靠应用层的逻辑，事后解决冲突 自定义冲突解决逻辑 在写入时执行 只要数据库系统在复制变更日志时检测到冲突，就会调用应用层的冲突处理程序 在读取时执行 当检测到冲突时，所有冲突写入值都会暂时保存下来。下一次读取数据时，会将数据的多个版本读返回给应用层。应用层可能会提示用户或自动解决冲突，并将最后的结果返回到数据库。 自动冲突解决 无冲突的数据结构 可合并的持久数据结构，三向合并功能 操作转换，为可同时编辑的有序列表设计 拓扑结构 复制的拓扑结构描述了写请求从一个节点传播到其他节点的通信路径。 多个主节点存在多个可能的同步的拓扑结构。 环形拓扑结构 星型拓扑结构 全部-至-全部型拓扑结构 环形和星形拓扑的问题是，如果某一个节点发生了故障，在修复之前，会影响其他节点之间复制日志的转发。 全链接拓扑也存在一些自身的问题。主要是存在某些网络链路比其他链路更快的情况，从而导致复制日志之间的覆盖 为了使得日志消息正确有序，可以使用一种称为版本向量的技术 无主节点复制 选择放弃主节点，允许任何副本直接接受来自客户端的请求 节点失效时写入数据库 半数写入确认即可认为写入成功，读取时从多个副本同时读取，按照版本号确定那个值是最新的 读修复与反熵 失效节点上线后如何恢复错过的请求 读修复 当客户端并行读取多个副本时，可以检测到过期的返回值，然后将新值写入到该副本。这种方怯主要适合那些被频繁读取的场景。 反熵过程 数据存储用后台进程不断寻找副本之间的差异，将缺少的数据复制过去。如果没有反熵过程的存储系统只有在读的时候可以修复数据 读写 quorum 如果有 n 个副本，写人需要 w 个节点确认，读取必须至少查询 r 个节点， 则只要 w + r &amp;gt; n ，读取的节点中一定会包含最新值，一个常见的选择是设置 n 为某奇数(通常为 3 或 5), w = r = (n + 1) / 2 仲裁条件 w + r &amp;gt; n 定义了系统可容忍的失效节点数，如下所示: 当 w &amp;lt; n，如果一个节点不可用，仍然可以处理写入。 当 r &amp;lt; n，如果一个节点不可用，仍然可以处理读取。 假定 n=3, w=2, r=2，则可以容忍一个不可用的节点。 假定 n=5, w=3, r=3，则可以容忍两个不可用的节点 通常，读取和写入操作总是并行发送到所有的 n 个副本。参数 w 和参数 r 只是决定要等待的节点数。即有多少个节点需要返回结果，我们才能判断出结果的正确性。 Quorum 一致性的局限性 w + r &amp;gt; n 一定可以读到最新值，但是不一定要多数，只要读写之间有重叠就可以，可以等待更少的时间就可以返回。 即使 w + r &amp;gt; n 也可能读到旧值： 如果采用了 sloppy quorum，写操作的 w 节点和读取的 r 节点可能完全不同，因此无法保证读写请求一定存在重叠的节点 如果两个写操作同时发生，则无法明确先后顺序，需要根据时间戳来确定胜者，但由于时钟偏差问题，某些写入可能会被错误的抛弃 如果写操作与读操作同时发生 ，写操作可能仅在一部分副本上完成。此时，读取时返回旧值还是新值存在不确定性。 如果某些副本上已经写入成功，而其他一些副本发生写入失败，且总的成功副本数少于 w，那些已成功的副本上不会做回滚。这意味着尽管这样的写操作被视为失败，后续的读操作仍可能返回新值。 如果具有新值的节点后来发生失效，但恢复数据来自某个旧值， 则总的新值副本数会低于 w，这就打破了之前的判定条件 即使一切正常工作，也会出现一些边界情况。 监控旧值 即使应用可以容忍旧值，也需要了解复制当前的运行状态，如果出现了明显的滞后，它就是个重要的信号提醒我们需要采取必要的措施来排查原因。 对于主从复制的系统，由于主节点和从节点上写人都遵从相同的顺序，而每个节点都维护了复制日志执行的当前偏移量。通过对比主节点和从节点当前偏移量的差值，即可衡量该从节点落后于主节点的程度 对于无主节点的系统，还没有一个可用的方案。 宽松的 quorum 与数据回传 当客户端连不上存储节点时，把数据写入一个可访问的节点，这个节点不在 n 的结合中，等到恢复后，把这个数据的节点回传到 n 原始节点中。 多数据中心操作 副本的数量 n 是包含所有数据中心的节点总数。配置时，可以指定每个数据中心各有多少副本。每个客户端的写入都会发送到所有副本，但客户端通常只会等待来自本地数据中心内的 quorum 节点数的确认，这样避免了高延迟和跨数据中心可能的网络异常。尽管可以灵活配置，但对远程数据中心的写入由于延迟很高，通常都被配置为异步方式 检测并发写 最后写入者获胜 数据带上时间戳，丢弃较早的写入，牺牲了数据持久性，如果不能接收丢失数据的话，可以为每一次写入分配 UUID 主键 Happen-before 关系和并发 如果一个操作无能意识到另一个操作，那么旧可以称他们时并发操作 确定前后关系 服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，并将新版本号与写入的值一起保存。 当客户端读取主键时，服务器将返回所有当前值以及最新的版本号。且要求写之前，客户必须先发送读请求。 客户端写主键，写请求必须包含之前读到的版本号、读到的值和新值合并后的集合。写请求的响应可以像读操作一样，会返回所有当前值，这样就可以像购物车例子那样一步步链接起多个写入的值。 当服务器收到带有特定版本号的写入时，覆盖该版本号或更低版本的所有值，但必须保存更高版本号的所有值。 合并同时写入的值 一个简单的方法是基于版本号或时间戳来选择其中的一个值，但这意味着会丢失部分数据。所以，需要在应用程序代码中额外做些工作。 考虑到在应用代码中合并非常复杂且容易出错，因此可以设计一些专门的数据结构来自动执行合并，例如， Riak 支持称为 CRDT 一系列数据结构，以合理的方式高效自动合并，包括支持删除标记。 版本矢量 当多个副本同时接受写入时，我们需要为每个副本和每个主键均定义一个版本号。每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本看到的版本号。通过这些信息来指示要覆盖哪些值、该保留哪些并发值。 数据分区 面对一些海量数据集或非常高的查询压力，复制技术还不够，我们还需要将数据拆分成为分区，也称为分片 分区通常是这样定义的，即每一条数据(或者每条记录，每行或每个文档)只属于某个特定分区 采用数据分区的主要目的是提高可扩展性。不同的分区可以放在一个无共享集群的不同节点上。这样一个大数据集可以分散在更多的磁盘上，查询负载也随之分布到更多的处理器上。 对单个分区进行查询时，每个节点对自己所在分区可以独立执行查询操作，因此添加更多的节点可以提高查询吞吐量。超大而复杂的查询尽管比较困难，但也可能做到跨节点的并行处理。 数据分区与数据复制 分区通常与复制结合使用，即每个分区在多个节点都存有副本。这意味着某条记录属于特定的分区，而同样的内容会保存在不同的节点上以提高系统的容错性。 一个节点可能即是某些分区的主副本，同时又是其他分区的从副本 键-值数据的分区 分区的主要目标是将数据和查询负载均匀分布在所有节点上 分区不均匀，则会出现某些分区节点比其他分区承担更多的数据量或查询负载，称之为倾斜。 负载严重不成比例的分区即成为系统热点 基于关键字区间分区 为每个分区分配一段连续的关键字或者关键宇区间范围，如果知道关键字区间的上下限，就可以轻松确定那个分区包含这些关键字。如果还知道哪个分区分配在哪个节点，就可以直接向该节点发出请求 为了更均匀地分布数据，分区边界理应适配数据本身的分布特征 每个分区内可以按照关键字排序保存，这样可以轻松支持区间查询，即将关键字作为一个拼接起来的索引项从而一次查询得到多个相关记录 分区热点问题 基于关键字哈希值分区 一个好的哈希函数可以处理数据倾斜并使其均匀分布 丧失了良好的区间查询特性 Cassandra 中的表可以声明为由多个列组成的复合主键。复合主键只有第一部分可用于哈希分区，而其他列则用作组合索引来对 Cassandra SSTable 中的数据进行排序 基于哈希的分区方法可以减轻热点，但是无法做到完全避免。 一个简单的解决方法是对这小部分热点数据添加随机数再次分区，缺点是查询时需要查询所有分区再做合并。 分区与二级索引 基于文档的二级索引 每个列表都有一个唯一的文档 ID，用此 ID 对数据库进行分区 每个分区完全独立，各自维护自己的二级索引 二级索引的查询代价高昂，容易导致读延迟显著放大 基于此条的二级索引分区 对所有的数据构建全局索引，而不是每个分区维护自己的本地索引 全局索引也必须进行分区，且可以与数据关键字采用不同的分区策略 分区再平衡 查询压力增加，因此需要更多的 CPU 来处理负载 数据规模增加，因此需要更多的磁盘和内存来存储数据 节点可能出现故障，因此需要其他机器来接管失效的节点 所有这些变化都要求数据和请求可以从一个节点转移到另一个节点。这样一个迁移负载的过程称为再平衡 需求 平衡之后，负载、数据存储、读写请求等应该在集群范围更均匀地分布。 再平衡执行过程中，数据库应该可以继续正常提供读写服务。 避免不必要的负载迁移，以加快动态再平衡，并尽量减少网络和磁盘 I/O 影响。 动态再平衡策略 节点增加时，取模再平衡导致频繁的数据迁移 固定数量的分区 首先创建远超实际节点数的分区数，然后为每个节点分配多个分区。 接下来，如果集群中添加了一个新节点，该新节点可以从每个现有的节点上匀走几个分区，直到分区再次达到全局平衡 分区的数量再创建数据库时就确定好，原则上可以拆分和合并 需要分区规模和数据规模相适应 动态分区 每个分区总是分配给一个节点，而每个节点可以承载多个分区，这点与固定数量的分区一样。当一个大的分区发生分裂之后，可以将其中的一半转移到其他某节点以平衡负载。 分区数量可以自动适配数据总量 少量的数据，少量的分区就足够了 大量的数据，每个分区的大小则被限制在一个可配的最大值 按节点比例分区 每个节点具有固定数量的分区。此时，当节点数不变时，每个分区的大小与数据集大小保持正比的增长关系;当节点数增加时，分区则会调整变得更小。较大的数据量通常需要大量的节点来存储，因此这种方式也使每个分区大小保持稳定。 全自动的平衡会出现难以预测的结果，将自动平衡与自动故障相结合也可能存在一定风险，让管理员介入再平衡是个更好的选择 请求路由 允许客户端链接任意的节点。如果某节点恰好拥有所请求的分区，则直接处理该请求:否则，将请求转发到下一个合适的节点，接收答复，并将答复返回给客户端。 将所有客户端的请求都发送到一个路由层，由后者负责将请求转发到对应的分区节点上 客户端感知分区和节点分配关系 并行查询执行 典型的数据仓库查询包含多个联合、过滤、分组和聚合操作。MPP 查询优化器会将复杂的查询分解成许多执行阶段和分区，以便在集群的不同节点上并行执行。尤其是涉及全表扫描这样的查询操作，可以通过并行执行获益颇多。 事务 出错 数据库软件或硬件可能会随时失效(包括正在执行写操作的过程中)。 应用程序可能随时崩溃(包括一系列操作执行到中间某一步)。 应用与数据库节点之间的链接可能随时会中断，数据库节点之间也存在同样问题。 多个客户端可能同时写入数据库 ，导致数据覆盖。 客户端可能读到一些无意义的、部分更新的数据。 客户端之间由于边界条件竞争所引入的各种奇怪问题。 深入理解事务 ACID 原子性(Atomicity) 在出错时中止事务，并将部分完成的写入全部丢弃。 一致性(Consistency) 指对数据有特定的预期状态，任何数据更改必须满足这些状态约束(或者恒等条件) 如果某事务从一个有效的状态开始，并且事务中任何更新操作都没有违背约束，那么最后的结果依然符合有效状态。 隔离性(Isolation) 并发执行的多个事务相互隔离，它们不能互相交叉，数据库系统要确保当事务提交时，其结果与串行执行完全相同 持久性(Durability) 提供一个安全可靠的地方来存储数据而不用担心数据丢失，一且事务提交成功，即使存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失 单对象和多对象事务操作 单对象写入 基于日志恢复实现原子性，对每个对象采取加锁的方式来实现隔离 通常意义上的事务针对的是多个对象，将多个操作聚合为一个逻辑执行单元 多对象事务的必要性 当出现跨分区时，多对象事务非常难以正确实现，同时在高可用或者极致性能的场景下也会带来很多负面影响 没有原子性保证时，错误处理就会异常复杂，而缺乏隔离性则容易出现并发性方面的各种奇怪问题 处理错误与中止 如果存在违反原子性、隔离性或持久性的风险，则完全放弃整个事务，而不是部分放弃。 支持安全的重试机制才是中止流程的重点 弱隔离级别 某个事务修改数据而另一个事务同时要读取该数据，或者两个事务同时修改相同数据时，才会引发并发问题 可串行化的隔离会严重影响性能，而许多数据库却不愿意牺牲性能，因而更多倾向于采用较弱的隔离级别，它可以防止某些但并非全部的并发问题 RC 读数据库时，只能看到已成功提交的数据 写数据库时，只会覆盖已成功提交的数据 脏读 一个事物写入部分数据，但是没有提交，另一个事务可以看到尚未提交的数据，意味着出现了脏读 防止脏读 如果事务需要更新多个对象，脏读意味着另一个事物可能会看到部分实现 事务中止，所有写入操作需要回滚，脏读导致另一个事务读取到需要被回滚的数据 防止脏写 后面的事务覆盖前面事务对同一个值的修改，RC 隔离级别可以防止脏写，通常的方法是推迟第二个写请求，知道前面的事务完成提交。 实现 RC 数据库通常采用行级锁来防止脏写:当事务想修改某个对象时，它必须首先获得该对象的锁;然后一直持有锁直到事务提交(或中止) 同样采用行锁来防止脏读:所有试图读取该对象的事务必须先申请锁，事务完成后释放锁。从而确保不会发生读取一个脏的、未提交的值 快照隔离级别与 RR RC 存在不可重复读的问题，在同一事物的多次读取中读到不同的值 场景 备份 分析查询与完整性检查场景 总体想法 每个事务都从数据库的一致性快照中读取，事务一开始所看到是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事务都只看到该特定时间点的旧数据。 快照级别隔离对于长时间运行的只读查询(如备份和分析)非常有用。如果数据在执行查询的同时还在发生变化，那么查询结果对应的物理含义就难以理清。而如果查询的是数据库在某时刻点所冻结的一致性快照，则查询结果的含义非常明确。 实现快照级别隔离 与读-提交隔离类似，快照级别隔离的实现通常采用写锁来防止脏写，这意味着正在进行写操作的事务会阻止同一对象上的其他事务 读取时不需要加锁，这使得数据库在写入的同时不会影响长时间的只读查询。 多版本并发控制 考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以数据库保留了对象多个不同的提交版本 实现快照级别隔离 事务开始时，首先赋予一个唯一的、单调递增的事务 ID(txid)。每当事务向数据库写入新内容时，所写的数据都会被标记写入者的事务 ID。表中的每一行都有一个 created_by 字段，其中包含了创建该行的事务 ID。每一行还有一个 deleted_by 字段，初始为空。如果事务要删除某行，主行实际上并未从数据库中删除，而只是将 deleted_by 字段设置为请求删除的事务 ID 。事后，当确定没有其他事务引用该标记删除的行时，数据库的垃圾回收进程才去真正删除并释放存储空间。 一致性快照的可见性规则 每笔事务开始时，数据库列出所有当时尚在进行中的其他事务，然后忽略这些事务完成的部分写入，即不可见。 所有中止事务所做的修改全部不可见 较晚事务 ID 所做的任何修改不可见，不管这些事务是否完成了提交。 除此之外，其他所有的写入都对应用查询可见 可见性条件 事务开始的时刻，创建该对象的事务已经完成了提交 对象没有被标记为删除; 或者即使标记了，但删除事务在当前事务开始时还没有完成提交 索引与快照隔离级别 一种方案是索引直接指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。当后台的垃圾回收进程决定删除某个旧对象版本时，对应的索引条目也需要随之删除 另一种追加/写时复制的技术，当需要更新时，不会修改现有的页面，而总是创建一个新的修改副本，拷贝必要的内容，然后让父结点，或者递归向上直到树的 root 结点都指向新创建的结点。那些不受更新影响的页面都不需要复制，保持不变并被父结点所指向 可重复读与命名混淆 快照级别隔离对于只读事务特别有效。但是，具体到实现，许多数据库却对它有着不同的命名。Oracle 称之为可串行化，PostgreSQL 和 MySQL 则称为可重复读 SQL 标准对隔离级别的定义还是存在一些缺陷，某些定义模棱两可，不够精确，且不能做到与实现无关。尽管有几个数据库实现了可重复读，表面上看符合标准，但它们实际所提供的保证却大相径庭 防止更新丢失 应用程序从数据库读取某些值，根据应用逻辑做出修改，然后写回新值。 当有两个事务在同样的数 据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失 几种解决方案 原子写操作 原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会其他事务可以读它。这种技术有时被称为游标稳定性。另一种实现方式是强制所有的原子操作都在单线程上执行。 显示加锁 FOR UPDATE 指令指示数据库对返回的所有结果行要加锁 自动检测更新丢失 先让他们并发执行，但如果事务管理器检测到了更新丢失风险，则会中止当前事务，并强制回退到安全的“读-修改-写回”方式 原子比较与设置 UPDATE wiki_pages SET content = &amp;rsquo;new content&amp;rsquo; WHERE id = 1234 AND content = &amp;lsquo;old content&amp;rsquo; 冲突解决与复制 对于多副本数据库，加锁和原子不再有效，通常采用异步的方式来更新，目前许多多副本数据库采用 LWW 策略，但是容易丢失更新 写倾斜与幻读 即如果两个事务读取相同的一组对象，然后更新其中一部分: 不同的事务可能更新不同的对象，则可能发生写倾斜; 而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失 先前方案的限制 单对象的原子操作无效 自动检测不支持检测写倾斜 数据库不支持此约束 一个较优的选择是显示对依赖的数据加锁 在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读 快照级别隔离可以避免只读查询时的幻读，但是对于我们上面所讨论那些读-写事务，它却无法解决棘手的写倾斜问题。 实体化冲突 如果查询结果没有对象可以加锁，人为引入一些可以加锁的对象 串行化 实际串行执行 解决并发问题最直接的方法是避免并发 可行性 内存越来越便直，现在讲多应用可以将整个活动数据集都加载到内存中。当事务所需的所有数据都在内存中时，事务的执行速度要比等待磁盘 I/O 快得多。 数据库设计人员意识到 OLTP 事务通常执行很快，只产生少量的读写操作。相比之下，运行时间较长的分析查询则通常是只读的，可以在一致性快照上运行，而不需要运行在串行主循环里。 采用存储过程封装事务 数据库设计者认为，如果整个过程是一个事务，那么就可以方便地原子化执行。 采用单线程串行执行的系统往往不支持交互式的多语句事务 优缺点 语言并没有跟上通用编程语言的发展，语义都相当丑陋、过时，而且缺乏如今大多数编程语言所常用的函数库。 在数据库中运行代码难以管理 数据库中一个设计不好的存储过程要比同样低效的应用服务器代码带来更大的麻烦 分区 为了扩展到多个 CPU 核和多节点，可以对数据进行分区 对于跨分区的事务，数据库必须在涉及的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行化。 由于跨分区事务具有额外的协调开销，其性能比单分区内要慢得多 串行执行约束条件 事务必须简短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能 仅限于活动数据集完全可以加载到内存的场景 写入吞吐量必须足够低，才能在单个 CPU 核上处理; 否则就需要采用分区，最好没有跨分区事务。 跨分区事务虽然也可以支持，但是占比必须很小。 两段式加锁 多个事务可以同时读取同一对象，但只要出现任何写操作，则必须加锁以独占访问 如果事务 A 已经读取了某个对象，此时事务 B 想要写入该对象，那么 B 必须等到 A 提交或中止之才能继续。以确保 B 不会在事务 A 执行的过程中间去修改对象。 如果事务 A 已经修改了对象，此时事务 B 想要读取该对象，则 B 必须等到 A 提交或中止之后才能继续。对于 2PL，不会出现读到旧值的情况 实现 如果事务要读取对象，必须先以共享模式获得锁。可以有多个事务同时获得一个对象的共享锁，但是如果某个事务已经获得了对象的独占锁，则所有其他事务必须等待。 如果事务要修改对象，必须以独占模式获取锁。不允许多个事务同时持有该锁(包括共享或独占模式)，换言之，如果对象上已被加锁，则修改事务必须等待。 如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。升级锁的流程等价于直接获得独占锁。 事务获得锁之后，一直持有锁直到事务结束(包括提交或中止)。这也是名字“两阶段”的来由，在第一阶段即事务执行之前要获取锁，第二阶段(即事务结束时)则释放锁。 由于使用了这么多的锁机制，所以很容易出现死锁现象，数据库系统会自动检测事务之间的死锁情况，并强行中止其中的一个以打破僵局，这样另一个可以继续向前执行。而被中止的事务需要由应用层来重试。 性能 降低了事务的并发性 2PL 模式下数据库的访问延迟具有非常大的不确定性 谓词锁 它的作用类似于之前描述的共享/独占锁，而区别在于，它并不属于某个特定的对象(如表的某一行)，而是作用于满足某些搜索条件的所有查询对象 如果事务 A 想要读取某些搞足匹配条件的对象，例如采用 SELECT 查询，它必须以共享模式获得查询条件的谓词锁。如果另一个事务 B 正持有任何一个匹配对象的互斥锁，那么 A 必须等到 B 释放锁之后才能继续执行查询。 如果事务 A 想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁匹配(即冲突)。如果事务 B 持有这样的谓词锁，那么 A 必须等到 B 完成提交(或中止)后才能继续。 索引区间锁 谓词锁性能不佳 :如果活动事务中存在许多锁，那么检查匹配这些锁就变得非常耗时 大多数使用 2PL 的数据库实际上实现的是索引区间锁(或者 next­ key locking) ，本质上它是对谓词锁的简化或者近似 索引区间锁扩大了锁定了对象的范围，但是开销低了很多 如果没有合适的索引可以施加区间锁，数据库退回到添加表锁 可串行化的快照隔离 悲观与乐观的并发控制 可串行化的快照隔离是一种乐观并发控制 当事务提交时 (只有可串行化的事务被允许提交)，数据库会检查是否确实发生了冲突(即违反了隔离性原则)，如果是的话，中止事务并接下来重试。 基于过期的条件做决定 读取之前已经有未提交的写入 读取之后，又有新的写入 检测是否读取了过期的 MVCC 对象 当事务提交时，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须中止当前事务。 检测写是否影响了之前的读 当另一个事务尝试修改时，它首先检查索引，从而确定是否最近存在一些读目标数据的其他事务。这个过程类似于在受影响的宇段范围上获取写锁，但它并不会阻塞读取，而是直到读事务提交时才进一步通知他们 :所读到的数据现在已经发生了变化。 可串行化快照隔离的性能 可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁 可串行化快照隔离可以突破单个 CPU 核的限制。 分布式系统的挑战 即使系统面临各种出错可能，也需要完成预定工作 故障与部分失效 单节点：要么工作，要么出错 分布式系统：部分失效和不确定性 云计算和超算 超算：定时备份任务状态，然后保存在持久存储上，当某节点出现故障，停止整个集群的任务，修复后从最近的检查点开始运行。 云计算 都是在线服务，无法容忍完全不可用 普通硬件，故障率较高 基于 IP 和以太网通信 总是会有部分组建故障 容忍系统部分失败 网络慢且不可靠 我们需要依靠软件提供容错，在不可靠系统上构建可靠的系统 需要知道在发生故障时，系统的预期行为是什么 不可靠的网络 系统的可靠性取决于最不可靠的组件 常见出错场景 请求可能已经丢失 请求还在队列，无法马上发送 请求接收方已经宕机 远程接收节点暂时无法响应 消息在回复过程中丢失 远程接收方已经处理请求，但回复却被延迟处理 现实中的网络故障 人为错误是故障的主要原因 冗余硬件不见得降低故障率 检测故障 负载均衡器需要避免向己失效的节点继续分发请求 对于主从复制的分布式数据库，如果主节点失败，需要将某个从节点提升为主节点，不过由于网络的不确定性很难判断节点是否确实失效。 然而不幸的是，由于网络的不确定性使得判断节点是否失效非常困难;而只有在某些特定场景下，或许你可以明确知道哪里出错了 假设可以登录节点，但发现服务进程没有侦听目标端口，那么操作系统会返回 RST 或 FIN 标志的数据包来辅助关闭或拒绝 TCP 连接。但是，如果节点在处理请求的过程中发生了崩溃，则很难知道该节点实际处理了多少数据 如果服务进程崩溃，但操作系统仍正常运行，可以通过脚本通知其他节点，以便新节点来快速接管而跳过等待超时。 如果有权访问数据中心网络交换机，则可以通过管理接口查询是否存在硬件级别的链路故障 如果路由器已经确认目标节点不可访问，则会返回 ICMP “目标不可达”数据包来回复请求 超时和无限期的延迟 较长的超时时间意味着更长时间的等待，才能宣告节点失败。 较短的时间可以快速帮助检测，但是可能出现误判，导致同一操作在不同节点执行了两次。 当一个节点故障，其承担的职责需要交给其他节点，这个过程会给其他节点和网络带来压力，特别是系统此时处于高负荷状态。转移负载会导致失效扩散，从而造成所有节点崩溃，服务完全不可用。 网络拥塞与排队 当多个不同节点同时发送数据包到相同的目标节点时，网络交换机会出现排队，然后依次将数据包转发到目标网络。如果网络负载过重，数据包可能必须等待一段时间才能获得发送机会。如果数据量太大，交换机队列塞满，之后的数据包则会被丢弃，网络还在运转，但会引发大量数据包重传。 当数据包到达目标机器后，如果所有 CPU 核都处于繁忙状态，则网络数据包请求会被操作系统排队，直到应用程序能够处理。根据机器的配置和负载情况，这里也会引人一段不确定的等待时间 在虚拟化环境下，CPU 核会切换虚拟机，从而导致正在运行的操作系统会突然暂停几十毫秒。在这段时间，客户虚机无屈从网络中接收任何数据，入向的包会被虚拟机管理器排队缓冲，进一步增加了网络延迟的不确定性 TCP 执行流量控制时，节点会主动限制自己的发送 速率以避免加重网络链路或接收节点负载。这意味着数据甚至在进入网络之前，已经在发送方开始了排队。 如采延迟或丢弃的数据价值不大， UDP 是个不错的选择 超时设置并不是一个不变的常量，而是持续测量响应时间及其变化，然后根据最新的响应时间分布来自动调整 同步和异步网络 固定电话有持续端到端的低延迟和足够的带宽来传输音频文件。 当通过电话网络拨打电话时，系统会动态建立一条电路:在整个线路上为呼叫分配一个固定的、带宽有保证通信链路，该电路一直维持到通话结束 这种网络本质是同步的:即使数据中间经过了多个路由器，16bit 空间在电路建立时已经在网络中得到预留，不会受到排队的影响。由于没有排队，网络最大的端到端延迟是固定的。我们称之为有界延迟。 网络 固定电话独占一段连接，网络连接则是尽可能使用所有带宽。 基于分组交换协议的网络注定收到排队的影响 TCP 动态调整传输速率则可以充分利用所有可用的网络容量 当前广泛部署的技术无法为我们提供延迟或可靠性方面的硬件级保证，我们必须假设会出现网络拥塞，排队和无上限的延迟 不可靠的时钟 但是由于网络的不确定延迟，精确测量面临着很多挑战。这些情况使得多节点通信时很难确定事情发生的先后顺序。 通过 NTP 服务器同步机器时间的时钟 单调时钟和墙上时钟 墙上时钟 与 NPT 同步，可以回退到过去，时间精度较为粗糙。 单调时钟 保证时间单调往前 不同的 CPU 有不同过得单调时间，任务在不同 CPU 调度时需要调整之间偏差。 精度高，可以计算微秒甚至更短的间隔。 时钟同步与准确性 计算机中的石英钟不够准确 如果与 NTP 服务器的时钟差别过大，可能会出现拒绝同步，或者本地时间将被强制重置 与 NTP 服务器同步失败 网络延迟导致的 NTP 服务器延迟 NTP 服务器故障，或者配置错误 闰秒处理，在一天的周期内逐步调整闰秒 虚拟机中的时钟会突然因为切换出现暂停，然后突然向前发生了跳跃 不信任不可控设备上的时钟 依赖同步的时钟 如果应用需要精确同步的时钟，最好仔细监控所有节点上的时钟偏差。如果某个节点的时钟漂移超出上限，应将其宣告为失效，并从集群中移除。这样的监控的目的是确保在造成重大影响之前尽早发现并处理问题 时间戳与事件顺序 多主节点复制的分布式数据库依赖墙上时钟，导致在 LWW 中，错误写入旧值 时钟的置信区间 时间存在误差，因此，我们不应该将时钟读数视为一个精确的时间点，而更应该视为带有置信区间的时间范围。 大多数系统不提供置信区间的信息，所以无法知道误差范围 全局快照的同步时钟 当数据库分布在多台机器上时，由于需要复杂的协调以产生全局的单调递增的事务 ID 进程暂停 其他节点该如何确信该主节点没有被宣告失效，可以安全地写入 定时从其他节点获取租约，只要租约不过期它就是主节点 进程暂停导致租约过期，被其他节点接管 GC 虚拟机暂停 终端休眠 上下文切换 磁盘 I/O 和网络 I/O 内存访问出现缺页异常 使用 SIGSTOP 暂停进程 保证响应时间 实时操作系统 内存分配收到严格限制或被禁止 需要大量测试验证 调整 GC 的影响 把 GC 暂停视为节点的一个计划内的临时离线，当节点启动垃圾回收时，通知其他节点来接管客户端的请求。此外 ，系统可以提前为前端应用发出预警，应用会等待当前请求完成，但停止向该节点发送新的请求，这样垃圾回收可以在无干扰的情况下更加高效运行。这个技巧以某种方式对客户端隐藏垃圾回收，降低负面影响 只对短期对象执行垃圾回收，然后在其变成长期存活对象之前，采取定期重启的策略从而避免对长期存活对象执行全面回收。每次选悻一个节点重新启动，在重启之前，重新平衡节点之间的流量，思路与读动升级类似 知识，真相与谎言 当节点不通时，无法判断是网络原因还是节点原因 真相由多数决定 超过一半的节点收不到某节点的回复则视为失败 节点不能判断自身的状态，需要依靠多数投票 主节点与锁 只允许一个节点作为数据库分区的主节点，以防止出现脑裂 只允许一个事务或客户端持有特定资源的锁，以防止同时写入从而导致数据破坏。 只允许一个用户来使用特定的用户名，从而确保用户名可以唯一标识用户 出错 节点的唯一锁失效之后认为自己还持有锁导致导致多个客户端同时写入出错 Fencing 令牌 我们假设每次锁服务在授予锁或租约时，还会同时返回一个 fencing 令牌，该令牌(数字)每授授予一次就会递增(列如，由锁服务增加)。然后，要求客户端每次向存储系统发送写请求时，都必须包含所持有的 fencing 令牌.</description></item><item><title>数据密集型应用系统设计::数据系统基础</title><link>/notes/designing_data_intensive_application_foundations_of_data_systems/</link><pubDate>Sat, 20 Mar 2021 21:57:43 +0800</pubDate><guid>/notes/designing_data_intensive_application_foundations_of_data_systems/</guid><description>数据系统基础 可靠、可扩展与可维护的应用系统 数据密集型应用通常基于标准模块构建而成，每个模块负责单一的常用功能 数据库:用以存储数据，这样之后应用可以再次访问 高速缓存:缓存那些复杂或操作代价昂贵的结果，以加快下一次访问 索引:用户可以按关键字搜索数据并支持各种过滤 流式处理:持续发送消息至另一个进程，处理采用异步方式 批处理:定期处理大最的累积数据 可靠性 当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转 对软件典型的期望 应用程序执行用户所期望的功能 可以容忍用户出现错误或者不正确的软件使用方法 性能可以应对典型场景、 合理负载压力和数据量 系统可防止任何未经授权的访问和滥用 可能出错的事情称为错误(faults)或故障 系统可应对错误则称为容错(fault­ tolerant)或者弹性(resilient) 容错总是指特定类型的故障，这样的系统才更有实际意义 故障通常被定义为组件偏离其正常规格 失效意味系统作为一个整体停止，无法向用户提供所需的服务。 通过故意引发故障的方式，来持续检验、测试系统的容错机制，增加对真实发生故障时应对的信心 硬件故障 采用硬件冗余方案对于大多数应用场景还是足够的 多机冗余则只对少最的关键应用更有意义，对于这些应用，高可用性是绝对必要的 通过软件容错的方式来容忍多机失效成为新的手段，或者至少成为硬件容错的有力补充 软件错误 因为节点之间是由软件关联的，因而往往会导致更多的系统故障 避免软件故障需要考虑很多细节 认真检查依赖 的假设条件与系统之间交互 进行全面的测试 进程隔离 允许进程崩溃并自动重启 反复评估，监控并分析生产环节的行为表现 等 人为失误 人是不可靠的，该如何保证系统的可靠性呢 以最小出错的方式来设计系统。 想办法分离最容易出错的地方、容易引发故障的接口 充分的测试: 从各单元测试到全系统集成测试以及手动测试 当出现人为失误时，提供快速的恢复机制以尽最减少故障影响 设置详细而清晰的监控子系统，包括性能指标和错误率 推行管理流程并加以培训 等 可靠性的重要性 导致商誉下降，影响效率，营收损失 即使在所谓 “非关键“ 应用中我们也应秉持对用户负责的态度 可扩展性 可扩展性是用来描述系统应对负载增加能力的术语 随着规模的增长， 例如数据量、 流量或复杂性，系统应以合理的方式来匹配这种增长 描述负载 负载可以用称为负载参数的若干数字来描述 Web 服务器的每秒请求处理次数 数据库中写入的比例 聊天室的同时活动用户数量 缓存命中率 等 描述性能 负载增加，但系统资源(如 CPU、内存、网络带宽等)保持不变，系统性能会发生什么变化 负载增加，如果要保持性能不变，需要增加多少资源 延迟与响应时间 响应时间是客户端看到的:除了处理请求时间(服务时间，service time)外，还包括来回网络延迟和各种排队延迟 延迟则是请求花费在处理上的时间 不要将响应时间视为一个固定的数字，而是可度量的一种数值分布 影响响应时间的因素 上下文切换和进程调度 网络数据包丢失和 TCP 重传 垃圾回收暂停 缺页中断和磁盘 I/O 服务器机架的机械振动 我们经常考察的是服务请求的平均响应时间 中位数指标非常适合描述多少用户需要等待多长时间 采用较高的响应时间百分位数(tail latencies, 尾部延迟或长尾效应)很重要， 因为它们直接影响用户的总体服务体验 系统响应时间取决于最慢的那个服务 垂直扩展(升级到更强大的机器) 水平扩展(将负载分布到多个更小的机器) 最近通常的做法一直是，将数据库运行在一个节点上，直到高扩展性或高可用性的要求迫使不得不做水平扩展。 超大规模的系统往往针对特定应用而高度定制，架构取决于多种因素 读取量、写入量 待存储的数据量 数据的复杂程度 响应时间要求 访问模式 等 对于早期的初创公司或者尚未定型的产品，快速迭代推出产品功能往往比投入精力来应对不可知的扩展性更为重要。 可维护性 软件的大部分成本在于整个生命周期的持续投入 开发阶段 维护与缺陷修复 监控系统来保持正常运行 故障排查 适配新平台 搭配新场景 技术缺陷的完善 增加新功能 等 可运维性 监视系统的健康状况，并在服务出现异常状态时快速恢复服务 追踪问题的原因，例如系统故障或性能下降 保持软件和平台至最新状态，例如安全补丁方面 了解不同系统如何相互影响，避免执行带有破坏性的操作 预测未来可能的问题，并在问题发生之前即使解决(例如容量规划) 建立用于部署、配置管理等良好的实践规范和工具包 执行复杂的维护任务，例如将应用程序从一个平台迁移到另一个平台 当配置更改时，维护系统的安全稳健 制定流程来规范操作行为，并保持生产环境稳定 保持相关知识的传承 简单性 复杂性有各种各样的表现方式 状态空间的脖胀 模块紧耦合 令入纠结的相互依赖关系 不一致的命名和术语 为了性能而采取的特殊处理 为解决某特定问题而引入的特殊框架 消除意外复杂性最好手段之一是抽象 一个好的设计抽象可用于各种不同的应用程序 也带来更高质量的软件 设计好的抽象还是很有挑战性 可演化性 一成不变的系统需求几乎没有，想法和目标经常在不断变化 组织流程方面，敏捷开发模式为适应变化提供了很好的参考 数据模型与查询语言 数据模型可能是开发软件最重要的部分 复杂的应用程序可能会有更多的中间层 每层都通过提供一个简洁的数据模型来隐藏下层的复杂性 关系模型 数据被组织成关系 每个关系都是元组(tuples)的无序集合(在 SQL 中称为行) 如果数据存储在关系表中，那么应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层 查询优化器自动决定以何种顺序执行查询，以及使用哪些索引 只需构建一次查询优化器，然后使用该数据库的所有应用程序都可以从中受益 网络模型 它也被称为 CODASYL 模型 网络模型中，一个记录可能有多个父结点 在网络模型中，记录之间的链接不是外键，而更像是编程语言中的指针 访问记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。 查询和更新数据库变得异常复杂而没有灵活性 文档模型 无强制模式 数据的结构是隐式的，只有在读取时才解释 文档通常存储为编码为 JSON、XML 或其二进制变体的连续字符串 存储局部性具有性能优势 局部性优势仅适用需要同时访问文档大部分内容的场景 NoSQL Not Only SQL 比关系数据库更好的扩展性需求，包括支持超大数据集或超高写入吞吐量 普遍偏爱免费和开源软件而不是商业数据库产品 关系模型不能很好地支持一些特定的查询操作 对关系模式一些限制性感到沮丧，渴望更具动态和表达力的数据模型 在可预见的将来，关系数据库可能仍将继续与各种非关系数据存储一起使用，这种思路有时也被称为混合持久化 文档数据库的比较 在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同 相关项都由唯一的标识符引用 在关系模型中被称为外键 文档模型中被称为文档引用 支持文档数据模型的主要论点是模式灵活性， 由于局部性而带来较好的性能 关系模型则强在联结操作、多对一和多对多关系更简洁的表达上，与文档模型抗衡 对于高度关联的数据，文档模型不太适合，关系模型可以胜任，而图模型则是最为自然的 融合关系模型与文档模型是未来数据库发展的一条很好的途径 数据存储与检索 哈希索引 Bitcask 默认存储引擎 提供高性能的读和写，只要所有的 key 可以放入内存 只需一次磁盘寻址 只追加到文件末尾，不做原地更新 适合每个键的值频繁更新的场景 执行压缩的同时将多个段合并在一起以节省空间 优点 追加和分段合并主要是顺序写，它通常比随机写入快得多 如果段文件是追加的或不可变的，则并发和崩溃恢复要简单得多 合并旧段可以避免随着时间的推移数据文件出现碎片化的问题 局限性 hash 表必须全部放入内存，磁盘表现难以良好 区间查询查询效率低 SSTables 要求 key-value 对按照 key 排序 每个键在每个合并的段文件中只能出现一次 合并段更加简单高效 在文件中查找特定的键时，不再需要在内存中保存所有键的索引 在压缩块开头保存稀疏索引 构建和维护 SSTables 当写入时，将其添加到内存中的平衡树数据结构中(例如如红黑树)。这个内存中的树有时被称为内存表。 当内存表大于某个闹值(通常为几兆字节)时，将其作为 SSTable 文件写入磁盘。由于树已经维护了按键排序的 key-value 对，写磁盘可以比较高效。新的 SSTable 文件成为数据库的最新部分。当 SSTable 写磁盘的同时 ，写入可以继续添加到一个新的内存表实例 为了处理读请求，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标(或为空) 后台进程周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值 崩溃处理 - 在磁盘上保留单独的日志，每个写入都会立即追加到该日志，每当将内存表写入 SSTable 时，相应的日志可以被丢弃 LSM-tree Log-Structured Merge-Tree 确定键不存在之前，必须先检查内存表，然后将段一直回溯访问到最旧的段文件 为了优化这种访问，存储引擎通常使用额外的布隆过滤器 可以支持非常高的写入吞吐量。 B-trees 经受了长久的时间考验 是几乎所有关系数据库中的标准索引实现 B-tree 将数据库分解成固定大小的块或页, 这种设计更接近底层硬件，因为磁盘也是以固定大小的块排列 查找索引中的一个键时, 从根开始。 孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。 大多数数据库可以适合 3~4 层的 B-tree 使 B-tree 可靠 B-tree 底层的基本写操作是使用新数据覆盖磁盘上的旧页, 对该页的所有引用保持不变 从崩溃中恢复, 预写日志(write-ahead log, WAL)，也称为重做日志 每个 B-tree 的修改必 须先更新 WAL 然后再修改树本身的页 多个线程要同时访问 B-tree , 注意并发控制 ，否则线程可能会看到树处于不一致的状态。通常使用锁存器(轻量级的锁)保护树的数据结构来完成 优化 B-tree 利用 COW 来做并发控制 保存键的缩略信息，而不是完整的键，这样可以节省页空间 对树进行布局，以便相邻叶子页可以按顺序保存在磁盘上 添加额外的指针到树中。 例如，每个叶子页面可能会向左和向右引用其同级的兄弟页，这样可以顺序扫描键，而不用跳回到 父页 分形树 对比 B-tree 和 LSM-tree B-tree 的 实现比 LSM-tree 的实现更为成熟 LSM-tree 通常对于写快 而 B-tree 被认为对于读取更快。读取通常在 LSM-tree 上较慢 LSM-tree 的优点 LSM-tree 通常能够承受比 B-tree 更高的写入吞吐量 它们有时具有较低的写放大 它们以顺序方式写入紧凑的 SSTable 文件 磁盘的顺序写比随机写要快得多 LSM-tree 可以支持更好地压缩，因此通常磁盘上的文件比 B-tree 小很多 更少的碎片 LSM-tree 的缺点 压缩过程有时会干扰正在进行的读写操作 压缩和写入共享带宽, 数据库的数据量越大，压缩所需的磁盘带宽就越多 写入高并且压缩没有仔细配置，随着未合并段的不断增加，读取会变慢 其他索引结构 二级索引 索引中的键是查询搜索的对象 实际存储的行 对其他地方存储的行的引用 存储行的具体文件被称为堆文件 避免数据复制，实际数据只存在一个地方 当新值大于旧值时，需要将数据移动到新空间，在原地保存一个指向新地址的指针 将索引行直接存储在索引中，聚簇索引 在某些数据库中，表的主键始终是聚簇索引，表的二级索引引用主键索引 索引覆盖 索引中保存了一些表的列值，刚好满足查询条件 加快读取速度，更大的写开销和事物开销 多列索引 将几个字段按照顺序组成一个键 专门的空间索引，R 树 全文索引 Lucene 采用了类似 SSTable 的索引结构 内存中的索引是键中的字符序列的有限状态自动机 在内存中保存所有内容 用于缓存的内存数据库可以容忍丢失 不能丢失的可以持久化到磁盘或者冗余到其他机器 关系型数据库的数据也可以完全存在数据库 使用磁盘格式的编码开销大于 KV 结构的数据库 基于内存的数据库可以提供更多的数据结构 更容易水平扩展 NVM 技术的发展 事务处理与分析处理 ACID(原子性、一致性、隔离性和持久性) OLTP 和 OLAP 对比 属性 OLTP OLAP 主要读特征 基于键，每次查询返回少量的记录 对大量记录进行汇总 主要写特征 随机访问，低延迟写入用户的输入 批量导入( ETL)或事件流 典型使用场景 终端用户，通过网络应用程序 内部分析师，为决策提供支持 数据表征 最新的数据状态(当前时间点) 随着时间而变化的所有事件历史 数据规模 GB 到 TB TB 到 PB OLTP 存储引擎 日志结构 原地更新 SQL 可以同时胜任 OLAP 和 OLTP 数据仓库 在线的数据分析影响 LATP 性能 数据仓库可以针对分析访问模式进行优化 星型和雪花型分析模式 星型模型 模式的中心是一个所谓的事实表，事实表的每一行表示特定时间发生的事件 其他列可能会引用其他表的外键，称为维度表 事实表中的每一行都代表一个事件，维度通常代表事件的对象(who)、什么(what)、地点(where)、时间(when)、方法(how)以及原因(why) 雪花模型 在星型模型的基础上维度进一步细分为子空间 在典型的数仓中，表的列非常宽，有时有几百列 列式存储 访问的数据通常只有少数列 来自表的一列的所有值相邻存储 列压缩 位图编码 内存带宽和矢量化处理 CPU 缓存 SIMD 列存储中的排序 行的存储顺序并不太重要 第一列排序出现相同值时，可以指定第二列继续进行排序 面向列的存储具有多个排序顺序，这有些类似在面向行的存储中具有多个二级索引 列存储的写操作 LSM-Tree 物化聚合 物化视图，内容是一些查询的结果 从虚拟视图查询时，SQL 引擎将其动态扩展到视图的底层查询，然后处理扩展查询 OLAP 立方体，由不同唯独分组的聚合网格 数据立方体缺乏像查询原始数据那样的灵活性 数据编码与演化 双向的兼容性 较新的代码可以读取由旧代码编写的数据 较旧的代码可以读取由新代码编写的数据 数据编码格式 在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对 CPU 的高效访问和操作进行了优化 将数据写入文件或通过网络发送时，必须将其编码为某种自包含的字节序列 语言特定的格式 语言绑定 安全问题 兼容性问题 性能问题 JSON，XML，CSV 数字编码有很多模糊之处。在 XML 和 csv 中，无怯区分数字和碰巧由数字组成的字符串 JSON 区分字符串和数字，但不区分整数和浮点数，并且不指定精度。 JSON 和 XML 对 Unicode 字符串(即人类可读文本)有很好的支持，但是它们不支持二进制字符串(没有字符编码的字节序列) XML 和 JSON 都有可选的模式支持 CSV 没有任何模式，因此应用程序需要定义每行和每列的含义 二进制变体 大数据集收益明显 MessagePack 一种 JSON 的二进制编码 Thrift 与 Protocol Buffers 需要模式来编码任意的数据 Thrift 与使用 Thrift 接口定义语言来描述模式 Protocol Buffers 使用类似模式 没有字段名 如果字段设置了 required，但字段未填充，则运行时检查将出现失败 字段标签和模式演化 字段标签(field tag)对编码数据的含义至关重要。编码永远不直接引用字段名称 可以添加新的字段到模式，只要给每个字段一个新的标记号码。如果旧的代码(不知道添加的新标记号码)试图读取新代码写入的数据，包括一个它不能识别的标记号码中新的字段，则它可以简单地忽略该字段 只要每个字段都有一个唯一的标记号码，新的代码总是可以读取旧的数据，因为标记号码仍然具有相同的含义 为了保持向后兼容性，在模式的初始部署之后添加的每个字段都必须是可选的或具有默认值 Avro 二进制编码格式 Avro IDL 用于人工编辑 另一种(基于 JSON)更易于机器读取 只有当读取数据的代码使用与写入数据的代码完全相同的模式肘，才能正确解码二进制数据。读和写的模式如果有任何不匹配 都将无法解码数据 模式演化 在不同的上下文环境中保存单一的模式 模式的优点 它们可以比各种“二进制 JSON”变体更紧凑，可以省略编码数据中的宇段名称。 模式是一种有价值的文档形式，因为模式是解码所必需的，所以可以确定它是最新的 模式数据库允许在部署任何内容之前检查模式更改的向前和向后兼容 对于静态类型编程语言的用户来说，从模式生成代码的能力是有用的，它能够在编译时进行类型检查 数据流模式 进程间数据流动的方式 通过数据库 通过服务调用 通过异步消息传递 基于数据库的数据流 服务版本不一致 向前兼容，旧版本的代码不处理新版本加入的值 不同时间写入不同的值导致字段丢失 创建归档时使用统一的编码 基于服务的数据流 REST 和 RPC 服务器公开的 API 称为服务 服务器和客户端使用的数据编码必须在不同版本的服务 API 之间兼容 网络服务 运行在用户设备上的客户端应用程序，通过 HTTP 向服务发出请求, 这些请求通常通过公共互联网进行 一种服务向同一组织拥有的另一项服务提出请求，这些服务通常位于同一数据中心内 ，作为面向服务/微型架构的一部分。支持这种用例的软件有时被称为中间件 一种服务向不同组织所拥有的服务提出请求，经常需通过互联网 。这用于不同组织后端系统之间的数据交换。此类别包括由在线服务(如信用卡处理系统)提供的公共 API，或用于共享访问用户数据的 OAuth 有两种流行的 Web 服务方方法 : REST 和 SOAP REST 它强调简单的数据格式，使用 URL 来标识资源，并使用 HTTP 功能进行缓存控制、身份验证和内容类型协商 SOAP 基于 XML 的协议，用于发出网络 API 请求 SOAP Web 服务的 API 使用被称为 WSDL 过于复杂, 无法手动构建，SOAP 用户严重依赖工具支持、代码生成和 IDE 远程过程调用(RPC)的问题 结果不可预测 服务幂等 网络波动 大对象编码解析 不同的语言的支持问题 RPC 的发展方向 封装可能失败的异步操作 并行请求多项服务 服务发现 RPC 方案的向后和向前兼容性属性取决于它所使用的具体编码技术 基于消息传递的数据流 如果接收方不可用或过载，它可以充当缓冲区，从而提高系统的可靠性。 它可以自动将消息重新发送到崩溃的进程，从而防止消息丢失。 它支持将一条消息发送给多个接收方 它在逻辑上将发送方与接收方分离 消息代理 一个进程向指定的队列或主题发送消息，并且代理确保消息被传递给队列或主题的一个或多个消费者或订阅者 在同一主题上可以有许多生产者和许多消费者 主题只提供单向数据流 消息代理通常不会强制任何特定的数据模型 分布式 Actor 框架 Actor 模型是用于单个进程中并发的编程模型 逻辑被封装在 Actor 中，而不是直接处理线程 每个 Actor 通常代表一个客户端或实体，它可能具有某些本地状态(不与其他任何 Actor 共享) 它通过发送和接收异步消息与其他 Actor 通信。 不保证消息传送: 在某些错误情况下，消息将丢失。 由于每个 Actor 一次只处理一条消息，因此不需要担心线程，每个 Actor 都可以由框架独立调度。 三种流行的分布式 Actor 框架处理消息编码的方式 默认情况下，Akka 使用 Java 的内置序列化，它不提供向前或向后兼容性。但是，可以用类似 Protocol Buffers 的东西替代它，从而获得滚动升级的能力 默认情况下， Orleans 使用不支持滚动升级部署的自定义数据编码格式:要部署新版本的应用程序，需要建立一个新的集群，将流量从旧集群导入到新集群，然后关闭旧集群。像 Akka 一样，也可以使用自定义序列化插件。 在 Erlang OTP 中，很难对记录模式进行更改, 滚动升级在技术上是可能的，但要求仔细规划。</description></item><item><title>系统设计::设计谷歌硬盘</title><link>/notes/system_design_interview_15/</link><pubDate>Mon, 15 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_15/</guid><description>设计谷歌硬盘 近年来，Google Drive、Dropbox、微软 OneDrive 和苹果 iCloud 等云存储服务已经变得非常流行。在本章中，你被要求设计 Google Drive。
在进入设计之前，让我们花点时间来了解一下 Google Drive。Google Drive 是一个文件存储和同步服务，帮助你在云端存储文档、照片、视频和其他文件。你可以从任何电脑、智能手机和平板电脑访问你的文件。你可以轻松地与朋友、家人和同事分享这些文件[1]。图 15-1 和 15-2 分别显示了谷歌硬盘在浏览器和移动应用程序上的样子。
理解问题并确定设计范围 设计谷歌硬盘是一个大项目，因此，提出问题以缩小范围是很重要的。
应聘者：最重要的功能是什么？
面试官：上传和下载文件，文件同步，以及通知。
应聘者：这是一个移动应用，一个网络应用，还是两者都有？
面试官：都是。
应聘者：支持的文件格式有哪些？
面试官：任何文件类型。
应聘者：文件是否需要加密？
面试官：是的。是的，存储中的文件必须是加密的。
应聘者：文件大小有限制吗？
面试官：有，文件必须是 10GB 或更小。
应聘者：该产品有多少用户？
面试官：10M DAU。
在本章中，我们将重点介绍以下功能。
添加文件。添加文件的最简单方法是将文件拖放到 Google Drive 中。 下载文件。 在多个设备上同步文件。当一个文件被添加到一个设备上时，它将自动同步到其他设备。 查看文件修订情况。 与你的朋友、家人和同事分享文件 当一个文件被编辑、删除或与你分享时，发送通知。本章未讨论的功能包括。 谷歌文档的编辑和协作。Google doc 允许多个人同时编辑同一个文件。这不在我们的设计范围之内。 除了澄清需求之外，了解非功能需求也很重要。
可靠性。可靠性对于一个存储系统是极其重要的。数据丢失是不可接受的。 快速的同步速度。如果文件同步需要太多时间，用户会变得不耐烦并放弃该产品。 带宽使用。如果一个产品需要大量不必要的网络带宽，用户就会不高兴，特别是当他们使用移动数据计划时。 可扩展性。系统应该能够处理大量的流量。 高可用性。当一些服务器离线、速度减慢或出现意外的网络错误时，用户仍应能使用该系统。 粗略估计 假设该应用程序有 5000 万注册用户和 1000 万 DAU。 用户得到 10GB 的免费空间。 假设用户每天上传 2 个文件。平均文件大小为 500KB。 读写比为 1:1。 分配的总空间。5000 万 * 10 GB = 500 Petabyte 上传 API 的 QPS：1000 万 * 2 峰值 QPS = QPS * 2 = 480 提出高水平的设计并获得认同 我们不从一开始就展示高层次的设计图，而是采用一种稍微不同的方法。我们将从简单的东西开始：在一个单一的服务器中建立所有的东西。然后，逐渐扩大规模，支持数百万用户。通过做这个练习，它将刷新你对书中涉及的一些重要话题的记忆。</description></item><item><title>系统设计::设计YOUTUBE</title><link>/notes/system_design_interview_14/</link><pubDate>Sun, 14 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_14/</guid><description>设计 YOUTUBE 在本章中，你被要求设计 YouTube。这个问题的解决方案可以应用于其他面试问题，如设计一个视频共享平台，如 Netflix 和 Hulu。图 14-1 显示了 YouTube 的主页。
YouTube 看起来很简单：内容创作者上传视频，观众点击播放。它真的那么简单吗？并非如此。在简单的背后有很多复杂的技术。让我们看看 2020 年 YouTube 的一些令人印象深刻的统计数据、人口统计学和有趣的事实[1] [2]。
每月活跃用户总数：20 亿。 每天观看的视频数量。50 亿。 73%的美国成年人使用 YouTube。 YouTube 上有 5000 万创作者。 2019 年全年，YouTube 的广告收入为 151 亿美元，比 2018 年增长 36%。 YouTube 占所有移动互联网流量的 37%。 YouTube 有 80 种不同的语言。 从这些统计数据中，我们知道 YouTube 是巨大的，全球性的，并且赚了很多钱。
理解问题，确立设计范围 如图 14-1 所示，除了观看视频，你还可以在 YouTube 上做很多事情。例如，评论、分享或喜欢一个视频，将一个视频保存到播放列表中，订阅一个频道等等。在 45 或 60 分钟的采访中，不可能设计所有内容。因此，提出问题以缩小范围是很重要的。
应聘者：哪些功能是重要的？
面试官：上传视频和观看视频的能力。
应聘者：我们需要支持哪些客户？
面试官：移动应用、网络浏览器和智能电视。
应聘者：我们有多少日活跃用户？
面试官：500 万
应聘者：每天花在产品上的平均时间是多少？
面试官：30 分钟。
应聘者：我们需要支持国际用户吗？
面试官：是的，很大比例的用户是国际用户。
应聘者：支持的视频分辨率是多少？
面试官：系统可以接受大部分的视频分辨率和格式。</description></item><item><title>系统设计::设计一个搜索自动补全系统</title><link>/notes/system_design_interview_13/</link><pubDate>Sat, 13 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_13/</guid><description>设计一个搜索自动补全系统 在谷歌上搜索或在亚马逊购物时，当你在搜索框中输入时，会有一个或多个与搜索词相匹配的内容呈现给你。这一功能被称为自动补全、提前输入、边输入边搜索或增量搜索。图 13-1 是谷歌搜索的一个例子，当在搜索框中输&amp;quot;dinner&amp;quot;时，显示了一个自动补全的结果列表。搜索自动补全是许多产品的一个重要功能。这就把我们引向了面试问题：设计一个搜索自动补全系统，也&amp;quot;设计 top k&amp;quot;&amp;ldquo;设计 top k 最多人搜索的查询&amp;rdquo;。
理解问题并确定设计范围 处理任何系统设计面试问题的第一步是提出足够的问题来澄清需求。下面是一个应聘者与面试官互动的例子。
应聘者：是否只支持在搜索查询的开始阶段进行匹配，还是在中间也支持？ 面试官：只有在搜索查询的开始阶段。 应聘者：系统应该返回多少个自动补全的建议？ 面试官：5 应聘者：系统如何知道要返回哪 5 条建议？ 面试官：这是由受欢迎程度决定的，由历史查询频率决定。 应聘者：系统是否支持拼写检查？ 面试官：不，不支持拼写检查或自动更正。 应聘者：搜索查询是用英语吗？ 面试官：是的。如果最后时间允许，我们可以讨论多语言支持。 应聘者：我们是否允许大写字母和特殊字符？ 面试官：不，我们假设所有的搜索查询都是小写字母。 应聘者：有多少用户使用该产品？ 面试官：1000 万 DAU。
以下是需求的摘要。
快速响应时间。当用户输入搜索查询时，自动补全的建议必须足够快地显示出来。一篇关于 Facebook 自动补全系统的文章[1]显示，该系统需要在 100 毫秒内返回结果。否则会造成卡顿。 相关性。自动补全的建议应该与搜索词相关。 排序。系统返回的结果必须按照流行度或其他排名模式进行排序。 可扩展性。系统可以处理高流量。 高可用性。当系统的一部分脱机、速度减慢或遇到意外的网络错误时，系统应保持可用和可访问。 粗略估计 假设有 1000 万日活跃用户（DAU）。
一个人平均每天进行 10 次搜索。 每个查询字符串有 20 个字节的数据。 假设我们使用 ASCII 字符编码。1 个字符 = 1 个字节 假设一个查询包含 4 个词，每个词平均包含 5 个字符。 那就是每个查询有 4 x 5 = 20 字节。 对于在搜索框中输入的每一个字符，客户端都会向后台发送一个自动补全建议的请求。平均来说，每个搜索查询会发送 20 个请求。例如，在你输入完&amp;quot;dinner&amp;quot;时，以下 6 个请求被发送到后端。 search?</description></item><item><title>系统设计::设计一个聊天系统</title><link>/notes/system_design_interview_12/</link><pubDate>Fri, 12 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_12/</guid><description>设计一个聊天系统 在这一章中，我们探讨了一个聊天系统的设计。几乎每个人都在使用一个聊天应用程序。图 12-1 显示了市场上一些最流行的应用程序。
聊天应用程序对不同的人执行不同的功能。敲定确切的要求是极其重要的。例如，当面试官想到一对一的聊天时，您不希望设计一个专注于群组聊天的系统。探索功能要求是很重要的。
理解问题并确定设计范围 就要设计的聊天应用程序的类型达成一致是至关重要的。在市场上，有像 Facebook Messenger、微信和 WhatsApp 这样一对一的聊天应用，也有像 Slack 这样专注于群组聊天的办公聊天应用，或者像 Discord 这样专注于大型群组互动和低语音聊天延迟的游戏聊天应用。
第一组澄清问题应该明确面试官要求你设计一个聊天系统时，她心里想的到底是什么。至少要弄清楚你是应该专注于一对一的聊天还是群组聊天应用。你可以问以下一些问题。
应聘者：我们应该设计什么样的聊天应用程序？一对一还是基于群组？
面试官：它应该同时支持 1 对 1 和群组聊天。
应聘者：这是一个移动应用吗？还是网络应用？或者两者都是？
面试官：都是。
应聘者：这个应用程序的规模是多少？是创业公司的应用还是大规模的？
面试官：它应该支持 5000 万日活跃用户（DAU）。
应聘者：对于群组聊天，群组成员的限制是什么？
面试官：最多 100 人
应聘者：聊天软件的哪些功能很重要？能否支持附件？
面试官：1 对 1 聊天，群聊，在线指标。系统只支持文字信息。
应聘者：信息大小有限制吗？
面试官：是的。是的，文本长度应小于 10 万个字符。
应聘者：是否需要端对端加密？
面试官：不需要。目前不需要，但如果时间允许，我们会讨论这个问题。
应聘者：我们应将聊天记录保存多长时间？
面试官：永远。
在这一章中，我们将重点设计一个类似于 Facebook messenger 的聊天应用，并强调以下特点。
一对一的聊天，传递延迟低 小型群组聊天（最多 100 人）。 显示在线 支持多种设备。同一账户可以同时登录多个账户。 推送通知 就设计规模达成一致也很重要。我们将设计一个支持 5000 万 DAU 的系统。
提出高层次的设计并获得认同 为了开发一个高质量的设计，我们应该对客户和服务器的通信方式有一个基本的了解。在一个聊天系统中，客户端可以是移动应用程序或 Web 应用程序。客户端之间并不直接交流。相反，每个客户端都连接到一个聊天服务，它支持上面提到的所有功能。让我们专注于基本操作。聊天服务必须支持以下功能。
接收来自其他客户的消息。 为每条消息寻找合适的收件人，并将消息转发给收件人。 如果收件人不在线，在服务器上保留该收件人的消息，直到她在线。 图 12-2 显示了客户端（发送者和接收者）和聊天服务之间的关系。</description></item><item><title>系统设计::设计一个新闻源系统</title><link>/notes/system_design_interview_11/</link><pubDate>Thu, 11 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_11/</guid><description>设计一个新闻源系统 在本章中，你被要求设计一个新闻源系统。什么是新闻源？根据 Facebook 的帮助页面，&amp;ldquo;新闻源是在你的主页中间不断更新的故事列表。新闻提要包括状态更新、照片、视频、链接、应用活动，以及你在 Facebook 上关注的人、网页和团体的喜欢&amp;rdquo;[1]。这是一个流行的面试问题。经常被问到的类似问题有：设计 Facebook 的新闻提要，Instagram 的提要，Twitter 的时间线，等等。
理解问题并确定设计范围 第一组澄清问题是为了了解当面试官要求你设计一个新闻源系统时，她的想法是什么。最起码，你应该弄清楚要支持哪些功能。下面是一个应聘者与面试官互动的例子。
应聘者：这是一个移动应用程序吗？还是一个网络应用？或者两者都是？ 面试官：都是 应聘者：有哪些重要的功能？ 面试官：用户可以发布帖子，并在新闻源页面上看到她朋友的帖子。 应聘者：新闻源是按照逆时针顺序还是任何特定的顺序排序的，比如话题得分？比如说，你的亲密朋友的帖子得分更高。 面试官：为了简单起见，我们假设新闻源是按逆时针顺序排序的。 应聘者：一个用户可以有多少个朋友？ 面试官：5000 应聘者：流量是多少？ 面试官：1000 万 DAU 应聘者：新闻源可以包含图片、视频，还是只有文字？ 面试官：可以。它可以包含媒体文件，包括图片和视频。
现在你已经收集了需求，我们把重点放在设计系统上。
提出高层次的设计并获得认同 该设计分为两个流程：新闻发布和新闻源构建。
新闻发布：当一个用户发布了一个帖子，相应的数据被写入缓存和数据库。一个帖子被填充到她朋友的新闻源中。 新闻源构建：为简单起见，我们假设新闻源是通过将朋友的帖子按逆时针顺序聚合而构建的。 新闻源 API 新闻源 API 是客户端与服务器通信的主要方式。这些 API 是基于 HTTP 的，允许客户端执行操作，其中包括发布状态、检索新闻源、添加朋友等。我们讨论两个最重要的 API：Feed publishing API 和 News Feed retrieval API。
Feed publishing API 要发布一个帖子，将向服务器发送一个 HTTP POST 请求。该 API 显示如下。
POST /v1/me/feed
Params: content：内容是帖子的文本。 auth_token：它用于验证 API 请求。 新闻提要检索 API 检索新闻提要的 API 如下所示。
GET /v1/me/feed</description></item><item><title>系统设计::设计一个推送系统</title><link>/notes/system_design_interview_10/</link><pubDate>Wed, 10 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_10/</guid><description>设计一个推送系统 近年来，通知系统已经成为许多应用程序的一个非常流行的功能。通知会提醒用户一些重要的信息，如突发新闻、产品更新、事件、产品等。它已经成为我们日常生活中不可缺少的一部分。在本章中，你被要求设计一个通知系统。
一个通知不仅仅是移动推送通知。三种类型的通知格式是：移动推送通知、SMS 消息和电子邮件。图 10-1 显示了这些通知中的每一种的例子。
理解问题并确定设计范围 构建一个每天发送数百万条通知的可扩展系统并不是一件容易的事。它需要对通知生态系统有深刻的理解。面试问题被特意设计成开放式和模糊不清的，你有责任提出问题来澄清需求。
应聘者：系统支持哪些类型的通知？面试官。推送通知，短信，和电子邮件。
应聘者：这是一个实时系统吗？
面试官：让我们说这是一个软实时系统。我们希望用户能尽快收到通知。但是，如果系统处于高负荷工作状态，稍有延迟是可以接受的。
应聘者：支持的设备有哪些？
面试官：iOS 设备，安卓设备，以及笔记本/台式机。
应聘者：什么会触发通知？
面试官：通知可以由客户端应用程序触发。也可以在服务器端安排。
应聘者：用户是否可以选择退出？
面试官：是的，选择退出的用户将不会再收到通知。
应聘者：每天有多少通知被发送出去？
面试官：1000 万条移动推送通知，100 万条短信，500 万封电子邮件。
提出高层次的设计并获得认同 本节展示了支持各种通知类型的高层设计：iOS 推送通知、Android 推送通知、SMS 消息和电子邮件。它的结构如下。
不同类型的通知 联系信息收集流程 通知的发送/接收流程 不同类型的通知 我们首先看一下每种通知类型在高层次上是如何工作的。
iOS 推送通知 我们主要需要三个组件来发送一个 iOS 推送通知。
提供者。提供者构建并向苹果推送通知服务（APNS）发送通知请求。为了构建一个推送通知，提供者提供以下数据。 设备令牌。这是一个用于发送推送通知的唯一标识符。 有效载荷。这是一个 JSON 字典，包含通知的有效载荷。下面是一个例子。 APNS：这是苹果提供的一个远程服务，用于向 iOS 设备传播推送通知。 iOS 设备。它是终端客户，接收推送通知。 Android 推送通知 Android 也采用了类似的通知流程。通常不使用 APN，而是使用 Firebase Cloud Messaging（FCM）来向安卓设备发送推送通知。
SMS 消息 对于 SMS 消息，通常使用第三方 SMS 服务，如 Twilio[1]、Nexmo[2]和其他许多服务。它们中的大多数是商业服务。
电子邮件 虽然公司可以建立自己的电子邮件服务器，但许多公司选择了商业电子邮件服务。Sendgrid[3]和 Mailchimp[4]是最受欢迎的电子邮件服务之一，它们提供了更好的发送率和数据分析。
图 10-6 显示了包括所有第三方服务后的设计。</description></item><item><title>系统设计::设计网络爬虫</title><link>/notes/system_design_interview_09/</link><pubDate>Tue, 09 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_09/</guid><description>设计网页爬虫 在这一章中，我们重点讨论网络爬虫设计：一个有趣的、经典的系统设计面试问题。
网络爬虫被称为机器人或蜘蛛。它被搜索引擎广泛用于发现网络上新的或更新的内容。内容可以是一个网页、一张图片、一段视频、一个 PDF 文件，等等。网络爬虫从收集一些网页开始，然后跟踪这些网页上的链接来收集新内容。图 9-1 显示了爬虫过程的一个直观例子。
爬虫有许多用途。
搜索引擎的索引。这是最常见的使用情况。爬虫收集网页，为搜索引擎创建一个本地索引。例如，Googlebot 是 Google 搜索引擎背后的网络爬虫。 网络归档。这是一个从网络上收集信息的过程，以保存数据供将来使用。例如，许多国家图书馆运行爬虫来存档网站。著名的例子是美国国会图书馆[1]和欧盟的网络档案[2]。 网络挖掘。网络的爆炸性增长为数据挖掘提供了前所未有的机会。网络挖掘有助于从互联网上发现有用的知识。例如，顶级金融公司使用爬虫下载股东会议和年度报告，以了解公司的关键举措。 网络监控。爬虫有助于监测互联网上的版权和商标侵权行为。例如，Digimarc[3]利用爬虫来发现盗版作品和报告。 开发一个网络爬虫的复杂性取决于我们打算支持的规模。它可以是一个小型的学校项目，只需要几个小时就能完成，也可以是一个巨大的项目，需要一个专门的工程团队不断改进。因此，我们将在下面探讨要支持的规模和功能。
理解问题并确定设计范围 网络爬虫的基本算法很简单。
给定一组 URLs，下载所有由 URLs 寻址的网页。 从这些网页中提取 URLs 将新的 URL 添加到要下载的 URL 列表中。重复这 3 个步骤。 网络爬虫的工作是否真的像这种基本算法一样简单？并非如此。设计一个巨大的可扩展的网络爬虫是一项极其复杂的任务。任何人都不可能在面试时间内设计出一个大规模的网络爬虫。在进入设计之前，我们必须问一些问题来了解需求并确定设计范围。
候选人:爬虫的主要目的是什么？是用于搜索引擎索引、数据挖掘，还是其他？
面试官:搜索引擎索引。
应聘者:网络爬虫每月能收集多少个网页？
面试官:10 亿个网页。
应聘者:包括哪些内容类型？只包括 HTML，还是包括其他内容类型，如 PDF 和图片？
面试官:只包括 HTML。
应聘者:我们应该考虑新增加的或编辑过的网页吗？
面试官:是的，我们应该考虑新添加或编辑过的网页。
应聘者:我们是否需要存储从网上抓取的 HTML 网页？
面试官:需要。是的，最多 5 年。
应聘者:我们如何处理有重复内容的网页？
面试官:有重复内容的页面应该被忽略。
以上是一些你可以问面试官的样本问题。理解需求并澄清含糊不清的地方是很重要的。即使你被要求设计一个简单的产品，如网络爬虫，你和你的面试官也可能有不同的假设。
除了与面试官澄清功能外，记下一个好的网络爬虫的以下特点也很重要。
可伸缩。网络是非常大的。那里有数十亿的网页。网络爬虫应该使用并行化技术，效率极高。 健壮性。网络中充满了陷阱。坏的 HTML、无反应的服务器、崩溃、恶意链接等都很常见。爬虫器必须处理所有这些边缘情况。 礼貌性。爬虫不应该在很短的时间间隔内向一个网站发出过多的请求。 可扩展性。该系统是灵活的，因此需要最小的变化来支持新的内容类型。例如，如果我们想在将来抓取图像文件，我们应该不需要重新设计整个系统。 粗略估计 下面的估计是基于许多假设，与面试官沟通以保持一致是很重要的。
假设每个月有 10 亿个网页被下载。 QPS：1,000,000,000 / 30 天 / 24 小时 / 3600 秒 =~ 400 页/秒。 峰值 QPS = 2 * QPS = 800 假设平均网页大小为 500k。 10 亿页 x 500k = 每月 500TB 存储量。如果你对数字存储单位不清楚，可以再看一下第二章的 &amp;ldquo;2 的力量&amp;quot;部分。 假设数据存储 5 年，500TB * 12 个月 * 5 年 = 30PB。储存五年的内容需要一个 30PB 的存储。 提出高层次的设计并获得认同 一旦需求明确了，我们就开始进行高层设计。受以前关于网络抓取的研究[4][5]的启发，我们提出了一个高层设计，如图 9-2 所示。</description></item><item><title>系统设计::设计短链接</title><link>/notes/system_design_interview_08/</link><pubDate>Mon, 08 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_08/</guid><description>设计短链接 在这一章中，我们将解决一个有趣而经典的系统设计面试问题：设计一个像 tinyurl 一样的短链接务。
了解问题并确定设计范围 系统设计面试的问题是故意留有余地的。为了设计出一个精心设计的系统，关键是要问清楚问题。
应聘者：你能举个例子说明短链接的工作原理吗？
面试官：假设 URL https://www.systeminterview.com/q=chatsystem&amp;amp;c=loggedin&amp;amp;v=v3&amp;amp;l=long 是原始的 URL。你的服务创建了一个长度更短的别名： https://tinyurl.com/y7keocwj 。如果你点击这个别名，它就会把你重定向到原来的网址。
应聘者：流量是多少？
面试官：每天有 1 亿个 URL 产生。
应聘者：缩短后的 URL 有多长？
面试官。越短越好。
应聘者：缩短后的 URL 允许有哪些字符？
面试官：缩短的 URL 可以是数字（0-9）和字符（a-z，A-Z）的组合。
应聘者：缩短后的 URL 可以删除或更新吗？
面试官：为简单起见，我们假设缩短的 URL 不能被删除或更新。
以下是基本的使用情况。
URL 缩短：给定一个长的 URL =&amp;gt; 返回一个短得多的 URL URL 重定向：给定一个较短的 URL =&amp;gt; 重定向到原来的 URL 高可用性、可扩展性和容错性考虑 粗略估计 写操作。每天产生 1 亿个 URL。 每秒写操作：1 亿/24/3600=1160 读取操作。假设读操作与写操作的比例为 10:1，每秒的读操作：1160 * 10 = 11,600 假设短链接服务将运行 10 年，这意味着我们必须支持 1 亿 * 365 * 10 = 3650 亿条记录。 假设平均 URL 长度为 100。 10 年内的存储需求。3650 亿 * 100 字节 * 10 年=365TB 重要的是，你要和你的面试官一起走过这些假设和计算，以便你们两个人达成共识。</description></item><item><title>系统设计::在分布式系统中设计一个唯一ID生成器</title><link>/notes/system_design_interview_07/</link><pubDate>Sun, 07 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_07/</guid><description>在分布式系统中设计一个唯一 ID 生成器 在本章中，你被要求设计一个分布式系统中的唯一 ID 生成器。你的第一个想法可能是在传统的数据库中使用一个带有自动增加属性的主键。然而，auto_increment 在分布式环境中不起作用，因为单个数据库服务器不够大，以最小的延迟在多个数据库中生成唯一的 ID 是具有挑战性的。
这里有几个唯一 ID 的例子。
了解问题并确定设计范围 提出明确的问题是解决任何系统设计面试问题的第一步。下面是一个候选人与面试官互动的例子。
候选人：唯一 ID 的特点是什么？
面试官：ID 必须是唯一的，而且是可排序的。
候选者：对于每条新记录，ID 是否递增 1？
面试官：ID 按时间递增，但不一定只按 1 递增。在晚上创建的 ID 比同一天早上创建的 ID 要大。
候选人：ID 是否只包含数值？
面试官：是的，这是对的。
候选热：ID 的长度要求是什么？
面试官：ID 最长 64 位。
候选热：系统的规模是多少？
面试官：系统应该能够每秒生成 10,000 个 ID。
以上是一些你可以问面试官的样本问题。理解需求并澄清模糊之处非常重要。对于这个面试问题，要求列举如下。
ID 必须是唯一的。 ID 只能是数值。 IDs 最长 64 位的。 IDs 按日期排序。 有能力每秒产生超过 10,000 个唯一的 ID。 提出高层次的设计并获得认同 在分布式系统中，可以使用多种选项来生成唯一的 ID。我们考虑的选项是。
多主机复制 通用唯一标识符 UUID Ticket server Twitter Snowflake 让我们来看看他们中的每一个，他们是如何工作的，以及每个选项的优点/缺点。</description></item><item><title>系统设计::设计键值存储</title><link>/notes/system_design_interview_06/</link><pubDate>Sat, 06 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_06/</guid><description>设计键值存储 键值存储，也被称为键值数据库，是一个非关系型数据库。每一个独特的标识符都被存储为一个带有相关值的键。这种数据配对被称为 &amp;ldquo;键-值&amp;quot;对。
在一个键值对中，键必须是唯一的，与键相关的值可以通过键来访问。key 可以是纯文本或散列值。出于性能方面的考虑，短键的效果更好。键是什么样子的？这里有几个例子。
普通文本 key：&amp;ldquo;last_logged_in_at&amp;rdquo; 哈希后的 key：253DDEC4 键值对中的值可以是字符串、列表、对象，等等。在键值存储中，值通常被视为不透明的对象，如 Amazon dynamo [1], Memcached [2], Redis [3], 等等。
下面是键值存储中的一个数据片段。
在本章中，要求你设计一个支持以下操作的键值存储。
- put(key, value) // 插入与 &amp;#34;key &amp;#34;相关的 &amp;#34;value&amp;#34;。 - get(key) // 获取与 &amp;#34;key &amp;#34;相关的 &amp;#34;value&amp;#34;。 理解问题并确定设计范围 没有完美的设计。每一个设计都要实现关于读、写和内存使用的权衡的具体平衡。另一个必须做出的权衡是在一致性和可用性之间。在本章中，我们设计了一个包括以下特征的键值存储。
一个键值对的大小很小：小于 10KB。 有能力存储大数据。 高可用性。系统响应迅速，即使在故障时也能响应。 高可扩展性。系统可以被扩展以支持大型数据集。 自动扩展。服务器的增加/删除应该是基于流量的自动。 可调整的一致性。 低延迟。 单个服务器键值存储 开发一个部署在单一服务器上的键值存储很容易。一个直观的方法是将键值对存储在一个哈希表中，这样可以将所有的东西保存在内存中。尽管内存访问速度很快，但由于空间的限制，在内存中容纳所有内容可能是不可能的。为了在单个服务器中容纳更多的数据，可以做两个优化。
数据压缩 只在内存中存储经常使用的数据，其余的存储在磁盘上。 即使进行了这些优化，单个服务器也会很快达到其容量。为了支持大数据，需要一个分布式的键值存储。
分布式键值存储 分布式键值存储也被称为分布式哈希表，它将键值对分布在许多服务器上。在设计分布式系统时，理解 CAP（一致性、可用性、分区容错）定理很重要。
CAP 定理 CAP 定理指出，一个分布式系统不可能同时提供这三种保证中的两种以上：一致性、可用性和分区容错。让我们建立几个定义。
一致性：一致性意味着所有客户在同一时间看到相同的数据，无论他们连接到哪个节点。 可用性：可用性意味着任何请求数据的客户端都能得到响应，即使有些节点发生了故障。 分区容错：分区表示两个节点之间的通信中断。分区容错意味着尽管网络分区，系统仍能继续运行。 CAP 定理指出，必须牺牲三个属性中的一个来支持三个属性中的两个，如图 6-1 所示。
现在，键值存储是根据它们支持的两个 CAP 特性来分类的。
CP（一致性和分区容忍）系统：CP 键值存储支持一致性和分区容忍，同时牺牲了可用性。 AP（可用性和分区容忍）系统：AP 键值存储支持可用性和分区容忍，同时牺牲了一致性。 CA（一致性和可用性）系统：CA 键值存储支持一致性和可用性，同时牺牲了分区容忍度。 由于网络故障是不可避免的，一个分布式系统必须容忍网络分区。因此，CA 系统不能存在于现实世界的应用中。</description></item><item><title>系统设计::设计一致性哈希</title><link>/notes/system_design_interview_05/</link><pubDate>Fri, 05 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_05/</guid><description>设计一致性哈希 为了实现横向扩展，在服务器之间有效而均匀地分配请求/数据是很重要的。一致性哈希是实现这一目标的常用技术。但首先，让我们深入了解一下这个问题。
重哈希问题 如果你有 n 个缓存服务器，平衡负载的一个常用方法是使用下面的哈希方法。
serverIndex = hash(key) % N，其中 N 是服务器池的大小。
让我们用一个例子来说明它是如何工作的。如表 5-1 所示，我们有 4 个服务器和 8 个字符串 key 及其哈希值。
key hash hash %4 key0 18358617 1 key1 26143584 0 key2 18131146 2 key3 35863496 0 key4 34085809 1 key5 27581703 3 key6 38164978 2 key8 22530351 3 Table 5-1
为了获取存储 key 的服务器，我们执行模块化操作 f(key) % 4。例如，hash(key0) % 4 = 1 意味着客户端必须联系服务器 1 来获取缓存的数据。图 5-1 显示了基于表 5-1 的 key 的分布。</description></item><item><title>系统设计::设计一个限流器</title><link>/notes/system_design_interview_04/</link><pubDate>Thu, 04 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_04/</guid><description>设计一个限流器 在网络系统中，限流器被用来控制客户端或服务所发送的流量速率。在 HTTP 世界中，限流器限制了允许在指定时间内发送的客户端请求的数量。如果 API 请求数超过了限流器定义的阈值，所有多余的调用都会被阻止。这里有几个例子。
一个用户每秒钟可以写不超过 2 个帖子。 你每天最多可以从同一个 IP 地址创建 10 个账户。 你每周从同一设备上领取奖励的次数不能超过 5 次。 在本章中，要求你设计一个限流器。在开始设计之前，我们首先看一下使用 API 限流器的好处。
防止由拒绝服务（DoS）攻击引起的资源饥饿。几乎所有大型科技公司发布的 API 都执行了某种形式的限流。例如，Twitter 将每 3 小时的推文数量限制为 300 条。Google docs APIs 有如下默认限制：每个用户每 60 秒读取请求 300 次。限流器通过阻止多余的调用来防止 DoS 攻击，无论是有意的还是无意的。 降低成本。限制多余的请求意味着更少的服务器和分配更多的资源分配给高优先级的 API。限流对于使用付费的第三方 API 的公司极为重要。例如，你对以下外部 API 的调用是按次数收费的：检查信用、付款、检索健康记录等。限制调用次数是降低成本的关键。 防止服务器过载。为了减少服务器的负荷，使用限流器来过滤掉由机器人或用户的不当行为造成的过多请求。 理解问题并确定设计范围 限流可以通过不同的算法来实现，每一种算法都有其优点和缺点。面试官和候选人之间的互动有助于澄清我们要建立的限流器的类型。
候选人：我们要设计什么样的限流器？是客户端的限流器还是服务器端的 API 限流器？
面试官：好问题。我们的重点是服务器端的 API 限流器。
候选人：限流器是根据 IP、用户 ID 还是其他属性来节制 API 请求？
面试官：限流器应该足够灵活，以支持不同的节流规则。
应聘者：系统的规模是多少？它是为初创公司还是拥有庞大用户群的大公司建立的？
面试官：系统必须能够处理大量的请求。
应聘者：系统能否在分布式环境中工作？
面试官：是的。
应聘者：限流器是一个单独的服务还是应该在应用程序代码中实现？
面试官：是的。这是一个由你决定的设计。
应聘者：我们是否需要通知那些被限制的用户？
面试官：是的。
需求:
以下是对该系统要求的总结。 准确地限制过多的请求。 低延时。限流器不应该减慢 HTTP 响应时间。 尽可能少地使用内存。 分布式限流。限流器可以在多个服务器或进程中共享。 异常处理。当用户的请求被节制时，向用户显示明确的异常。 高容错性。如果限流器有任何问题（例如，一个缓存服务器离线），它不会影响整个系统。 提出高层次的设计并获得认同 让我们保持简单，使用基本的客户和服务器模式进行通信。</description></item><item><title>系统设计::系统设计面试框架</title><link>/notes/system_design_interview_03/</link><pubDate>Wed, 03 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_03/</guid><description>系统设计面试框架 你刚刚在你梦想中的公司获得了令人羡慕的现场面试机会。招聘协调员给你发了一份当天的时间表。扫视清单，你感觉很好，直到你的目光落在这个面试环节&amp;ndash;系统设计面试。
系统设计面试往往令人生畏。它可能像 &amp;ldquo;设计一个众所周知的产品 X？&amp;ldquo;一样模糊。问题模棱两可，看起来不合理地宽泛。你的疲惫是可以理解的。毕竟，怎么可能有人在一个小时内设计出一个流行的产品，而这个产品是花了几百个甚至几千个工程师才建成的？
好消息是，没有人期望你能做到。现实世界的系统设计是极其复杂的。例如，谷歌搜索具有欺骗性的简单性；然而，支撑这种简单性的技术数量确实令人吃惊。如果没有人期望你在一小时内设计出一个真实世界的系统，那么系统设计面试的好处是什么？
系统设计面试模拟了现实生活中的问题解决，两个同事合作解决一个模糊的问题，并提出一个符合他们目标的解决方案。这个问题是开放式的，没有完美的答案。与你在设计过程中付出的努力相比，最终的设计并不那么重要。这使你能够展示你的设计技能，为你的设计选择辩护，并以建设性的方式回应反馈。
让我们切换角度，考虑一下当面试官走进会议室与你见面时，她的脑子里在想什么。面试官的首要目标是准确评估你的能力。她最不希望的是，因为会议进行得不顺利，没有足够的信号，而给出一个没有结论的评价。面试官在系统设计面试中寻找的是什么？
许多人认为，系统设计面试是关于一个人的技术设计能力。它远不止于此。一个有效的系统设计面试给人以强烈的信号，表明一个人的合作能力，在压力下工作的能力，以及建设性地解决模糊性的能力。提出好问题的能力也是一项重要的技能，许多面试官专门寻找这种技能。
一个好的面试官也会寻找错误。过度工程化是许多工程师的一个真正的病症，因为他们喜欢设计的纯粹性，而忽视了权衡。他们往往没有意识到过度工程系统的复合成本，而许多公司为这种无知付出了高昂的代价。你当然不希望在系统设计面试中表现出这种倾向。其他的错误包括狭隘的心态、固执等等。
在这一章中，我们将讲述一些有用的技巧，并介绍一个简单而有效的框架来解决系统设计面试问题。
有效的系统设计面试的 4 个流程 每个系统设计面试都是不同的。一个好的系统设计面试是开放式的，没有一个放之四海而皆准的解决方案。然而，在每个系统设计面试中都有一些步骤和共同点。
理解问题并确定设计范围 &amp;ldquo;老虎为什么咆哮？&amp;rdquo;
班级后面有一只手举了起来。
&amp;ldquo;是的，吉米？&amp;quot;，老师回答。
&amp;ldquo;因为他很饿&amp;rdquo;。
&amp;ldquo;非常好，吉米&amp;rdquo;。
在整个童年时期，吉米一直是班上第一个回答问题的人。每当老师提出问题时，教室里总有一个孩子喜欢在问题上一试身手，不管他是否知道答案。这就是吉米。
吉米是一个王牌学生。他以能快速知道所有答案为荣。在考试中，他通常是第一个完成问题的人。在任何学术竞赛中，他都是老师的首选。
不要像吉米那样。
在系统设计面试中，不加思索地迅速给出答案不会给你加分。在没有彻底理解需求的情况下回答问题是一个巨大的错误，因为面试不是一个小游戏比赛。没有正确的答案。
所以，不要直接跳进去给出一个解决方案。慢下来。深入思考并提出问题以澄清需求和假设。这一点极为重要。
作为一个工程师，我们喜欢解决困难的问题并跳入最终的设计；然而，这种方法很可能导致你设计出错误的系统。作为一个工程师，最重要的技能之一是提出正确的问题，做出适当的假设，并收集建立一个系统所需的所有信息。因此，不要害怕提出问题。
当你提出问题时，面试官要么直接回答你的问题，要么要求你做出假设。如果是后者，请在白板或纸上写下你的假设。你以后可能会用到它们。
要问什么样的问题？提出问题以了解确切的要求。这里有一个问题清单，可以帮助你开始工作。 我们要建立什么具体的功能？ 该产品有多少用户？ 公司预计扩大规模的速度如何？3 个月、6 个月和 1 年后的预期规模是什么？ 该公司的技术栈是什么？你可以利用哪些现有的服务来简化设计？ 例子:
如果你被要求设计一个新闻源系统，你要问一些问题，帮助你澄清需求。你和面试官之间的对话可能是这样的。
候选人：这是一个移动应用程序吗？还是一个网络应用？或者两者都是？
面试官。都是。
应聘者：产品最重要的功能是什么？面试官。能够发帖并看到朋友的新闻提要。
应聘者：新闻源是按时间倒序还是按特定顺序排序的？特定顺序意味着每个帖子都有不同的权重。例如，来自你的亲密朋友的帖子比来自一个小组的帖子更重要。
采访者。为了简单起见，让我们假设 feed 是按逆时针顺序排序的。
候选人：一个用户可以有多少个朋友？面试官。5000
考生：流量是多少？面试官。1000 万日活跃用户（DAU）。
应聘者：饲料可以包含图片、视频，还是只有文字？
面试官：可以。它可以包含媒体文件，包括图片和视频。
以上是你可以问面试官的一些样本问题。理解要求并澄清含糊之处非常重要。
提出高层次的设计并获得认同 在这个步骤中，我们的目标是制定一个高层次的设计，并与面试官就设计达成一致。在这个过程中，与面试官合作是个好主意。
想出一个初步的设计蓝图。征求反馈意见。把你的面试官当作队友，一起工作。许多优秀的面试官喜欢交谈和参与。 在白板或纸上画出带有关键部件的方框图。这可能包括客户端（移动/网络）、API、网络服务器、数据存储、缓存、CDN、消息队列，等等。 做事后计算，评估你的蓝图是否符合规模限制。努力思考。在深入研究之前，如果有必要进行逆向计算，请与你的面试官沟通。 如果可能的话，通过一些具体的使用案例。这将帮助你确定高级设计的框架。也有可能这些用例会帮助你发现你还没有考虑过的边缘案例。
我们应该在这里包括 API 端点和数据库模式吗？这取决于问题的情况。对于像 &amp;ldquo;设计谷歌搜索引擎 &amp;ldquo;这样的大型设计问题，这有点太低级了。对于像为多人扑克游戏设计后端这样的问题，这是一个公平的游戏。与你的面试官沟通。
例子:
让我们用 &amp;ldquo;设计一个新闻源系统 &amp;ldquo;来演示如何进行高层设计。这里不要求你了解系统的实际工作情况。所有的细节将在第 11 章解释。
在高层次上，设计分为两个流程：Feed 发布和新闻源构建。 帖子发布：当用户发布帖子时，相应的数据被写入缓存/数据库，该帖子将被填充到朋友的新闻提要中。 新闻源构建：新闻源是通过将朋友的帖子按照逆时针顺序聚合起来而构建的。 图 3-1 和图 3-2 分别展示了新闻发布和新闻源构建流程的高级设计。</description></item><item><title>系统设计::粗略评估</title><link>/notes/system_design_interview_02/</link><pubDate>Tue, 02 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_02/</guid><description>粗略评估 在系统设计面试中，有时你会被要求用粗略评估系统容量或性能要求。根据 Google 高级研究员 Jeff Dean 的说法，&amp;ldquo;粗略计算是你使用思想实验和常见的性能数字的组合来创建的估计，以很好地感觉到哪些设计可以满足你的要求&amp;rdquo;
你需要对可扩展性的基础知识有一个很好的感觉，以便有效地进行粗略计算。你需要好地理解以下概念：二的幂，每个程序员都应该知道的延迟数字，以及可用性数字。
2 的幂 尽管在处理分布式系统时，数据量可能变得巨大，但计算都可以归结为基础知识。为了获得正确的计算结果，关键是要知道使用 2 的幂的数据量单位。一个字节是一个 8 位的序列。一个 ASCII 字符使用一个字节的内存（8 比特）。下面是一个解释数据量单位的表格
Power Approximate value Full name Short name 10 1 Thousand 1 Kilobyte 1 KB 20 1 Million 1 Megabyte 1 MB 30 1 Billion 1 Gigabyte 1 GB 40 1 Trillion 1 Terabyte 1 TB 50 1 Quadrillion 1 Petabyte 1 PB 每个程序都应该知道的延迟数字 来自谷歌的 Dr.Dean 展示了 2010 年典型计算机操作的时间长度。随着计算机变得更快、更强大，有些数字已经过时了。然而，这些数字应该仍然能够让我们了解不同计算机操作的快慢。
Operation name Time L1 cache reference 0.</description></item><item><title>系统设计::从零到一百万</title><link>/notes/system_design_interview_01/</link><pubDate>Mon, 01 Feb 2021 22:20:24 +0800</pubDate><guid>/notes/system_design_interview_01/</guid><description>从零到一百万 设计一个支持数百万用户的系统是一个挑战，这是一个需要不断完善和无止境改进的历程。在本章中，我们将构建一个支持单个用户的系统，并逐步将其扩展到服务数百万用户。读完本章，你将掌握一手的技巧，帮助你破解系统设计的面试题。
单服务器设置
千里之行始于足下，构建一个复杂的系统也不例外。先从简单的东西开始，所有的东西都运行在一台服务器上。图 1-1 是单服务器设置的说明，所有的东西都在一台服务器上运行：Web 应用、数据库、缓存等。
为了理解这种设置，研究一下请求流程和流量来源是很有帮助的。我们先来看看请求流程（图 1-2）。
用户通过域名访问网站，如 api.mysite.com。通常，域名系统（DNS）是由第三方提供的付费服务，而不是由我们的服务器托管。 互联网协议（IP）地址返回给浏览器或移动应用。在本例中，返回的 IP 地址为 15.125.23.214。 获得 IP 地址后，超文本传输协议（HTTP）[1]请求直接发送到您的网络服务器。 Web 服务器返回 HTML 页面或 JSON 响应进行渲染。 接下来，我们来看看流量来源。你的 Web 服务器的流量来自两个方面：Web 应用和移动应用。
Web 应用：它使用服务器端语言（Java、Python 等）组合来处理业务逻辑、存储等，使用客户端语言（HTML 和 JavaScript）来进行展示。 移动应用。HTTP 协议是移动应用与 Web 服务器之间的通信协议。JavaScript 对象符号（JSON）由于其简单性，是常用的 API 响应格式来传输数据。JSON 格式的 API 响应示例如下所示。 { &amp;#34;firstName&amp;#34;: &amp;#34;John&amp;#34;, &amp;#34;lastName&amp;#34;: &amp;#34;Smith&amp;#34;, &amp;#34;address&amp;#34;: { &amp;#34;streetAddress&amp;#34;: &amp;#34;21 2nd street&amp;#34;, &amp;#34;city&amp;#34;: &amp;#34;New York&amp;#34;, &amp;#34;state&amp;#34;: &amp;#34;NY&amp;#34;, &amp;#34;postal Code&amp;#34;: 10021 }, &amp;#34;phoneNumbers&amp;#34;: [&amp;#34;212 555-1234&amp;#34;, &amp;#34;646 555-4567&amp;#34;] } GET /users/12 – Retrieve user object for id = 12</description></item></channel></rss>