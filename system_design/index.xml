<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>System_designs | Y.CH.Y</title><link>/system_design/</link><atom:link href="/system_design/index.xml" rel="self" type="application/rss+xml"/><description>System_designs</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Y.CH.Y</copyright><lastBuildDate>Mon, 15 Feb 2021 22:20:24 +0800</lastBuildDate><item><title>系统设计::设计谷歌硬盘</title><link>/system_design/system_design_interview_15/</link><pubDate>Mon, 15 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_15/</guid><description>&lt;h2 id="设计谷歌硬盘">设计谷歌硬盘&lt;/h2>
&lt;p>近年来，Google Drive、Dropbox、微软 OneDrive 和苹果 iCloud 等云存储服务已经变得非常流行。在本章中，你被要求设计 Google Drive。&lt;/p>
&lt;p>在进入设计之前，让我们花点时间来了解一下 Google Drive。Google Drive 是一个文件存储和同步服务，帮助你在云端存储文档、照片、视频和其他文件。你可以从任何电脑、智能手机和平板电脑访问你的文件。你可以轻松地与朋友、家人和同事分享这些文件[1]。图 15-1 和 15-2 分别显示了谷歌硬盘在浏览器和移动应用程序上的样子。&lt;/p>
&lt;img src="../../../system_design_interview/index-244_1.jpg" width="66%"/>
&lt;img src="../../../system_design_interview/index-245_1.jpg" width="33%"/>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>设计谷歌硬盘是一个大项目，因此，提出问题以缩小范围是很重要的。&lt;/p>
&lt;p>应聘者：最重要的功能是什么？&lt;br>
面试官：上传和下载文件，文件同步，以及通知。&lt;br>
应聘者：这是一个移动应用，一个网络应用，还是两者都有？&lt;br>
面试官：都是。&lt;br>
应聘者：支持的文件格式有哪些？&lt;br>
面试官：任何文件类型。&lt;br>
应聘者：文件是否需要加密？&lt;br>
面试官：是的。是的，存储中的文件必须是加密的。&lt;br>
应聘者：文件大小有限制吗？&lt;br>
面试官：有，文件必须是 10GB 或更小。&lt;br>
应聘者：该产品有多少用户？&lt;br>
面试官：10M DAU。&lt;/p>
&lt;p>在本章中，我们将重点介绍以下功能。&lt;/p>
&lt;ul>
&lt;li>添加文件。添加文件的最简单方法是将文件拖放到 Google Drive 中。&lt;/li>
&lt;li>下载文件。&lt;/li>
&lt;li>在多个设备上同步文件。当一个文件被添加到一个设备上时，它将自动同步到其他设备。&lt;/li>
&lt;li>查看文件修订情况。&lt;/li>
&lt;li>与你的朋友、家人和同事分享文件&lt;/li>
&lt;li>当一个文件被编辑、删除或与你分享时，发送通知。本章未讨论的功能包括。&lt;/li>
&lt;li>谷歌文档的编辑和协作。Google doc 允许多个人同时编辑同一个文件。这不在我们的设计范围之内。&lt;/li>
&lt;/ul>
&lt;p>除了澄清需求之外，了解非功能需求也很重要。&lt;/p>
&lt;ul>
&lt;li>可靠性。可靠性对于一个存储系统是极其重要的。数据丢失是不可接受的。&lt;/li>
&lt;li>快速的同步速度。如果文件同步需要太多时间，用户会变得不耐烦并放弃该产品。&lt;/li>
&lt;li>带宽使用。如果一个产品需要大量不必要的网络带宽，用户就会不高兴，特别是当他们使用移动数据计划时。&lt;/li>
&lt;li>可扩展性。系统应该能够处理大量的流量。&lt;/li>
&lt;li>高可用性。当一些服务器离线、速度减慢或出现意外的网络错误时，用户仍应能使用该系统。&lt;/li>
&lt;/ul>
&lt;h3 id="粗略估计">粗略估计&lt;/h3>
&lt;ul>
&lt;li>假设该应用程序有 5000 万注册用户和 1000 万 DAU。&lt;/li>
&lt;li>用户得到 10GB 的免费空间。&lt;/li>
&lt;li>假设用户每天上传 2 个文件。平均文件大小为 500KB。&lt;/li>
&lt;li>读写比为 1:1。&lt;/li>
&lt;li>分配的总空间。5000 万 * 10 GB = 500 Petabyte&lt;/li>
&lt;li>上传 API 的 QPS：1000 万 * 2&lt;/li>
&lt;li>峰值 QPS = QPS * 2 = 480&lt;/li>
&lt;/ul>
&lt;h3 id="提出高水平的设计并获得认同">提出高水平的设计并获得认同&lt;/h3>
&lt;p>我们不从一开始就展示高层次的设计图，而是采用一种稍微不同的方法。我们将从简单的东西开始：在一个单一的服务器中建立所有的东西。然后，逐渐扩大规模，支持数百万用户。通过做这个练习，它将刷新你对书中涉及的一些重要话题的记忆。&lt;/p>
&lt;p>让我们从下面列出的单一服务器设置开始。&lt;/p>
&lt;ul>
&lt;li>一个网络服务器，用于上传和下载文件。&lt;/li>
&lt;li>一个数据库，用于跟踪元数据，如用户数据、登录信息、文件信息等。&lt;/li>
&lt;li>一个存储系统来存储文件。我们分配了 1TB 的存储空间来存储文件。&lt;/li>
&lt;/ul>
&lt;p>我们花了几个小时建立一个 Apache 网络服务器，一个 MySql 数据库，以及一个名为 drive/的目录作为根目录来存储上传的文件。在 drive/目录下，有一个目录列表，被称为命名空间。每个命名空间包含该用户的所有上传文件。服务器上的文件名与原始文件名保持一致。每个文件或文件夹都可以通过加入命名空间和相对路径来唯一地识别。&lt;/p>
&lt;p>图 15-3 显示了/drive 目录在左边的样子和它在右边的扩展视图的一个例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-248_1.jpg" width="66%"/>
&lt;p>APIs&lt;/p>
&lt;p>API 是什么样子的？我们主要需要 3 个 API：上传文件、下载文件和获得文件修订。&lt;/p>
&lt;ol>
&lt;li>上传一个文件到 Google Drive 支持两种类型的上传。&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>简单上传。当文件大小较小时，使用这种上传类型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>可恢复上传。当文件大小较多，而且网络中断的可能性很大时，使用这种上传类型。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>下面是一个可恢复上传 API 的例子： &lt;a href="https://api.example.com/files/upload?uploadType=resumable">https://api.example.com/files/upload?uploadType=resumable&lt;/a>&lt;/p>
&lt;p>参数。&lt;/p>
&lt;ul>
&lt;li>uploadType=resumable&lt;/li>
&lt;li>数据。要上传的本地文件。&lt;/li>
&lt;/ul>
&lt;p>一个可恢复的上传是通过以下 3 个步骤实现的[2]。&lt;/p>
&lt;ul>
&lt;li>发送初始请求以检索可恢复的 URL。&lt;/li>
&lt;li>上传数据并监控上传状态。&lt;/li>
&lt;li>如果上传受到干扰，恢复上传。&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>从 Google Drive 下载一个文件&lt;/li>
&lt;/ol>
&lt;p>示例 API：https://api.example.com/files/download Params:&lt;/p>
&lt;ul>
&lt;li>path: 下载文件的路径。&lt;/li>
&lt;/ul>
&lt;p>例子参数。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;/recipes/soup/best_soup.txt&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>获取文件修订版&lt;/li>
&lt;/ol>
&lt;p>示例 API：https://api.example.com/files/list_revisions&lt;/p>
&lt;ul>
&lt;li>Params:
&lt;ul>
&lt;li>path。你想获得修订历史的文件的路径。&lt;/li>
&lt;li>limit：要返回的最大修订数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>例子参数。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;/recipes/soup/best_soup.txt&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;limit&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">20&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>所有的 API 都需要用户认证并使用 HTTPS。安全套接字层（SSL）保护客户端和后端服务器之间的数据传输。&lt;/p>
&lt;p>脱离单一服务器&lt;/p>
&lt;p>随着更多的文件被上传，最终你会得到空间满了的提示，如图 15-4 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-249_1.jpg" width="44%"/>
&lt;p>只剩下 10MB 的存储空间了! 这是一个紧急情况，因为用户无法再上传文件。我想到的第一个解决方案是将数据分片，因此它被存储在多个存储服务器上。图 15-5 显示了一个基于 user_id 的分片的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-250_1.jpg" width="55%"/>
&lt;p>你通宵达旦地设置了数据库分片，并密切监控。一切又顺利地运行了。你已经阻止了火灾的发生，但你仍然担心在存储服务器中断的情况下可能出现的数据损失。你四处打听，你的后台大师朋友弗兰克告诉你，许多领先的公司如 Netflix 和 Airbnb 都使用 Amazon S3 进行存储。&amp;ldquo;亚马逊简单存储服务（Amazon S3）是一种对象存储服务，提供行业领先的可扩展性、数据可用性、安全性和性能&amp;rdquo; [3]。你决定做一些研究，看看它是否合适。&lt;/p>
&lt;p>经过大量的阅读，你对 S3 存储系统有了很好的了解，决定将文件存储在 S3 中。Amazon S3 支持同区域和跨区域的复制。一个区域是指亚马逊网络服务（AWS）拥有数据中心的地理区域。如图 15-6 所示，数据可以在同区域（左侧）和跨区域（右侧）进行复制。冗余文件存储在多个区域，以防范数据丢失并确保可用性。一个桶就像文件系统中的一个文件夹。&lt;/p>
&lt;img src="../../../system_design_interview/index-250_2.jpg" width="77%"/>
&lt;p>把文件放到 S3 后，你终于可以睡个好觉了，不用担心数据丢失。为了阻止类似的问题在未来发生，你决定对可以改进的地方做进一步研究。以下是你发现的几个方面。&lt;/p>
&lt;ul>
&lt;li>负载平衡器。添加一个负载平衡器来分配网络流量。负载平衡器确保流量的均匀分布，如果一个网络服务器发生故障，它将重新分配流量。&lt;/li>
&lt;li>网络服务器。在添加了负载平衡器后，可以根据流量负载，轻松添加/删除更多的网络服务器。&lt;/li>
&lt;li>元数据数据库。将数据库移出服务器以避免单点故障。同时，设置数据复制和分片，以满足可用性和可扩展性要求。&lt;/li>
&lt;li>文件存储。Amazon S3 用于文件存储。为了确保可用性和耐久性，文件被复制在两个独立的地理区域。&lt;/li>
&lt;/ul>
&lt;p>在应用了上述改进后，你已经成功地将 Web 服务器、元数据数据库和文件存储从一台服务器上解耦。更新后的设计如图 15-7 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-251_1.jpg" width="55%"/>
&lt;p>同步冲突&lt;/p>
&lt;p>对于像 Google Drive 这样的大型存储系统，同步冲突时有发生。当两个用户同时修改同一个文件或文件夹时，就会发生冲突。我们如何解决这个冲突呢？这里是我们的策略：第一个被处理的版本获胜，而后来被处理的版本则收到冲突。图 15-8 显示了一个同步冲突的例子。
&lt;img src="../../../system_design_interview/index-252_1.jpg" width="77%"/>&lt;/p>
&lt;p>在图 15-8 中，用户 1 和用户 2 试图同时更新同一个文件，但用户 1 的文件被我们的系统首先处理。用户 1 的更新操作通过了，但是，用户 2 得到一个同步冲突。我们怎样才能解决用户 2 的冲突呢？我们的系统展示了同一个文件的两个副本：用户 2 的本地副本和服务器上的最新版本（图 15-9）。用户 2 可以选择合并这两个文件，或者用另一个版本覆盖一个版本。&lt;/p>
&lt;img src="../../../system_design_interview/index-252_2.jpg" width="66%"/>
&lt;p>当多个用户同时编辑同一个文件时，要保持文件的同步性是很有挑战性的。有兴趣的读者请参考参考资料[4] [5]。&lt;/p>
&lt;p>高层设计&lt;/p>
&lt;p>图 15-10 说明了拟议的高层设计。让我们来看看系统的每个组成部分。&lt;/p>
&lt;img src="../../../system_design_interview/index-253_1.jpg" width="77%"/>
&lt;ul>
&lt;li>用户。用户通过浏览器或移动应用程序使用该应用程序。&lt;/li>
&lt;li>块服务器。块服务器将区块上传到云存储。块存储，被称为块级存储，是一种在基于云的环境中存储数据文件的技术。一个文件可以分成几个块，每个块都有一个独特的哈希值，存储在我们的元数据数据库中。每个区块被视为一个独立的对象，并存储在我们的存储系统（S3）中。为了重建一个文件，块以特定的顺序被连接。至于块的大小，我们使用 Dropbox 作为参考：它将块的最大大小设置为 4MB[6]。&lt;/li>
&lt;li>云存储。一个文件被分割成更小的块并存储在云存储中。&lt;/li>
&lt;li>冷存储。冷存储是为存储非活动数据而设计的计算机系统，这意味着文件在很长一段时间内不会被访问。&lt;/li>
&lt;li>负载平衡器。负载平衡器在 API 服务器之间均匀地分配请求。&lt;/li>
&lt;li>API 服务器。这些服务器几乎负责除上传流程以外的所有工作。API 服务器用于用户认证、管理用户资料、更新文件元数据等。&lt;/li>
&lt;li>元数据数据库。它存储用户、文件、块、版本等的元数据。请注意，文件被存储在云端，元数据数据库只包含元数据。&lt;/li>
&lt;li>元数据缓存。一些元数据被缓存起来，以便快速检索。&lt;/li>
&lt;li>通知服务。它是一个发布者/订阅者系统，允许数据在某些事件发生时从通知服务传输到客户端。在我们的具体案例中，当一个文件在其他地方被添加/编辑/删除时，通知服务会通知相关客户，这样他们就可以拉到最新的变化。&lt;/li>
&lt;li>离线备份队列。如果客户处于离线状态，无法提取最新的文件变化，离线备份队列会存储信息，这样当客户在线时，变化会被同步。&lt;/li>
&lt;/ul>
&lt;p>我们已经在高层讨论了 Google Drive 的设计。有些组件很复杂，值得仔细研究；我们将在深入研究中详细讨论这些组件。&lt;/p>
&lt;h3 id="设计深究">设计深究&lt;/h3>
&lt;p>在本节中，我们将仔细研究以下内容：块服务器、元数据数据库、上传流程、下载流程、通知服务、保存存储空间和故障处理。&lt;/p>
&lt;p>块服务器&lt;/p>
&lt;p>对于定期更新的大文件，每次更新时发送整个文件会消耗大量的带宽。提出了两个优化方案，以尽量减少传输的网络流量。&lt;/p>
&lt;ul>
&lt;li>Delta 同步。当一个文件被修改时，只有被修改的块被同步，而不是使用同步算法的整个文件 [7] [8]。&lt;/li>
&lt;li>压缩。对块进行压缩可以大大减少数据大小。因此，根据文件类型，使用压缩算法对块进行压缩。例如，gzip 和 bzip2 被用来压缩文本文件。压缩图像和视频则需要不同的压缩算法。&lt;/li>
&lt;/ul>
&lt;p>在我们的系统中，块服务器为上传文件做繁重的工作。块服务器通过将文件分割成区块，压缩每个区块，并对其进行加密，来处理从客户端传来的文件。与其将整个文件上传到存储系统，不如只传输经过修改的块。&lt;/p>
&lt;p>图 15-11 显示了当一个新文件被添加时，块服务器是如何工作的。
&lt;img src="../../../system_design_interview/index-255_1.jpg" width="77%"/>&lt;/p>
&lt;ul>
&lt;li>一个文件被分割成更小的块。&lt;/li>
&lt;li>每个区块都使用压缩算法进行压缩。&lt;/li>
&lt;li>为了确保安全，每个区块在被发送到云存储之前都要进行加密。&lt;/li>
&lt;li>块被上传到云存储。&lt;/li>
&lt;/ul>
&lt;p>图 15-12 说明了 delta 同步，意味着只有修改过的块被传输到云存储。突出显示的区块 &amp;ldquo;block 2 &amp;ldquo;和 &amp;ldquo;block 5 &amp;ldquo;代表改变的区块。使用 delta 同步，只有这两个块被上传到云存储中。&lt;/p>
&lt;img src="../../../system_design_interview/index-256_1.jpg" width="55%"/>
&lt;p>块服务器使我们能够通过提供 delta 同步和压缩来节省网络流量。&lt;/p>
&lt;p>高一致性要求&lt;/p>
&lt;p>我们的系统默认要求强一致性。一个文件在同一时间被不同的客户端显示出不同的内容，这是不可接受的。系统需要为元数据缓存和数据库层提供强一致性。&lt;/p>
&lt;p>内存缓存默认采用最终一致性模型，这意味着不同的副本可能有不同的数据。为了实现强一致性，我们必须确保以下几点。&lt;/p>
&lt;ul>
&lt;li>缓存复制中的数据和主站是一致的。&lt;/li>
&lt;li>在数据库写入时使缓存无效，以确保缓存和数据库持有相同的值。在关系型数据库中实现强一致性很容易，因为它保持了 ACID（原子性、一致性、隔离性、持久性）属性[9]。然而，NoSQL 数据库默认不支持 ACID 属性。ACID 属性必须以编程方式纳入同步逻辑中。在我们的设计中，我们选择了关系型数据库，因为 ACID 是原生支持的。&lt;/li>
&lt;/ul>
&lt;p>元数据数据库&lt;/p>
&lt;p>图 15-13 显示了数据库模式的设计。请注意这是一个高度简化的版本，因为它只包括最重要的表和有趣的字段。&lt;/p>
&lt;img src="../../../system_design_interview/index-257_1.jpg" width="77%"/>
&lt;ul>
&lt;li>用户：用户表包含用户的基本信息，如用户名、电子邮件、个人照片等。&lt;/li>
&lt;li>设备。设备表存储设备信息。Push_id 用于发送和接收移动推送通知。请注意一个用户可以有多个设备。&lt;/li>
&lt;li>命名空间。命名空间是一个用户的根目录。&lt;/li>
&lt;li>文件：文件表存储所有与最新文件有关的信息。&lt;/li>
&lt;li>File_version。它存储了一个文件的版本历史。现有的行是只读的，以保持文件修订历史的完整性。&lt;/li>
&lt;li>块：区块表存储所有与文件区块相关的内容。它存储与一个文件块有关的一切。任何版本的文件都可以通过以正确的顺序连接所有的块来重新构建。&lt;/li>
&lt;/ul>
&lt;p>上传流程&lt;/p>
&lt;p>让我们讨论一下客户上传文件时发生了什么。为了更好地理解这个流程，我们画出如图 15-14 所示的顺序图。&lt;/p>
&lt;img src="../../../system_design_interview/index-258_1.jpg" width="77%"/>
&lt;p>在图 15-14 中，两个请求被平行发送：添加文件元数据和上传文件到云存储。这两个请求都来自客户端 1。&lt;/p>
&lt;ul>
&lt;li>添加文件元数据。&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>客户端 1 发送一个请求，添加新文件的元数据。&lt;/li>
&lt;li>将新文件元数据存储在元数据数据库中，并将文件上传状态改为 &amp;ldquo;待定&amp;rdquo;。&lt;/li>
&lt;li>通知通知服务，正在添加一个新文件。&lt;/li>
&lt;li>通知服务通知相关的客户端（客户端 2）有文件正在被上传。&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>上传文件到云存储。&lt;/li>
&lt;/ul>
&lt;p>2.1 客户端 1 将文件内容上传到块服务器。&lt;br>
2.2 块服务器将文件分块，对区块进行压缩、加密，并将其上传到云存储。&lt;br>
2.3 一旦文件被上传，云存储会触发上传完成回调。该请求被发送到 API 服务器。&lt;br>
2.4 在 Metadata DB 中，文件状态变为 &amp;ldquo;已上传&amp;rdquo;。&lt;br>
2.5 通知通知服务，文件状态变为 &amp;ldquo;上传&amp;rdquo;。&lt;br>
2.6 通知服务通知相关客户（客户 2），一个文件已完全上传。&lt;/p>
&lt;p>当一个文件被编辑时，流程是类似的，所以我们将不重复它。&lt;/p>
&lt;p>下载流程&lt;/p>
&lt;p>当一个文件在其他地方被添加或编辑时，下载流程被触发。客户端如何知道一个文件是由另一个客户端添加或编辑的？有两种方法可以让客户端知道。&lt;/p>
&lt;ul>
&lt;li>如果客户端 A 在线，而文件被另一个客户端更改，通知服务会通知客户端 A，某处发生了变化，所以它需要调取最新的数据。- 如果客户端 A 处于离线状态，而另一个客户端更改了文件，数据将被保存到缓存中。当脱机的客户端再次上线时，它就会拉出最新的变化。&lt;/li>
&lt;/ul>
&lt;p>一旦客户端知道一个文件被改变，它首先通过 API 服务器请求元数据，然后下载块来构建文件。图 15-15 显示了详细的流程。注意，由于空间的限制，图中只显示了最重要的部分。&lt;/p>
&lt;img src="../../../system_design_interview/index-259_1.jpg" width="77%"/>
&lt;ol>
&lt;li>通知服务通知客户端 2，一个文件在其他地方被改变。&lt;/li>
&lt;li>一旦客户端 2 知道有新的更新，它就会发送一个请求来获取元数据。&lt;/li>
&lt;li>API 服务器调用元数据 DB 来获取变化的元数据。&lt;/li>
&lt;li>元数据被返回给 API 服务器。&lt;/li>
&lt;li>客户端 2 获得元数据。&lt;/li>
&lt;li>一旦客户端收到元数据，它就向块服务器发送请求，下载区块。&lt;/li>
&lt;li>块服务器首先从云存储中下载区块。&lt;/li>
&lt;li>云存储将区块返回给块服务器。&lt;/li>
&lt;li>客户端 2 下载所有的新区块来重建文件。&lt;/li>
&lt;/ol>
&lt;p>通知服务&lt;/p>
&lt;p>为了保持文件的一致性，任何在本地进行的文件突变都需要通知其他客户端以减少冲突。通知服务就是为这个目的而建立的。在高层，通知服务允许在事件发生时将数据传输给客户端。这里有几个选择。&lt;/p>
&lt;ul>
&lt;li>长时间轮询。Dropbox 使用长轮询[10]。&lt;/li>
&lt;li>WebSocket。WebSocket 在客户端和服务器之间提供一个持久的连接。通信是双向的。&lt;/li>
&lt;/ul>
&lt;p>尽管这两个选项都很好用，但由于以下两个原因，我们选择了长轮询。&lt;/p>
&lt;ul>
&lt;li>通知服务的通信不是双向的。服务器向客户端发送有关文件变化的信息，但不是反过来。&lt;/li>
&lt;li>WebSocket 适用于实时双向通信，如聊天应用程序。对于谷歌硬盘，通知的发送频率不高，没有突发数据。&lt;/li>
&lt;/ul>
&lt;p>通过长轮询，每个客户端与通知服务建立一个长轮询连接。如果检测到一个文件的变化，客户端将关闭长轮询连接。关闭连接意味着客户端必须连接到元数据服务器以下载最新的变化。在收到响应或达到连接超时后，客户端立即发送一个新的请求，以保持连接开放。&lt;/p>
&lt;p>节省存储空间&lt;/p>
&lt;p>为了支持文件版本历史并确保可靠性，同一文件的多个版本被存储在多个数据中心。如果频繁地备份所有文件的修订版，存储空间会很快被填满。提出了三种技术来减少存储成本。&lt;/p>
&lt;ul>
&lt;li>去除重复的数据块。在账户层面消除冗余块是节省空间的一个简单方法。如果两个块有相同的哈希值，那么它们就是相同的。&lt;/li>
&lt;li>采用智能数据备份策略。可以采用两种优化策略。&lt;/li>
&lt;li>设置一个限制：我们可以为存储的版本数量设置一个限制。如果达到限制，最旧的版本将被新的版本取代。&lt;/li>
&lt;li>只保留有价值的版本。有些文件可能经常被编辑。例如，为一个大量修改的文件保存每个编辑过的版本可能意味着该文件在短时间内被保存超过 1000 次。为了避免不必要的复制，我们可以限制保存版本的数量。我们对最近的版本给予更多的权重。实验有助于找出保存的最佳版本数。&lt;/li>
&lt;li>将不经常使用的数据移至冷库。冷数据是指几个月或几年都没有活动的数据。像亚马逊 S3 glacier[11]这样的冷存储要比 S3 便宜得多。&lt;/li>
&lt;/ul>
&lt;p>故障处理&lt;/p>
&lt;p>大规模系统中可能会出现故障，我们必须采取设计策略来处理这些故障。你的面试官可能会有兴趣听到你如何处理以下系统故障的情况。&lt;/p>
&lt;ul>
&lt;li>负载平衡器故障。如果一个负载均衡器发生故障，次要的将成为活动的，并接过流量。负载平衡器通常使用心跳来监控对方，这是负载平衡器之间发送的定期信号。如果一个负载平衡器在一段时间内没有发送心跳信号，则被认为是失败。&lt;/li>
&lt;li>块服务器故障。如果一个块服务器发生故障，其他服务器就会接收未完成的或待处理的作业。&lt;/li>
&lt;li>云存储失败。S3 桶在不同地区被多次复制。如果文件在一个地区不可用，它们可以从不同的地区取回。&lt;/li>
&lt;li>API 服务器故障。它是一个无状态的服务。如果一个 API 服务器失败，流量会被负载平衡器重定向到其他 API 服务器。&lt;/li>
&lt;li>元数据缓存失败。元数据缓存服务器是多次复制的。如果一个节点发生故障，你仍然可以访问其他节点来获取数据。我们会调出一个新的缓存服务器来替换故障的那个。&lt;/li>
&lt;li>Metadata DB 故障。&lt;/li>
&lt;li>主站停机。如果主节点宕机，提升一个从属节点作为新的主节点，并带起一个新的从属节点。&lt;/li>
&lt;li>从机停机。如果一个从属服务器宕机，你可以使用另一个从属服务器进行读取操作，并带来另一个数据库服务器来替代故障的服务器。&lt;/li>
&lt;li>通知服务失败。每个在线用户都与通知服务器保持长期的轮询连接。&lt;/li>
&lt;/ul>
&lt;p>通知服务器的长期轮询连接。因此，每个通知服务器都与许多用户相连。根据 Dropbox 在 2012 年的谈话[6]，每台机器有超过 100 万个连接被打开。如果一台服务器发生故障，所有的长轮询连接都会丢失，因此客户必须重新连接到不同的服务器。即使一台服务器可以保持许多开放的连接，它也不能一次重新连接所有丢失的连接。与所有丢失的客户重新连接是一个相对缓慢的过程。&lt;/p>
&lt;ul>
&lt;li>离线备份队列故障。队列是多次复制的。如果一个队列发生故障，该队列的消费者可能需要重新订阅备份队列。&lt;/li>
&lt;/ul>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在本章中，我们提出了一个支持 Google Drive 的系统设计。强一致性、低网络带宽和快速同步的结合使得这个设计很有意思。我们的设计包含两个流程：管理文件元数据和文件同步。通知服务是该系统的另一个重要组成部分。它使用长时间的轮询来让客户了解最新的文件变化。&lt;/p>
&lt;p>像任何系统设计面试问题一样，没有完美的解决方案。每个公司都有其独特的限制，你必须设计一个系统来适应这些限制。了解你的设计和技术选择的权衡是很重要的。如果还有几分钟的时间，你可以谈谈不同的设计选择。&lt;/p>
&lt;p>例如，我们可以从客户端直接向云存储上传文件，而不是通过块状服务器。这种方法的优点是，它使文件上传的速度更快，因为一个文件只需要传输一次到云存储。在我们的设计中，一个文件首先被传输到块服务器，然后再传输到云存储。然而，这种新方法有一些缺点。&lt;/p>
&lt;ul>
&lt;li>首先，同样的分块、压缩和加密逻辑必须在不同的平台（iOS、Android、Web）上实现。这很容易出错，需要大量的工程努力。在我们的设计中，所有这些逻辑都在一个集中的地方实现：块服务器。&lt;/li>
&lt;li>其次，由于客户端很容易被入侵或操纵，在客户端实现加密逻辑并不理想。&lt;/li>
&lt;/ul>
&lt;p>该系统的另一个有趣的演变是将在线/离线逻辑转移到一个单独的服务。让我们称它为存在感服务。通过将存在服务从通知服务器中移出，在线/离线功能可以很容易地被其他服务所整合。&lt;/p>
&lt;p>祝贺你走到了这一步! 现在给自己拍拍屁股吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1]&lt;a href="https://www.google.com/drive/">Google Drive&lt;/a>&lt;br>
[2]&lt;a href="https://developers.google.com/drive/api/v2/manage-uploads">Upload file data&lt;/a>&lt;br>
[3]&lt;a href="https://aws.amazon.com/s3">Amazon S3&lt;/a>&lt;br>
[4]&lt;a href="https://neil.fraser.name/writing/sync/">Differential Synchronizatio&lt;/a>&lt;br>
[5]&lt;a href="https://www.youtube.com/watch?v=S2Hp_1jqpY8">Differential Synchronization youtube tal&lt;/a>&lt;br>
[6]&lt;a href="https://youtu.be/PE4gwstWhmc">How We’ve Scaled Dropbox&lt;/a>&lt;br>
[7] Tridgell, A., &amp;amp; Mackerras, P. (1996). The rsync algorithm.&lt;br>
[8]&lt;a href="https://github.com/librsync/librsync">Librsync. (n.d.). Retrieved April 18, 2015, fro&lt;/a>&lt;br>
[9]&lt;a href="https://en.wikipedia.org/wiki/ACID">ACID&lt;/a>&lt;br>
[10]&lt;a href="https://www.dropbox.com/static/business/resources/Security_Whitepaper.pdf">Dropbox security white paper&lt;/a>&lt;br>
[11]&lt;a href="https://aws.amazon.com/glacier/faqs/">Amazon S3 Glacier&lt;/a>&lt;/p></description></item><item><title>系统设计::设计YOUTUBE</title><link>/system_design/system_design_interview_14/</link><pubDate>Sun, 14 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_14/</guid><description>&lt;h2 id="设计-youtube">设计 YOUTUBE&lt;/h2>
&lt;p>在本章中，你被要求设计 YouTube。这个问题的解决方案可以应用于其他面试问题，如设计一个视频共享平台，如 Netflix 和 Hulu。图 14-1 显示了 YouTube 的主页。&lt;/p>
&lt;img src="../../../system_design_interview/index-220_1.jpg" width="77%"/>
&lt;p>YouTube 看起来很简单：内容创作者上传视频，观众点击播放。它真的那么简单吗？并非如此。在简单的背后有很多复杂的技术。让我们看看 2020 年 YouTube 的一些令人印象深刻的统计数据、人口统计学和有趣的事实[1] [2]。&lt;/p>
&lt;ul>
&lt;li>每月活跃用户总数：20 亿。&lt;/li>
&lt;li>每天观看的视频数量。50 亿。&lt;/li>
&lt;li>73%的美国成年人使用 YouTube。&lt;/li>
&lt;li>YouTube 上有 5000 万创作者。&lt;/li>
&lt;li>2019 年全年，YouTube 的广告收入为 151 亿美元，比 2018 年增长 36%。&lt;/li>
&lt;li>YouTube 占所有移动互联网流量的 37%。&lt;/li>
&lt;li>YouTube 有 80 种不同的语言。&lt;/li>
&lt;/ul>
&lt;p>从这些统计数据中，我们知道 YouTube 是巨大的，全球性的，并且赚了很多钱。&lt;/p>
&lt;h3 id="理解问题确立设计范围">理解问题，确立设计范围&lt;/h3>
&lt;p>如图 14-1 所示，除了观看视频，你还可以在 YouTube 上做很多事情。例如，评论、分享或喜欢一个视频，将一个视频保存到播放列表中，订阅一个频道等等。在 45 或 60 分钟的采访中，不可能设计所有内容。因此，提出问题以缩小范围是很重要的。&lt;/p>
&lt;p>应聘者：哪些功能是重要的？&lt;br>
面试官：上传视频和观看视频的能力。&lt;br>
应聘者：我们需要支持哪些客户？&lt;br>
面试官：移动应用、网络浏览器和智能电视。&lt;br>
应聘者：我们有多少日活跃用户？&lt;br>
面试官：500 万&lt;br>
应聘者：每天花在产品上的平均时间是多少？&lt;br>
面试官：30 分钟。&lt;br>
应聘者：我们需要支持国际用户吗？&lt;br>
面试官：是的，很大比例的用户是国际用户。&lt;br>
应聘者：支持的视频分辨率是多少？&lt;br>
面试官：系统可以接受大部分的视频分辨率和格式。&lt;br>
应聘者：是否需要加密？&lt;br>
面试官：是的&lt;br>
应聘者：对视频的文件大小有要求吗？&lt;br>
面试官：是的。我们的平台专注于小型和中型的视频。允许的最大视频尺寸是 1GB。&lt;br>
应聘者：我们能否利用亚马逊、谷歌或微软提供的一些现有云计算基础设施？&lt;br>
面试官：这是个好问题。对于大多数公司来说，从头开始建立一切是不现实的，建议利用一些现有的云服务。&lt;/p>
&lt;p>在本章中，我们重点设计一个具有以下特点的视频流媒体服务。&lt;/p>
&lt;ul>
&lt;li>快速上传视频的能力&lt;/li>
&lt;li>流畅的视频流&lt;/li>
&lt;li>改变视频质量的能力&lt;/li>
&lt;li>基础设施成本低&lt;/li>
&lt;li>高可用性、可扩展性和可靠性要求&lt;/li>
&lt;li>支持的客户端：移动应用程序、网络浏览器和智能电视&lt;/li>
&lt;/ul>
&lt;h3 id="粗略估计">粗略估计&lt;/h3>
&lt;p>下面的估计是基于许多假设，所以必须与面试官沟通，以确保她和你达成共识。&lt;/p>
&lt;ul>
&lt;li>假设该产品有 500 万日活跃用户（DAU）。&lt;/li>
&lt;li>用户每天观看 5 个视频。&lt;/li>
&lt;li>10%的用户每天上传 1 个视频。&lt;/li>
&lt;li>假设平均视频大小为 300MB。&lt;/li>
&lt;li>每天需要的总存储空间。500 万*10%*300MB=150TB&lt;/li>
&lt;li>CDN 成本。
&lt;ul>
&lt;li>当云 CDN 提供视频时，你要为从 CDN 传输出来的数据收费。&lt;/li>
&lt;li>让我们使用亚马逊的 CDN CloudFront 进行成本估算（图 14-2）[3]。假设 100%的流量都来自美国。每 GB 的平均成本是 0.02 美元。为简单起见，我们只计算视频流的成本。&lt;/li>
&lt;li>500 万 * 5 个视频 * 0.3GB * 0.02 美元 = 每天 150,000 美元。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>从粗略的成本估算中，我们知道从 CDN 提供视频服务需要花费很多钱。即使云供应商愿意为大客户大幅降低 CDN 成本，但成本仍然很高。我们将深入讨论降低 CDN 成本的方法。&lt;/p>
&lt;img src="../../../system_design_interview/index-222_1.jpg" width="77%"/>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>如前所述，面试官建议利用现有的云服务，而不是从头开始建立一切。CDN 和 blob 存储是我们要利用的云服务。有些读者可能会问，为什么不自己建立一切？下面列出了原因。&lt;/p>
&lt;ul>
&lt;li>系统设计面试不是要从头开始建立一切。在有限的时间内，选择正确的技术来做好一项工作，比详细解释技术的工作原理更重要。例如，提到用于存储源视频的 blob 存储就足以应付面试。谈论 blob 存储的详细设计可能是一种矫枉过正。&lt;/li>
&lt;li>建立可扩展的 blob 存储或 CDN 是非常复杂和昂贵的。即使像 Netflix 或 Facebook 这样的大公司也不会自己建立一切。Netflix 利用亚马逊的云服务[4]，而 Facebook 使用 Akamai 的 CDN[5]。&lt;/li>
&lt;/ul>
&lt;p>在高层次上，该系统包括三个组成部分（图 14-3）。&lt;/p>
&lt;img src="../../../system_design_interview/index-223_1.jpg" width="55%"/>
&lt;p>客户端：你可以在你的电脑、移动电话和智能电视上观看 YouTube。&lt;br>
CDN：视频存储在 CDN 中。当你按下播放键时，视频会从 CDN 上流传下来。&lt;br>
API 服务器。除了视频流之外，其他一切都要通过 API 服务器。这包括订阅推荐、生成视频上传 URL、更新元数据数据库和缓存、用户注册等。&lt;/p>
&lt;p>在问答环节，面试官表现出对两个流程的兴趣。&lt;/p>
&lt;ul>
&lt;li>视频上传流程&lt;/li>
&lt;li>视频流媒体流程&lt;/li>
&lt;/ul>
&lt;p>我们将分别探讨它们的高层设计。&lt;/p>
&lt;h4 id="视频上传流程">视频上传流程&lt;/h4>
&lt;p>图 14-4 显示了视频上传的高级设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-224_1.jpg" width="66%"/>
&lt;p>它由以下部分组成。&lt;/p>
&lt;ul>
&lt;li>用户：用户在电脑、移动电话或智能电视等设备上观看 YouTube。&lt;/li>
&lt;li>负载平衡器：负载平衡器在 API 服务器之间均匀地分配请求。&lt;/li>
&lt;li>API 服务器：除了视频流，所有的用户请求都要通过 API 服务器。&lt;/li>
&lt;li>元数据数据库：视频元数据存储在元数据数据库中。它是分片和复制的，以满足性能和高可用性要求。&lt;/li>
&lt;li>元数据缓存：为了提高性能，视频元数据和用户对象被缓存起来。&lt;/li>
&lt;li>原始存储：一个 blob 存储系统被用来存储原始视频。维基百科中关于 blob 存储的一段引文显示。&amp;ldquo;二进制大对象（BLOB）是数据库管理系统中作为单一实体存储的二进制数据的集合&amp;rdquo; [6]。&lt;/li>
&lt;li>转码服务器：视频转码也被称为视频编码。它是将一种视频格式转换为其他格式（MPEG、HLS 等）的过程，为不同的设备和带宽能力提供可能的最佳视频流。- 转码存储。它是一个存储转码视频文件的 blob 存储。&lt;/li>
&lt;li>CDN：视频被缓存在 CDN 中。当你点击播放按钮时，视频会从 CDN 中流出来。&lt;/li>
&lt;li>完成队列：它是一个消息队列，存储有关视频转码完成事件的信息。&lt;/li>
&lt;li>完成处理程序：它包括一个工作列表，从完成队列中提取事件数据并更新元数据缓存和数据库。&lt;/li>
&lt;/ul>
&lt;p>现在我们已经单独了解了每个组件，让我们来看看视频上传流程是如何工作的。该流程被分解为两个平行运行的过程。&lt;/p>
&lt;p>a. 上传实际的视频。&lt;/p>
&lt;p>b. 更新视频元数据。元数据包含关于视频 URL、大小、分辨率、格式、用户信息等信息。&lt;/p>
&lt;p>流程 a：上传实际视频&lt;/p>
&lt;img src="../../../system_design_interview/index-226_1.jpg" width="66%"/>
&lt;p>图 14-5 显示了如何上传实际视频。解释如下。&lt;/p>
&lt;ol>
&lt;li>视频被上传到原始存储器。&lt;/li>
&lt;li>转码服务器从原始存储中获取视频并开始转码。&lt;/li>
&lt;li>一旦转码完成，以下两个步骤将平行执行。&lt;br>
3a. 转码后的视频被发送到转码后的存储器。&lt;br>
3b. 转码完成事件被排入完成队列。&lt;br>
3a.1. 转码后的视频被分发到 CDN。&lt;br>
3b.1. 完成处理程序包含一堆工作线程，不断从队列中提取事件数据。
3b.1.a.和 3b.1.b. 完成处理程序在视频转码完成后更新元数据数据库和缓存。&lt;/li>
&lt;li>API 服务器通知客户端，视频已经成功上传，可以进行流媒体播放。&lt;/li>
&lt;/ol>
&lt;p>流程 b：更新元数据&lt;/p>
&lt;p>当文件被上传到原始存储区时，并行的客户端会发送一个更新视频元数据的请求，如图 14-6 所示。该请求包含视频元数据，包括文件名、大小、格式等。API 服务器更新元数据缓存和数据库。&lt;/p>
&lt;img src="../../../system_design_interview/index-227_1.jpg" width="33%"/>
&lt;p>视频流流程&lt;/p>
&lt;p>每当你在 YouTube 上观看一个视频时，它通常立即开始流媒体，你不会等到整个视频被下载。下载意味着整个视频被复制到你的设备上，而流媒体意味着你的设备不断接收来自远程源视频的视频流。当你观看流媒体视频时，你的客户端每次加载一点数据，所以你可以立即和连续地观看视频。&lt;/p>
&lt;p>在我们讨论视频流流程之前，让我们看看一个重要的概念：流媒体协议。这是一种控制视频流媒体数据传输的标准化方式。流行的流媒体协议有。&lt;/p>
&lt;ul>
&lt;li>MPEG-DASH。MPEG 代表 &amp;ldquo;移动图像专家组&amp;rdquo;，DASH 代表 &amp;ldquo;HTTP 动态自适应流&amp;rdquo;。&lt;/li>
&lt;li>苹果 HLS。HLS 是 &amp;ldquo;HTTP Live Streaming &amp;ldquo;的缩写。&lt;/li>
&lt;li>Microsoft Smooth Streaming.&lt;/li>
&lt;li>Adobe HTTP 动态流（HDS）。你不需要完全理解甚至记住这些流媒体协议名称，因为它们是需要特定领域知识的低级细节。这里重要的是要理解不同的流媒体协议支持不同的视频编码和播放机。当我们设计一个视频流媒体服务时，我们必须选择正确的流媒体协议来支持我们的用例。要了解更多关于流媒体协议的信息，这里有一篇很好的文章[7]。&lt;/li>
&lt;/ul>
&lt;p>视频直接从 CDN 进行流式传输。离你最近的边缘服务器将提供视频。因此，延迟非常小。图 14-7 显示了视频流的高水平设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-228_1.jpg" width="33%"/>
&lt;h3 id="深入设计">深入设计&lt;/h3>
&lt;p>在高层设计中，整个系统被分解成两个部分：视频上传流和视频流。在本节中，我们将通过重要的优化来完善这两个流程，并引入错误处理机制。&lt;/p>
&lt;p>视频转码&lt;/p>
&lt;p>当你录制视频时，设备（通常是手机或相机）会给视频文件一个特定的格式。如果你想让视频在其他设备上顺利播放，视频必须被编码成兼容的比特率和格式。比特率是指随着时间推移，比特被处理的速度。更高的比特率通常意味着更高的视频质量。高比特率流需要更多的处理能力和快速的互联网速度。&lt;/p>
&lt;p>视频转码的重要性在于以下原因。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>原始视频消耗大量的存储空间。一段长达一小时的高清视频以每秒 60 帧的速度录制，可以占用几百 GB 的空间。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>许多设备和浏览器只支持某些类型的视频格式。因此，出于兼容性的考虑，将视频编码为不同的格式很重要。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>为了确保用户观看高质量的视频，同时保持流畅的播放，向拥有高网络带宽的用户提供更高分辨率的视频，向拥有低带宽的用户提供低分辨率的视频是一个好主意。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>网络条件可能改变，特别是在移动设备上。为了确保视频能够连续播放，根据网络条件自动或手动切换视频质量对用户的流畅体验至关重要。有许多类型的编码格式，然而，它们中的大多数包含两部分。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>容器。这就像一个篮子，包含视频文件、音频和元数据。你可以通过文件扩展名来判断容器格式，如.avi、.mov 或.mp4。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>编解码器。这些是压缩和解压算法，旨在减少视频尺寸，同时保留视频质量。最常用的视频编解码器是 H.264、VP9 和 HEVC。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>有向无环图（DAG）模型&lt;/p>
&lt;p>转码视频的计算成本很高，而且很耗时。此外，不同的内容创作者可能有不同的视频处理要求。例如，有些内容创作者需要在视频上面加水印，有些自己提供缩略图，有些上传高清视频，而有些则不需要。&lt;/p>
&lt;p>为了支持不同的视频处理管道并保持高度的并行性，必须增加一些抽象层次，让客户端程序员定义要执行哪些任务。例如，Facebook 的流媒体视频引擎使用了一个有向无环图（DAG）编程模型，该模型分阶段定义任务，因此它们可以按顺序或平行地执行[8]。在我们的设计中，我们采用类似的 DAG 模型来实现灵活性和并行性。图 14-8 表示一个用于视频转码的 DAG。&lt;/p>
&lt;img src="../../../system_design_interview/index-230_1.jpg" width="77%"/>
&lt;p>在图 14-8 中，原始视频被分割成视频、音频和元数据。下面是一些可以应用于视频文件的任务。&lt;/p>
&lt;ul>
&lt;li>检查。确保视频有良好的质量，没有畸形。&lt;/li>
&lt;li>视频编码。视频被转换以支持不同的分辨率、编解码、比特率等。图 14-9 显示了一个视频编码文件的例子。&lt;/li>
&lt;li>缩略图。缩略图可以由用户上传或由系统自动生成。&lt;/li>
&lt;li>水印。在你的视频上面叠加一个图像，包含关于你视频的识别信息。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-231_1.jpg" width="55%"/>
&lt;p>视频转码架构&lt;/p>
&lt;p>拟议的视频转码架构利用云服务，如图 14-10 所示。&lt;/p>
&lt;p>该架构有六个主要组成部分：预处理器、DAG 调度器、资源管理器、任务者、临时存储和作为输出的编码视频。让我们仔细看看每个组件。&lt;/p>
&lt;p>预处理器&lt;/p>
&lt;img src="../../../system_design_interview/index-232_1.jpg" width="88%"/>
&lt;p>预处理器有 4 个职责。&lt;/p>
&lt;ol>
&lt;li>视频拆分。视频流被分割或进一步分割成更小的图片组（GOP）排列。GOP 是一组/大块的帧按特定顺序排列。每个块是一个独立的可播放单元，通常是几秒钟的长度。&lt;/li>
&lt;li>一些旧的移动设备或浏览器可能不支持视频分割。预处理程序通过 GOP 对齐方式为老客户分割视频。&lt;/li>
&lt;li>DAG 生成。处理器根据客户程序员编写的配置文件生成 DAG。图 14-12 是一个简化的 DAG 表示，它有 2 个节点和 1 条边。&lt;/li>
&lt;/ol>
&lt;img src="../../../system_design_interview/index-232_2.jpg" width="33%"/>
&lt;p>这个 DAG 表示法是由下面两个配置文件生成的（图 14-13）。&lt;/p>
&lt;ol start="4">
&lt;li>缓存数据。预处理器是一个分段视频的缓存器。为了提高可靠性，预处理器将 GOPs 和元数据存储在临时存储中。如果视频编码失败，系统可以使用持久化的数据进行重试操作。&lt;/li>
&lt;/ol>
&lt;img src="../../../system_design_interview/index-233_1.jpg" width="77%"/>
&lt;p>DAG 调度器把 DAG 图分割成各阶段的任务，并把它们放在资源管理器的任务队列中。图 14-15 显示了 DAG 调度器如何工作的一个例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-233_2.jpg" width="77%"/>
&lt;p>如图 14-15 所示，原始视频被分割成三个阶段。第 1 阶段：视频、音频和元数据。视频文件在第 2 阶段被进一步分成两个任务：视频编码和缩略图。音频文件需要进行音频编码，作为第 2 阶段任务的一部分。&lt;/p>
&lt;p>资源管理器&lt;/p>
&lt;img src="../../../system_design_interview/index-234_1.jpg" width="88%"/>
&lt;p>资源管理器负责管理资源分配的效率。它包含 3 个队列和一个任务调度器，如图 14-17 所示。&lt;/p>
&lt;ul>
&lt;li>任务队列。它是一个优先级队列，包含要执行的任务。&lt;/li>
&lt;li>工作队列。它是一个优先级队列，包含工人的利用信息。&lt;/li>
&lt;li>运行队列。它包含关于当前运行的任务和运行任务的工作者的信息。&lt;/li>
&lt;li>任务调度器。它挑选最佳任务/工作者，并指示所选的任务工作者执行工作。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-234_2.jpg" width="88%"/>
&lt;p>资源管理器的工作方式如下。&lt;/p>
&lt;ul>
&lt;li>任务调度器从任务队列中获得最高优先级的任务。&lt;/li>
&lt;li>任务调度器从工作线程队列中获得运行任务的最佳任务工作线程。&lt;/li>
&lt;li>任务调度器指示选择的任务工作线程运行任务。&lt;/li>
&lt;li>任务调度器绑定任务/工作线程信息并将其放入运行队列。&lt;/li>
&lt;li>一旦任务完成，任务调度器就会将任务从运行队列中移除。&lt;/li>
&lt;/ul>
&lt;p>任务组&lt;/p>
&lt;img src="../../../system_design_interview/index-235_1.jpg" width="77%"/>
&lt;p>任务工作者运行在 DAG 中定义的任务。不同的任务工作线程可以运行不同的任务，如图 14-19 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-235_2.jpg" width="22%"/>
&lt;p>临时存储&lt;/p>
&lt;img src="../../../system_design_interview/index-235_3.jpg" width="77%"/>
&lt;p>这里使用了多种存储系统。存储系统的选择取决于数据类型、数据大小、访问频率、数据寿命等因素。例如，元数据经常被工作者访问，而且数据大小通常很小。因此，在内存中缓存元数据是一个好主意。对于视频或音频数据，我们把它们放在 blob 存储中。一旦相应的视频处理完成，临时存储中的数据就会被释放出来。&lt;/p>
&lt;p>编码视频&lt;/p>
&lt;img src="../../../system_design_interview/index-236_1.jpg" width="77%"/>
&lt;p>编码后的视频是编码管道的最终输出。下面是一个输出的例子： funny_720p.mp4 。&lt;/p>
&lt;p>系统优化&lt;/p>
&lt;p>在这一点上，你应该对视频上传流程、视频流媒体流程和视频转码有良好的理解。接下来，我们将通过优化来完善系统，包括速度、安全和节约成本。&lt;/p>
&lt;p>速度优化：并行化视频上传&lt;/p>
&lt;p>将一个视频作为一个整体上传是低效的。我们可以通过 GOP 对齐将视频分成小块，如图 14-22 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-236_2.jpg" width="77%"/>
&lt;p>这允许在前一次上传失败时快速恢复上传。按 GOP 分割视频文件的工作可以由客户端实现，以提高上传速度，如图 14-23 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-236_3.jpg" width="55%"/>
&lt;p>速度优化：将上传中心放在靠近用户的地方 另一个提高上传速度的方法是在全球范围内建立多个上传中心（图 14-24）。美国的人可以把视频上传到北美的上传中心，而中国的人可以把视频上传到亚洲的上传中心。为了实现这一目标，我们使用 CDN 作为上传中心。&lt;/p>
&lt;img src="../../../system_design_interview/index-237_1.jpg" width="77%"/>
&lt;p>速度优化：无处不在的并行性 实现低延迟需要认真努力。另一个优化是建立一个松散耦合的系统，并实现高并行性。&lt;/p>
&lt;p>我们的设计需要进行一些修改以实现高并行性。让我们放大视频如何从原始存储空间传输到 CDN 的流程。该流程如图 14-25 所示，显示了输出取决于前一步的输入。这种依赖性使并行化变得困难。&lt;/p>
&lt;img src="../../../system_design_interview/index-237_2.jpg" width="77%"/>
&lt;p>为了使系统更加松散耦合，我们引入了消息队列，如图 14-26 所示。让我们用一个例子来解释消息队列是如何使系统更加松散耦合的。&lt;/p>
&lt;ul>
&lt;li>在引入消息队列之前，编码模块必须等待下载模块的输出。&lt;/li>
&lt;li>引入消息队列后，编码模块不需要再等待下载模块的输出。如果消息队列中存在事件，编码模块可以并行地执行这些工作。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-238_1.jpg" width="77%"/>
&lt;p>安全优化：预签署的上传 URL 安全是任何产品最重要的方面之一。为了确保只有授权用户将视频上传到正确的位置，我们引入了预签名的 URL，如图 14-27 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-239_1.jpg" width="77%"/>
&lt;p>上传流程更新如下。&lt;/p>
&lt;ol>
&lt;li>客户端向 API 服务器发出 HTTP 请求，以获取预签名的 URL，该 URL 赋予了对 URL 中标识的对象的访问许可。预签名的 URL 一词是通过上传文件到 Amazon S3 使用的。其他云服务提供商可能使用不同的名称。例如，微软 Azure blob 存储支持同样的功能，但称之为 &amp;ldquo;共享访问签名&amp;rdquo;[10]。&lt;/li>
&lt;li>API 服务器用一个预先签名的 URL 来响应。&lt;/li>
&lt;li>一旦客户端收到响应，它就使用预先签署的 URL 上传视频。&lt;/li>
&lt;/ol>
&lt;p>安全优化：保护你的视频 许多内容制作者不愿意在网上发布视频，因为他们担心自己的原创视频会被盗。为了保护有版权的视频，我们可以采用以下三种安全方案之一。&lt;/p>
&lt;ul>
&lt;li>数字版权管理（DRM）系统。三个主要的 DRM 系统是苹果 FairPlay、谷歌 Widevine 和微软 PlayReady。&lt;/li>
&lt;li>AES 加密。你可以对视频进行加密并配置一个授权策略。加密的视频将在播放时被解密。这确保了只有授权用户才能观看加密的视频。&lt;/li>
&lt;li>视觉水印。这是一个覆盖在你的视频上面的图像，包含你视频的识别信息。它可以是你的公司标志或公司名称。&lt;/li>
&lt;/ul>
&lt;p>节省成本的优化 CDN 是我们系统的一个重要组成部分。它确保了在全球范围内的快速视频传输。然而，从背面计算，我们知道 CDN 是昂贵的，特别是当数据量很大时。我们如何才能减少成本？&lt;/p>
&lt;p>以前的研究表明，YouTube 视频流遵循长尾分布[11] [12]。这意味着少数流行的视频被频繁访问，但其他许多视频的观看者很少或没有。基于这一观察，我们实施了一些优化。&lt;/p>
&lt;ol>
&lt;li>只从 CDN 提供最受欢迎的视频，其他视频从我们的高容量存储视频服务器提供（图 14-28）。&lt;/li>
&lt;li>对于不太受欢迎的内容，我们可能不需要存储许多编码的视频版本。短视频可以按需编码。&lt;/li>
&lt;li>一些视频只在某些地区流行。没有必要将这些视频分发到其他地区。&lt;/li>
&lt;li>像 Netflix 一样建立自己的 CDN，并与互联网服务提供商（ISP）合作。建立你的 CDN 是一个巨大的项目；然而，这对大型流媒体公司来说可能是有意义的。ISP 可以是 Comcast、AT&amp;amp;T、Verizon 或其他互联网供应商。ISP 分布在世界各地，离用户很近。通过与 ISP 合作，你可以改善观看体验，减少带宽费用。&lt;/li>
&lt;/ol>
&lt;img src="../../../system_design_interview/index-240_1.jpg" width="44%"/>
&lt;p>所有这些优化都是基于内容流行度、用户访问模式、视频大小等。在做任何优化之前，分析历史观看模式是很重要的。这里有一些关于这个主题的有趣文章。[12] [13].&lt;/p>
&lt;p>错误处理&lt;/p>
&lt;p>对于一个大规模的系统，系统错误是不可避免的。为了建立一个高度容错的系统，我们必须优雅地处理错误并快速恢复。存在两种类型的错误。&lt;/p>
&lt;ul>
&lt;li>可恢复的错误。对于可恢复的错误，如视频段转码失败，一般的想法是重试几次操作。如果任务继续失败，而且系统认为它无法恢复，它就会向客户返回一个适当的错误代码。&lt;/li>
&lt;li>不可恢复的错误。对于不可恢复的错误，如畸形的视频格式，系统会停止与视频相关的运行任务，并向客户端返回适当的错误代码。&lt;/li>
&lt;/ul>
&lt;p>每个系统组件的典型错误由以下游戏规则涵盖。&lt;/p>
&lt;ul>
&lt;li>上传错误：重试几次。&lt;/li>
&lt;li>分割视频错误：如果旧版本的客户端不能按 GOP 对齐方式分割视频，整个视频就会被传递给服务器。分割视频的工作是在服务器端完成的。&lt;/li>
&lt;li>转码错误：重试。&lt;/li>
&lt;li>预处理程序错误：重新生成 DAG 图。&lt;/li>
&lt;li>DAG 调度器错误：重新调度一个任务。&lt;/li>
&lt;li>资源管理器队列故障：使用一个副本。&lt;/li>
&lt;li>任务工作者故障：在一个新的工作者上重试任务。&lt;/li>
&lt;li>API 服务器宕机。API 服务器是无状态的，所以请求将被引导到不同的 API 服务器。&lt;/li>
&lt;li>元数据缓存服务器宕机：数据被多次复制。如果一个节点发生故障，你仍然可以访问其他节点来获取数据。我们可以调出一个新的缓存服务器来代替死去的那个。&lt;/li>
&lt;li>元数据 DB 服务器宕机。
&lt;ul>
&lt;li>主服务器宕机了。如果主服务器宕机了，可以提升其中一个从服务器作为新的主服务器。&lt;/li>
&lt;li>从属服务器坏了。如果一个从属服务器坏了，你可以使用另一个从属服务器来读取数据，并建立另一个数据库服务器来代替死去的那个。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在本章中，我们介绍了 YouTube 等视频流服务的架构设计。如果在采访结束时有多余的时间，这里有几个补充要点。&lt;/p>
&lt;ul>
&lt;li>扩展 API 层：因为 API 服务器是无状态的，所以很容易水平地扩展 API 层。&lt;/li>
&lt;li>扩大数据库的规模。你可以谈谈数据库的复制和分片。&lt;/li>
&lt;li>实时流媒体。它指的是一个视频如何被录制和实时播放的过程。虽然我们的系统不是专门为直播设计的，但直播和非直播有一些相似之处：都需要上传、编码和流媒体。显著的区别是。
&lt;ul>
&lt;li>直播流媒体有更高的延迟要求，所以它可能需要不同的流媒体协议。&lt;/li>
&lt;li>直播流对并行性的要求较低，因为小块的数据已经被实时处理了。&lt;/li>
&lt;li>实时流媒体需要不同的错误处理集。任何花费太多时间的错误处理都是不可接受的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>视频撤下。侵犯版权、色情或其他非法行为的视频应被删除。有些可以在上传过程中被系统发现，而有些则可能通过用户标记发现。&lt;/li>
&lt;/ul>
&lt;p>祝贺你走到这一步！现在给自己拍拍手吧。现在给自己拍拍背。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1] &lt;a href="https://www.omnicoreagency.com/youtube-statistics/">YouTube by the numbers&lt;/a>&lt;br>
[2] &lt;a href="https://blog.hubspot.com/marketing/youtube-demographics">2019 YouTube Demographics&lt;/a>&lt;br>
[3] &lt;a href="https://aws.amazon.com/cloudfront/pricing/">Cloudfront Pricing&lt;/a>&lt;br>
[4] &lt;a href="https://aws.amazon.com/solutions/case-studies/netflix/">Netflix on AWS&lt;/a>&lt;br>
[5] &lt;a href="https://www.akamai.com/">Akamai homepage&lt;/a>&lt;br>
[6] &lt;a href="https://en.wikipedia.org/wiki/Binary_large_object">Binary large object&lt;/a>&lt;br>
[7] &lt;a href="https://www.dacast.com/blog/streaming-protocols/">Here’s What You Need to Know About Streaming Protocols&lt;/a>&lt;br>
[8] &lt;a href="https://www.cs.princeton.edu/~wlloyd/papers/sve-sosp17.pdf">SVE: Distributed Video Processing at Facebook Scale&lt;/a>&lt;br>
[9] &lt;a href="https://www.upyun.com/opentalk/399.html">Weibo video processing architecture (in Chinese)&lt;/a>&lt;br>
[10] &lt;a href="https://docs.microsoft.com/en-us/rest/api/storageservices/delegate-access-with-shared-accesssignature">Delegate access with a shared access signature&lt;/a>&lt;br>
[11] [YouTube scalability talk by early YouTube employee](&lt;a href="https://www.youtube.com/watch">https://www.youtube.com/watch&lt;/a>? v=w5WVu624fY8)&lt;br>
[12] &lt;a href="https://arxiv.org/pdf/0707.3670.pdf">Understanding the characteristics of internet short video sharing: A youtube-based measurement study&lt;/a>&lt;br>
[13] &lt;a href="https://netflixtechblog.com/content-popularity-for-open-connect-b86d56f613b">Content Popularity for Open Connect&lt;/a>&lt;/p></description></item><item><title>系统设计::设计一个搜索自动补全系统</title><link>/system_design/system_design_interview_13/</link><pubDate>Sat, 13 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_13/</guid><description>&lt;h2 id="设计一个搜索自动补全系统">设计一个搜索自动补全系统&lt;/h2>
&lt;p>在谷歌上搜索或在亚马逊购物时，当你在搜索框中输入时，会有一个或多个与搜索词相匹配的内容呈现给你。这一功能被称为自动补全、提前输入、边输入边搜索或增量搜索。图 13-1 是谷歌搜索的一个例子，当在搜索框中输&amp;quot;dinner&amp;quot;时，显示了一个自动补全的结果列表。搜索自动补全是许多产品的一个重要功能。这就把我们引向了面试问题：设计一个搜索自动补全系统，也&amp;quot;设计 top k&amp;quot;&amp;ldquo;设计 top k 最多人搜索的查询&amp;rdquo;。&lt;/p>
&lt;img src="../../../system_design_interview/index-200_1.jpg" width="44%"/>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>处理任何系统设计面试问题的第一步是提出足够的问题来澄清需求。下面是一个应聘者与面试官互动的例子。&lt;/p>
&lt;p>应聘者：是否只支持在搜索查询的开始阶段进行匹配，还是在中间也支持？
面试官：只有在搜索查询的开始阶段。
应聘者：系统应该返回多少个自动补全的建议？
面试官：5
应聘者：系统如何知道要返回哪 5 条建议？
面试官：这是由受欢迎程度决定的，由历史查询频率决定。
应聘者：系统是否支持拼写检查？
面试官：不，不支持拼写检查或自动更正。
应聘者：搜索查询是用英语吗？
面试官：是的。如果最后时间允许，我们可以讨论多语言支持。
应聘者：我们是否允许大写字母和特殊字符？
面试官：不，我们假设所有的搜索查询都是小写字母。
应聘者：有多少用户使用该产品？
面试官：1000 万 DAU。&lt;/p>
&lt;p>以下是需求的摘要。&lt;/p>
&lt;ul>
&lt;li>快速响应时间。当用户输入搜索查询时，自动补全的建议必须足够快地显示出来。一篇关于 Facebook 自动补全系统的文章[1]显示，该系统需要在 100 毫秒内返回结果。否则会造成卡顿。&lt;/li>
&lt;li>相关性。自动补全的建议应该与搜索词相关。&lt;/li>
&lt;li>排序。系统返回的结果必须按照流行度或其他排名模式进行排序。&lt;/li>
&lt;li>可扩展性。系统可以处理高流量。&lt;/li>
&lt;li>高可用性。当系统的一部分脱机、速度减慢或遇到意外的网络错误时，系统应保持可用和可访问。&lt;/li>
&lt;/ul>
&lt;h3 id="粗略估计">粗略估计&lt;/h3>
&lt;p>假设有 1000 万日活跃用户（DAU）。&lt;/p>
&lt;ul>
&lt;li>一个人平均每天进行 10 次搜索。&lt;/li>
&lt;li>每个查询字符串有 20 个字节的数据。&lt;/li>
&lt;li>假设我们使用 ASCII 字符编码。1 个字符 = 1 个字节&lt;/li>
&lt;li>假设一个查询包含 4 个词，每个词平均包含 5 个字符。&lt;/li>
&lt;li>那就是每个查询有 4 x 5 = 20 字节。&lt;/li>
&lt;li>对于在搜索框中输入的每一个字符，客户端都会向后台发送一个自动补全建议的请求。平均来说，每个搜索查询会发送 20 个请求。例如，在你输入完&amp;quot;dinner&amp;quot;时，以下 6 个请求被发送到后端。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-txt" data-lang="txt">&lt;span style="display:flex;">&lt;span> search?q=d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> search?q=di
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> search?q=din
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> search?q=dinn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> search?q=dinne
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> search?q=dinner
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>~24,000 次/秒（QPS）= 10,000,000 用户 * 10 次/天 * 20 个字符/24 小时/3600 秒。&lt;/li>
&lt;li>峰值 QPS = QPS * 2 = ~48,000&lt;/li>
&lt;li>假设每天的查询中有 20% 是新的。1000 万 * 10 次查询/天 * 每次查询 20 字节 * 20% = 0.4GB。这意味着每天有 0.4GB 的新数据被添加到存储中。&lt;/li>
&lt;/ul>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>在高层次上，该系统被分解成两个。&lt;/p>
&lt;ul>
&lt;li>数据收集服务。它收集用户的输入查询，并实时汇总它们。对于大型数据集来说，实时处理并不实际；但是，这是一个很好的起点。我们将在深入研究中探索一个更现实的解决方案。&lt;/li>
&lt;li>查询服务。给定一个搜索查询或前缀，返回 5 个最常搜索的术语。&lt;/li>
&lt;/ul>
&lt;p>数据收集服务&lt;/p>
&lt;p>让我们用一个简化的例子来看看数据收集服务是如何工作的。假设我们有一个频率表，存储查询字符串和其频率，如图 13-2 所示。在开始时，频率表是空的。后来，用户依次输入查&amp;quot;twitch&amp;quot;、&amp;ldquo;twitter&amp;rdquo;、&amp;ldquo;twitte&amp;quot;&amp;ldquo;twillo&amp;rdquo;。图 13-2 显示了频率表的更新情况。&lt;/p>
&lt;img src="../../../system_design_interview/index-203_1.jpg" width="66%"/>
&lt;p>查询服务&lt;/p>
&lt;p>假设我们有一个频率表，如表 13-1 所示。它有两个字段。&lt;/p>
&lt;ul>
&lt;li>查询：它存储查询字符串。&lt;/li>
&lt;li>频率：它代表一个查询被搜索的次数。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-204_1.jpg" width="66%"/>
&lt;p>当用户在搜索框中输&amp;quot;t&amp;quot;时，假设频率表以表 13-1 为基础，就会显示以下前 5 个被搜索的查询（图 13-3）。&lt;/p>
&lt;img src="../../../system_design_interview/index-204_2.jpg" width="33%"/>
&lt;p>要获得前 5 个经常搜索的查询，执行以下 SQL 查询。&lt;/p>
&lt;img src="../../../system_design_interview/index-204_3.jpg" width="50%"/>
&lt;p>当数据集较小时，这是一个可以接受的解决方案。当它很大时，访问数据库就会成为一个瓶颈。我们将在深入探讨优化问题。&lt;/p>
&lt;h3 id="深入设计">深入设计&lt;/h3>
&lt;p>在高层设计中，我们讨论了数据收集服务和查询服务。高层设计并不是最优的，但它可以作为一个很好的起点。在本节中，我们将深入研究几个组件，并探讨以下的优化方法。&lt;/p>
&lt;ul>
&lt;li>Trie 数据结构&lt;/li>
&lt;li>数据收集服务&lt;/li>
&lt;li>查询服务&lt;/li>
&lt;li>扩展存储&lt;/li>
&lt;li>Trie 操作&lt;/li>
&lt;/ul>
&lt;h4 id="trie-数据结构">Trie 数据结构&lt;/h4>
&lt;p>在高层设计中，关系型数据库被用于存储。然而，从关系型数据库中获取前 5 个搜索查询的效率很低。数据结构 trie（前缀树）被用来克服这个问题。由于 trie 数据结构对系统至关重要，我们将投入大量时间来设计一个定制的 trie。请注意，一些想法来自文章[2]和[3]。&lt;/p>
&lt;p>了解基本的 trie 数据结构对于这个面试问题是至关重要的。然而，这更像是一个数据结构问题，而不是一个系统设计问题。此外，许多在线材料都解释了这个概念。在本章中，我们将只讨论 trie 数据结构的概述，并着重讨论如何优化基本 trie 以提高响应时间。&lt;/p>
&lt;p>Trie（发音&amp;quot;try&amp;rdquo;）是一种树状的数据结构，可以紧凑地存储字符串。这个名字来自于检索一词，表明它是为字符串检索操作设计的。trie 的主要思想包括以下内容。&lt;/p>
&lt;ul>
&lt;li>trie 是一个树状的数据结构。&lt;/li>
&lt;li>根代表一个空字符串。&lt;/li>
&lt;li>每个节点存储一个字符，有 26 个子节点，每个子节点代表一个可能的字符。为了节省空间，我们不画空链接。&lt;/li>
&lt;li>每个树节点代表一个单词或一个前缀字符串。&lt;/li>
&lt;/ul>
&lt;p>图 13-5 显示了一个带有搜索查&amp;quot;tree&amp;quot;、&amp;ldquo;try&amp;rdquo;、&amp;ldquo;true&amp;rdquo;、&amp;ldquo;toy&amp;rdquo;、&amp;ldquo;wish&amp;rdquo;、&amp;ldquo;wi&amp;quot;的 trie。搜索查询以较粗的边框突出显示。&lt;/p>
&lt;img src="../../../system_design_interview/index-207_1.jpg" width="66%"/>
&lt;p>基本的 trie 数据结构在节点中存储字符。为了支持按频率排序，需要将频率信息包含在节点中。假设我们有以下频率表。&lt;/p>
&lt;img src="../../../system_design_interview/index-207_2.jpg" width="66%"/>
&lt;p>在向节点添加频率信息后，更新的三角形数据结构如图 13-6 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-208_1.jpg" width="66%"/>
&lt;p>自动补全是如何在 Trie 中工作的？在深入研究算法之前，让我们定义一些术语。&lt;/p>
&lt;ul>
&lt;li>p：前缀的长度&lt;/li>
&lt;li>n：trie 中的节点总数&lt;/li>
&lt;li>c：一个给定节点的子节点的数量&lt;/li>
&lt;/ul>
&lt;p>获得前 k 个搜索次数最多的查询的步骤如下。&lt;/p>
&lt;ol>
&lt;li>找到前缀。时间复杂度。O(p)。&lt;/li>
&lt;li>从前缀节点遍历子树，得到所有有效的子节点。如果一个子节点能够形成一个有效的查询字符串，它就是有效的。时间复杂度。O(c)&lt;/li>
&lt;li>对子节点进行排序，得到前 k 名。O(clogc)&lt;/li>
&lt;/ol>
&lt;p>让我们用一个如图 13-7 所示的例子来解释这个算法。假设 k 等于 2，一个用户在搜索框中输&amp;quot;tr&amp;rdquo;。该算法的工作原理如下。&lt;/p>
&lt;ul>
&lt;li>第 1 步：找到前缀节&amp;quot;tr&amp;quot;。&lt;/li>
&lt;li>第 2 步：遍历子树，得到所有有效的子节点。在这种情况下，节点[tree: 10]、[true: 35]、[try: 29]是有效的。&lt;/li>
&lt;li>第 3 步：对子节点进行排序，得到前两名。[true: 35]和[try: 29]是前缀&amp;quot;t&amp;quot;的前两个查询。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-209_1.jpg" width="66%"/>
&lt;p>这个算法的时间复杂度是上述每个步骤所花费的时间之和。O(p) + O(c) + O(clogc)&lt;/p>
&lt;p>上述算法是直截了当的。然而，它太慢了，因为在最坏的情况下，我们需要遍历整个 trie 来获得前 k 个结果。下面是两个优化方案。&lt;/p>
&lt;ol>
&lt;li>限制前缀的最大长度&lt;/li>
&lt;li>缓存每个节点上的顶级搜索查询 让我们逐一看看这些优化措施。&lt;/li>
&lt;/ol>
&lt;p>限制前缀的最大长度 用户很少在搜索框中输入一个长的搜索查询。因此，可以说 p 是一个小的整数，比如 50。如果我们限制前缀的长度，&amp;ldquo;查找前&amp;quot;的时间复杂度就可以从 O(p)减少到 O(小常数)，也就是 O(1)。&lt;/p>
&lt;p>在每个节点上缓存顶级搜索查询 为了避免遍历整个三角形，我们在每个节点上存储前 k 个最常用的查询。由于 5 到 10 个自动补全的建议对用户来说已经足够了，所以 k 是一个相对较小的数字。在我们的具体案例中，只有前 5 个搜索查询被缓存。&lt;/p>
&lt;p>通过在每个节点缓存顶级搜索查询，我们大大降低了检索前 5 个查询的时间复杂性。然而，这种设计需要大量的空间来存储每个节点的顶级查询。用空间换取时间是非常值得的，因为快速响应时间非常重要。&lt;/p>
&lt;p>图 13-8 显示了更新后的 trie 数据结构。前 5 个查询被存储在每个节点上。例如，前缀&amp;quot;b&amp;quot;的节点存储以下内容。[best: 35, bet: 29, bee: 20, be: 15, beer: 10]。&lt;/p>
&lt;img src="../../../system_design_interview/index-210_1.jpg" width="66%"/>
&lt;p>让我们重新审视一下应用这两个优化后的算法的时间复杂性。&lt;/p>
&lt;ol>
&lt;li>寻找前缀节点。时间复杂度。O(1)&lt;/li>
&lt;li>返回 top k。由于 top k 查询被缓存，这一步的时间复杂度为 O(1)。由于每个步骤的时间复杂度都降低到 O(1)，我们的算法只需要 O(1)来获取 top k 查询。&lt;/li>
&lt;/ol>
&lt;p>数据收集服务&lt;/p>
&lt;p>在我们之前的设计中，每当用户键入一个搜索查询，数据就会实时更新。由于以下两个原因，这种方法并不实用。&lt;/p>
&lt;ul>
&lt;li>用户每天可能会输入数十亿次的查询。在每次查询中更新 trie 会大大减慢查询服务的速度。&lt;/li>
&lt;li>一旦建立了 trie，顶级建议可能不会有太大变化。因此，没有必要经常更新 trie。&lt;/li>
&lt;/ul>
&lt;p>为了设计一个可扩展的数据收集服务，我们研究了数据的来源和数据的使用方式。像 Twitter 这样的实时应用需要最新的自动补全建议。然而，许多谷歌关键词的自动补全建议可能每天都不会有太大变化。&lt;/p>
&lt;p>尽管用例不同，数据收集服务的底层基础仍然是相同的，因为用于建立三角形的数据通常来自分析或日志服务。&lt;/p>
&lt;p>图 13-9 显示了重新设计的数据收集服务。每个组件都被逐一检查。&lt;/p>
&lt;img src="../../../system_design_interview/index-211_1.jpg" width="77%"/>
&lt;p>分析日志。它存储关于搜索查询的原始数据。日志是只附加的，不被索引。表 13-3 显示了一个日志文件的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-211_2.jpg" width="77%"/>
&lt;p>聚合器。&lt;/p>
&lt;p>分析日志的大小通常非常大，而且数据的格式也不对。我们需要聚合数据，以便我们的系统可以轻松处理这些数据。&lt;/p>
&lt;p>根据不同的用例，我们可能会以不同的方式聚合数据。对于 Twitter 这样的实时应用，我们会在较短的时间间隔内聚合数据，因为实时结果很重要。另一方面，对于许多用例来说，聚集数据的频率较低，比如每周一次，可能就足够了。在采访过程中，验证实时结果是否重要。我们假设 Trie 每周都会重建。&lt;/p>
&lt;p>聚合的数据。&lt;/p>
&lt;p>表 13-4 显示了一个每周汇总数据的例子。&amp;ldquo;时&amp;quot;字段代表一个星期的开始时间。&amp;ldquo;频&amp;quot;字段是该周相应查询的出现次数之和。&lt;/p>
&lt;img src="../../../system_design_interview/index-212_1.jpg" width="77%"/>
&lt;p>工作者。工作者是一组服务器，以固定的时间间隔执行异步工作。他们建立 Trie 数据结构并将其存储在 Trie DB 中。&lt;/p>
&lt;p>Trie Cache。Trie Cache 是一个分布式缓存系统，它将 Trie 保存在内存中，以便快速读取。它每周对数据库进行一次快照。&lt;/p>
&lt;p>Trie DB。Trie DB 是持久性存储。有两个选项可用于存储数据。&lt;/p>
&lt;ol>
&lt;li>文件存储。由于每周都会建立一个新的 Trie，我们可以定期对其进行快照，将其序列化，并将序列化的数据存储在数据库中。像 MongoDB[4]这样的文档存储很适合序列化的数据。&lt;/li>
&lt;li>键值存储。通过应用以下逻辑，一个 trie 可以用哈希表的形式来表示 [4]。
&lt;ul>
&lt;li>trie 中的每个前缀都被映射到哈希表中的一个键。&lt;/li>
&lt;li>每个 trie 节点上的数据被映射到哈希表中的一个值。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>图 13-10 显示了 trie 和哈希表之间的映射关系。&lt;/p>
&lt;img src="../../../system_design_interview/index-213_1.jpg" width="88%"/>
&lt;p>在图 13-10 中，左边的每个 trie 节点被映射到右边的 &amp;lt;key, value&amp;gt; 对。如果你不清楚键值存储如何工作，请参考第 6 章：设计键值存储。&lt;/p>
&lt;p>查询服务&lt;/p>
&lt;p>在高层设计中，查询服务直接调用数据库来获取前 5 个结果。图 13-11 显示了改进后的设计，因为之前的设计效率很低。&lt;/p>
&lt;img src="../../../system_design_interview/index-214_1.jpg" width="66%"/>
&lt;ol>
&lt;li>一个搜索查询被发送到负载均衡器。&lt;/li>
&lt;li>负载平衡器将请求路由到 API 服务器。&lt;/li>
&lt;li>API 服务器从 Trie Cache 获得 Trie 数据，并为客户构建自动补全的建议。&lt;/li>
&lt;li>如果数据不在 Trie Cache 中，我们将数据补充回缓存中。这样一来，所有对同一前缀的后续请求都会从缓存中返回。缓存缺失可能发生在缓存服务器没有内存或离线的情况下。&lt;/li>
&lt;/ol>
&lt;p>查询服务需要快如闪电的速度。我们提出以下优化方案。&lt;/p>
&lt;ul>
&lt;li>AJAX 请求。对于网络应用，浏览器通常会发送 AJAX 请求来获取自动补全的结果。AJAX 的主要好处是，发送/接收请求/响应时不会刷新整个网页。&lt;/li>
&lt;li>浏览器缓存。对于许多应用程序，自动补全搜索建议可能不会在短时间内&lt;/li>
&lt;li>短时间内变化不大。因此，自动补全的建议可以保存在浏览器缓存中，以允许后续请求直接从缓存中获得结果。谷歌搜索引擎也使用同样的缓存机制。图 13-12 显示了当你在 Google 搜索引擎上输&amp;quot;系统设计面&amp;quot;时的响应头。正如你所看到的，Google 将结果在浏览器中缓存了 1 小时。请注意：cache-control 中&amp;quot;privat&amp;quot;意味着结果是为单个用户准备的，不能被共享缓存所缓存。&amp;ldquo;maxage=360&amp;quot;意味着缓存的有效期为 3600 秒，也就是一个小时。&lt;/li>
&lt;li>数据采样。对于一个大规模的系统，记录每个搜索查询需要大量的处理能力和存储。数据采样很重要。例如，每 N 个请求中只有 1 个被系统记录下来。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-215_1.jpg" width="88%"/>
&lt;p>Trie 操作&lt;/p>
&lt;p>Trie 是自动补全系统的一个核心组成部分。让我们来看看 Trie 操作（创建、更新和删除）是如何工作的。&lt;/p>
&lt;p>创建&lt;/p>
&lt;p>Trie 是由工人使用聚合的数据创建的。数据的来源是来自分析日志/数据库。&lt;/p>
&lt;p>更新&lt;/p>
&lt;p>有两种方法来更新 trie。&lt;/p>
&lt;p>选项 1：每周更新 trie。一旦一个新的 trie 被创建，新的 trie 将取代旧的 trie。&lt;/p>
&lt;p>选项 2：直接更新单个 trie 节点。我们尽量避免这种操作，因为它很慢。然而，如果 trie 的大小较小，它是一个可以接受的解决方案。当我们更新一个 trie 节点时，它的祖先一直到根都必须被更新，因为祖先存储了子节点的顶级查询。图 13-13 显示了一个更新操作的例子。在左边，搜索查&amp;quot;啤&amp;quot;的原始值是 10。在右边，它被更新为 30。正如你所看到的，该节点和它的祖先&amp;quot;啤&amp;quot;值被更新为 30。&lt;/p>
&lt;img src="../../../system_design_interview/index-216_1.jpg" width="88%"/>
&lt;p>删除&lt;/p>
&lt;p>我们必须删除仇恨的、暴力的、色情的、或危险的自动补全建议。我们在 Trie Cache 前面添加一个过滤层（图 13-14）来过滤掉不需要的建议。有了过滤层，我们就可以根据不同的过滤规则灵活地删除结果。不需要的建议被异步地从数据库中移除，这样正确的数据集将在下一个更新周期中被用于构建 Trie。&lt;/p>
&lt;img src="../../../system_design_interview/index-216_2.jpg" width="66%"/>
&lt;p>扩展存储&lt;/p>
&lt;p>现在我们已经开发了一个将自动补全查询带给用户的系统，是时候解决当 trie 增长到无法在一台服务器中容纳时的可扩展性问题了。&lt;/p>
&lt;p>由于英语是唯一被支持的语言，一种天真的分片方式是基于第一个字符。下面是一些例子。&lt;/p>
&lt;ul>
&lt;li>如果我们需要两台服务器来存储，我们可以在第一台服务器上存储从&amp;rsquo;a&amp;rsquo;到&amp;rsquo;m&amp;rsquo;的查询，而在第二台服务器上存储&amp;rsquo;n&amp;rsquo;到&amp;rsquo;z&amp;rsquo;的查询。&lt;/li>
&lt;li>如果我们需要三台服务器，我们可以把查询分成&amp;rsquo;a&amp;rsquo;到&amp;rsquo;i&amp;rsquo;，&amp;lsquo;j&amp;rsquo;到&amp;rsquo;r&amp;rsquo;，&amp;rsquo;s&amp;rsquo;到&amp;rsquo;z&amp;rsquo;。&lt;/li>
&lt;/ul>
&lt;p>按照这个逻辑，我们可以将查询分成 26 个服务器，因为英语中有 26 个字母。让我们把基于第一个字符的分片定义为第一层分片。要存储超过 26 个服务器的数据，我们可以在第二层甚至第三层进行分片。例如，以&amp;rsquo;a&amp;rsquo;开头的数据查询可以分成 4 个服务器：&amp;lsquo;aa-ag&amp;rsquo;、&amp;lsquo;ahan&amp;rsquo;、&amp;lsquo;ao-au&amp;rsquo;和&amp;rsquo;av-az&amp;rsquo;。&lt;/p>
&lt;p>乍一看，这种方法似乎很合理，直到你意识到，以字母&amp;rsquo;c&amp;rsquo;开头的单词比&amp;rsquo;x&amp;rsquo;多得多。这就造成了分布不均。为了缓解数据不平衡问题，我们分析了历史数据分布模式，并应用了更智能的分片逻辑，如图 13-15 所示。分片地图管理器维护着一个查找数据库，用于识别行应该被存储在哪里。例如，如果&amp;quot;u&amp;rdquo;、&amp;ldquo;v&amp;rdquo;、&amp;ldquo;w&amp;rdquo;、&amp;ldquo;x&amp;quot;的历史查询数量相似，我们可以维护两个分片：一个用&amp;quot;s&amp;rdquo;，另一个用&amp;rdquo;&amp;ldquo;&amp;ldquo;z&amp;rdquo;。&lt;/p>
&lt;img src="../../../system_design_interview/index-217_1.jpg" width="66%"/>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在你完成深层研究后，你的面试官可能会问你一些后续问题。&lt;/p>
&lt;p>面试官：你如何扩展你的设计以支持多语言？&lt;/p>
&lt;p>为了支持其他非英语的查询，我们在 trie 节点中存储 Unicode 字符。如果你对 Unicode 不熟悉，这里有一个定义。&amp;ldquo;一个编码标准涵盖了世界上所有书写系统的所有字符，包括现代和古代的&amp;rdquo;[5]。&lt;/p>
&lt;p>采访者。如果一个国家的顶级搜索查询与其他国家不同怎么办？&lt;/p>
&lt;p>在这种情况下，我们可能会为不同国家建立不同的尝试。为了提高响应时间，我们可以将尝试存储在 CDN 中。&lt;/p>
&lt;p>采访者。我们如何支持趋势性（实时）的搜索查询？&lt;/p>
&lt;p>假设一个新闻事件爆发了，一个搜索查询突然变得很流行。我们原来的设计将无法工作，因为。&lt;/p>
&lt;ul>
&lt;li>离线工人还没有被安排更新 Trie，因为这被安排在每周的基础上运行。&lt;/li>
&lt;li>即使它被安排了，也需要太长的时间来建立三角形。&lt;/li>
&lt;/ul>
&lt;p>构建实时搜索自动补全系统很复杂，超出了本书的范围，所以我们只给出一些想法。&lt;/p>
&lt;ul>
&lt;li>通过分片减少工作数据集。&lt;/li>
&lt;li>改变排名模型，给最近的搜索查询分配更多的权重。&lt;/li>
&lt;li>数据可能以流的形式出现，所以我们不能一次就获得所有的数据。流式数据意味着数据是连续产生的。流处理需要一套不同的系统。Apache Hadoop MapReduce [6], Apache Spark Streaming [7], Apache Storm[8]、Apache Kafka [9]等。因为所有这些主题都需要特定的领域知识，所以我们在此不做详述。&lt;/li>
&lt;/ul>
&lt;p>恭喜你走到这一步! 现在给自己拍拍背吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1] &lt;a href="https://www.facebook.com/notes/facebookengineering/the-life-of-a-typeahead-query/389105248919/">The Life of a Typeahead Query&lt;/a>&lt;br>
[2] &lt;a href="https://medium.com/@prefixyteam/how-we-built-prefixy-a-scalable-prefix-search-servicefor-powering-autocomplete-c20f98e2eff1">How We Built Prefixy: A Scalable Prefix Search Service for Powering Autocomplete&lt;/a>&lt;br>
[3] &lt;a href="https://people.eecs.berkeley.edu/~sylvia/papers/pht.pdf">Prefix Hash Tree An Indexing Data Structure over Distributed Hash Tables&lt;/a>&lt;br>
[4] &lt;a href="https://en.wikipedia.org/wiki/MongoDB">MongoDB wikipedia&lt;/a>&lt;br>
[5] &lt;a href="https://www.unicode.org/faq/basic_q.html">Unicode frequently asked questions&lt;/a>&lt;br>
[6] &lt;a href="https://hadoop.apache.org/">Apache hadoop&lt;/a>&lt;br>
[7] &lt;a href="https://spark.apache.org/streaming/">Spark streaming&lt;/a>&lt;br>
[8] &lt;a href="https://storm.apache.org/">Apache storm&lt;/a>&lt;br>
[9] &lt;a href="https://kafka.apache.org/documentation/">Apache kafka&lt;/a>&lt;/p></description></item><item><title>系统设计::设计一个聊天系统</title><link>/system_design/system_design_interview_12/</link><pubDate>Fri, 12 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_12/</guid><description>&lt;h2 id="设计一个聊天系统">设计一个聊天系统&lt;/h2>
&lt;p>在这一章中，我们探讨了一个聊天系统的设计。几乎每个人都在使用一个聊天应用程序。图 12-1 显示了市场上一些最流行的应用程序。&lt;/p>
&lt;img src="../../../system_design_interview/index-178_1.jpg" width="80%"/>
&lt;p>聊天应用程序对不同的人执行不同的功能。敲定确切的要求是极其重要的。例如，当面试官想到一对一的聊天时，您不希望设计一个专注于群组聊天的系统。探索功能要求是很重要的。&lt;/p>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>就要设计的聊天应用程序的类型达成一致是至关重要的。在市场上，有像 Facebook Messenger、微信和 WhatsApp 这样一对一的聊天应用，也有像 Slack 这样专注于群组聊天的办公聊天应用，或者像 Discord 这样专注于大型群组互动和低语音聊天延迟的游戏聊天应用。&lt;/p>
&lt;p>第一组澄清问题应该明确面试官要求你设计一个聊天系统时，她心里想的到底是什么。至少要弄清楚你是应该专注于一对一的聊天还是群组聊天应用。你可以问以下一些问题。&lt;/p>
&lt;p>应聘者：我们应该设计什么样的聊天应用程序？一对一还是基于群组？&lt;br>
面试官：它应该同时支持 1 对 1 和群组聊天。&lt;br>
应聘者：这是一个移动应用吗？还是网络应用？或者两者都是？&lt;br>
面试官：都是。&lt;br>
应聘者：这个应用程序的规模是多少？是创业公司的应用还是大规模的？&lt;br>
面试官：它应该支持 5000 万日活跃用户（DAU）。&lt;br>
应聘者：对于群组聊天，群组成员的限制是什么？&lt;br>
面试官：最多 100 人&lt;br>
应聘者：聊天软件的哪些功能很重要？能否支持附件？&lt;br>
面试官：1 对 1 聊天，群聊，在线指标。系统只支持文字信息。&lt;br>
应聘者：信息大小有限制吗？&lt;br>
面试官：是的。是的，文本长度应小于 10 万个字符。&lt;br>
应聘者：是否需要端对端加密？&lt;br>
面试官：不需要。目前不需要，但如果时间允许，我们会讨论这个问题。&lt;br>
应聘者：我们应将聊天记录保存多长时间？&lt;br>
面试官：永远。&lt;/p>
&lt;p>在这一章中，我们将重点设计一个类似于 Facebook messenger 的聊天应用，并强调以下特点。&lt;/p>
&lt;ul>
&lt;li>一对一的聊天，传递延迟低&lt;/li>
&lt;li>小型群组聊天（最多 100 人）。&lt;/li>
&lt;li>显示在线&lt;/li>
&lt;li>支持多种设备。同一账户可以同时登录多个账户。&lt;/li>
&lt;li>推送通知&lt;/li>
&lt;/ul>
&lt;p>就设计规模达成一致也很重要。我们将设计一个支持 5000 万 DAU 的系统。&lt;/p>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>为了开发一个高质量的设计，我们应该对客户和服务器的通信方式有一个基本的了解。在一个聊天系统中，客户端可以是移动应用程序或 Web 应用程序。客户端之间并不直接交流。相反，每个客户端都连接到一个聊天服务，它支持上面提到的所有功能。让我们专注于基本操作。聊天服务必须支持以下功能。&lt;/p>
&lt;ul>
&lt;li>接收来自其他客户的消息。&lt;/li>
&lt;li>为每条消息寻找合适的收件人，并将消息转发给收件人。&lt;/li>
&lt;li>如果收件人不在线，在服务器上保留该收件人的消息，直到她在线。&lt;/li>
&lt;/ul>
&lt;p>图 12-2 显示了客户端（发送者和接收者）和聊天服务之间的关系。&lt;/p>
&lt;img src="../../../system_design_interview/index-180_1.jpg" width="60%"/>
&lt;p>当客户打算开始聊天时，它使用一个或多个网络协议连接到聊天服务。对于一个聊天服务，网络协议的选择很重要。让我们与面试官讨论一下这个问题。&lt;/p>
&lt;p>对于大多数客户/服务器应用程序，请求是由客户发起的。对于聊天应用程序的发送方来说也是如此。在图 12-2 中，当发送方通过聊天服务向接收方发送消息时，它使用经过时间考验的 HTTP 协议，这是最常见的网络协议。在这种情况下，客户端打开与聊天服务的 HTTP 连接并发送消息，通知服务将消息发送给接收方。keep-alive 对此很有效，因为 keep-alive 头允许客户端与聊天服务保持持久的连接。它也减少了 TCP 握手的次数。HTTP 在发送方是一个很好的选择，许多流行的聊天应用程序，如 Facebook[1]最初使用 HTTP 来发送消息。&lt;/p>
&lt;p>然而，接收方就比较复杂了。由于 HTTP 是由客户发起的，所以从服务器上发送消息并不是一件小事。多年来，许多技术被用来模拟服务器发起的连接：轮询、长轮询和 WebSocket。这些都是在系统设计访谈中广泛使用的重要技术，所以让我们逐一检查一下&lt;/p>
&lt;h4 id="轮询">轮询&lt;/h4>
&lt;p>如图 12-3 所示，轮询是一种技术，客户端定期询问服务器是否有消息可用。根据轮询的频率，轮询的成本可能很高。它可能会消耗宝贵的服务器资源来回答一个大部分时间都没有答案的问题。&lt;/p>
&lt;img src="../../../system_design_interview/index-181_1.jpg" width="80%"/>
&lt;h4 id="长轮询">长轮询&lt;/h4>
&lt;p>因为轮询可能是低效的，接下来的进展是长轮询（图 12-4）。&lt;/p>
&lt;img src="../../../system_design_interview/index-182_1.jpg" width="80%"/>
&lt;p>在长期轮询中，客户端保持连接开放，直到有实际可用的新消息或达到一个超时阈值。一旦客户端收到新消息，它立即向服务器发送另一个请求，重新启动这个过程。长时间轮询有一些缺点。&lt;/p>
&lt;ul>
&lt;li>发送者和接收者可能不会连接到同一个聊天服务器。基于 HTTP 的服务器通常是无状态的。如果您使用轮询进行负载平衡，接收信息的服务器可能没有与接收信息的客户端建立长轮询连接。&lt;/li>
&lt;li>服务器没有很好的方法来告诉客户是否断开了连接。&lt;/li>
&lt;li>这是很低效的。如果一个用户不怎么聊天，长轮询仍然会在超时后进行定期连接。&lt;/li>
&lt;/ul>
&lt;h4 id="websocket">WebSocket&lt;/h4>
&lt;p>WebSocket 是从服务器向客户端发送异步更新的最常见解决方案。图 12-5 显示了它的工作原理。&lt;/p>
&lt;img src="../../../system_design_interview/index-183_1.jpg" width="70%"/>
&lt;p>WebSocket 连接是由客户端发起的。它是双向的和持久的。它以 HTTP 连接的形式开始，并可通过一些定义明确的握手方式 &amp;ldquo;升级 &amp;ldquo;为 WebSocket 连接。通过这种持久的连接，服务器可以向客户端发送更新。即使有防火墙，WebSocket 连接通常也能工作。这是因为它们使用 80 或 443 端口，这些端口也被 HTTP/HTTPS 连接使用。&lt;/p>
&lt;p>前面我们说过，在发送方，HTTP 是一个很好的协议，但由于 WebSocket 是双向的，所以没有充分的技术理由不使用它来发送。图 12-6 显示了 WebSockets（ws）在发送方和接收方的使用情况。&lt;/p>
&lt;img src="../../../system_design_interview/index-183_2.jpg" width="60%"/>
&lt;p>通过使用 WebSocket 进行发送和接收，它简化了设计，并使客户端和服务器上的实现更加直接。由于 WebSocket 连接是持久的，因此有效的连接管理在服务器端至关重要。&lt;/p>
&lt;h4 id="高层设计">高层设计&lt;/h4>
&lt;p>刚才我们提到，选择 WebSocket 作为客户端和服务器之间的主要通信协议，是因为它的双向通信，需要注意的是，其他一切都不一定是 WebSocket。事实上，聊天应用程序的大多数功能（注册、登录、用户资料等）都可以使用 HTTP 上的传统请求/响应方法。让我们深入了解一下，看看系统的高级组件。&lt;/p>
&lt;p>如图 12-7 所示，聊天系统被分成三大类：无状态服务、有状态服务和第三方集成。&lt;/p>
&lt;img src="../../../system_design_interview/index-184_1.jpg" width="60%"/>
&lt;p>无状态服务&lt;/p>
&lt;p>无状态服务是传统的面向公众的请求/响应服务，用于管理登录、注册、用户资料等。这些是许多网站和应用程序的共同特征。&lt;/p>
&lt;p>无状态服务位于负载均衡器后面，其工作是根据请求路径将请求路由到正确的服务。这些服务可以是单体的，也可以是单独的微服务。我们不需要自己建立许多这样的无状态服务，因为市场上有一些服务可以很容易地被整合。我们将深入讨论的一个服务是服务发现。它的主要工作是给客户提供一个客户可以连接到的聊天服务器的 DNS 主机名列表。&lt;/p>
&lt;p>有状态的服务&lt;/p>
&lt;p>唯一有状态的服务是聊天服务。该服务是有状态的，因为每个客户都与聊天服务器保持持久的网络连接。在这个服务中，只要服务器仍然可用，客户端通常不会切换到另一个聊天服务器。服务发现与聊天服务密切协调，以避免服务器过载。我们将在深入研究中详细介绍。&lt;/p>
&lt;p>第三方整合&lt;/p>
&lt;p>对于一个聊天应用程序，推送通知是最重要的第三方整合。它是一种在新消息到来时通知用户的方式，即使应用程序没有运行。正确整合推送通知是至关重要的。更多信息请参考第 10 章 设计一个通知系统。&lt;/p>
&lt;p>可扩展性&lt;/p>
&lt;p>在小规模的情况下，上面列出的所有服务都可以装在一台服务器中。即使在我们设计的规模下，理论上也可以在一台现代云服务器中容纳所有的用户连接。一台服务器所能处理的并发连接数很可能是限制性因素。在我们的方案中，在 100 万并发用户的情况下，假设每个用户连接在服务器上需要 10K 的内存（这是一个非常粗略的数字，非常依赖于语言的选择），它只需要大约 10GB 的内存来容纳所有的连接在一个盒子上。&lt;/p>
&lt;p>如果我们提出一个所有东西都装在一台服务器上的设计，这可能会在面试官心中引起很大的反响。没有技术专家会在一台服务器中设计这样的规模。由于许多因素，单台服务器的设计是一个失败者。单一的故障点是其中最大的。&lt;/p>
&lt;p>然而，从单服务器设计开始是完全可以的。只要确保面试官知道这是个起点。把我们提到的一切放在一起，图 12-8 显示了调整后的高层设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-186_1.jpg" width="60%"/>
&lt;p>在图 12-8 中，客户端与聊天服务器保持一个持久的 WebSocket 连接，以进行实时消息传递。&lt;/p>
&lt;ul>
&lt;li>聊天服务器促进消息的发送/接收。&lt;/li>
&lt;li>存在感服务器管理在线/离线状态。&lt;/li>
&lt;li>API 服务器处理一切，包括用户登录、注册、更改资料等。&lt;/li>
&lt;li>通知服务器发送推送通知。&lt;/li>
&lt;li>最后，键值存储用于存储聊天历史。当一个离线用户上线时，她会看到她之前所有的聊天历史。&lt;/li>
&lt;/ul>
&lt;p>存储&lt;/p>
&lt;p>在这一点上，我们已经准备好了服务器，服务已经开始运行，第三方集成已经完成。在技术栈的深处是数据层。数据层通常需要一些努力才能得到正确的结果。我们必须做出的一个重要决定是决定使用正确的数据库类型：关系型数据库还是 NoSQL 数据库？为了做出一个明智的决定，我们将研究数据类型和读/写模式。&lt;/p>
&lt;p>在典型的聊天系统中存在两种数据类型。第一类是通用数据，如用户资料、设置、用户朋友列表。这些数据被存储在强大而可靠的关系数据库中。复制和分片是满足可用性和可扩展性要求的常用技术。&lt;/p>
&lt;p>第二种是聊天系统特有的：聊天历史数据。了解读/写模式很重要。&lt;/p>
&lt;ul>
&lt;li>聊天系统的数据量是巨大的。之前的一项研究[2]显示，Facebook messenger 和 Whatsapp 每天处理 600 亿条信息。&lt;/li>
&lt;li>只有最近的聊天记录被频繁访问。用户通常不会去查找旧的聊天记录。&lt;/li>
&lt;li>虽然在大多数情况下都会查看最近的聊天记录，但用户可能会使用需要随机访问数据的功能，如搜索、查看你提到的信息、跳转到特定的信息等。这些情况应该由数据访问层来支持。&lt;/li>
&lt;li>对于 1 对 1 的聊天应用程序，读与写的比例约为 1:1。&lt;/li>
&lt;/ul>
&lt;p>选择正确的存储系统，支持我们所有的用例是至关重要的。我们推荐键值存储，理由如下。&lt;/p>
&lt;ul>
&lt;li>键值存储允许轻松地进行横向扩展。&lt;/li>
&lt;li>键值存储为访问数据提供了非常低的延时。&lt;/li>
&lt;li>关系型数据库不能很好地处理长尾[3]的数据。当索引变大时，随机访问是很昂贵的。&lt;/li>
&lt;li>键值存储被其他被证明可靠的聊天应用程序所采用。例如，Facebook Messager和 Discord 都使用键值存储。Facebook Messager使用 HBase[4]，而 Discord 使用 Cassandra[5]。&lt;/li>
&lt;/ul>
&lt;p>数据模型&lt;/p>
&lt;p>刚才，我们谈到了使用键值存储作为我们的存储层。最重要的数据是消息数据。让我们仔细看一下。&lt;/p>
&lt;p>1 对 1 聊天的消息表 图 12-9 显示了 1 对 1 聊天的消息表。主键是 message_id，它有助于决定消息序列。我们不能依靠 created_at 来决定消息的顺序，因为两条消息可能同时被创建。&lt;/p>
&lt;img src="../../../system_design_interview/index-188_1.jpg" width="40%"/>
&lt;p>群聊的消息表&lt;/p>
&lt;p>图 12-10 显示了群聊的消息表。复合主键是（channel_id, message_id）。channel 和 group 在这里代表相同的含义。 channel_id 是分区键，因为群聊中的所有查询都在一个频道中操作。&lt;/p>
&lt;img src="../../../system_design_interview/index-188_2.jpg" width="40%"/>
&lt;p>消息 ID&lt;/p>
&lt;p>如何生成 message_id 是一个值得探索的有趣话题。Message_id 承担着确保消息顺序的责任。为了确定消息的顺序，message_id 必须满足以下两个要求。&lt;/p>
&lt;ul>
&lt;li>ID 必须是唯一的。&lt;/li>
&lt;li>ID 应该是可以按时间排序的，也就是说，新行的 ID 比旧行的 ID 高。&lt;/li>
&lt;/ul>
&lt;p>我们怎样才能实现这两个保证呢？我想到的第一个想法是 MySql 中的 &amp;ldquo;auto_increment &amp;ldquo;关键字。然而，NoSQL 数据库通常不提供这样的功能。&lt;/p>
&lt;p>第二个方法是使用一个全局性的 64 位序列号生成器，如 Snowflake[6]。这将在 &amp;ldquo;第七章：在分布式系统中设计一个唯一的 ID 生成器 &amp;ldquo;中讨论。&lt;/p>
&lt;p>最后一种方法是使用本地序列号生成器。本地意味着 ID 只在一个组内是唯一的。本地 ID 发挥作用的原因是，在一对一的信道或一个组的信道内维持消息序列就足够了。与全局 ID 的实现相比，这种方法更容易实现。&lt;/p>
&lt;h3 id="深究设计">深究设计&lt;/h3>
&lt;p>在系统设计面试中，通常希望你能深入了解高层设计中的一些组件。对于聊天系统，服务发现、消息流和在线/离线指标值得深入探讨。&lt;/p>
&lt;h4 id="服务发现">服务发现&lt;/h4>
&lt;p>服务发现的主要作用是根据地理位置、服务器容量等标准，为客户推荐最佳的聊天服务器。Apache Zookeeper [7] 是一个流行的服务发现开源解决方案。它注册了所有可用的聊天服务器，并根据预定义的标准为客户挑选最佳聊天服务器。&lt;/p>
&lt;p>图 12-11 显示了服务发现（Zookeeper）如何工作。&lt;/p>
&lt;img src="../../../system_design_interview/index-190_1.jpg" width="60%"/>
&lt;ol>
&lt;li>用户 A 试图登录到应用程序。&lt;/li>
&lt;li>负载均衡器将登录请求发送到 API 服务器。&lt;/li>
&lt;li>在后端认证用户后，服务发现为用户 A 找到最佳的聊天服务器。在这个例子中，服务器 2 被选中，服务器信息被返回给用户 A。&lt;/li>
&lt;li>用户 A 通过 WebSocket 连接到聊天服务器 2。&lt;/li>
&lt;/ol>
&lt;h4 id="消息流">消息流&lt;/h4>
&lt;p>了解一个聊天系统的端到端流程是很有意思的。在本节中，我们将探讨 1 对 1 的聊天流程、跨多个设备的信息同步和群组聊天流程。&lt;/p>
&lt;p>1 对 1 数据流&lt;/p>
&lt;p>图 12-12 解释了当用户 A 向用户 B 发送消息时发生的情况。&lt;/p>
&lt;img src="../../../system_design_interview/index-191_1.jpg" width="60%"/>
&lt;ol>
&lt;li>用户 A 向聊天服务器 1 发送一个聊天信息。&lt;/li>
&lt;li>聊天服务器 1 从 ID 生成器中获得一个消息 ID。&lt;/li>
&lt;li>聊天服务器 1 将消息发送到消息同步队列中。&lt;/li>
&lt;li>消息被存储在一个键值存储器中。&lt;/li>
&lt;li>如果用户 B 在线，该消息被转发到用户 B 连接的聊天服务器 2。&lt;/li>
&lt;li>聊天服务器 2 将消息转发给用户 B。用户 B 和聊天服务器 2 之间有一个持久的 WebSocket 连接。&lt;/li>
&lt;/ol>
&lt;p>多个设备间的信息同步&lt;/p>
&lt;p>许多用户有多个设备。我们将解释如何在多个设备上同步消息。图 12-13 显示了一个消息同步的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-192_1.jpg" width="60%"/>
&lt;p>在图 12-13 中，用户 A 有两台设备：一台手机和一台笔记本电脑。当用户 A 用手机登录聊天应用程序时，它与聊天服务器 1 建立了一个 WebSocket 连接。同样地，笔记本电脑和聊天服务器 1 之间也有一个连接。&lt;/p>
&lt;p>每个设备都维护着一个名为 cur_max_message_id 的变量，它记录着设备上最新的消息 ID。满足以下两个条件的消息被认为是新闻消息。&lt;/p>
&lt;ul>
&lt;li>收件人 ID 等于当前登录的用户 ID。&lt;/li>
&lt;li>键值存储中的消息 ID 大于 cur_max_message_id 。&lt;/li>
&lt;/ul>
&lt;p>由于每个设备上都有不同的 cur_max_message_id，消息同步很容易，因为每个设备都可以从 KV 存储中获得新消息。&lt;/p>
&lt;p>小群组聊天流程&lt;/p>
&lt;p>与一对一的聊天相比，群组聊天的逻辑更复杂。图 12-14 和 12-15 解释了该流程。&lt;/p>
&lt;img src="../../../system_design_interview/index-193_1.jpg" width="60%"/>
&lt;p>图 12-14 解释了用户 A 在群聊中发送消息时发生的情况。假设群里有 3 个成员（用户 A、用户 B 和用户 C）。首先，用户 A 的消息被复制到每个组员的消息同步队列中：一个给用户 B，另一个给用户 C。你可以把消息同步队列看成是一个收件人的收件箱。这种设计选择对小型群组聊天来说是很好的，因为。&lt;/p>
&lt;ul>
&lt;li>它简化了消息同步的流程，因为每个客户只需要检查自己的收件箱就可以得到新的消息。&lt;/li>
&lt;li>当群组人数较少时，在每个接收者的收件箱中存储一份副本不会太昂贵。&lt;/li>
&lt;/ul>
&lt;p>微信使用类似的方法，它将一个群组限制在 500 个成员[8]。然而，对于有大量用户的群组，为每个成员存储一份信息副本是不可接受的。&lt;/p>
&lt;p>在收件人方面，一个收件人可以接收来自多个用户的信息。每个收件人都有一个收件箱（消息同步队列），其中包含来自不同发送者的消息。图 12-15 说明了这种设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-194_1.jpg" width="60%"/>
&lt;p>显示在线&lt;/p>
&lt;p>在线状态指示器是许多聊天应用程序的一个基本功能。通常情况下，您可以在用户的个人照片或用户名旁边看到一个绿点。本节解释幕后发生的事情。&lt;/p>
&lt;p>在高层设计中，在场服务器负责管理在线状态，并通过 WebSocket 与客户进行沟通。有几个流程会触发在线状态的变化。让我们来看看它们中的每一个。&lt;/p>
&lt;p>用户登录&lt;/p>
&lt;p>用户登录流程在 &amp;ldquo;服务发现 &amp;ldquo;部分进行了解释。在客户端和实时服务之间建立 WebSocket 连接后，用户 A 的在线状态和最后活动时间戳被保存在 KV 存储中。在场指示器显示用户在登录后处于在线状态。&lt;/p>
&lt;img src="../../../system_design_interview/index-194_2.jpg" width="60%"/>
&lt;p>用户登出&lt;/p>
&lt;p>当一个用户注销时，会经过用户注销流程，如图 12-17 所示。在线状态在 KV 存储中被改变为离线。存在指示器显示一个用户是离线的。&lt;/p>
&lt;img src="../../../system_design_interview/index-195_1.jpg" width="80%"/>
&lt;p>用户断线&lt;/p>
&lt;p>我们都希望我们的互联网连接是一致和可靠的。然而，情况并非总是如此；因此，我们必须在设计中解决这个问题。当用户从互联网上断开连接时，客户端和服务器之间的持久性连接就会丢失。处理用户断开连接的一个天真的方法是将用户标记为离线，并在连接重新建立时将其状态改为在线。然而，这种方法有一个重大缺陷。用户在短时间内频繁地断开和重新连接到互联网是很常见的。例如，当用户通过隧道时，网络连接可能会打开和关闭。在每次断开/重新连接时更新在线状态会使存在指标变化得过于频繁，导致用户体验不佳。&lt;/p>
&lt;p>我们引入一个心跳机制来解决这个问题。定期地，一个在线的客户端向在场服务器发送一个心跳事件。如果存在服务器在一定时间内收到心跳事件，比如说来自客户端的 X 秒，那么用户就被认为是在线的。否则，它就处于离线状态。&lt;/p>
&lt;p>在图 12-18 中，客户端每 5 秒向服务器发送一个心跳事件。在发送了 3 个心跳事件后，客户端被断开连接，并且在 x=30 秒内没有重新连接（这个数字是任意选择的，以显示逻辑）。在线状态被改变为离线。&lt;/p>
&lt;img src="../../../system_design_interview/index-196_1.jpg" width="80%"/>
&lt;p>在线状态 fanout&lt;/p>
&lt;p>用户 A 的朋友如何知道状态变化？图 12-19 解释了它是如何工作的。存在服务器使用一个发布-订阅模型，其中每个朋友对维护一个频道。当用户 A 的在线状态改变时，它将事件发布到三个频道，即频道 A-B、A-C 和 A-D。这三个频道分别由用户 B、C 和 D 订阅。因此，朋友们很容易得到在线状态的更新。客户端和服务器之间的通信是通过实时 WebSocket。&lt;/p>
&lt;img src="../../../system_design_interview/index-196_2.jpg" width="80%"/>
&lt;p>上述设计对小规模的用户群是有效的。例如，微信使用类似的方法，因为它的用户群上限为 500 人。对于较大的群组，通知所有成员的在线状态是昂贵和耗时的。假设一个群有 100,000 个成员。每一个状态变化将产生 100,000 个事件。为了解决性能瓶颈，一个可能的解决方案是只在用户进入群组或手动刷新好友列表时获取在线状态。&lt;/p>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在本章中，我们介绍了一个聊天系统架构，它支持 1 对 1 的聊天和小群组聊天。WebSocket 用于客户端和服务器之间的实时通信。聊天系统包含以下组件：用于实时消息传递的聊天服务器、用于管理在线存在的存在服务器、用于发送推送通知的推送通知服务器、用于聊天历史持久性的键值存储以及用于其他功能的 API 服务器。&lt;/p>
&lt;p>如果你在采访结束时有多余的时间，这里有额外的谈话要点。&lt;/p>
&lt;ul>
&lt;li>扩展聊天应用程序以支持媒体文件，如照片和视频。媒体文件的大小明显大于文本。压缩、云存储和缩略图是有趣的话题，可以谈一谈。&lt;/li>
&lt;li>端到端加密。Whatsapp 支持信息的端到端加密。只有发件人和收件人可以阅读信息。有兴趣的读者可以参考参考资料中的文章[9]。&lt;/li>
&lt;li>在客户端缓存消息，可以有效减少客户端和服务器之间的数据传输。&lt;/li>
&lt;li>提高加载时间。Slack 建立了一个地理分布的网络来缓存用户的数据、频道等，以提高加载时间[10]。&lt;/li>
&lt;li>错误处理。
&lt;ul>
&lt;li>聊天服务器的错误。一个聊天服务器可能有几十万，甚至更多的持续连接。如果一个聊天服务器离线，服务发现（Zookeeper）会提供一个新的聊天服务器，让客户建立新的连接。&lt;/li>
&lt;li>消息重发机制。重试和排队是重新发送消息的常用技术。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>恭喜你走到这一步! 现在给自己拍拍屁股吧。干得好!&lt;/p>
&lt;h3 id="参考材料">参考材料&lt;/h3>
&lt;p>[1] &lt;a href="https://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf">Erlang at Facebook&lt;/a>&lt;br>
[2] &lt;a href="https://www.theverge.com/2016/4/12/11415198/facebook-messenger-whatsapp-numbermessages-vs-sms-f8-2016">Messenger and WhatsApp process 60 billion messages a day&lt;/a>&lt;br>
[3] &lt;a href="https://en.wikipedia.org/wiki/Long_tail">Long tail&lt;/a>&lt;br>
[4] &lt;a href="https://www.facebook.com/notes/facebookengineering/the-underlying-technology-of-messages/454991608919/">The Underlying Technology of Messages&lt;/a>&lt;br>
[5] &lt;a href="https://blog.discordapp.com/how-discordstores-billions-of-messages-7fa6ec7ee4c7">How Discord Stores Billions of Messages&lt;/a>&lt;br>
[6] &lt;a href="https://blog.twitter.com/engineering/en_us/a/2010/announcingsnowflake.html">Announcing Snowflake&lt;/a>&lt;br>
[7] &lt;a href="https://zookeeper.apache.org/">Apache ZooKeeper&lt;/a>&lt;br>
[8] &lt;a href="https://www.infoq.cn/article/the-road-of-the-growth-weixin-background">From nothing: the evolution of WeChat background system (Article in Chinese)&lt;/a>&lt;br>
[9] &lt;a href="https://faq.whatsapp.com/en/android/28030015/">End-to-end encryption&lt;/a>&lt;br>
[10] &lt;a href="https://slack.engineering/flannel-an-application-level-edge-cache-to-make-slack-scaleb8a6400e2f6b">Flannel: An Application-Level Edge Cache to Make Slack Scale&lt;/a>&lt;/p></description></item><item><title>系统设计::设计一个新闻源系统</title><link>/system_design/system_design_interview_11/</link><pubDate>Thu, 11 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_11/</guid><description>&lt;h2 id="设计一个新闻源系统">设计一个新闻源系统&lt;/h2>
&lt;p>在本章中，你被要求设计一个新闻源系统。什么是新闻源？根据 Facebook 的帮助页面，&amp;ldquo;新闻源是在你的主页中间不断更新的故事列表。新闻提要包括状态更新、照片、视频、链接、应用活动，以及你在 Facebook 上关注的人、网页和团体的喜欢&amp;rdquo;[1]。这是一个流行的面试问题。经常被问到的类似问题有：设计 Facebook 的新闻提要，Instagram 的提要，Twitter 的时间线，等等。&lt;/p>
&lt;img src="../../../system_design_interview/index-166_1.jpg" width="40%"/>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>第一组澄清问题是为了了解当面试官要求你设计一个新闻源系统时，她的想法是什么。最起码，你应该弄清楚要支持哪些功能。下面是一个应聘者与面试官互动的例子。&lt;/p>
&lt;p>应聘者：这是一个移动应用程序吗？还是一个网络应用？或者两者都是？
面试官：都是
应聘者：有哪些重要的功能？
面试官：用户可以发布帖子，并在新闻源页面上看到她朋友的帖子。
应聘者：新闻源是按照逆时针顺序还是任何特定的顺序排序的，比如话题得分？比如说，你的亲密朋友的帖子得分更高。
面试官：为了简单起见，我们假设新闻源是按逆时针顺序排序的。
应聘者：一个用户可以有多少个朋友？
面试官：5000
应聘者：流量是多少？
面试官：1000 万 DAU
应聘者：新闻源可以包含图片、视频，还是只有文字？
面试官：可以。它可以包含媒体文件，包括图片和视频。&lt;/p>
&lt;p>现在你已经收集了需求，我们把重点放在设计系统上。&lt;/p>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>该设计分为两个流程：新闻发布和新闻源构建。&lt;/p>
&lt;ul>
&lt;li>新闻发布：当一个用户发布了一个帖子，相应的数据被写入缓存和数据库。一个帖子被填充到她朋友的新闻源中。&lt;/li>
&lt;li>新闻源构建：为简单起见，我们假设新闻源是通过将朋友的帖子按逆时针顺序聚合而构建的。&lt;/li>
&lt;/ul>
&lt;h4 id="新闻源-api">新闻源 API&lt;/h4>
&lt;p>新闻源 API 是客户端与服务器通信的主要方式。这些 API 是基于 HTTP 的，允许客户端执行操作，其中包括发布状态、检索新闻源、添加朋友等。我们讨论两个最重要的 API：Feed publishing API 和 News Feed retrieval API。&lt;/p>
&lt;p>Feed publishing API 要发布一个帖子，将向服务器发送一个 HTTP POST 请求。该 API 显示如下。&lt;/p>
&lt;p>&lt;code>POST /v1/me/feed&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Params:
&lt;ul>
&lt;li>content：内容是帖子的文本。&lt;/li>
&lt;li>auth_token：它用于验证 API 请求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>新闻提要检索 API 检索新闻提要的 API 如下所示。&lt;/p>
&lt;p>&lt;code>GET /v1/me/feed&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Params:
&lt;ul>
&lt;li>auth_token：它用于验证 API 请求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>新闻发布&lt;/p>
&lt;p>图 11-2 显示了 feed 发布流程的高层设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-169_1.jpg" width="60%"/>
&lt;ul>
&lt;li>用户：一个用户可以在浏览器或移动应用程序上查看新闻提要。一个用户通过 API 发布内容为 &amp;ldquo;你好&amp;quot;的帖子：/v1/me/feed? content=Hello&amp;amp;auth_token={auth_token}。&lt;/li>
&lt;li>负载平衡器：将流量分配给网络服务器。&lt;/li>
&lt;li>网络服务器：网络服务器将流量重定向到不同的内部服务。&lt;/li>
&lt;li>帖子服务：在数据库和缓存中持久保存帖子。&lt;/li>
&lt;li>Fanout 服务：推送新内容到朋友的新闻源。新闻源数据被存储在缓存中，以便快速检索。&lt;/li>
&lt;li>通知服务：通知朋友有新内容，并发送推送通知。&lt;/li>
&lt;/ul>
&lt;h4 id="新闻源构建">新闻源构建&lt;/h4>
&lt;p>在这一节中，我们将讨论新闻源是如何在幕后构建的。图 11-3 显示了高层设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-170_1.jpg" width="60%"/>
&lt;ul>
&lt;li>用户：一个用户发送了一个请求来检索她的新闻提要。该请求看起来像这样:/v1/me/feed。&lt;/li>
&lt;li>负载平衡器：负载平衡器将流量重定向到网络服务器。&lt;/li>
&lt;li>网络服务器：网络服务器将请求路由到新闻传送服务。&lt;/li>
&lt;li>新闻源服务：新闻源服务从缓存中获取新闻源。&lt;/li>
&lt;li>新闻源缓存：存储渲染新闻源所需的新闻源 ID。&lt;/li>
&lt;/ul>
&lt;h3 id="深入设计">深入设计&lt;/h3>
&lt;p>高层设计简要地涵盖了两个流程：Feed 发布和新闻源构建。在这里，我们更深入地讨论这些主题。&lt;/p>
&lt;h4 id="深入-feed-发布">深入 Feed 发布&lt;/h4>
&lt;p>图 11-4 概述了 Feed 发布的详细设计。我们已经讨论了高层设计中的大部分组件，我们将专注于两个组件：网络服务器和 fanout 服务。&lt;/p>
&lt;img src="../../../system_design_interview/index-171_1.jpg" width="80%"/>
&lt;p>网络服务器&lt;/p>
&lt;p>除了与客户进行通信外，网络服务器还执行认证和速率限制。&lt;/p>
&lt;p>图 11-4 概述了 Feed 发布的详细设计。我们已经讨论了高层设计中的大部分组件，我们将重点讨论两个组件：网络服务器和 fanout 服务。只有用有效的 auth_token 登录的用户才被允许发帖。系统限制用户在一定时期内的发帖数量，这对于防止垃圾邮件和滥用内容至关重要。&lt;/p>
&lt;p>fanout 服务&lt;/p>
&lt;p>fanout 是向所有朋友传递一个帖子的过程。两种类型的fanout模式是：写时 fanout（也叫推模式）和读时 fanout（也叫拉模式）。这两种模式都有优点和缺点。我们解释它们的工作流程，并探讨支持我们系统的最佳方法。&lt;/p>
&lt;p>写时 fanout。用这种方法，新闻提要在写的时候就已经预先计算好了。一个新的帖子在发布后立即传递到朋友的缓存中。&lt;/p>
&lt;ul>
&lt;li>优点
&lt;ul>
&lt;li>新闻源是实时生成的，可以立即推送给朋友。&lt;/li>
&lt;li>获取新闻源的速度很快，因为新闻源是在写的时候预先计算的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缺点
&lt;ul>
&lt;li>如果一个用户有很多朋友，获取朋友名单并为所有朋友生成新闻源是缓慢和耗时的。这被称为热键问题。&lt;/li>
&lt;li>对于不活跃的用户或那些很少登录的用户，预先计算新闻源会浪费计算资源。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>读取时的 fanout。新闻提要是在阅读时间内产生的。这是一个按需的模式。当用户加载她的主页时，最近的帖子被拉出。&lt;/p>
&lt;ul>
&lt;li>优点
&lt;ul>
&lt;li>对于不活跃的用户或那些很少登录的用户，读取时的fanout效果更好，因为它不会在他们身上浪费计算资源。&lt;/li>
&lt;li>数据不会被推送给朋友，所以不存在热键问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缺点
&lt;ul>
&lt;li>获取新闻源的速度很慢，因为新闻源不是预先计算的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>我们采用了一种混合方法，以获得两种方法的好处并避免其中的陷阱。由于快速获取新闻源是至关重要的，我们对大多数用户使用推送模式。对于名人或有很多朋友/粉丝的用户，我们让粉丝按需提取新闻内容以避免系统过载。一致性散列是缓解热键问题的一个有用技术，因为它有助于更均匀地分配请求/数据。&lt;/p>
&lt;p>让我们仔细看看图 11-5 中所示的fanout服务。&lt;/p>
&lt;img src="../../../system_design_interview/index-173_1.jpg" width="60%"/>
&lt;p>fanout服务的工作方式如下。&lt;/p>
&lt;ol>
&lt;li>从图数据库中获取朋友 ID。图形数据库适合于管理朋友关系和朋友推荐。有兴趣的读者希望了解更多关于这个概念的信息，请参考参考资料[2]。&lt;/li>
&lt;li>从用户缓存中获取朋友信息。然后，系统根据用户设置过滤出朋友。例如，如果你把某人调成静音，她的帖子就不会出现在你的新闻提要中，尽管你们仍然是朋友。帖子可能不显示的另一个原因是，用户可以有选择地与特定的朋友分享信息或对其他人隐藏信息。&lt;/li>
&lt;li>将好友列表和新帖子的 ID 发送到消息队列中。&lt;/li>
&lt;li>Fanout 工作者从消息队列中获取数据，并将新闻源数据存储在新闻源缓存中。你可以把新闻源缓存看作是一个&amp;lt;post_id, user_id&amp;gt;的映射表。每当有新的帖子，它将被追加到新闻源表中，如图 11-6 所示。如果我们在缓存中存储整个用户和帖子对象，内存消耗会变得非常大。因此，只有 ID 被存储。为了保持较小的内存大小，我们设置了一个可配置的限制。用户在新闻源中滚动浏览成千上万的帖子的机会很小。大多数用户只对最新的内容感兴趣，所以缓存的失误率很低。&lt;/li>
&lt;li>将&amp;lt;post_id, user_id&amp;gt;存储在新闻源缓冲区。图 11-6 显示了新闻源在缓存中的样子的一个例子。&lt;/li>
&lt;/ol>
&lt;img src="../../../system_design_interview/index-174_1.jpg" width="33%"/>
&lt;p>新闻源检索的深入研究&lt;/p>
&lt;p>图 11-7 说明了新闻提要检索的详细设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-174_2.jpg" width="75%"/>
&lt;p>如图 11-7 所示，媒体内容（图片、视频等）被存储在 CDN 中，以便快速检索。让我们看看客户端如何检索新闻提要。&lt;/p>
&lt;ol>
&lt;li>一个用户发送一个请求来检索她的新闻提要。该请求看起来像这样。&lt;code>/v1/me/feed&lt;/code>&lt;/li>
&lt;li>负载均衡器将请求重新分配到网络服务器。&lt;/li>
&lt;li>网络服务器调用新闻源服务以获取新闻源。&lt;/li>
&lt;li>新闻源服务从新闻源缓存中获得一个列表的帖子 ID。&lt;/li>
&lt;li>一个用户的新闻提要不仅仅是一个提要 ID 的列表。它包含用户名、个人资料图片、帖子内容、帖子图片等。因此，新闻源服务从缓冲区（用户缓冲区和帖子缓冲区）获取完整的用户和帖子对象，以构建完全混合化的新闻源。&lt;/li>
&lt;li>完全混合的新闻源以 JSON 格式返回给客户端进行渲染。&lt;/li>
&lt;/ol>
&lt;p>缓存架构&lt;/p>
&lt;p>缓存对于一个新闻源系统来说是极其重要的。我们将缓存层分为 5 层，如图 11-8 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-175_1.jpg" width="66%"/>
&lt;ul>
&lt;li>新闻提要。它存储新闻提要的 ID。&lt;/li>
&lt;li>内容。它存储每个帖子的数据。受欢迎的内容被存储在热缓存中。&lt;/li>
&lt;li>社会图谱。它存储用户关系数据。&lt;/li>
&lt;li>行动。它存储了关于用户是否喜欢某个帖子、回复某个帖子或对某个帖子采取其他行动的信息。&lt;/li>
&lt;li>计数器。它存储了喜欢、回复、追随者、关注等的计数器。&lt;/li>
&lt;/ul>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在本章中，我们设计了一个新闻源系统。我们的设计包含两个流程：feed 发布和新闻源检索。&lt;/p>
&lt;p>像任何系统设计的面试问题一样，没有完美的方法来设计一个系统。每个公司都有其独特的约束，你必须设计一个系统来适应这些约束。了解你的设计和技术选择的权衡是很重要的。如果还有几分钟的时间，你可以谈谈可扩展性问题。为了避免重复讨论，下面只列出高层次的谈话要点。&lt;/p>
&lt;p>数据库的扩展。&lt;/p>
&lt;ul>
&lt;li>垂直扩展与水平扩展&lt;/li>
&lt;li>SQL vs NoSQL&lt;/li>
&lt;li>主-从复制&lt;/li>
&lt;li>读取复制&lt;/li>
&lt;li>一致性模型&lt;/li>
&lt;li>数据库分片&lt;/li>
&lt;/ul>
&lt;p>其他要点&lt;/p>
&lt;ul>
&lt;li>保持网络层的无状态&lt;/li>
&lt;li>尽可能地缓存数据&lt;/li>
&lt;li>支持多个数据中心&lt;/li>
&lt;li>丢掉有消息队列的几个组件&lt;/li>
&lt;li>监测关键指标。例如，在高峰期的 QPS 和用户刷新他们的新闻提要时的延迟是值得监测的。&lt;/li>
&lt;/ul>
&lt;p>祝贺你走到了这一步! 现在给自己拍拍背吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>Reference materials&lt;/p>
&lt;p>[1] &lt;a href="https://www.facebook.com/help/327131014036297/">How News Feed Works&lt;/a>&lt;/p>
&lt;p>[2] &lt;a href="http://geekswithblogs.net/brendonpage/archive/2015/10/26/friend-of-friendrecommendations-with-neo4j.aspx">Friend of Friend recommendations Neo4j and SQL Sever&lt;/a>&lt;/p></description></item><item><title>系统设计::设计一个推送系统</title><link>/system_design/system_design_interview_10/</link><pubDate>Wed, 10 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_10/</guid><description>&lt;h2 id="设计一个推送系统">设计一个推送系统&lt;/h2>
&lt;p>近年来，通知系统已经成为许多应用程序的一个非常流行的功能。通知会提醒用户一些重要的信息，如突发新闻、产品更新、事件、产品等。它已经成为我们日常生活中不可缺少的一部分。在本章中，你被要求设计一个通知系统。&lt;/p>
&lt;p>一个通知不仅仅是移动推送通知。三种类型的通知格式是：移动推送通知、SMS 消息和电子邮件。图 10-1 显示了这些通知中的每一种的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-151_1.jpg" width="75%"/>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>构建一个每天发送数百万条通知的可扩展系统并不是一件容易的事。它需要对通知生态系统有深刻的理解。面试问题被特意设计成开放式和模糊不清的，你有责任提出问题来澄清需求。&lt;/p>
&lt;p>应聘者：系统支持哪些类型的通知？面试官。推送通知，短信，和电子邮件。&lt;br>
应聘者：这是一个实时系统吗？&lt;br>
面试官：让我们说这是一个软实时系统。我们希望用户能尽快收到通知。但是，如果系统处于高负荷工作状态，稍有延迟是可以接受的。&lt;br>
应聘者：支持的设备有哪些？&lt;br>
面试官：iOS 设备，安卓设备，以及笔记本/台式机。&lt;br>
应聘者：什么会触发通知？&lt;br>
面试官：通知可以由客户端应用程序触发。也可以在服务器端安排。&lt;br>
应聘者：用户是否可以选择退出？&lt;br>
面试官：是的，选择退出的用户将不会再收到通知。&lt;br>
应聘者：每天有多少通知被发送出去？&lt;br>
面试官：1000 万条移动推送通知，100 万条短信，500 万封电子邮件。&lt;/p>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>本节展示了支持各种通知类型的高层设计：iOS 推送通知、Android 推送通知、SMS 消息和电子邮件。它的结构如下。&lt;/p>
&lt;ul>
&lt;li>不同类型的通知&lt;/li>
&lt;li>联系信息收集流程&lt;/li>
&lt;li>通知的发送/接收流程&lt;/li>
&lt;/ul>
&lt;h4 id="不同类型的通知">不同类型的通知&lt;/h4>
&lt;p>我们首先看一下每种通知类型在高层次上是如何工作的。&lt;/p>
&lt;h4 id="ios-推送通知">iOS 推送通知&lt;/h4>
&lt;img src="../../../system_design_interview/index-153_1.jpg" width="50%"/>
&lt;p>我们主要需要三个组件来发送一个 iOS 推送通知。&lt;/p>
&lt;ul>
&lt;li>提供者。提供者构建并向苹果推送通知服务（APNS）发送通知请求。为了构建一个推送通知，提供者提供以下数据。
&lt;ul>
&lt;li>设备令牌。这是一个用于发送推送通知的唯一标识符。&lt;/li>
&lt;li>有效载荷。这是一个 JSON 字典，包含通知的有效载荷。下面是一个例子。&lt;/li>
&lt;li>
&lt;img src="../../../system_design_interview/index-153_2.jpg" width="50%"/>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>APNS：这是苹果提供的一个远程服务，用于向 iOS 设备传播推送通知。&lt;/li>
&lt;li>iOS 设备。它是终端客户，接收推送通知。&lt;/li>
&lt;/ul>
&lt;h4 id="android-推送通知">Android 推送通知&lt;/h4>
&lt;p>Android 也采用了类似的通知流程。通常不使用 APN，而是使用 Firebase Cloud Messaging（FCM）来向安卓设备发送推送通知。&lt;/p>
&lt;img src="../../../system_design_interview/index-154_1.jpg" width="50%"/>
&lt;h4 id="sms-消息">SMS 消息&lt;/h4>
&lt;p>对于 SMS 消息，通常使用第三方 SMS 服务，如 Twilio[1]、Nexmo[2]和其他许多服务。它们中的大多数是商业服务。&lt;/p>
&lt;img src="../../../system_design_interview/index-154_2.jpg" width="50%"/>
&lt;h4 id="电子邮件">电子邮件&lt;/h4>
&lt;p>虽然公司可以建立自己的电子邮件服务器，但许多公司选择了商业电子邮件服务。Sendgrid[3]和 Mailchimp[4]是最受欢迎的电子邮件服务之一，它们提供了更好的发送率和数据分析。&lt;/p>
&lt;img src="../../../system_design_interview/index-154_3.jpg" width="50%"/>
&lt;p>图 10-6 显示了包括所有第三方服务后的设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-155_1.jpg" width="40%"/>
&lt;h4 id="联系信息收集流程">联系信息收集流程&lt;/h4>
&lt;p>为了发送通知，我们需要收集移动设备令牌、电话号码或电子邮件地址。如图 10-7 所示，当用户安装我们的应用程序或首次注册时，API 服务器会收集用户的联系信息并将其存储在数据库中。&lt;/p>
&lt;img src="../../../system_design_interview/index-155_2.jpg" width="70%"/>
&lt;p>图 10-8 显示了存储联系信息的简化数据库表。电子邮件地址和电话号码存储在用户表中，而设备令牌则存储在设备表中。一个用户可以有多个设备，表明推送通知可以被发送到所有的用户设备上。&lt;/p>
&lt;img src="../../../system_design_interview/index-156_1.jpg" width="80%"/>
&lt;h4 id="通知发送接收流程">通知发送/接收流程&lt;/h4>
&lt;p>我们将首先介绍初始设计；然后，提出一些优化方案。&lt;/p>
&lt;p>高层设计&lt;/p>
&lt;p>图 10-9 显示了设计，下面对每个系统组件进行解释。&lt;/p>
&lt;img src="../../../system_design_interview/index-156_2.jpg" width="80%"/>
&lt;p>1 到 N 服务：一个服务可以是一个微服务，一个 cron job，或者一个触发通知发送事件的分布式系统。例如，一个计费服务发送电子邮件提醒客户到期付款，或者一个购物网站通过短信告诉客户他们的包裹明天会被送到。通知系统。通知系统是发送/接收通知的中心环节。从简单的东西开始，只使用一个通知服务器。它为服务 1 到 N 提供 API，并为第三方服务建立通知有效载荷。&lt;/p>
&lt;p>第三方服务。第三方服务负责向用户发送通知。在与第三方服务集成时，我们需要额外注意可扩展性。良好的可扩展性意味着一个灵活的系统，可以很容易地插入或拔出第三方服务。另一个重要的考虑因素是，第三方服务可能在新的市场或在未来无法使用。例如，FCM 在中国是不可用的。因此，在那里使用替代的第三方服务，如 Jpush、PushY 等。&lt;/p>
&lt;p>iOS, Android, SMS, Email: 用户在他们的设备上接收通知。&lt;/p>
&lt;p>在这个设计中发现了三个问题。&lt;/p>
&lt;ul>
&lt;li>单点故障（SPOF）。单一的通知服务器意味着 SPOF。&lt;/li>
&lt;li>难以扩展。通知系统在一台服务器上处理所有与推送通知有关的事情。要独立扩展数据库、缓存和不同的通知处理组件是很有挑战性的。&lt;/li>
&lt;li>性能瓶颈。处理和发送通知可能是资源密集型的。例如，构建 HTML 页面和等待第三方服务的响应可能需要时间。在一个系统中处理所有的事情会导致系统过载，特别是在高峰期。&lt;/li>
&lt;/ul>
&lt;p>高层设计（改进） 在列举了最初设计中的挑战后，我们对设计进行了如下改进。&lt;/p>
&lt;ul>
&lt;li>将数据库和缓存移出通知服务器。&lt;/li>
&lt;li>增加更多的通知服务器，并设置自动横向扩展。&lt;/li>
&lt;li>引入消息队列来解耦系统组件。&lt;/li>
&lt;/ul>
&lt;p>图 10-10 显示了改进后的高层设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-158_1.jpg" width="80%"/>
&lt;p>浏览上图的最佳方式是从左到右。&lt;/p>
&lt;p>1 到 N 服务：它们代表不同的服务，通过通知服务器提供的 API 发送通知。&lt;/p>
&lt;p>通知服务器。它们提供以下功能。&lt;/p>
&lt;ul>
&lt;li>为服务提供发送通知的 API。这些 API 只能由内部或经过验证的客户访问，以防止垃圾邮件。&lt;/li>
&lt;li>进行基本验证，以验证电子邮件、电话号码等。&lt;/li>
&lt;li>查询数据库或缓存以获取渲染通知所需的数据。&lt;/li>
&lt;li>将通知数据放到消息队列中进行并行处理。下面是一个发送电子邮件的 API 的例子。&lt;/li>
&lt;/ul>
&lt;p>&lt;code>POST https://api.example.com/v/sms/send&lt;/code>&lt;/p>
&lt;p>请求正文&lt;/p>
&lt;img src="../../../system_design_interview/index-159_1.jpg" width="50%"/>
&lt;p>缓存：用户信息、设备信息、通知模板被缓存起来。&lt;br>
数据库：它存储关于用户、通知、设置等的数据。&lt;br>
消息队列：它们消除了组件之间的依赖性。当大量的通知被发送出去时，消息队列充当缓冲器。每种通知类型都被分配了一个不同的消息队列，所以一个第三方服务的中断不会影响其他通知类型。&lt;br>
工作服务器：工作服务器是一个服务器列表，它从消息队列中提取通知事件并将其发送到相应的第三方服务。&lt;br>
第三方服务：在最初的设计中已经解释过了。&lt;br>
iOS, Android, SMS, Email：在最初的设计中已经解释过了。&lt;/p>
&lt;p>接下来，让我们来看看每个组件是如何一起工作来发送通知的。&lt;/p>
&lt;ol>
&lt;li>一个服务调用通知服务器提供的 API 来发送通知。&lt;/li>
&lt;li>通知服务器从缓存或数据库中获取元数据，如用户信息、设备令牌和通知设置。&lt;/li>
&lt;li>通知事件被发送到相应的队列中进行处理。例如，一个 iOS 推送通知事件被发送到 iOS PN 队列中。&lt;/li>
&lt;li>工作服务器从消息队列中提取通知事件。&lt;/li>
&lt;li>工作服务器向第三方服务发送通知。&lt;/li>
&lt;li>第三方服务向用户设备发送通知。&lt;/li>
&lt;/ol>
&lt;h3 id="深究设计">深究设计&lt;/h3>
&lt;p>在高层设计中，我们讨论了不同类型的通知、联系人信息收集流程和通知发送/接收流程。我们将深入探讨以下问题。&lt;/p>
&lt;ul>
&lt;li>可靠性。&lt;/li>
&lt;li>额外的组件和注意事项：通知模板、通知设置、限流、重试机制、推送通知的安全性、监控排队通知和事件跟踪。&lt;/li>
&lt;li>更新设计&lt;/li>
&lt;/ul>
&lt;h4 id="可靠性">可靠性&lt;/h4>
&lt;p>在设计分布式环境的通知系统时，我们必须回答几个重要的可靠性问题。&lt;/p>
&lt;p>如何防止数据丢失？&lt;/p>
&lt;p>在一个通知系统中，最重要的要求之一是不能丢失数据。通知通常可以被延迟或重新排序，但绝不会丢失。为了满足这一要求，通知系统将通知数据持久化在一个数据库中，并实现重试机制。如图 10-11 所示，通知日志数据库包括了数据的持久性。&lt;/p>
&lt;img src="../../../system_design_interview/index-160_1.jpg" width="50%"/>
&lt;p>收件人会正好收到一次通知吗？&lt;/p>
&lt;p>简短的回答是不会。尽管在大多数情况下，通知会被准确地传递一次，但分布式的性质可能会导致重复的通知。为了减少重复的发生，我们引入了一个删除机制，并仔细处理每个失败的案例。下面是一个简单的重复计算逻辑。&lt;/p>
&lt;p>当一个通知事件第一次到达时，我们通过检查事件的 ID 来检查它是否以前被看过。如果它以前被看到过，它就被丢弃。否则，我们就会发出通知。有兴趣的读者可以探讨一下为什么我们不能有完全的一次发送，请参考参考资料[5]。&lt;/p>
&lt;h4 id="其他组件和考虑因素">其他组件和考虑因素&lt;/h4>
&lt;p>我们已经讨论了如何收集用户的联系信息，发送和接收通知。一个通知系统远不止这些。在这里，我们讨论额外的组件，包括模板重用、通知设置、事件跟踪、系统监控、限流等。&lt;/p>
&lt;p>通知模板&lt;/p>
&lt;p>一个大型的通知系统每天会发出数百万条通知，其中许多通知都遵循类似的格式。通知模板的引入是为了避免从头开始建立每一个通知。通知模板是一个预先格式化的通知，通过定制参数、样式、跟踪链接等来创建你独特的通知。下面是一个推送通知的例子模板。&lt;/p>
&lt;p>BODY&lt;/p>
&lt;p>你梦想着它。我们敢于这样做。[ITEM NAME] 回来了&amp;ndash;只到[DATE]。&lt;/p>
&lt;p>CTA:&lt;/p>
&lt;p>现在就订购。或者，保存我的[ITEM NAME]。&lt;/p>
&lt;p>使用通知模板的好处包括：保持一致的格式，减少差错，以及节省时间。&lt;/p>
&lt;p>通知设置&lt;/p>
&lt;p>用户一般每天都会收到太多的通知，他们很容易感到不堪重负。因此，许多网站和应用程序让用户对通知设置进行细化控制。这些信息被存储在通知设置表中，有以下字段。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-txt" data-lang="txt">&lt;span style="display:flex;">&lt;span>user_id bigInt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>channel varchar # 推送通知、电子邮件或短信
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>opt_in boolean # 选择接收通知
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在向用户发送任何通知之前，我们首先检查用户是否选择接收这种类型的通知。&lt;/p>
&lt;p>限流&lt;/p>
&lt;p>为了避免用户被太多的通知所淹没，我们可以限制用户可以收到的通知的数量。这一点很重要，因为如果我们发送得太频繁，接收者可能会完全关闭通知。&lt;/p>
&lt;p>重试机制&lt;/p>
&lt;p>当第三方服务发送通知失败时，该通知将被添加到消息队列中进行重试。如果问题持续存在，将向开发者发出警报。&lt;/p>
&lt;p>推送通知的安全性&lt;/p>
&lt;p>对于 iOS 或 Android 应用程序，appKey 和 appSecret 被用来保护推送通知的 API[6]。只有经过认证或验证的客户端才允许使用我们的 API 发送推送通知。有兴趣的用户应该参考参考资料[6]。&lt;/p>
&lt;p>监控排队通知&lt;/p>
&lt;p>要监控的一个关键指标是排队通知的总数量。如果数量很大，说明工作服务器处理通知事件的速度不够快。为了避免通知交付的延迟，需要更多的工作服务器。图 10-12（归功于[7]）显示了一个待处理的排队消息的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-162_1.jpg" width="50%"/>
&lt;p>事件跟踪&lt;/p>
&lt;p>通知指标，如打开率、点击率和参与度，对了解客户行为很重要。分析服务实现了事件跟踪。通常需要在通知系统和分析服务之间进行整合。图 10-13 显示了为分析目的可能被跟踪的事件的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-162_2.jpg" width="60%"/>
&lt;p>更新设计&lt;/p>
&lt;p>把所有东西放在一起，图 10-14 显示了更新的通知系统设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-163_1.jpg" width="70%"/>
&lt;p>在这个设计中，与之前的设计相比，增加了许多新的组件。&lt;/p>
&lt;ul>
&lt;li>通知服务器配备了两个更关键的功能：认证和限流。&lt;/li>
&lt;li>我们还增加了一个重试机制来处理通知失败。如果系统发送通知失败，它们会被放回消息队列中，工作者会重试预定的次数。&lt;/li>
&lt;li>此外，通知模板提供了一个一致和有效的通知创建过程。&lt;/li>
&lt;li>最后，监测和跟踪系统被添加到系统健康检查和未来改进中。&lt;/li>
&lt;/ul>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>通知是不可缺少的，因为它们让我们及时了解重要信息。它可能是关于你在 Netflix 上最喜欢的电影的推送通知，也可能是关于新产品折扣的电子邮件，或者是关于你在线购物付款确认的消息。&lt;/p>
&lt;p>在这一章中，我们描述了一个可扩展的通知系统的设计，它支持多种通知格式。推送通知、SMS 消息和电子邮件。我们采用了消息队列来解耦系统组件。&lt;/p>
&lt;p>除了高层次的设计，我们还深入挖掘了更多的组件和优化。&lt;/p>
&lt;ul>
&lt;li>可靠性。我们提出了一个强大的重试机制，以减少故障率。&lt;/li>
&lt;li>安全性。AppKey/appSecret 对被用来确保只有经过验证的客户才能发送通知。&lt;/li>
&lt;li>跟踪和监控。这些都是在通知流程的任何阶段实现的，以捕获重要的统计信息。&lt;/li>
&lt;li>尊重用户设置。用户可以选择不接收通知。我们的系统在发送通知之前首先检查用户的设置。&lt;/li>
&lt;li>速率限制。用户会欣赏他们收到的通知数量的频率上限。&lt;/li>
&lt;/ul>
&lt;p>恭喜你走到这一步! 现在给自己拍拍胸脯吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1] &lt;a href="https://www.twilio.com/sms">Twilio SMS&lt;/a>&lt;br>
[2] &lt;a href="https://www.nexmo.com/products/sms">Nexmo SMS&lt;/a>&lt;br>
[3] &lt;a href="https://sendgrid.com/">Sendgrid&lt;/a>&lt;br>
[4] &lt;a href="https://mailchimp.com/">Mailchimp&lt;/a>&lt;br>
[5] &lt;a href="https://bravenewgeek.com/you-cannot-haveexactly-once-delivery/">You Cannot Have Exactly-Once Delivery&lt;/a>&lt;br>
[6] &lt;a href="https://cloud.ibm.com/docs/services/mobilepush?topic=mobile-pushnotification-security-in-push-notifications">Security in Push Notifications&lt;/a>&lt;br>
[7] &lt;a href="https://bit.ly/2sotIa6">RadditMQ&lt;/a>&lt;/p></description></item><item><title>系统设计::设计网络爬虫</title><link>/system_design/system_design_interview_09/</link><pubDate>Tue, 09 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_09/</guid><description>&lt;h2 id="设计网页爬虫">设计网页爬虫&lt;/h2>
&lt;p>在这一章中，我们重点讨论网络爬虫设计：一个有趣的、经典的系统设计面试问题。&lt;/p>
&lt;p>网络爬虫被称为机器人或蜘蛛。它被搜索引擎广泛用于发现网络上新的或更新的内容。内容可以是一个网页、一张图片、一段视频、一个 PDF 文件，等等。网络爬虫从收集一些网页开始，然后跟踪这些网页上的链接来收集新内容。图 9-1 显示了爬虫过程的一个直观例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-132_1.jpg" width="80%"/>
&lt;p>爬虫有许多用途。&lt;/p>
&lt;ul>
&lt;li>搜索引擎的索引。这是最常见的使用情况。爬虫收集网页，为搜索引擎创建一个本地索引。例如，Googlebot 是 Google 搜索引擎背后的网络爬虫。&lt;/li>
&lt;li>网络归档。这是一个从网络上收集信息的过程，以保存数据供将来使用。例如，许多国家图书馆运行爬虫来存档网站。著名的例子是美国国会图书馆[1]和欧盟的网络档案[2]。&lt;/li>
&lt;li>网络挖掘。网络的爆炸性增长为数据挖掘提供了前所未有的机会。网络挖掘有助于从互联网上发现有用的知识。例如，顶级金融公司使用爬虫下载股东会议和年度报告，以了解公司的关键举措。&lt;/li>
&lt;li>网络监控。爬虫有助于监测互联网上的版权和商标侵权行为。例如，Digimarc[3]利用爬虫来发现盗版作品和报告。&lt;/li>
&lt;/ul>
&lt;p>开发一个网络爬虫的复杂性取决于我们打算支持的规模。它可以是一个小型的学校项目，只需要几个小时就能完成，也可以是一个巨大的项目，需要一个专门的工程团队不断改进。因此，我们将在下面探讨要支持的规模和功能。&lt;/p>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>网络爬虫的基本算法很简单。&lt;/p>
&lt;ol>
&lt;li>给定一组 URLs，下载所有由 URLs 寻址的网页。&lt;/li>
&lt;li>从这些网页中提取 URLs&lt;/li>
&lt;li>将新的 URL 添加到要下载的 URL 列表中。重复这 3 个步骤。&lt;/li>
&lt;/ol>
&lt;p>网络爬虫的工作是否真的像这种基本算法一样简单？并非如此。设计一个巨大的可扩展的网络爬虫是一项极其复杂的任务。任何人都不可能在面试时间内设计出一个大规模的网络爬虫。在进入设计之前，我们必须问一些问题来了解需求并确定设计范围。&lt;/p>
&lt;p>候选人:爬虫的主要目的是什么？是用于搜索引擎索引、数据挖掘，还是其他？&lt;br>
面试官:搜索引擎索引。&lt;br>
应聘者:网络爬虫每月能收集多少个网页？&lt;br>
面试官:10 亿个网页。&lt;br>
应聘者:包括哪些内容类型？只包括 HTML，还是包括其他内容类型，如 PDF 和图片？&lt;br>
面试官:只包括 HTML。&lt;br>
应聘者:我们应该考虑新增加的或编辑过的网页吗？&lt;br>
面试官:是的，我们应该考虑新添加或编辑过的网页。&lt;br>
应聘者:我们是否需要存储从网上抓取的 HTML 网页？&lt;br>
面试官:需要。是的，最多 5 年。&lt;br>
应聘者:我们如何处理有重复内容的网页？&lt;br>
面试官:有重复内容的页面应该被忽略。&lt;/p>
&lt;p>以上是一些你可以问面试官的样本问题。理解需求并澄清含糊不清的地方是很重要的。即使你被要求设计一个简单的产品，如网络爬虫，你和你的面试官也可能有不同的假设。&lt;/p>
&lt;p>除了与面试官澄清功能外，记下一个好的网络爬虫的以下特点也很重要。&lt;/p>
&lt;ul>
&lt;li>可伸缩。网络是非常大的。那里有数十亿的网页。网络爬虫应该使用并行化技术，效率极高。&lt;/li>
&lt;li>健壮性。网络中充满了陷阱。坏的 HTML、无反应的服务器、崩溃、恶意链接等都很常见。爬虫器必须处理所有这些边缘情况。&lt;/li>
&lt;li>礼貌性。爬虫不应该在很短的时间间隔内向一个网站发出过多的请求。&lt;/li>
&lt;li>可扩展性。该系统是灵活的，因此需要最小的变化来支持新的内容类型。例如，如果我们想在将来抓取图像文件，我们应该不需要重新设计整个系统。&lt;/li>
&lt;/ul>
&lt;h3 id="粗略估计">粗略估计&lt;/h3>
&lt;p>下面的估计是基于许多假设，与面试官沟通以保持一致是很重要的。&lt;/p>
&lt;ul>
&lt;li>假设每个月有 10 亿个网页被下载。&lt;/li>
&lt;li>QPS：1,000,000,000 / 30 天 / 24 小时 / 3600 秒 =~ 400 页/秒。&lt;/li>
&lt;li>峰值 QPS = 2 * QPS = 800&lt;/li>
&lt;li>假设平均网页大小为 500k。&lt;/li>
&lt;li>10 亿页 x 500k = 每月 500TB 存储量。如果你对数字存储单位不清楚，可以再看一下第二章的 &amp;ldquo;2 的力量&amp;quot;部分。&lt;/li>
&lt;li>假设数据存储 5 年，500TB * 12 个月 * 5 年 = 30PB。储存五年的内容需要一个 30PB 的存储。&lt;/li>
&lt;/ul>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>一旦需求明确了，我们就开始进行高层设计。受以前关于网络抓取的研究[4][5]的启发，我们提出了一个高层设计，如图 9-2 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-136_1.jpg" width="80%"/>
&lt;p>首先，我们探索每个设计组件以了解它们的功能。然后，我们一步一步地考察爬虫的工作流程。&lt;/p>
&lt;h4 id="种子网址">种子网址&lt;/h4>
&lt;p>一个网络爬虫使用种子网址作为爬虫过程的起点。例如，要抓取一所大学网站的所有网页，选择种子 URL 的一个直观方法是使用该大学的域名。&lt;/p>
&lt;p>要抓取整个网络，我们需要创造性地选择种子网址。一个好的种子网址可以作为一个好的起点，爬虫可以利用它来遍历尽可能多的链接。一般的策略是将整个 URL 空间划分为更小的空间。第一个建议的方法是基于地域性，因为不同的国家可能有不同的流行网站。另一种方法是根据主题来选择种子 URL；例如，我们可以将 URL 空间划分为购物、体育、保健等。种子网址的选择是一个开放式的问题。不指望你能给出完美的答案。只要尽力思考就可以了。&lt;/p>
&lt;h4 id="url-frontier">URL Frontier&lt;/h4>
&lt;p>大多数现代网络爬虫将抓取状态分为两种：待下载和已下载。存储待下载的 URL 的组件被称为 URL Frontier。你可以把它称为先进先出（FIFO）队列。关于 URL Frontier 的详细信息，请参考深入研究。&lt;/p>
&lt;h4 id="html-下载器">HTML 下载器&lt;/h4>
&lt;p>HTML 下载器从互联网上下载网页。这些 URL 是由 URL Frontier 提供的。&lt;/p>
&lt;h4 id="dns-解析器">DNS 解析器&lt;/h4>
&lt;p>要下载一个网页，URL 必须被翻译成一个 IP 地址。HTML 下载器调用 DNS 解析器来获得 URL 的相应 IP 地址。例如，截至 2019 年 5 月 3 日，URL &lt;a href="https://www.wikipedia.org">www.wikipedia.org&lt;/a> 被转换为 IP 地址 198.35.26.96。&lt;/p>
&lt;h4 id="内容解析器">内容解析器&lt;/h4>
&lt;p>网页被下载后，必须对其进行解析和验证，因为畸形的网页可能引发问题并浪费存储空间。在抓取服务器中实施内容解析器会减慢抓取过程。因此，内容解析器是一个单独的组件。&lt;/p>
&lt;h4 id="看到的内容">看到的内容？&lt;/h4>
&lt;p>在线研究[6]显示，29%的网页是重复的内容，这可能导致同一内容被多次存储。我们引入 &amp;ldquo;所见内容 &amp;ldquo;数据结构，以消除数据冗余并缩短处理时间。它有助于检测以前存储在系统中的新内容。为了比较两个 HTML 文档，我们可以逐个字符进行比较。然而，这种方法既慢又费时，特别是当涉及到数十亿的网页时。完成这项任务的一个有效方法是比较两个网页的哈希值[7]。&lt;/p>
&lt;h4 id="内容存储">内容存储&lt;/h4>
&lt;p>它是一个用于存储 HTML 内容的存储系统。存储系统的选择取决于诸如数据类型、数据大小、访问频率、寿命等因素。磁盘和内存都可以使用。&lt;/p>
&lt;ul>
&lt;li>大多数内容被存储在磁盘上，因为数据集太大，无法装入内存。&lt;/li>
&lt;li>受欢迎的内容被保存在内存中以减少延迟。&lt;/li>
&lt;/ul>
&lt;h4 id="url-提取器">URL 提取器&lt;/h4>
&lt;p>URL 提取器分析和提取 HTML 页面的链接。图 9-3 显示了一个链接提取过程的例子。通过添加 &amp;ldquo;&lt;a href="https://en.wikipedia.org">https://en.wikipedia.org&lt;/a>&amp;rdquo; 前缀，相对路径被转换为绝对 URL。&lt;/p>
&lt;img src="../../../system_design_interview/index-138_1.jpg" width="80%"/>
&lt;h4 id="url-过滤器">URL 过滤器&lt;/h4>
&lt;p>URL 过滤器排除了某些内容类型、文件扩展名、错误链接和 &amp;ldquo;黑名单 &amp;ldquo;网站的 URL。&lt;/p>
&lt;h4 id="url-seen">URL Seen?&lt;/h4>
&lt;p>&amp;ldquo;URL Seen?&amp;rdquo; 是一个数据结构，用于跟踪以前访问过的或已经在 Frontier 中的 URL。&amp;ldquo;URL Seen?&amp;rdquo; 有助于避免多次添加相同的 URL，因为这可能会增加服务器负载并导致潜在的无限循环。&lt;/p>
&lt;p>布隆过滤器和哈希表是实现 &amp;ldquo;URL Seen?&amp;rdquo; 组件的常用技术。我们不会在这里介绍布隆过滤器和哈希表的详细实现。更多信息请参考参考资料[4] [8]。&lt;/p>
&lt;h4 id="url-存储">URL 存储&lt;/h4>
&lt;p>URL 存储可以存储已经访问过的 URL。&lt;/p>
&lt;p>到目前为止，我们已经讨论了每个系统组件。接下来，我们把它们放在一起，解释工作流程。&lt;/p>
&lt;h4 id="网络爬虫的工作流程">网络爬虫的工作流程&lt;/h4>
&lt;p>为了更好地解释工作流程的步骤，在设计图中加入了序列号，如图 9-4 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-139_1.jpg" width="80%"/>
&lt;ul>
&lt;li>第 1 步：在 URL Frontier 中添加种子 URL&lt;/li>
&lt;li>第 2 步：HTML 下载器从 URL Frontier 中获取 URL 的列表。&lt;/li>
&lt;li>第 3 步：HTML 下载器从 DNS 解析器获取 URLs 的 IP 地址，并开始下载。&lt;/li>
&lt;li>第 4 步：内容解析器解析 HTML 页面并检查页面是否畸形。&lt;/li>
&lt;li>第 5 步：内容被解析和验证后，它被传递给 &amp;ldquo;Content Seen&amp;quot;组件。&lt;/li>
&lt;li>第 6 步：&amp;ldquo;Content Seen&amp;quot;组件检查 HTML 页面是否已经在存储器中。
&lt;ul>
&lt;li>如果它在存储器中，这意味着不同 URL 中的相同内容已经被处理。在这种情况下，该 HTML 页面被丢弃。&lt;/li>
&lt;li>如果它不在存储器中，则系统以前没有处理过相同的内容。该内容被传递给链接提取器。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>第 7 步：链接提取器从 HTML 页面中提取链接。&lt;/li>
&lt;li>第 8 步：提取的链接被传递给 URL 过滤器。&lt;/li>
&lt;li>第 9 步：在链接被过滤后，它们被传递给 &amp;ldquo;URL Seen? &amp;ldquo;组件。&lt;/li>
&lt;li>第 10 步。&amp;ldquo;URL Seen &amp;ldquo;组件检查一个 URL 是否已经在存储中，如果是，它就会在之前被处理，而不需要做任何事情。&lt;/li>
&lt;li>第 11 步：如果一个 URL 之前没有被处理过，它将被添加到 URL Frontier 中。&lt;/li>
&lt;/ul>
&lt;h3 id="设计深究">设计深究&lt;/h3>
&lt;p>到现在为止，我们已经讨论了高层设计。接下来，我们将深入讨论最重要的构建组件和技术。&lt;/p>
&lt;ul>
&lt;li>深度优先搜索（DFS）与广度优先搜索（BFS）的对比&lt;/li>
&lt;li>URL 前沿阵地&lt;/li>
&lt;li>HTML 下载器&lt;/li>
&lt;li>健壮性&lt;/li>
&lt;li>可扩展性&lt;/li>
&lt;li>检测并避免有问题的内容&lt;/li>
&lt;/ul>
&lt;h4 id="dfs-vs-bfs">DFS vs BFS&lt;/h4>
&lt;p>你可以把网络想象成一个有向图，其中网页作为节点，超链接（URL）作为边。抓取过程可以被视为从一个网页到其他网页的有向图的遍历。两种常见的图形遍历算法是 DFS 和 BFS。然而，DFS 通常不是一个好的选择，因为 DFS 的深度可能很深。&lt;/p>
&lt;p>BFS 通常被网络爬虫使用，由先进先出（FIFO）队列实现。在先进先出队列中，URL 是按照它们被排队的顺序进行排队的。然而，这种实现方式有两个问题。&lt;/p>
&lt;ul>
&lt;li>来自同一网页的大多数链接都被链接回同一主机。在图 9-5 中，wikipedia.com 的所有链接都是内部链接，使得爬虫忙于处理来自同一主机（wikipedia.com）的 URL。当爬虫试图平行下载网页时，维基百科服务器将被请求淹没。这被认为是 &amp;ldquo;不礼貌的&amp;rdquo;。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-140_1.jpg" width="66%"/>
&lt;p>标准的 BFS 没有考虑到 URL 的优先级。网络很大，不是每个页面都有相同的质量和重要性。因此，我们可能希望根据页面排名、网络流量、更新频率等来确定 URL 的优先次序。&lt;/p>
&lt;h4 id="url-frontier-1">URL frontier&lt;/h4>
&lt;p>URL frontier 有助于解决这些问题。URL frontier 是一个数据结构，存储要下载的 URL。URL frontier 是确保礼貌性、URL 优先性和实效性的一个重要组成部分。在参考资料中提到了一些关于 URL frontier 的值得注意的论文[5][9]。这些论文的结论如下。&lt;/p>
&lt;h4 id="礼貌性">礼貌性&lt;/h4>
&lt;p>一般来说，网络爬虫应该避免在短时间内向同一主机服务器发送太多的请求。发送过多的请求被认为是 &amp;ldquo;不礼貌的&amp;rdquo;，甚至被视为拒绝服务（DOS）攻击。例如，在没有任何约束的情况下，爬虫每秒可以向同一个网站发送成千上万的请求。这可能使网络服务器不堪重负。&lt;/p>
&lt;p>执行礼貌的一般想法是，每次从同一主机下载一个页面。在两个下载任务之间可以增加一个延迟。礼貌性约束是通过维护网站主机名到下载（工作者）线程的映射来实现的。每个下载者线程都有一个单独的 FIFO 队列，并且只下载从该队列中获得的 URLs。图 9-6 显示了管理礼貌的设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-141_1.jpg" width="66%"/>
&lt;ul>
&lt;li>队列路由器。它确保每个队列（b1，b2，&amp;hellip;bn）只包含来自同一主机的 URL。&lt;/li>
&lt;li>映射表。它将每个主机映射到一个队列。&lt;/li>
&lt;li>FIFO 队列 b1、b2 到 bn：每个队列包含来自同一主机的 URL。&lt;/li>
&lt;li>队列选择器。每个工作线程都被映射到一个先进先出队列，它只从该队列下载 URL。队列选择逻辑是由队列选择器完成的。&lt;/li>
&lt;li>工作线程 1 至 N。一个工作线程从同一主机逐一下载网页。在两个下载任务之间可以添加一个延迟&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-142_1.jpg" width="66%"/>
&lt;h4 id="优先级">优先级&lt;/h4>
&lt;p>一个关于苹果产品的讨论论坛上的随机帖子与苹果主页上的帖子具有非常不同的权重。尽管它们都有 &amp;ldquo;苹果 &amp;ldquo;这个关键词，但爬虫首先抓取苹果主页是明智之举。&lt;/p>
&lt;p>我们根据有用性来确定 URL 的优先级，有用性可以通过 PageRank[10]、网站流量、更新频率等来衡量。&amp;ldquo;Prioritizer &amp;ldquo;是处理 URL 优先级的组件。请参考参考资料[5][10]，了解关于这个概念的深入信息。&lt;/p>
&lt;p>图 9-7 显示了管理 URL 优先权的设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-143_1.jpg" width="66%"/>
&lt;ul>
&lt;li>优先排序器。它将 URL 作为输入并计算出优先级。&lt;/li>
&lt;li>队列 f1 至 fn：每个队列都有一个分配的优先级。具有高优先级的队列以更高的概率被选中。&lt;/li>
&lt;li>队列选择器。随机选择一个队列，偏向于具有较高优先级的队列。&lt;/li>
&lt;/ul>
&lt;p>图 9-8 展示了 URL frontier 设计，它包含两个模块。&lt;/p>
&lt;ul>
&lt;li>前队列：管理优先次序&lt;/li>
&lt;li>后队列：管理礼貌性&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-144_1.jpg" width="66%"/>
&lt;h4 id="保持更新">保持更新&lt;/h4>
&lt;p>网页在不断被添加、删除和编辑。网络爬虫必须定期重新抓取下载的网页，以保持我们的数据集是新的。重新抓取所有的 URL 是非常耗时和耗资源的。以下是一些优化实效性的策略。&lt;/p>
&lt;ul>
&lt;li>根据网页的更新历史重新抓取。&lt;/li>
&lt;li>对 URL 进行优先排序，首先更频繁地重新抓取重要网页。&lt;/li>
&lt;/ul>
&lt;h4 id="url-frontier-存储">URL Frontier 存储&lt;/h4>
&lt;p>在现实世界的搜索引擎的抓取中，url frontier 中的 URL 数量可能是数以亿计的[4]。把所有的东西都放在内存中既不耐用也不具有可扩展性。把所有东西都放在磁盘里也不可取，因为磁盘很慢；而且它很容易成为抓取的瓶颈。&lt;/p>
&lt;p>我们采用了一种混合方法。大部分的 URL 都存储在磁盘上，所以存储空间不是问题。为了减少从磁盘上读取和写入磁盘的成本，我们在内存中维护缓冲区，用于 enqueue/dequeue 操作。缓冲区中的数据会定期写入磁盘。&lt;/p>
&lt;h4 id="html-下载器-1">HTML 下载器&lt;/h4>
&lt;p>HTML 下载器使用 HTTP 协议从互联网上下载网页。在讨论 HTML 下载器之前，我们先看一下 Robots 排除协议。&lt;/p>
&lt;h4 id="robotstxt">Robots.txt&lt;/h4>
&lt;p>Robots.txt，称为 Robots 排除协议，是网站用来与爬虫通信的标准。它规定了允许爬虫下载哪些页面。在试图爬虫一个网站之前，爬虫应首先检查其相应的 robots.txt，并遵守其规则。&lt;/p>
&lt;p>为了避免重复下载 robots.txt 文件，我们对该文件的结果进行了缓存。该文件会定期下载并保存到缓存中。下面是取自 &lt;a href="https://www.amazon.com/robots.txt">https://www.amazon.com/robots.txt&lt;/a> 的 robots.txt 文件的一个片段。一些目录，如 creatorhub，是不允许谷歌机器人进入的。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-txt" data-lang="txt">&lt;span style="display:flex;">&lt;span>User-agent: Googlebot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Disallow: /creatorhub/*
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Disallow: /rss/people/*/reviews
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Disallow: /gp/pdp/rss/*/reviews
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Disallow: /gp/cdp/member-reviews/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Disallow: /gp/aw/cr/
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>除了 robots.txt，性能优化是我们将涵盖的 HTML 下载器的另一个重要概念。&lt;/p>
&lt;h4 id="性能优化">性能优化&lt;/h4>
&lt;p>下面是 HTML 下载器的性能优化手段。&lt;/p>
&lt;ol>
&lt;li>分布式爬虫&lt;/li>
&lt;/ol>
&lt;p>为了实现高性能，抓取工作被分配到多个服务器，每个服务器运行多个线程。URL 空间被分割成更小的部分；因此，每个下载器负责 URL 的一个子集。图 9-9 显示了一个分布式抓取的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-146_1.jpg" width="50%"/>
&lt;ol start="2">
&lt;li>缓存 DNS 解析器&lt;/li>
&lt;/ol>
&lt;p>DNS 解析器是爬虫的一个瓶颈，因为由于许多 DNS 接口的同步性，DNS 请求可能需要时间。DNS 的响应时间从 10ms 到 200ms 不等。一旦爬虫线程对 DNS 进行了请求，其他线程就会被阻断，直到第一个请求完成。维护我们的 DNS 缓存以避免频繁调用 DNS 是一种有效的速度优化技术。我们的 DNS 缓存保持域名到 IP 地址的映射，并通过 cron 作业定期更新。&lt;/p>
&lt;ol start="3">
&lt;li>地域性&lt;/li>
&lt;/ol>
&lt;p>按地理分布抓取服务器。当爬虫服务器离网站主机较近时，爬虫者会经历更快的下载时间。设计定位适用于大多数系统组件：抓取服务器、缓存、队列、存储等。&lt;/p>
&lt;ol start="4">
&lt;li>短暂的超时&lt;/li>
&lt;/ol>
&lt;p>有些网站服务器响应缓慢，或者根本不响应。为了避免漫长的等待时间，规定了一个最大的等待时间。如果一个主机在预定的时间内没有反应，爬虫就会停止工作，抓取其他一些网页。&lt;/p>
&lt;h4 id="健壮性">健壮性&lt;/h4>
&lt;p>除了性能优化，健壮性也是一个重要的考虑因素。我们提出一些方法来提高系统的健壮性。&lt;/p>
&lt;ul>
&lt;li>一致性散列：这有助于在下载者之间分配负载。一个新的下载器服务器可以使用一致的散列法添加或删除。更多细节请参考第五章：设计一致的散列。&lt;/li>
&lt;li>保存抓取状态和数据。为了防止故障，爬行状态和数据被写入一个存储系统。通过加载保存的状态和数据，可以很容易地重新启动被破坏的爬行。&lt;/li>
&lt;li>异常处理。在一个大规模的系统中，错误是不可避免的，而且很常见。爬虫必须优雅地处理异常，而不会使系统崩溃。&lt;/li>
&lt;li>数据验证。这是防止系统错误的一个重要措施。&lt;/li>
&lt;/ul>
&lt;h4 id="可扩展性">可扩展性&lt;/h4>
&lt;p>由于几乎每个系统都在不断发展，设计目标之一是使系统足够灵活，以支持新的内容类型。抓取器可以通过插入新的模块来扩展。图 9-10 显示了如何添加新模块。&lt;/p>
&lt;img src="../../../system_design_interview/index-147_1.jpg" width="80%"/>
&lt;ul>
&lt;li>PNG 下载器模块被插入以下载 PNG 文件。&lt;/li>
&lt;li>网络监控模块的加入是为了监控网络，防止版权和商标侵权。&lt;/li>
&lt;/ul>
&lt;h4 id="检测并避免有问题的内容">检测并避免有问题的内容&lt;/h4>
&lt;p>本节讨论了检测和预防冗余、无意义或有害内容的问题。&lt;/p>
&lt;ol>
&lt;li>冗余内容&lt;/li>
&lt;/ol>
&lt;p>如前所述，近 30%的网页是重复的。哈希值或校验值有助于检测重复内容[11]。&lt;/p>
&lt;ol start="2">
&lt;li>蜘蛛陷阱&lt;/li>
&lt;/ol>
&lt;p>蜘蛛陷阱是一个导致爬虫处于无限循环的网页。例如，一个无限深的目录结构列举如下：&lt;/p>
&lt;p>&lt;a href="https://www.spidertrapexample.com/foo/bar/foo/bar/foo/bar/">www.spidertrapexample.com/foo/bar/foo/bar/foo/bar/&lt;/a>&amp;hellip;&lt;/p>
&lt;p>这样的蜘蛛陷阱可以通过为 URLs 设置最大长度来避免。然而，没有一个放之四海而皆准的解决方案来检测蜘蛛陷阱。含有蜘蛛陷阱的网站很容易被识别，因为在这类网站上发现的网页数量异常多。很难开发出避免蜘蛛陷阱的自动算法；然而，用户可以手动验证和识别蜘蛛陷阱，并将这些网站从爬虫中排除，或应用一些定制的 URL 过滤器。&lt;/p>
&lt;ol start="3">
&lt;li>数据噪音&lt;/li>
&lt;/ol>
&lt;p>有些内容几乎没有价值，如广告、代码片段、垃圾网址等。这些内容对爬虫没有用处，如果可能的话，应将其排除。&lt;/p>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在这一章中，我们首先讨论了一个好的爬虫的特征：可扩展性、礼貌性、可扩展性和健壮性。然后，我们提出了一个设计，并讨论了关键的组成部分。构建一个可扩展的网络爬虫并不是一件微不足道的事情，因为网络是非常大的，而且充满了陷阱。尽管我们已经涵盖了许多主题，但仍然遗漏了许多相关的谈话内容。&lt;/p>
&lt;ul>
&lt;li>服务器端渲染。众多网站使用 JavaScript、AJAX 等脚本来产生链接。如果我们直接下载和解析网页，我们将无法检索动态生成的链接。为了解决这个问题，我们在解析网页之前先进行服务器端的渲染（也叫动态渲染）[12]。&lt;/li>
&lt;li>过滤掉不需要的页面。由于存储容量和抓取资源有限，反垃圾邮件组件有利于过滤掉低质量和垃圾邮件页面[13] [14]。&lt;/li>
&lt;li>数据库复制和分片。复制和分片等技术被用来提高数据层的可用性、可扩展性和可靠性。&lt;/li>
&lt;li>横向扩展。对于大规模的抓取，需要数百甚至数千台服务器来执行下载任务。关键是要保持服务器的无状态。&lt;/li>
&lt;li>可用性、一致性和可靠性。这些概念是任何大型系统成功的核心。我们在第 1 章中详细讨论了这些概念。刷新你对这些主题的记忆。&lt;/li>
&lt;li>分析。收集和分析数据是任何系统的重要组成部分，因为数据是微调的关键成分。&lt;/li>
&lt;/ul>
&lt;p>恭喜你走到这一步! 现在给自己拍拍胸脯吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1] &lt;a href="https://www.loc.gov/websites/">US Library of Congress&lt;/a>&lt;br>
[2] &lt;a href="http://data.europa.eu/webarchive">EU Web Archive&lt;/a>&lt;br>
[3] &lt;a href="https://www.digimarc.com/products/digimarc-services/piracy-intelligence">Digimarc&lt;/a>&lt;br>
[4] Heydon A., Najork M. Mercator: A scalable, extensible web crawler World Wide Web, 2 (4) (1999), pp. 219-229&lt;br>
[5] &lt;a href="http://infolab.stanford.edu/~olston/publications/crawling_survey.pdf">By Christopher Olston, Marc Najork: Web Crawling&lt;/a>&lt;br>
[6] &lt;a href="https://tinyurl.com/y6tmh55y">29% Of Sites Face Duplicate Content Issues&lt;/a>&lt;br>
[7] Rabin M.O., et al. Fingerprinting by random polynomials Center for Research in Computing Techn., Aiken Computation Laboratory, Univ. (1981)&lt;br>
[8] B. H. Bloom, “Space/time trade-offs in hash coding with allowable errors,” Communications of the ACM, vol. 13, no. 7, pp. 422–426, 1970.&lt;br>
[9] &lt;a href="https://www.ics.uci.edu/~lopes/teaching/cs221W12/slides/Lecture05.pdf">Donald J. Patterson, Web Crawling&lt;/a>&lt;br>
[10] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank citation ranking: Bringing order to the web,” Technical Report, Stanford University, 1998.&lt;br>
[11] Burton Bloom. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM, 13(7), pages 422&amp;ndash;426, July 1970.&lt;br>
[12] &lt;a href="https://developers.google.com/search/docs/guides/dynamic-rendering">Google Dynamic Rendering&lt;/a>&lt;br>
[13] T. Urvoy, T. Lavergne, and P. Filoche, “Tracking web spam with hidden style similarity,” in Proceedings of the 2nd International Workshop on Adversarial Information Retrieval on the Web, 2006.&lt;br>
[14] H.-T. Lee, D. Leonard, X. Wang, and D. Loguinov, “IRLbot: Scaling to 6 billion pages and beyond,” in Proceedings of the 17th International World Wide Web Conference, 2008.&lt;/p></description></item><item><title>系统设计::设计短链接</title><link>/system_design/system_design_interview_08/</link><pubDate>Mon, 08 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_08/</guid><description>&lt;h2 id="设计短链接">设计短链接&lt;/h2>
&lt;p>在这一章中，我们将解决一个有趣而经典的系统设计面试问题：设计一个像 tinyurl 一样的短链接务。&lt;/p>
&lt;h3 id="了解问题并确定设计范围">了解问题并确定设计范围&lt;/h3>
&lt;p>系统设计面试的问题是故意留有余地的。为了设计出一个精心设计的系统，关键是要问清楚问题。&lt;/p>
&lt;p>应聘者：你能举个例子说明短链接的工作原理吗？&lt;br>
面试官：假设 URL &lt;a href="https://www.systeminterview.com/q=chatsystem&amp;amp;c=loggedin&amp;amp;v=v3&amp;amp;l=long">https://www.systeminterview.com/q=chatsystem&amp;amp;c=loggedin&amp;amp;v=v3&amp;amp;l=long&lt;/a> 是原始的 URL。你的服务创建了一个长度更短的别名： &lt;a href="https://tinyurl.com/y7keocwj">https://tinyurl.com/y7keocwj&lt;/a> 。如果你点击这个别名，它就会把你重定向到原来的网址。&lt;br>
应聘者：流量是多少？&lt;br>
面试官：每天有 1 亿个 URL 产生。&lt;br>
应聘者：缩短后的 URL 有多长？&lt;br>
面试官。越短越好。&lt;br>
应聘者：缩短后的 URL 允许有哪些字符？&lt;br>
面试官：缩短的 URL 可以是数字（0-9）和字符（a-z，A-Z）的组合。&lt;br>
应聘者：缩短后的 URL 可以删除或更新吗？&lt;br>
面试官：为简单起见，我们假设缩短的 URL 不能被删除或更新。&lt;/p>
&lt;p>以下是基本的使用情况。&lt;/p>
&lt;ol>
&lt;li>URL 缩短：给定一个长的 URL =&amp;gt; 返回一个短得多的 URL&lt;/li>
&lt;li>URL 重定向：给定一个较短的 URL =&amp;gt; 重定向到原来的 URL&lt;/li>
&lt;li>高可用性、可扩展性和容错性考虑&lt;/li>
&lt;/ol>
&lt;h3 id="粗略估计">粗略估计&lt;/h3>
&lt;ul>
&lt;li>写操作。每天产生 1 亿个 URL。&lt;/li>
&lt;li>每秒写操作：1 亿/24/3600=1160&lt;/li>
&lt;li>读取操作。假设读操作与写操作的比例为 10:1，每秒的读操作：1160 * 10 = 11,600&lt;/li>
&lt;li>假设短链接服务将运行 10 年，这意味着我们必须支持 1 亿 * 365 * 10 = 3650 亿条记录。&lt;/li>
&lt;li>假设平均 URL 长度为 100。&lt;/li>
&lt;li>10 年内的存储需求。3650 亿 * 100 字节 * 10 年=365TB&lt;/li>
&lt;/ul>
&lt;p>重要的是，你要和你的面试官一起走过这些假设和计算，以便你们两个人达成共识。&lt;/p>
&lt;h3 id="提出高水平的设计并获得认同">提出高水平的设计并获得认同&lt;/h3>
&lt;p>在本节中，我们将讨论 API 端点、URL 重定向和 URL 缩短流程。&lt;/p>
&lt;h4 id="api-端点">API 端点&lt;/h4>
&lt;p>API 端点促进了客户和服务器之间的通信。我们将设计 REST 风格的 API。如果你不熟悉 restful API，你可以查阅外部资料，比如参考资料中的资料[1]。一个 URL 短链接主要需要两个 API 端点。&lt;/p>
&lt;ol>
&lt;li>URL 缩短。为了创建一个新的短 URL，客户端发送一个 POST 请求，其中包含一个参数：原来的长 URL。该 API 看起来像这样。&lt;/li>
&lt;/ol>
&lt;p>&lt;code>POST api/v1/data/shorten&lt;/code>&lt;/p>
&lt;ul>
&lt;li>请求参数：{longUrl: longURLString}&lt;/li>
&lt;li>返回 shortURL&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>URL 重定向。为了将短 URL 重定向到相应的长 URL，客户端发送一个 GET 请求。该 API 看起来像这样。&lt;/li>
&lt;/ol>
&lt;p>&lt;code>GET api/v1/shortUrl&lt;/code>&lt;/p>
&lt;ul>
&lt;li>为 HTTP 重定向返回 longURL&lt;/li>
&lt;/ul>
&lt;h4 id="url-重定向">URL 重定向&lt;/h4>
&lt;p>图 8-1 显示了当你在浏览器上输入一个 tinyurl 时会发生什么。一旦服务器收到 tinyurl 请求，它就会用 301 重定向将短网址改为长网址。&lt;/p>
&lt;img src="../../../system_design_interview/index-121_1.jpg" width="80%"/>
&lt;p>客户端和服务器之间的详细通信情况如图 8-2 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-122_1.jpg" width="50%"/>
&lt;p>这里值得讨论的一点是 301 重定向与 302 重定向。&lt;/p>
&lt;p>301 重定向。301 重定向表明请求的 URL 被 &amp;ldquo;永久&amp;rdquo; 地移到长 URL 上。由于是永久重定向，浏览器会缓存响应，对同一 URL 的后续请求将不会被发送到 URL 短链接服务中。相反，请求被直接重定向到长网址服务器。&lt;/p>
&lt;p>302 重定向。302 重定向意味着 URL 被 &amp;ldquo;暂时&amp;quot;移到长 URL 上，这意味着对同一 URL 的后续请求将首先被发送到 URL 短链接服务上。然后，它们会被重定向到长网址服务器。&lt;/p>
&lt;p>每种重定向方法都有其优点和缺点。如果优先考虑的是减少服务器负载，使用 301 重定向是有意义的，因为只有同一 URL 的第一个请求被发送到 URL 短链接服务器。然而，如果分析很重要，302 重定向是一个更好的选择，因为它可以更容易跟踪点击率和点击来源。&lt;/p>
&lt;p>实现 URL 重定向的最直观的方法是使用哈希表。假设哈希表存储&amp;lt;shortURL, longURL&amp;gt;对，URL 重定向可以通过以下方式实现。&lt;/p>
&lt;ul>
&lt;li>获取 longURL: longURL = hashTable.get(shortURL)&lt;/li>
&lt;li>一旦你得到 longURL，就执行 URL 重定向。&lt;/li>
&lt;/ul>
&lt;h4 id="url-缩短">URL 缩短&lt;/h4>
&lt;p>让我们假设短的 URL 看起来像这样：www.tinyurl.com/{hashValue}。为了支持缩短URL的用例，我们必须找到一个哈希函数fx，将长URL映射到hashValue，如图8-3所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-123_1.jpg" width="50%"/>
&lt;p>哈希函数必须满足以下要求。&lt;/p>
&lt;ul>
&lt;li>每个 longURL 必须被散列到一个 hashValue。&lt;/li>
&lt;li>每个 hashValue 都可以被映射回 longURL。&lt;/li>
&lt;/ul>
&lt;p>哈希函数的详细设计将在深入研究中讨论。&lt;/p>
&lt;h3 id="设计深挖">设计深挖&lt;/h3>
&lt;p>到目前为止，我们已经讨论了 URL 缩短和 URL 重定向的高层设计。在本节中，我们将深入探讨以下内容：数据模型、哈希函数、URL 缩短和 URL 重定向。&lt;/p>
&lt;h4 id="数据模型">数据模型&lt;/h4>
&lt;p>在高层设计中，所有的东西都存储在一个哈希表中。这是一个很好的出发点；然而，这种方法对于现实世界的系统来说是不可行的，因为内存资源是有限的，而且很昂贵。一个更好的选择是将&amp;lt;shortURL, longURL&amp;gt;映射存储在一个关系数据库中。图 8-4 显示了一个简单的数据库表设计。该表的简化版本包含 3 个列：ID、shortURL、longURL。&lt;/p>
&lt;img src="../../../system_design_interview/index-124_1.jpg" width="30%"/>
&lt;h4 id="哈希函数">哈希函数&lt;/h4>
&lt;p>哈希函数用于将一个长的 URL 散列成一个短的 URL，也称为 hashValue。&lt;/p>
&lt;h4 id="哈希值的长度">哈希值的长度&lt;/h4>
&lt;p>哈希值由[0-9, a-z, A-Z]中的字符组成，包含 10+26+26=62 个可能的字符。要想知道 hashValue 的长度，请找到最小的 n，使 62^n≥365 亿。根据粗略的估计，系统必须支持多达 365 亿个 URL。表 8-1 显示了 hashValue 的长度和它可以支持的相应最大 URL 数量。&lt;/p>
&lt;img src="../../../system_design_interview/index-125_1.jpg" width="80%"/>
&lt;p>当 n = 7 时，62 ^ n = ~3.5 万亿，3.5 万亿足以容纳 3650 亿个 URL，所以 hashValue 的长度为 7。&lt;/p>
&lt;p>我们将探索两种类型的 URL 短链接的哈希函数。第一种是 &amp;ldquo;哈希+碰撞解决&amp;rdquo;，第二种是 &amp;ldquo;base62 转换&amp;rdquo;。让我们逐一来看看它们。&lt;/p>
&lt;p>哈希+碰撞解析 要缩短一个长的 URL，我们应该实现一个哈希函数，将一个长的 URL 哈希成一个 7 字的字符串。一个直接的解决方案是使用知名的哈希函数，如 CRC32、MD5 或 SHA-1。下表比较了在这个 URL 上应用不同哈希函数后的哈希结果：https://en.wikipedia.org/wiki/Systems_design。&lt;/p>
&lt;img src="../../../system_design_interview/index-125_2.jpg" width="80%"/>
&lt;p>如表 8-2 所示，即使是最短的哈希值（来自 CRC32）也太长了（超过 7 个字符）。我们怎样才能使它更短呢？&lt;/p>
&lt;p>第一种方法是收集哈希值的前 7 个字符；但是，这种方法会导致哈希值的碰撞。为了解决哈希碰撞，我们可以递归地追加一个新的预定义字符串，直到不再发现碰撞。这个过程在图 8-5 中解释。&lt;/p>
&lt;img src="../../../system_design_interview/index-126_1.jpg" width="80%"/>
&lt;p>这种方法可以消除碰撞；但是，查询数据库以检查每个请求是否存在短网址的费用很高。一种叫做布隆过滤器的技术[2]可以提高性能。布隆过滤器是一种空间效率高的概率技术，用来测试一个元素是否是一个集合的成员。更多细节请参考参考资料[2]。&lt;/p>
&lt;p>base62 转换 基数转换是另一种常用于 URL 短链接的方法。基数转换有助于同一数字在其不同的数字表示系统之间的转换。基数 62 转换被使用，因为有 62 个可能的字符用于 hashValue。让我们用一个例子来解释转换是如何进行的：将 11157 10 转换成基数 62 表示法&lt;/p>
&lt;ul>
&lt;li>
&lt;p>从它的名字来看，base 62 是一种使用 62 个字符进行编码的方式。其映射方式为：。0-0，&amp;hellip;，9-9，10-a，11-b，&amp;hellip;，35-z，36-A，&amp;hellip;，61-Z，其中&amp;rsquo;a&amp;rsquo;代表 10，&amp;lsquo;Z&amp;rsquo;代表 61，等等。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11157 = 2 x 62^2 + 55 x 62^1 + 59 x 62^0 = [2, 55, 59] -&amp;gt; [2, T, X] 在基数 62 的表示。图 8-6 显示了转换的过程。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-127_1.jpg" width="80%"/>
&lt;ul>
&lt;li>因此，短网址是 &lt;a href="https://tinyurl.com/2TX">https://tinyurl.com/2TX&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>两种方法的比较，表 8-3 显示了两种方法的区别。&lt;/p>
&lt;img src="../../../system_design_interview/index-127_2.jpg" width="80%"/>
&lt;h4 id="url-缩短的深入研究">URL 缩短的深入研究&lt;/h4>
&lt;p>作为系统的核心部分之一，我们希望 URL 缩短的流程在逻辑上是简单和实用的。在我们的设计中使用了 62 进制转换。我们建立以下图表（图 8-7）来演示这个流程。&lt;/p>
&lt;img src="../../../system_design_interview/index-128_1.jpg" width="66%"/>
&lt;p>URL 缩短的深入研究&lt;/p>
&lt;p>作为系统的核心部分之一，我们希望 URL 缩短的流程在逻辑上是简单和实用的。在我们的设计中使用了 62 进制转换。我们建立以下图表（图 8-7）来演示这个流程。&lt;/p>
&lt;ol>
&lt;li>longURL 是输入。&lt;/li>
&lt;li>系统检查 longURL 是否在数据库中。&lt;/li>
&lt;li>如果是，说明 longURL 之前已经转换为 shortURL。在这种情况下，从数据库中获取 shortURL 并将其返回给客户端。&lt;/li>
&lt;li>如果不是，说明 longURL 是新的。一个新的唯一 ID（主键）由唯一 ID 生成器生成。&lt;/li>
&lt;li>用 62 进制转换将 ID 转换为 shortURL。&lt;/li>
&lt;li>用 ID、shortURL 和 longURL 创建一个新的数据库行。为了使这个流程更容易理解，让我们看一个具体的例子。&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>假设输入的 longURL 是：https://en.wikipedia.org/wiki/Systems_design&lt;/li>
&lt;li>唯一 ID 生成器返回 ID。2009215674938.&lt;/li>
&lt;li>使用 62 进制转换将 ID 转换为 shortURL。ID（2009215674938）被转换为 &amp;ldquo;zn9edcu&amp;rdquo;。&lt;/li>
&lt;li>将 ID、shortURL 和 longURL 保存到数据库中，如表 8-4 所示。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-128_2.jpg" width="80%"/>
&lt;p>值得一提的是，分布式唯一 ID 生成器。它的主要功能是生成全局唯一的 ID，用于创建 shortURLs。在一个高度分布式的环境中，实现一个唯一的 ID 生成器是具有挑战性的。幸运的是，我们已经在 &amp;ldquo;第 7 章：在分布式系统中设计一个唯一的 ID 生成器 &amp;ldquo;中讨论过一些解决方案。你可以参考它来复习你的记忆。&lt;/p>
&lt;h4 id="url-重定向的深入研究">URL 重定向的深入研究&lt;/h4>
&lt;p>图 8-8 显示了 URL 重定向的详细设计。由于读的次数多于写的次数，&amp;lt;shortURL, longURL&amp;gt;映射被存储在一个缓存中以提高性能。&lt;/p>
&lt;img src="../../../system_design_interview/index-129_1.jpg" width="100%"/>
&lt;p>URL 重定向的流程总结如下。&lt;/p>
&lt;ol>
&lt;li>一个用户点击一个简短的 URL 链接：https://tinyurl.com/zn9edcu&lt;/li>
&lt;li>负载均衡器将请求转发给网络服务器。&lt;/li>
&lt;li>如果短 URL 已经在缓存中，直接返回长 URL。&lt;/li>
&lt;li>如果短 URL 不在缓存中，从数据库中获取长 URL。如果它不在数据库中，很可能是用户输入了一个无效的短 URL。&lt;/li>
&lt;li>5.将 longURL 返回给用户。&lt;/li>
&lt;/ol>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在这一章中，我们谈到了 API 设计、数据模型、哈希函数、URL 缩短和 URL 重定向。&lt;/p>
&lt;p>如果在采访结束时有多余的时间，这里有几个额外的谈话要点。&lt;/p>
&lt;ul>
&lt;li>限流器。我们可能面临的一个潜在的安全问题是，恶意用户发送大量的 URL 缩短请求。限流器有助于根据 IP 地址或其他过滤规则来过滤掉请求。如果你想复习一下关于限流的知识，请参考 &amp;ldquo;第四章：设计一个限流器&amp;rdquo;。&lt;/li>
&lt;li>网络服务器的扩展。由于网络层是无状态的，所以很容易通过添加或删除网络服务器来扩展网络层。&lt;/li>
&lt;li>数据库的扩展。数据库复制和分片是常见的技术。&lt;/li>
&lt;li>分析。数据对商业成功越来越重要。将分析解决方案整合到 URL 短链接中可以帮助回答一些重要的问题，如有多少人点击了一个链接？他们何时点击链接？等等。&lt;/li>
&lt;li>可用性、一致性和可靠性。这些概念是任何大型系统成功的核心。我们在第 1 章中详细讨论了它们，请你复习一下这些话题。&lt;/li>
&lt;/ul>
&lt;p>祝贺你走到这一步! 现在给自己拍拍胸脯吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1] &lt;a href="https://www.restapitutorial.com/index.html">a restful tutorial&lt;/a>&lt;br>
[2] &lt;a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter&lt;/a>&lt;/p></description></item><item><title>系统设计::在分布式系统中设计一个唯一ID生成器</title><link>/system_design/system_design_interview_07/</link><pubDate>Sun, 07 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_07/</guid><description>&lt;h2 id="在分布式系统中设计一个唯一-id-生成器">在分布式系统中设计一个唯一 ID 生成器&lt;/h2>
&lt;p>在本章中，你被要求设计一个分布式系统中的唯一 ID 生成器。你的第一个想法可能是在传统的数据库中使用一个带有自动增加属性的主键。然而，auto_increment 在分布式环境中不起作用，因为单个数据库服务器不够大，以最小的延迟在多个数据库中生成唯一的 ID 是具有挑战性的。&lt;/p>
&lt;p>这里有几个唯一 ID 的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-110_1.jpg" width="30%"/>
&lt;h3 id="了解问题并确定设计范围">了解问题并确定设计范围&lt;/h3>
&lt;p>提出明确的问题是解决任何系统设计面试问题的第一步。下面是一个候选人与面试官互动的例子。&lt;/p>
&lt;p>候选人：唯一 ID 的特点是什么？&lt;br>
面试官：ID 必须是唯一的，而且是可排序的。&lt;br>
候选者：对于每条新记录，ID 是否递增 1？&lt;br>
面试官：ID 按时间递增，但不一定只按 1 递增。在晚上创建的 ID 比同一天早上创建的 ID 要大。&lt;br>
候选人：ID 是否只包含数值？&lt;br>
面试官：是的，这是对的。&lt;br>
候选热：ID 的长度要求是什么？&lt;br>
面试官：ID 最长 64 位。&lt;br>
候选热：系统的规模是多少？&lt;br>
面试官：系统应该能够每秒生成 10,000 个 ID。&lt;/p>
&lt;p>以上是一些你可以问面试官的样本问题。理解需求并澄清模糊之处非常重要。对于这个面试问题，要求列举如下。&lt;/p>
&lt;ul>
&lt;li>ID 必须是唯一的。&lt;/li>
&lt;li>ID 只能是数值。&lt;/li>
&lt;li>IDs 最长 64 位的。&lt;/li>
&lt;li>IDs 按日期排序。&lt;/li>
&lt;li>有能力每秒产生超过 10,000 个唯一的 ID。&lt;/li>
&lt;/ul>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>在分布式系统中，可以使用多种选项来生成唯一的 ID。我们考虑的选项是。&lt;/p>
&lt;ul>
&lt;li>多主机复制&lt;/li>
&lt;li>通用唯一标识符 UUID&lt;/li>
&lt;li>Ticket server&lt;/li>
&lt;li>Twitter Snowflake&lt;/li>
&lt;/ul>
&lt;p>让我们来看看他们中的每一个，他们是如何工作的，以及每个选项的优点/缺点。&lt;/p>
&lt;h4 id="多主机复制">多主机复制&lt;/h4>
&lt;p>如图 7-2 所示，第一个方法是多主机复制。&lt;/p>
&lt;img src="../../../system_design_interview/index-112_1.jpg" width="50%"/>
&lt;p>这种方法使用了数据库的自动递增功能。我们不是将下一个 ID 增加 1，而是增加 k，其中 k 是使用中的数据库服务器的数量。如图 7-2 所示，要生成的下一个 ID 等于同一服务器中的上一个 ID 加 2。这解决了一些可扩展性问题，因为 ID 可以随着数据库服务器的数量而扩展。然而，这种策略有一些主要的缺点。&lt;/p>
&lt;ul>
&lt;li>很难在多个数据中心中进行扩展&lt;/li>
&lt;li>在多个服务器上，ID 不会随着时间而上升。&lt;/li>
&lt;li>当一个服务器被添加或删除时，它不能很好地扩展。&lt;/li>
&lt;/ul>
&lt;h4 id="uuid">UUID&lt;/h4>
&lt;p>UUID 是另一种获得唯一 ID 的简单方法。UUID 是一个 128 位的数字，用于识别计算机系统中的信息。UUID 重复的概率非常低。引自维基百科，&amp;ldquo;在每秒产生 10 亿个 UUIDs 大约 100 年后，创造一个重复的概率会达到 50%&amp;rdquo; [1]。&lt;/p>
&lt;p>这里有一个 UUID 的例子：09c93e62-50b4-468d-bf8a-c07e1040bfb2。UUID 可以独立生成，不需要服务器之间的协调。图 7-3 介绍了 UUIDs 的设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-113_1.jpg" width="70%"/>
&lt;p>在这种设计中，每个网络服务器包含一个 ID 生成器，一个网络服务器负责独立生成 ID。&lt;/p>
&lt;ul>
&lt;li>优点。
&lt;ul>
&lt;li>生成 UUID 很简单。不需要服务器之间的协调，所以不会有任何同步的问题。&lt;/li>
&lt;li>该系统很容易扩展，因为每个网络服务器负责生成他们所消费的 ID。ID 生成器可以很容易地与网络服务器一起扩展。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缺点。
&lt;ul>
&lt;li>ID 的长度是 128 位，但我们的要求是 64 位。&lt;/li>
&lt;li>ID 不会随着时间的推移而增加。&lt;/li>
&lt;li>ID 可能是非数字性的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="ticket-server">Ticket Server&lt;/h4>
&lt;p>Ticket server 器是产生唯一 ID 的另一种有趣的方式。Flicker 开发了 Ticket server 器来生成分布式主键[2]。值得一提的是，该系统是如何工作的。&lt;/p>
&lt;img src="../../../system_design_interview/index-113_2.jpg" width="70%"/>
&lt;p>这个想法是在一个单一的数据库服务器（Ticket Server）中使用一个集中的自动增量功能。要了解更多这方面的信息，请参考 flicker 的工程博客文章[2]。&lt;/p>
&lt;ul>
&lt;li>优点。
&lt;ul>
&lt;li>数值化的 ID。&lt;/li>
&lt;li>它很容易实现，而且适用于中小规模的应用。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缺点：
&lt;ul>
&lt;li>单点故障。单一的 Ticket server 意味着如果 Ticket server 发生故障，所有依赖它的系统都将面临问题。为了避免单点故障，我们可以设置多个票务服务器。然而，这将引入新的挑战，如数据同步。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="twitter-snowflake">Twitter snowflake&lt;/h4>
&lt;p>上面提到的方法给了我们一些关于不同的 ID 生成系统如何工作的想法。然而，它们都不符合我们的具体要求；因此，我们需要另一种方法。Twitter 的唯一 ID 生成系统 &amp;ldquo;snowflake&amp;rdquo;[3]很有启发性，可以满足我们的要求。&lt;/p>
&lt;p>分而治之是我们的朋友。我们不是直接生成一个 ID，而是将一个 ID 分成不同的部分。图 7-5 显示了一个 64 位 ID 的布局。&lt;/p>
&lt;img src="../../../system_design_interview/index-114_1.jpg" width="70%"/>
&lt;p>下面对每个部分进行解释。&lt;/p>
&lt;ul>
&lt;li>符号位。1 位。它将永远是 0。 这是保留给未来使用的。它有可能被用来区分有符号和无符号的数字。&lt;/li>
&lt;li>时间戳。41 位。自纪元或自定义纪元以来的毫秒。我们使用 Twitter snowflake 的默认纪元 1288834974657，相当于 2010 年 11 月 4 日，01:42:54 UTC。&lt;/li>
&lt;li>数据中心 ID：5 位，这给了我们 2 ^ 5 = 32 个数据中心。&lt;/li>
&lt;li>机器 ID：5 位，每个数据中心有 2 ^ 5 = 32 台机器。&lt;/li>
&lt;li>序列号：12 位。对于在该机器/进程上产生的每一个 ID，序列号都会增加 1，该号码每隔一毫秒重置为 0。&lt;/li>
&lt;/ul>
&lt;h3 id="设计深究">设计深究&lt;/h3>
&lt;p>在高层设计中，我们讨论了在分布式系统中设计一个独特的 ID 生成器的各种方案。我们确定了一种基于 Twitter snowflake ID 生成器的方法。让我们深入了解一下这个设计。为了唤起我们的记忆，下面重新列出了设计图。&lt;/p>
&lt;img src="../../../system_design_interview/index-115_1.jpg" width="70%"/>
&lt;p>数据中心 ID 和机器 ID 是在启动时选择的，一般在系统运行后就固定下来。数据中心 ID 和机器 ID 的任何变化都需要仔细审查，因为这些数值的意外变化会导致 ID 冲突。时间戳和序列号是在 ID 生成器运行时生成的。&lt;/p>
&lt;p>时间戳&lt;/p>
&lt;p>最重要的 41 位组成了时间戳部分。由于时间戳随时间增长，ID 可按时间排序。图 7-7 显示了一个二进制表示法转换为 UTC 的例子。你也可以用类似的方法将 UTC 转换回二进制表示法。&lt;/p>
&lt;img src="../../../system_design_interview/index-115_2.jpg" width="70%"/>
&lt;p>可以用 41 位表示的最大时间戳是&lt;/p>
&lt;p>2 ^ 41 - 1 = 2199023255551 毫秒（ms），这给了我们。~ 69 年=2199023255551 毫秒/1000 秒/365 天/24 小时/3600 秒。这意味着 ID 生成器将工作 69 年，有一个接近今天日期的自定义纪元时间可以延迟溢出时间。69 年后，我们将需要一个新的纪元时间或采用其他技术来迁移 ID。&lt;/p>
&lt;p>序列号 序列号是 12 位，给我们 2 ^ 12 = 4096 种组合。这个字段是 0，除非在同一台服务器上一毫秒内产生一个以上的 ID。理论上，一台机器每毫秒最多可以支持 4096 个新 ID。&lt;/p>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在这一章中，我们讨论了设计唯一 ID 生成器的不同方法：多主机复制、UUID、Ticket server 和 Twitter snowflake 的唯一 ID 生成器。 我们最终选择了 snowflake，
因为它支持我们所有的用例，并且在分布式环境中是可扩展的。&lt;/p>
&lt;p>如果在采访结束时有多余的时间，这里有一些额外的谈话要点。&lt;/p>
&lt;ul>
&lt;li>时钟同步。在我们的设计中，我们假设 ID 代服务器有相同的时钟。当一个服务器在多个核心上运行时，这个假设可能并不真实。在多机器的情况下也存在同样的挑战。时钟同步的解决方案不在本书的讨论范围之内；然而，了解问题的存在是很重要的。网络时间协议是解决这个问题最流行的方案。有兴趣的读者可以参考参考资料[4]。&lt;/li>
&lt;li>节段长度的调整。例如，较少的序列号但较多的时间戳位对低并发和长期应用是有效的。&lt;/li>
&lt;li>高可用性。由于 ID 生成器是一个关键任务的系统，它必须是高度可用的。&lt;/li>
&lt;/ul>
&lt;p>祝贺你走到了这一步! 现在给自己拍拍胸脯吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1]&lt;a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">universally unique identifier&lt;/a>&lt;br>
[2]&lt;a href="https://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-thecheap/">ticket servers: distributed unique primary keys on the cheap:&lt;/a>&lt;br>
[3]&lt;a href="https://blog.twitter.com/engineering/en_us/a/2010/announcingsnowflake.html">announcing snowflake&lt;/a>&lt;br>
[4]&lt;a href="https://en.wikipedia.org/wiki/Network_Time_Protocol">network time protocol&lt;/a>&lt;/p></description></item><item><title>系统设计::设计键值存储</title><link>/system_design/system_design_interview_06/</link><pubDate>Sat, 06 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_06/</guid><description>&lt;h2 id="设计键值存储">设计键值存储&lt;/h2>
&lt;p>键值存储，也被称为键值数据库，是一个非关系型数据库。每一个独特的标识符都被存储为一个带有相关值的键。这种数据配对被称为 &amp;ldquo;键-值&amp;quot;对。&lt;/p>
&lt;p>在一个键值对中，键必须是唯一的，与键相关的值可以通过键来访问。key 可以是纯文本或散列值。出于性能方面的考虑，短键的效果更好。键是什么样子的？这里有几个例子。&lt;/p>
&lt;ul>
&lt;li>普通文本 key：&amp;ldquo;last_logged_in_at&amp;rdquo;&lt;/li>
&lt;li>哈希后的 key：253DDEC4&lt;/li>
&lt;/ul>
&lt;p>键值对中的值可以是字符串、列表、对象，等等。在键值存储中，值通常被视为不透明的对象，如 Amazon dynamo [1], Memcached [2], Redis [3], 等等。&lt;/p>
&lt;p>下面是键值存储中的一个数据片段。&lt;/p>
&lt;img src="../../../system_design_interview/index-87_1.jpg" width='50%'/>
&lt;p>在本章中，要求你设计一个支持以下操作的键值存储。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>- put(key, value) // 插入与 &amp;#34;key &amp;#34;相关的 &amp;#34;value&amp;#34;。
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- get(key) // 获取与 &amp;#34;key &amp;#34;相关的 &amp;#34;value&amp;#34;。
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>没有完美的设计。每一个设计都要实现关于读、写和内存使用的权衡的具体平衡。另一个必须做出的权衡是在一致性和可用性之间。在本章中，我们设计了一个包括以下特征的键值存储。&lt;/p>
&lt;ul>
&lt;li>一个键值对的大小很小：小于 10KB。&lt;/li>
&lt;li>有能力存储大数据。&lt;/li>
&lt;li>高可用性。系统响应迅速，即使在故障时也能响应。&lt;/li>
&lt;li>高可扩展性。系统可以被扩展以支持大型数据集。&lt;/li>
&lt;li>自动扩展。服务器的增加/删除应该是基于流量的自动。&lt;/li>
&lt;li>可调整的一致性。&lt;/li>
&lt;li>低延迟。&lt;/li>
&lt;/ul>
&lt;h3 id="单个服务器键值存储">单个服务器键值存储&lt;/h3>
&lt;p>开发一个部署在单一服务器上的键值存储很容易。一个直观的方法是将键值对存储在一个哈希表中，这样可以将所有的东西保存在内存中。尽管内存访问速度很快，但由于空间的限制，在内存中容纳所有内容可能是不可能的。为了在单个服务器中容纳更多的数据，可以做两个优化。&lt;/p>
&lt;ul>
&lt;li>数据压缩&lt;/li>
&lt;li>只在内存中存储经常使用的数据，其余的存储在磁盘上。&lt;/li>
&lt;/ul>
&lt;p>即使进行了这些优化，单个服务器也会很快达到其容量。为了支持大数据，需要一个分布式的键值存储。&lt;/p>
&lt;h3 id="分布式键值存储">分布式键值存储&lt;/h3>
&lt;p>分布式键值存储也被称为分布式哈希表，它将键值对分布在许多服务器上。在设计分布式系统时，理解 CAP（一致性、可用性、分区容错）定理很重要。&lt;/p>
&lt;h3 id="cap-定理">CAP 定理&lt;/h3>
&lt;p>CAP 定理指出，一个分布式系统不可能同时提供这三种保证中的两种以上：一致性、可用性和分区容错。让我们建立几个定义。&lt;/p>
&lt;ul>
&lt;li>一致性：一致性意味着所有客户在同一时间看到相同的数据，无论他们连接到哪个节点。&lt;/li>
&lt;li>可用性：可用性意味着任何请求数据的客户端都能得到响应，即使有些节点发生了故障。&lt;/li>
&lt;li>分区容错：分区表示两个节点之间的通信中断。分区容错意味着尽管网络分区，系统仍能继续运行。&lt;/li>
&lt;/ul>
&lt;p>CAP 定理指出，必须牺牲三个属性中的一个来支持三个属性中的两个，如图 6-1 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-90_1.jpg" width="50%"/>
&lt;p>现在，键值存储是根据它们支持的两个 CAP 特性来分类的。&lt;/p>
&lt;ul>
&lt;li>CP（一致性和分区容忍）系统：CP 键值存储支持一致性和分区容忍，同时牺牲了可用性。&lt;/li>
&lt;li>AP（可用性和分区容忍）系统：AP 键值存储支持可用性和分区容忍，同时牺牲了一致性。&lt;/li>
&lt;li>CA（一致性和可用性）系统：CA 键值存储支持一致性和可用性，同时牺牲了分区容忍度。&lt;/li>
&lt;/ul>
&lt;p>由于网络故障是不可避免的，一个分布式系统必须容忍网络分区。因此，CA 系统不能存在于现实世界的应用中。&lt;/p>
&lt;p>你在上面读到的主要是定义部分。为了使它更容易理解，让我们看看一些具体的例子。在分布式系统中，数据通常被多次复制。假设数据被复制在三个复制节点上，如图 62 所示，n1、n2 和 n3。&lt;/p>
&lt;p>在理想状态下，网络分区永远不会发生。写到 n1 的数据会自动复制到 n2 和 n3。一致性和可用性都得以实现。&lt;/p>
&lt;img src="../../../system_design_interview/index-91_1.jpg" width="50%"/>
&lt;p>在真实世界的分布式系统中，分区是无法避免的，当分区发生时，我们必须在一致性和可用性之间做出选择。在图 6-3 中，n3 发生故障，无法与 n1 和 n2 通信。如果客户端向 n1 或 n2 写数据，数据就不能传播到 n3。如果数据被写入 n3，但还没有传播到 n1 和 n2，n1 和 n2 就会有陈旧的数据。&lt;/p>
&lt;img src="../../../system_design_interview/index-92_1.jpg" width="50%"/>
&lt;p>如果我们选择一致性大于可用性（CP 系统），我们必须阻止对 n1 和 n2 的所有写操作，以避免这三个服务器之间的数据不一致，这使得系统不可用。银行系统通常有极高的一致性要求。例如，对银行系统来说，显示最新的余额信息是至关重要的。如果由于网络分区而发生不一致，在不一致问题解决之前，银行系统会返回一个错误。&lt;/p>
&lt;p>然而，如果我们选择可用性而不是一致性（AP 系统），系统就会继续接受读取，即使它可能返回陈旧的数据。对于写，n1 和 n2 将继续接受写，当网络分区被解决时，数据将被同步到 n3。&lt;/p>
&lt;p>选择适合你使用情况的正确 CAP 保证是建立分布式键值存储的一个重要步骤。你可以和你的面试官讨论这个问题，并据此设计系统。&lt;/p>
&lt;h3 id="系统组件">系统组件&lt;/h3>
&lt;p>在本节中，我们将讨论以下用于构建键值存储的核心组件和技术。&lt;/p>
&lt;ul>
&lt;li>数据分区&lt;/li>
&lt;li>数据复制&lt;/li>
&lt;li>一致性&lt;/li>
&lt;li>不一致的解决&lt;/li>
&lt;li>处理故障&lt;/li>
&lt;li>系统架构图&lt;/li>
&lt;li>写路径&lt;/li>
&lt;li>读路径&lt;/li>
&lt;/ul>
&lt;p>下面的内容主要是基于三个流行的键值存储系统。Dynamo[4]、Cassandra[5]和 BigTable[6]。&lt;/p>
&lt;h3 id="数据分区">数据分区&lt;/h3>
&lt;p>对于大型应用来说，将完整的数据集装入一台服务器是不可行的。实现这一目标的最简单方法是将数据分割成较小的分区，并将其存储在多个服务器中。在对数据进行分区时，有两个挑战。&lt;/p>
&lt;ul>
&lt;li>将数据均匀地分布在多个服务器上。&lt;/li>
&lt;li>当节点被添加或移除时，最大限度地减少数据移动。&lt;/li>
&lt;/ul>
&lt;p>第五章中讨论的一致性散列是解决这些问题的一个很好的技术。让我们重新审视一下一致散列法在高层次上的工作原理。&lt;/p>
&lt;ul>
&lt;li>首先，服务器被放置在一个哈希环上。在图 6-4 中，八个服务器，分别代表 s0, s1, &amp;hellip;, s7，被放置在哈希环上。&lt;/li>
&lt;li>接下来，一个 key 被散列在同一个环上，它被存储在顺时针方向移动时遇到的第一个服务器上。例如，使用这个逻辑，key0 被存储在 s1。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-93_1.jpg" width="50%"/>
&lt;p>使用一致的散列法对数据进行分区有以下优点。&lt;/p>
&lt;ul>
&lt;li>自动扩展：服务器可以根据负载情况自动添加和删除。&lt;/li>
&lt;li>异质性：服务器的虚拟节点数量与服务器容量成正比。例如，具有较高容量的服务器被分配有更多的虚拟节点。&lt;/li>
&lt;/ul>
&lt;h3 id="数据复制">数据复制&lt;/h3>
&lt;p>为了实现高可用性和可靠性，数据必须在 N 个服务器上进行异步复制，其中 N 是一个可配置参数。这 N 个服务器的选择采用以下逻辑：在一个 key 被映射到哈希环上的某个位置后，从该位置顺时针走，选择环上的前 N 个服务器来存储数据副本。在图 6-5（N=3）中，key0 被复制在 s1、s2 和 s3。&lt;/p>
&lt;img src="../../../system_design_interview/index-94_1.jpg" width="50%"/>
&lt;p>对于虚拟节点，环上的前 N 个节点可能由少于 N 个物理服务器拥有。为了避免这个问题，我们在执行顺时针行走逻辑时只选择唯一的服务器。&lt;/p>
&lt;p>由于停电、网络问题、自然灾害等原因，同一数据中心的节点经常在同一时间发生故障。为了提高可靠性，副本被放置在不同的数据中心，并且数据中心通过高速网络连接。&lt;/p>
&lt;h3 id="一致性">一致性&lt;/h3>
&lt;p>由于数据是在多个节点上复制的，因此必须在不同的复制体之间进行同步。法定人数共识可以保证读和写操作的一致性。让我们首先建立几个定义。&lt;/p>
&lt;p>N = 复制体的数量&lt;br>
W = 大小为 W 的写法定人数。为了使一个写操作被认为是成功的，写操作必须得到 W 个复制体的确认。&lt;br>
R = 规模为 R 的读取法定人数。为了使读取操作被认为是成功的，读取操作必须等待至少 R 个副本的响应。&lt;/p>
&lt;p>考虑以下图 6-6 所示的例子，N=3。&lt;/p>
&lt;img src="../../../system_design_interview/index-95_1.jpg" width="50%"/>
&lt;p>W = 1 并不意味着数据被写在一台服务器上。例如，在图 6-6 的配置中，数据是在 s0、s1 和 s2 复制的。W = 1 意味着协调器必须在写操作被认为是成功之前收到至少一个确认。例如，如果我们从 s1 得到一个确认，我们就不再需要等待 s0 和 s2 的确认了。协调器在客户端和节点之间充当代理。&lt;/p>
&lt;p>W、R 和 N 的配置是一个典型的延迟和一致性之间的权衡。如果 W=1 或 R=1，一个操作会被快速返回，因为协调者只需要等待任何一个副本的响应。如果 W 或 R&amp;gt;1，系统提供更好的一致性；然而，查询会更慢，因为协调者必须等待最慢的副本的响应。&lt;/p>
&lt;p>如果 W+R &amp;gt; N，强一致性得到保证，因为必须至少有一个重叠节点拥有最新的数据以保证一致性。&lt;/p>
&lt;p>如何配置 N、W 和 R 以适应我们的使用情况？下面是一些可能的设置。&lt;/p>
&lt;p>如果 R = 1，W = N，系统被优化为快速读取。&lt;br>
如果 W = 1，R = N，系统被优化为快速写入。&lt;br>
如果 W + R &amp;gt; N，强一致性得到保证（通常 N = 3，W = R = 2）。&lt;br>
如果 W + R &amp;lt;= N，强一致性不被保证。&lt;/p>
&lt;p>根据要求，我们可以调整 W、R、N 的值，以达到理想的一致性水平。&lt;/p>
&lt;h3 id="一致性模型">一致性模型&lt;/h3>
&lt;p>一致性模型是设计键值存储时需要考虑的其他重要因素。一致性模型定义了数据的一致性程度，并且存在广泛的可能的一致性模型。&lt;/p>
&lt;ul>
&lt;li>强一致性：任何读操作都会返回一个与最新的写数据项的结果相对应的值。客户端永远不会看到过时的数据。&lt;/li>
&lt;li>弱一致性：后续的读操作可能看不到最新的值。&lt;/li>
&lt;li>最终一致性：这是弱一致性的一种特殊形式。只要有足够的时间，所有的更新都会被传播，所有的副本都是一致的。&lt;/li>
&lt;/ul>
&lt;p>强一致性通常是通过强迫一个副本不接受新的读/写，直到每个副本都同意当前的写来实现的。这种方法对于高可用系统来说并不理想，因为它可能会阻塞新的操作。Dynamo 和 Cassandra 采用最终一致性，这是我们推荐的键值存储的一致性模型。从并发写入来看，最终一致性允许不一致的值进入系统，并迫使客户端读取这些值来进行调节。下一节将解释和解是如何与版本管理一起工作的。&lt;/p>
&lt;h3 id="不一致的解决方法版本管理">不一致的解决方法：版本管理&lt;/h3>
&lt;p>复制提供了高可用性，但会导致复制体之间的不一致。版本管理和矢量锁被用来解决不一致的问题。版本管理是指将每次数据修改作为一个新的不可更改的数据版本来处理。在我们谈论版本控制之前，让我们用一个例子来解释不一致是如何发生的。&lt;/p>
&lt;p>如图 6-7 所示，两个复制节点 n1 和 n2 都有相同的值。我们把这个值称为原始值。服务器 1 和服务器 2 在 get(&amp;ldquo;name&amp;rdquo;)操作中得到相同的值。&lt;/p>
&lt;img src="../../../system_design_interview/index-97_1.jpg" width="50%"/>
&lt;p>接下来，服务器 1 将名称改为 &amp;ldquo;johnSanFrancisco&amp;rdquo;，而服务器 2 将名称改为 &amp;ldquo;johnNewYork&amp;rdquo;，如图 6-8 所示。这两个改变是同时进行的。现在，我们有相互冲突的值，称为版本 v1 和 v2。&lt;/p>
&lt;img src="../../../system_design_interview/index-97_2.jpg" width="50%"/>
&lt;p>在这个例子中，原始值可以被忽略，因为修改是基于它的。然而，没有明确的方法来解决最后两个版本的冲突。为了解决这个问题，我们需要一个可以检测冲突和调和冲突的版本系统。矢量时钟是解决这个问题的一个常用技术。让我们来看看矢量时钟是如何工作的。矢量时钟是一个与数据项相关的[服务器，版本]对。它可以用来检查一个版本是否在前，是否成功，是否与其他版本冲突。&lt;/p>
&lt;p>假设一个矢量时钟由 D([S1, v1], [S2, v2], &amp;hellip;, [Sn, vn])表示，其中 D 是一个数据项，v1 是一个版本计数器，s1 是一个服务器号码，等等。如果数据项 D 被写入服务器 Si，系统必须执行以下任务之一。&lt;/p>
&lt;ul>
&lt;li>如果[Si, vi]存在，则递增 vi。&lt;/li>
&lt;li>否则，创建一个新条目[Si, 1]。&lt;/li>
&lt;/ul>
&lt;p>如图 6-9 所示，用一个具体的例子来解释上述的抽象逻辑。&lt;/p>
&lt;img src="../../../system_design_interview/index-98_1.jpg" width="50%"/>
&lt;ol>
&lt;li>一个客户向系统写入一个数据项 D1，该写入由服务器 Sx 处理，它现在拥有向量时钟 D1[(Sx, 1)]。&lt;/li>
&lt;li>另一个客户端读取最新的 D1，将其更新为 D2，并将其写回。D2 是从 D1 下降的，所以它覆盖了 D1。假设这个写是由同一个服务器 Sx 处理的，它现在有矢量时钟 D2([Sx, 2])。&lt;/li>
&lt;li>另一个客户端读取最新的 D2，将其更新为 D3，并将其写回。假设这个写是由服务器 Sy 处理的，它现在有向量时钟 D3([Sx, 2], [Sy, 1])。&lt;/li>
&lt;li>另一个客户端读取最新的 D2，将其更新为 D4，并将其写回。假设这个写是由服务器 Sz 处理的，它现在有 D4([Sx, 2], [Sz, 1])）。)&lt;/li>
&lt;li>当另一个客户端读取 D3 和 D4 时，它发现了一个冲突，这是由于数据项 D2 被 Sy 和 Sz 修改所引起的。该冲突由客户端解决，更新的数据被发送到服务器。假设写入是由 Sx 处理的，它现在有 D5（[Sx, 3], [Sy, 1], [Sz, 1]）。我们将很快解释如何检测冲突。&lt;/li>
&lt;/ol>
&lt;p>使用矢量时钟，如果 Y 的矢量时钟中每个参与者的版本计数器大于或等于版本 X 中的计数器，就很容易知道版本 X 是版本 Y 的祖先（即没有冲突）。例如，矢量时钟 D（[s0, 1], [s1, 1]）]是 D（[s0, 1], [s1, 2]）的祖先。因此，没有冲突被记录下来。&lt;/p>
&lt;p>同样地，如果在 Y 的向量钟中有任何参与者的计数器小于 X 中的相应计数器，你就可以知道一个版本 X 是 Y 的兄弟姐妹（即存在冲突）。D([s0, 1], [s1, 2]) 和 D([s0, 2], [s1, 1])。&lt;/p>
&lt;p>尽管矢量时钟可以解决冲突，但有两个明显的缺点。首先，矢量时钟增加了客户端的复杂性，因为它需要实现冲突解决逻辑。&lt;/p>
&lt;p>第二，矢量时钟中的[服务器：版本]对可能迅速增长。为了解决这个问题，我们为长度设置了一个阈值，如果超过了这个限制，最老的对就会被删除。这可能会导致和解的效率低下，因为不能准确地确定子孙关系。然而，根据 Dynamo 论文[4]，亚马逊还没有在生产中遇到这个问题；因此，对于大多数公司来说，这可能是一个可以接受的解决方案。&lt;/p>
&lt;h3 id="失败处理">失败处理&lt;/h3>
&lt;p>与任何大规模的系统一样，故障不仅是不可避免的，而且是常见的。处理故障情况是非常重要的。在本节中，我们首先介绍检测故障的技术。然后，我们将介绍常见的故障解决策略。&lt;/p>
&lt;p>故障处理，在一个分布式系统中，仅仅因为另一台服务器说故障，就认为一台服务器故障是不充分的。通常情况下，至少需要两个独立的信息源来标记一台服务器停机。&lt;/p>
&lt;p>如图 6-10 所示，全对全组播是一个直接的解决方案。然而，当系统中存在许多服务器时，这是不高效的。&lt;/p>
&lt;img src="../../../system_design_interview/index-100_1.jpg" width="50%"/>
&lt;p>一个更好的解决方案是使用分散的故障检测方法，如 Gossip 协议。Gossip 协议的工作原理如下。&lt;/p>
&lt;ul>
&lt;li>每个节点维护一个节点成员列表，其中包含成员 ID 和心跳计数器。&lt;/li>
&lt;li>每个节点周期性地增加其心跳计数器。&lt;/li>
&lt;li>每个节点定期向一组随机节点发送心跳，而这些节点又向另一组节点传播。&lt;/li>
&lt;li>一旦节点收到心跳，成员列表就会更新到最新的信息。&lt;/li>
&lt;li>如果心跳没有增加超过预定的时间，则该成员被认为是离线的。&lt;/li>
&lt;li>节点 s0 维护着左侧所示的节点成员列表。&lt;/li>
&lt;li>节点 s0 注意到节点 s2（成员 ID=2）的心跳计数器已经很长时间没有增加了。&lt;/li>
&lt;li>节点 s0 向一组随机节点发送包括 s2 的信息的心跳。一旦其他节点确认 s2 的心跳计数器长时间没有更新，节点 s2 就会被标记下来，这个信息会传播给其他节点。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-100_2.jpg" width="100%" />
&lt;p>处理临时故障&lt;/p>
&lt;p>在通过 Gossip 协议检测到故障后，系统需要部署某些机制来确保可用性。在严格的法定人数方法中，读和写操作可能会被阻止，正如在法定人数共识部分所说明的。&lt;/p>
&lt;p>一种叫做 &amp;ldquo;马虎的法定人数&amp;rdquo;[4]的技术被用来提高可用性。系统不强制执行法定人数要求，而是在哈希环上选择前 W 个健康的服务器进行写操作，前 R 个健康的服务器进行读操作。离线服务器被忽略。&lt;/p>
&lt;p>如果一个服务器由于网络或服务器故障而不可用，另一个服务器将临时处理请求。当停机的服务器起来后，变化将被推回以实现数据的一致性。这个过程被称为提示性交接。由于图 6-12 中 s2 不可用，读和写将暂时由 s3 处理。当 s2 重新上线时，s3 将把数据交还给 s2。&lt;/p>
&lt;img src="../../../system_design_interview/index-101_1.jpg" width="50%"/>
&lt;p>暗示交接是用来处理临时故障的。如果一个副本永久不可用怎么办？为了处理这种情况，我们实施了一个反熵协议来保持副本的同步。反熵包括比较副本上的每一块数据，并将每个副本更新为最新的版本。Merkle 树用于检测不一致，并尽量减少传输的数据量。&lt;/p>
&lt;p>引自维基百科[7]。&amp;ldquo;散列树或 Merkle 树是一棵树，其中每个非叶子节点都标有其子节点的标签或值（如果是叶子的话）的散列。哈希树允许对大型数据结构的内容进行有效和安全的验证&amp;rdquo;。&lt;/p>
&lt;p>假设 key 空间从 1 到 12，下面的步骤显示了如何建立一个 Merkle 树。高亮的方框表示不一致的地方。&lt;/p>
&lt;p>步骤 1：如图 6-13 所示，将 key 空间划分为桶（在我们的例子中为 4）。一个桶被用作根级节点，以保持树的有限深度。&lt;/p>
&lt;img src="../../../system_design_interview/index-102_1.jpg" />
&lt;p>第 2 步：一旦创建了桶，使用统一的散列方法对桶中的每个 key 进行散列（图 6-14）。&lt;/p>
&lt;img src="../../../system_design_interview/index-102_2.jpg" />
&lt;p>第 3 步：为每个桶创建一个哈希节点（图 6-15）。
&lt;img src="../../../system_design_interview/index-102_3.jpg" />&lt;/p>
&lt;p>第四步：通过计算子代的哈希值，向上建立树，直到根（图 6-16）。&lt;/p>
&lt;img src="../../../system_design_interview/index-103_1.jpg" />
&lt;p>要比较两个 Merkle 树，首先要比较根哈希值。如果根哈希值匹配，则两个服务器有相同的数据。如果根哈希值不一致，那么就比较左边的子哈希值，然后是右边的子哈希值。你可以遍历树，找到哪些桶没有被同步，只同步这些桶。&lt;/p>
&lt;p>使用 Merkle 树，需要同步的数据量与两个副本之间的差异成正比，而不是它们包含的数据量。在现实世界的系统中，桶的大小是相当大的。例如，一个可能的配置是每 10 亿个 key 有 100 万个桶，所以每个桶只包含 1000 个 key。&lt;/p>
&lt;p>处理数据中心的中断，数据中心的中断可能是由于停电、网络中断、自然灾害等原因发生的。为了建立一个能够处理数据中心中断的系统，在多个数据中心之间进行数据复制是很重要的。即使一个数据中心完全脱机，用户仍然可以通过其他数据中心访问数据。&lt;/p>
&lt;h3 id="系统架构图">系统架构图&lt;/h3>
&lt;p>现在我们已经讨论了设计键值存储的不同技术考虑，我们可以把重点转移到架构图上，如图 6-17 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-104_1.jpg" width="66%"/>
&lt;p>该架构的主要特点如下。&lt;/p>
&lt;ul>
&lt;li>客户端通过简单的 API 与键值存储进行通信：get（key）和 put（key，value）。&lt;/li>
&lt;li>协调器是一个节点，在客户端和键值存储之间充当代理。&lt;/li>
&lt;li>节点使用一致的散列法分布在一个环上。&lt;/li>
&lt;li>该系统是完全去中心化的，所以添加和移动节点可以是自动的。&lt;/li>
&lt;li>数据在多个节点上进行复制。&lt;/li>
&lt;li>没有单点故障，因为每个节点都有相同的责任。由于设计是分散的，每个节点执行许多任务，如图 6-18 所示。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-105_1.jpg" width="50%"/>
&lt;h3 id="写路径">写路径&lt;/h3>
&lt;p>图 6-19 解释了在一个写请求被引导到一个特定的节点后会发生什么。请注意，建议的写/读路径的设计主要是基于 Cassandra[8]的架构。&lt;/p>
&lt;img src="../../../system_design_interview/index-105_2.jpg" width="50%"/>
&lt;ol>
&lt;li>写入请求被保存在一个提交日志文件中。&lt;/li>
&lt;li>数据被保存在内存缓存中。&lt;/li>
&lt;li>当内存缓存满了或达到预定的阈值时，数据会被刷到磁盘上的 SSTable[9]。注：分类字符串表（SSTable）是一个由&amp;lt;key, value&amp;gt;对组成的分类列表。对于有兴趣了解更多关于 SSTable 的读者，请参考参考资料[9]。&lt;/li>
&lt;/ol>
&lt;h3 id="读路径">读路径&lt;/h3>
&lt;p>读取请求被引导到一个特定的节点后，它首先检查数据是否在内存缓存中。如果是，数据就会被返回给客户端，如图 6-20 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-106_1.jpg" width="50%"/>
&lt;p>如果数据不在内存中，就会从磁盘中检索出来。我们需要一个有效的方法来找出哪个 SSTable 中包含的 key。布隆过滤器[10]通常被用来解决这个问题。&lt;/p>
&lt;p>当数据不在内存中时，其读取路径如图 6-21 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-106_2.jpg" width="50%"/>
&lt;ol>
&lt;li>系统首先检查数据是否在内存中。如果没有，转到第 2 步。&lt;/li>
&lt;li>如果数据不在内存中，系统检查 Bloom 过滤器。&lt;/li>
&lt;li>布隆过滤器被用来计算哪些 SSTables 可能包含该键。&lt;/li>
&lt;li>SSTables 返回数据集的结果。&lt;/li>
&lt;li>数据集的结果被返回给客户端。&lt;/li>
&lt;/ol>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>本章涵盖了许多概念和技术。为了加深记忆，下表总结了分布式键值存储的特点和相应的技术。&lt;/p>
&lt;img src="../../../system_design_interview/index-108_1.jpg" width="50%"/>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1]&lt;a href="https://aws.amazon.com/dynamodb/">amazon dynamodb&lt;/a>&lt;br>
[2]&lt;a href="https://memcached.org/">memcached&lt;/a>&lt;br>
[3]&lt;a href="https://redis.io/">redis&lt;/a>&lt;br>
[4]&lt;a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">dynamo: amazon’s highly available key-value store&lt;/a>&lt;br>
[5]&lt;a href="https://cassandra.apache.org/">cassandra&lt;/a>&lt;br>
[6]&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtableosdi06.pdf">bigtable: a distributed storage system for structured data&lt;/a>&lt;br>
[7]&lt;a href="https://en.wikipedia.org/wiki/Merkle_tree">merkle tree&lt;/a>&lt;br>
[8]&lt;a href="https://cassandra.apache.org/doc/latest/architecture/">cassandra architecture&lt;/a>&lt;br>
[9]&lt;a href="https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/">sstable&lt;/a>&lt;br>
[10]&lt;a href="/en.wikipedia.org/wiki/Bloom_filter">bloom filter https&lt;/a>&lt;/p></description></item><item><title>系统设计::设计一致性哈希</title><link>/system_design/system_design_interview_05/</link><pubDate>Fri, 05 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_05/</guid><description>&lt;h2 id="设计一致性哈希">设计一致性哈希&lt;/h2>
&lt;p>为了实现横向扩展，在服务器之间有效而均匀地分配请求/数据是很重要的。一致性哈希是实现这一目标的常用技术。但首先，让我们深入了解一下这个问题。&lt;/p>
&lt;h3 id="重哈希问题">重哈希问题&lt;/h3>
&lt;p>如果你有 n 个缓存服务器，平衡负载的一个常用方法是使用下面的哈希方法。&lt;/p>
&lt;p>serverIndex = hash(key) % N，其中 N 是服务器池的大小。&lt;/p>
&lt;p>让我们用一个例子来说明它是如何工作的。如表 5-1 所示，我们有 4 个服务器和 8 个字符串 key 及其哈希值。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">key&lt;/th>
&lt;th style="text-align:center">hash&lt;/th>
&lt;th style="text-align:center">hash %4&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">key0&lt;/td>
&lt;td style="text-align:center">18358617&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key1&lt;/td>
&lt;td style="text-align:center">26143584&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key2&lt;/td>
&lt;td style="text-align:center">18131146&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key3&lt;/td>
&lt;td style="text-align:center">35863496&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key4&lt;/td>
&lt;td style="text-align:center">34085809&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key5&lt;/td>
&lt;td style="text-align:center">27581703&lt;/td>
&lt;td style="text-align:center">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key6&lt;/td>
&lt;td style="text-align:center">38164978&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key8&lt;/td>
&lt;td style="text-align:center">22530351&lt;/td>
&lt;td style="text-align:center">3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Table 5-1&lt;/p>
&lt;p>为了获取存储 key 的服务器，我们执行模块化操作 f(key) % 4。例如，hash(key0) % 4 = 1 意味着客户端必须联系服务器 1 来获取缓存的数据。图 5-1 显示了基于表 5-1 的 key 的分布。&lt;/p>
&lt;img src="../../system_design_interview/index-73_1.jpg" width="50%"/>
&lt;p>当服务器池的大小是固定的，而且数据分布均匀时，这种方法效果很好。然而，当新的服务器被添加，或现有的服务器被移除时，问题就出现了。例如，如果服务器 1 下线了，服务器池的大小就变成了 3。使用相同的哈希函数，我们可以得到相同的键的哈希值。但是应用模块化操作会给我们带来不同的服务器索引，因为服务器的数量减少了 1。 通过应用哈希%3，我们得到如表 5-2 所示的结果。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">key&lt;/th>
&lt;th style="text-align:center">hash&lt;/th>
&lt;th style="text-align:center">hash %3&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">key0&lt;/td>
&lt;td style="text-align:center">18358617&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key1&lt;/td>
&lt;td style="text-align:center">26143584&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key2&lt;/td>
&lt;td style="text-align:center">18131146&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key3&lt;/td>
&lt;td style="text-align:center">35863496&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key4&lt;/td>
&lt;td style="text-align:center">34085809&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key5&lt;/td>
&lt;td style="text-align:center">27581703&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key6&lt;/td>
&lt;td style="text-align:center">38164978&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">key7&lt;/td>
&lt;td style="text-align:center">22530351&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Table 5-2&lt;/p>
&lt;p>图 5-2 显示了基于表 5-2 的新的 key 分布。&lt;/p>
&lt;img src="../../system_design_interview/index-74_1.jpg" width="50%"/>
&lt;p>如图 5-2 所示，大多数 key 都被重新分配，而不仅仅是最初存储在脱机服务器（服务器 1）中的 key。这意味着，当服务器 1 离线时，大多数缓存客户会连接到错误的服务器来获取数据。这就造成了高速缓存失效的风暴。一致性哈希是一种有效的技术来缓解这个问题。&lt;/p>
&lt;h3 id="一致性哈希">一致性哈希&lt;/h3>
&lt;p>引自维基百科。&amp;ldquo;一致性哈希是一种特殊的哈希，当哈希表被重新放大并使用一致性哈希时，平均只有 k/n 个 key 需要被重新映射，其中 k 是 key 的数量，n 是槽的数量。相比之下，在大多数传统的哈希表中，阵列槽数的变化导致几乎所有的键都被重新映射[1]&amp;quot;。&lt;/p>
&lt;h3 id="哈希空间和哈希环">哈希空间和哈希环&lt;/h3>
&lt;p>现在我们了解了一致性哈希的定义，让我们来看看它是如何工作的。假设用 SHA-1 作为哈希函数 f，哈希函数的输出范围是：x0, x1, x2, x3, &amp;hellip;, xn。在密码学中，SHA-1 的哈希空间从 0 到 2^160 - 1。这意味着 x0 对应于 0，xn 对应于 2^160 - 1，中间的其他哈希值都在 0 和 2^160 - 1 之间。 图 5-3 显示了哈希空间。&lt;/p>
&lt;img src="../../system_design_interview/index-75_1.jpg" width="50%"/>
&lt;p>通过连接两端，我们得到一个哈希环，如图 5-4 所示。&lt;/p>
&lt;img src="../../system_design_interview/index-75_2.jpg" width="30%"/>
&lt;h3 id="哈希服务器">哈希服务器&lt;/h3>
&lt;p>使用相同的哈希函数 f，我们根据服务器 IP 或名称将服务器映射到环上。图 5-5 显示，4 个服务器被映射到了哈希环上。&lt;/p>
&lt;img src="../../system_design_interview/index-76_1.jpg" width="50%"/>
&lt;h3 id="哈希键值">哈希键值&lt;/h3>
&lt;p>值得一提的是，这里使用的哈希函数与 &amp;ldquo;重哈希 &amp;ldquo;中的哈希函数不同，而且没有模块化操作。如图 5-6 所示，4 个缓存 key（key0、key1、key2 和 key3）被哈希在哈希环上&lt;/p>
&lt;img src="../../system_design_interview/index-76_2.jpg" width="50%"/>
&lt;p>为了确定一把 key 存放在哪个服务器上，我们从 key 在环上的位置顺时针走，直到找到一个服务器。图 5-7 解释了这个过程。顺时针方向走，key 0 存储在服务器 0；key 1 存储在服务器 1；key 2 存储在服务器 2，key 3 存储在服务器 3。&lt;/p>
&lt;img src="../../system_design_interview/index-77_1.jpg" width="50%"/>
&lt;h3 id="添加一个服务器">添加一个服务器&lt;/h3>
&lt;p>使用上面描述的逻辑，增加一个新的服务器只需要重新分配一部分的 key。&lt;/p>
&lt;p>在图 5-8 中，在增加一个新的服务器 4 后，只有 key0 需要重新分配，k1、k2 和 k3 仍然在相同的服务器上。让我们仔细看一下这个逻辑。现在，key 0 将被存储在服务器 4 上，因为服务器 4 是它从 key 0 在环上的位置顺时针方向移动所遇到的第一个服务器。其他的 key 不会根据一致的哈希算法进行重新分配。&lt;/p>
&lt;img src="../../system_design_interview/index-78_1.jpg" width="50%"/>
&lt;img src="../../system_design_interview/index-79_1.jpg" width="50%"/>
&lt;h3 id="基本方法中的两个问题">基本方法中的两个问题&lt;/h3>
&lt;p>一致哈希算法是由麻省理工学院的 Karger 等人提出的[1]。其基本步骤是。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>使用一个均匀分布的哈希函数将服务器和 key 映射到环上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>要想知道一个 key 被映射到哪个服务器，从 key 的位置开始顺时针走，直到找到环上的第一个服务器。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这种方法有两个问题。首先，考虑到服务器可以被添加或删除，不可能在环上为所有服务器保持相同大小的分区。分区是相邻服务器之间的哈希空间。分配给每个服务器的环上分区的大小有可能非常小，也有可能相当大。在图 5-10 中，如果 s1 被移除，s2 的分区（用双向箭头突出显示）是 s0 和 s3 的分区的两倍大。&lt;/p>
&lt;img src="../../system_design_interview/index-80_1.jpg" width="50%"/>
&lt;p>其次，在环上有可能出现非均匀的 key 分布。例如，如果服务器被映射到图 5-11 中所列的位置，大部分的 key 都存储在服务器 2 上。然而，服务器 1 和服务器 3 没有数据。&lt;/p>
&lt;img src="../../system_design_interview/index-80_2.jpg" width="50%"/>
&lt;p>一种叫做虚拟节点或复制的技术被用来解决这些问题。&lt;/p>
&lt;h3 id="虚拟节点">虚拟节点&lt;/h3>
&lt;p>一个虚拟节点指的是真实的节点，每个服务器都由环上的多个虚拟节点代表。在图 5-12 中，服务器 0 和服务器 1 都有 3 个虚拟节点。3 是任意选择的；而在现实世界的系统中，虚拟节点的数量要大得多。我们不使用 s0，而是用 s0_0、s0_1 和 s0_2 来代表环上的服务器 0。同样地，s1_0、s1_1 和 s1_2 代表环上的服务器 1。通过虚拟节点，每个服务器负责多个分区。标签为 s0 的分区（边）由服务器 0 管理。 另一方面，标签为 s1 的分区则由服务器 1 管理。&lt;/p>
&lt;img src="../../system_design_interview/index-81_1.jpg" width="50%"/>
&lt;img src="../../system_design_interview/index-82_1.jpg" width="50%"/>
&lt;p>随着虚拟节点数量的增加，key 的分布变得更加平衡。这是因为标准差随着虚拟节点的增加而变小，导致数据分布平衡。标准差衡量的是数据的分布情况。在线研究[2]进行的实验结果表明，在一两百个虚拟节点的情况下，标准偏差在平均值的 5%（200 个虚拟节点）和 10%（100 个虚拟节点）之间。当我们增加虚拟节点的数量时，标准偏差会更小。然而，需要更多的空间来存储关于虚拟节点的数据。这是一种权衡，我们可以调整虚拟节点的数量以适应我们的系统要求。&lt;/p>
&lt;h3 id="寻找受影响的-key">寻找受影响的 key&lt;/h3>
&lt;p>当一个服务器被添加或删除时，有一部分数据需要重新分配。我们怎样才能找到受影响的范围来重新分配 key 呢？&lt;/p>
&lt;p>在图 5-14 中，服务器 4 被添加到环上。受影响的范围从 s4（新添加的节点）开始，围绕着环逆时针移动，直到找到一个服务器（s3）。因此，位于 s3 和 s4 之间的 key 需要重新分配到 s4。&lt;/p>
&lt;img src="../../system_design_interview/index-83_1.jpg" width="50%"/>
&lt;p>如图 5-15 所示，当一个服务器（s1）被移除时，受影响的范围从 s1（被移除的节点）开始，围绕环形网络逆时针移动，直到找到一个服务器（s0）。因此，位于 s0 和 s1 之间的 key 必须被重新分配到 s2。&lt;/p>
&lt;img src="../../system_design_interview/index-84_1.jpg" width="50%"/>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在本章中，我们深入讨论了一致性哈希的问题，包括为什么需要它以及它是如何工作的。一致性哈希的好处包括。&lt;/p>
&lt;ul>
&lt;li>当服务器被添加或删除时，最小化的 key 被重新分配。&lt;/li>
&lt;li>易于横向扩展，因为数据的分布更加均匀。&lt;/li>
&lt;li>缓解热点 key 问题。对一个特定分片的过度访问可能导致服务器过载。想象一下，Katy Perry、Justin Bieber 和 Lady Gaga 的数据都在同一个分片上结束。一致性哈希有助于通过更均匀地分配数据来缓解这一问题。&lt;/li>
&lt;/ul>
&lt;p>一致性哈希在现实世界的系统中被广泛使用，包括一些引人注目的系统。&lt;/p>
&lt;ul>
&lt;li>亚马逊的 Dynamo 数据库的分区组件[3]&lt;/li>
&lt;li>Apache Cassandra 中跨集群的数据分区[4]&lt;/li>
&lt;li>Discord 聊天应用程序[5]&lt;/li>
&lt;li>Akamai 内容分发网络 [6]&lt;/li>
&lt;li>磁悬浮网络负载平衡器 [7]&lt;/li>
&lt;/ul>
&lt;p>恭喜你走到这一步! 现在给自己拍拍胸脯吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1]&lt;a href="https://en.wikipedia.org/wiki/Consistent_hashing">consistent hashing&lt;/a>&lt;br>
[2]&lt;a href="https://tom-e-white.com/2007/11/consistent-hashing.html">consistent hashing&lt;/a>&lt;br>
[3]&lt;a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">dynamo: amazon’s highly available key-value store&lt;/a>&lt;br>
[4]&lt;a href="http://www.cs.cornell.edu/Projects/ladis2009/papers/Lakshman-ladis2009.PDF">cassandra - a decentralized structured storage system&lt;/a>&lt;br>
[5]&lt;a href="https://blog.discord.com/scaling-elixir-f9b8e1e7c29b">how discord scaled elixir to 5,000,000 concurrent users&lt;/a>&lt;br>
[6]&lt;a href="http://theory.stanford.edu/~tim/s16/l/l1.pdf">cs168:the modern algorithmic toolbox lecture #1: introduction and consistent hashing&lt;/a>&lt;br>
[7]&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44824.pdf">maglev: a fast and reliable software network load balancer&lt;/a>&lt;/p></description></item><item><title>系统设计::设计一个限流器</title><link>/system_design/system_design_interview_04/</link><pubDate>Thu, 04 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_04/</guid><description>&lt;h2 id="设计一个限流器">设计一个限流器&lt;/h2>
&lt;p>在网络系统中，限流器被用来控制客户端或服务所发送的流量速率。在 HTTP 世界中，限流器限制了允许在指定时间内发送的客户端请求的数量。如果 API 请求数超过了限流器定义的阈值，所有多余的调用都会被阻止。这里有几个例子。&lt;/p>
&lt;ul>
&lt;li>一个用户每秒钟可以写不超过 2 个帖子。&lt;/li>
&lt;li>你每天最多可以从同一个 IP 地址创建 10 个账户。&lt;/li>
&lt;li>你每周从同一设备上领取奖励的次数不能超过 5 次。&lt;/li>
&lt;/ul>
&lt;p>在本章中，要求你设计一个限流器。在开始设计之前，我们首先看一下使用 API 限流器的好处。&lt;/p>
&lt;ul>
&lt;li>防止由拒绝服务（DoS）攻击引起的资源饥饿。几乎所有大型科技公司发布的 API 都执行了某种形式的限流。例如，Twitter 将每 3 小时的推文数量限制为 300 条。Google docs APIs 有如下默认限制：每个用户每 60 秒读取请求 300 次。限流器通过阻止多余的调用来防止 DoS 攻击，无论是有意的还是无意的。&lt;/li>
&lt;li>降低成本。限制多余的请求意味着更少的服务器和分配更多的资源分配给高优先级的 API。限流对于使用付费的第三方 API 的公司极为重要。例如，你对以下外部 API 的调用是按次数收费的：检查信用、付款、检索健康记录等。限制调用次数是降低成本的关键。&lt;/li>
&lt;li>防止服务器过载。为了减少服务器的负荷，使用限流器来过滤掉由机器人或用户的不当行为造成的过多请求。&lt;/li>
&lt;/ul>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>限流可以通过不同的算法来实现，每一种算法都有其优点和缺点。面试官和候选人之间的互动有助于澄清我们要建立的限流器的类型。&lt;/p>
&lt;p>候选人：我们要设计什么样的限流器？是客户端的限流器还是服务器端的 API 限流器？&lt;br>
面试官：好问题。我们的重点是服务器端的 API 限流器。&lt;br>
候选人：限流器是根据 IP、用户 ID 还是其他属性来节制 API 请求？&lt;br>
面试官：限流器应该足够灵活，以支持不同的节流规则。&lt;br>
应聘者：系统的规模是多少？它是为初创公司还是拥有庞大用户群的大公司建立的？&lt;br>
面试官：系统必须能够处理大量的请求。&lt;br>
应聘者：系统能否在分布式环境中工作？&lt;br>
面试官：是的。&lt;br>
应聘者：限流器是一个单独的服务还是应该在应用程序代码中实现？&lt;br>
面试官：是的。这是一个由你决定的设计。&lt;br>
应聘者：我们是否需要通知那些被限制的用户？&lt;br>
面试官：是的。&lt;/p>
&lt;p>需求:&lt;/p>
&lt;ul>
&lt;li>以下是对该系统要求的总结。
&lt;ul>
&lt;li>准确地限制过多的请求。&lt;/li>
&lt;li>低延时。限流器不应该减慢 HTTP 响应时间。&lt;/li>
&lt;li>尽可能少地使用内存。&lt;/li>
&lt;li>分布式限流。限流器可以在多个服务器或进程中共享。&lt;/li>
&lt;li>异常处理。当用户的请求被节制时，向用户显示明确的异常。&lt;/li>
&lt;li>高容错性。如果限流器有任何问题（例如，一个缓存服务器离线），它不会影响整个系统。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>让我们保持简单，使用基本的客户和服务器模式进行通信。&lt;/p>
&lt;p>把限流器放在哪里？&lt;/p>
&lt;p>直观地说，你可以在客户端或服务器端实现一个限流器。&lt;/p>
&lt;ul>
&lt;li>客户端实现。一般来说，客户端是执行限流的一个不可靠的地方，因为客户端的请求很容易被恶意的人伪造。此外，我们可能无法控制客户端的实现。&lt;/li>
&lt;li>服务器端的实现。图 4-1 显示了一个放在服务器端的限流器。&lt;/li>
&lt;/ul>
&lt;img src="../../system_design_interview/index-53_1.jpg" width="50%"/>
&lt;p>除了客户端和服务器端的实现，还有一种替代方法。我们不在 API 服务器上设置限流器，而是创建一个限流器中间件，它可以节制对你的 API 的请求，如图 4-2 所示。&lt;/p>
&lt;img src="../../system_design_interview/index-53_2.jpg" width="50%"/>
&lt;p>让我们用图 4-3 中的一个例子来说明限流在这个设计中的作用。假设我们的 API 允许每秒 2 个请求，而一个客户在一秒钟内向服务器发送了 3 个请求。前两个请求被路由到 API 服务器。然而，限流器中间件会对第三个请求进行节流，并返回一个 HTTP 状态代码 429。HTTP 429 响应状态代码表明用户发送了太多的请求。&lt;/p>
&lt;img src="../../system_design_interview/index-54_1.jpg" width="50%"/>
&lt;p>云微服务已经广泛流行，限流通常在一个叫做 API 网关的组件中实现。API 网关是一个完全可管理的服务，支持限流、SSL 终止、认证、IP 白名单、服务静态内容等。现在，我们只需要知道，API 网关是一个支持限流的中间件。&lt;/p>
&lt;p>在设计限流器时，要问自己的一个重要问题是：限流器应该在哪里实现，在服务器端还是在网关中？这没有绝对的答案。这取决于你公司目前的技术栈、工程资源、优先级、目标等。这里有一些一般的指导方针。&lt;/p>
&lt;ul>
&lt;li>评估你目前的技术栈，如编程语言、缓存服务等。确保你目前的编程语言能够有效地在服务器端实现限流。&lt;/li>
&lt;li>确定适合你的业务需求的限流算法。当你在服务器端实现一切时，你可以完全控制算法。然而，如果你使用第三方网关，你的选择可能是有限的。&lt;/li>
&lt;li>如果你已经使用了微服务架构，并在设计中包含了一个 API 网关来执行认证、IP 白名单等，你可以在 API 网关上添加一个限流器。&lt;/li>
&lt;li>建立你自己的限流服务需要时间。如果你没有足够的&lt;/li>
&lt;/ul>
&lt;p>如果你没有足够的工程资源来实现一个限流器，商业 API 网关是一个更好的选择。&lt;/p>
&lt;p>限流的算法&lt;/p>
&lt;p>限流可以用不同的算法来实现，每一种算法都有明显的优点和缺点。尽管本章并不关注算法，但在高层次上了解它们有助于选择正确的算法或算法组合来适应我们的使用情况。下面是一个流行算法的列表。&lt;/p>
&lt;ul>
&lt;li>Token bucket&lt;/li>
&lt;li>Leaking bucket&lt;/li>
&lt;li>Fixed window counter&lt;/li>
&lt;li>Sliding window log&lt;/li>
&lt;li>Sliding window counter&lt;/li>
&lt;/ul>
&lt;p>Token bucket 算法&lt;/p>
&lt;p>Token bucket 算法被广泛用于限流。它很简单，很好理解，并被互联网公司普遍使用。亚马逊和 Stripe 都使用这种算法来限制他们的 API 请求。&lt;/p>
&lt;p>Token bucket 算法的工作原理如下。&lt;/p>
&lt;ul>
&lt;li>Token bucket 是一个有预先定义的容量的容器。Token 以预设的速度定期放入桶中。一旦桶满了，就不再添加 Token。如图 4-4 所示，Token bucket 的容量为 4，补给者每秒钟向桶中投入 2 个 Token。一旦桶满了，多余的 Token 就会溢出。&lt;/li>
&lt;/ul>
&lt;img src="../../system_design_interview/index-55_1.jpg" width="50%"/>
&lt;p>每个请求都会消耗一个 Token。当一个请求到达时，我们检查桶中是否有足够的 Token。图 4-5 解释了它是如何工作的。&lt;/p>
&lt;ul>
&lt;li>如果有足够的 Token，我们为每个请求取出一个 Token，然后请求就会通过。&lt;/li>
&lt;li>如果没有足够的 Token，则请求被放弃。&lt;/li>
&lt;/ul>
&lt;img src="../../system_design_interview/index-56_1.jpg" width="50%"/>
&lt;p>图 4-6 说明了 Token 消耗、再填充和限流逻辑是如何工作的。在这个例子中，Token bucket 的大小是 4，补给率是每 1 分钟 4 个。&lt;/p>
&lt;img src="../../system_design_interview/index-57_1.jpg" width="50%"/>
&lt;p>Token bucket 算法需要两个参数。&lt;/p>
&lt;ul>
&lt;li>桶的大小：桶中允许的最大 Token 数量&lt;/li>
&lt;li>填充率：每秒钟放入桶中的 Token 数量&lt;/li>
&lt;/ul>
&lt;p>我们需要多少个桶？这是不一样的，它取决于限流规则。这里有几个例子。&lt;/p>
&lt;ul>
&lt;li>通常有必要为不同的 API 端点设置不同的桶。例如，如果一个用户被允许每秒发 1 个帖子，每天添加 150 个朋友，并且每秒喜欢 5 个帖子，那么每个用户需要 3 个桶。&lt;/li>
&lt;li>如果我们需要根据 IP 地址来节制请求，每个 IP 地址需要一个桶。&lt;/li>
&lt;li>如果系统允许每秒最多 10,000 个请求，那么有一个由所有请求共享的全球桶是有意义的。&lt;/li>
&lt;/ul>
&lt;p>优点。&lt;/p>
&lt;ul>
&lt;li>该算法很容易实现。&lt;/li>
&lt;li>内存高效。&lt;/li>
&lt;li>Token bucket 允许短时间内的流量突发。只要有剩余的令牌，请求就可以通过。&lt;/li>
&lt;/ul>
&lt;p>缺点。&lt;/p>
&lt;ul>
&lt;li>算法中的两个参数是桶的大小和令牌填充率。然而，适当调整它们可能是一个挑战。&lt;/li>
&lt;/ul>
&lt;p>Leaking bucket 算法&lt;/p>
&lt;p>Leaking bucket 算法与令牌桶类似，只是请求是以固定的速度处理的。它通常用先入先出（FIFO）队列来实现。该算法的工作原理如下。&lt;/p>
&lt;ul>
&lt;li>当一个请求到达时，系统检查队列是否已满。如果队列未满，则将请求添加到队列中。&lt;/li>
&lt;li>否则，该请求将被放弃。&lt;/li>
&lt;li>请求被从队列中拉出并定期处理。&lt;/li>
&lt;/ul>
&lt;p>图 4-7 解释了该算法的工作原理。&lt;/p>
&lt;img src="../../system_design_interview/index-58_1.jpg" width="66%"/>
&lt;ul>
&lt;li>Leaking bucket 算法需要以下两个参数。
&lt;ul>
&lt;li>桶的大小：它等于队列大小。队列容纳了要以固定速率处理的请求。&lt;/li>
&lt;li>流出率：它定义了在一个固定的速率下可以处理多少个请求，通常以秒为单位。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Shopify，一家电子商务公司，使用 Leaking bucket 进行限流.&lt;/p>
&lt;ul>
&lt;li>优点
&lt;ul>
&lt;li>鉴于队列规模有限，内存效率高。&lt;/li>
&lt;li>请求以固定的速率处理，因此它适用于需要稳定流出速率的用例。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缺点
&lt;ul>
&lt;li>突发的流量会使队列中的旧请求填满，如果它们没有被及时处理，最近的请求将被限制速率。&lt;/li>
&lt;li>该算法中有两个参数。要适当地调整它们可能并不容易。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Fixed window counter 算法&lt;/p>
&lt;ul>
&lt;li>Fixed window counter 算法的工作原理如下。
&lt;ul>
&lt;li>该算法将时间线划分为固定大小的时间窗口，并为每个窗口分配一个计数器。&lt;/li>
&lt;li>每个请求都会使计数器增加一个。&lt;/li>
&lt;li>一旦计数器达到预定的阈值，新的请求就会被放弃，直到一个新的时间窗口开始。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>让我们用一个具体的例子来看看它是如何工作的。在图 4-8 中，时间单位是 1 秒，系统允许每秒钟最多有 3 个请求。在每个时间窗口中，如果收到的请求超过 3 个，额外的请求会被丢弃，如图 4-8 所示。&lt;/p>
&lt;img src="../../system_design_interview/index-59_1.jpg" width="50%"/>
&lt;p>这种算法的一个主要问题是，在时间窗口边缘的流量突发可能导致超过允许配额的请求通过。考虑以下情况。&lt;/p>
&lt;img src="../../system_design_interview/index-59_2.jpg" width="50%"/>
&lt;p>在图 4-9 中，系统允许每分钟最多有 5 个请求，可用配额在对人友好的整时重置。正如所见，在 2:00:00 和 2:01:00 之间有 5 个请求，在 2:01:00 和 2:02:00 之间还有 5 个请求。在 2:00:30 和 2:01:30 之间的 1 分钟窗口，有 10 个请求通过。这是允许的请求数的两倍。&lt;/p>
&lt;ul>
&lt;li>优点。
&lt;ul>
&lt;li>内存效率高&lt;/li>
&lt;li>易于理解&lt;/li>
&lt;li>在单位时间窗口结束时重新设置可用配额，适合某些使用情况。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缺点。
&lt;ul>
&lt;li>窗口边缘的流量激增可能导致超过允许的配额的请求被通过。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Sliding window log 算法&lt;/p>
&lt;p>如前所述，Fixed window counter 算法有一个主要问题：它允许更多的请求在窗口的边缘通过。Sliding window log 算法解决了这个问题。它的工作原理如下。&lt;/p>
&lt;ul>
&lt;li>该算法对请求的时间戳进行跟踪。时间戳数据通常被保存在缓存中，比如 Redis 的排序集。&lt;/li>
&lt;li>当一个新的请求进来时，删除所有过期的时间戳。过时的时间戳被定义为比当前时间窗口的开始时间更早的时间戳。&lt;/li>
&lt;li>将新请求的时间戳添加到日志中。&lt;/li>
&lt;li>如果日志的大小与允许的计数相同或更低，则接受请求。否则，它被拒绝。&lt;/li>
&lt;/ul>
&lt;p>我们用图 4-10 所示的一个例子来解释该算法。&lt;/p>
&lt;img src="../../system_design_interview/index-60_1.jpg" width="50%"/>
&lt;p>在这个例子中，限流器允许每分钟 2 个请求。通常情况下，Linux 的时间戳会存储在日志中。然而，在我们的例子中，为了提高可读性，使用了人类可读的时间表示。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>当一个新的请求在 1:00:01 到达时，日志是空的。因此，该请求被允许。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一个新的请求在 1:00:30 到达，时间戳 1:00:30 被插入到日志中。插入后，日志大小为 2，不大于允许的数量。因此，该请求被允许。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一个新的请求在 1:00:50 到达，时间戳被插入到日志中。插入后，日志的大小是 3，大于允许的大小 2。因此，这个请求被拒绝，尽管时间戳仍然在日志中。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一个新的请求在 1:01:40 到达。在[1:00:40,1:01:40]范围内的请求是在最新的时间范围内，但在 1:00:40 之前发送的请求是过时的。两个过时的时间戳，1:00:01 和 1:00:30，被从日志中删除。在删除操作后，日志大小变成 2；因此，请求被接受。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>优点。&lt;/p>
&lt;ul>
&lt;li>这个算法实现的限流是非常准确的。在任何滚动窗口中，请求都不会超过限流。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>缺点。&lt;/p>
&lt;ul>
&lt;li>该算法消耗了大量的内存，因为即使一个请求被拒绝，它的时间戳仍然可能被存储在内存中。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Sliding window counter 算法&lt;/p>
&lt;p>Sliding window counter 算法是一种混合方法，结合了 Fixed window counter 和 Sliding window log。该算法可以通过两种不同的方法来实现。我们将在本节中解释一种实现方法，并在本节末尾提供另一种实现方法的参考。图 4-11 说明了这种算法的工作原理。&lt;/p>
&lt;img src="../../system_design_interview/index-61_1.jpg" width="50%"/>
&lt;p>假设限流器允许每分钟最多 7 个请求，上一分钟有 5 个请求，当前一分钟有 3 个请求。对于一个在当前分钟内到达 30%位置的新请求，滚动窗口中的请求数用以下公式计算。&lt;/p>
&lt;ul>
&lt;li>当前窗口中的请求+前一个窗口中的请求*滚动窗口和前一个窗口的重叠百分比 - 使用这个公式，我们得到 3 + 5 * 0.7% = 6.5 个请求。根据不同的使用情况，这个数字可以向上或向下取整。在我们的例子中，它被向下四舍五入为 6。&lt;/li>
&lt;/ul>
&lt;p>由于限流器允许每分钟最多有 7 个请求，所以当前的请求可以通过。然而，再收到一个请求后就会达到限制。&lt;/p>
&lt;p>由于篇幅所限，我们在此不讨论其他的实现方法。有兴趣的读者可以参考参考资料。这种算法并不完美。它有优点和缺点。&lt;/p>
&lt;ul>
&lt;li>优点
&lt;ul>
&lt;li>因为速率是基于前一个窗口的平均速率，所以它可以平滑流量的高峰期。&lt;/li>
&lt;li>内存效率高。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>缺点
&lt;ul>
&lt;li>它只适用于不太严格的回看窗口。它是实际速率的近似值，因为它假定前一个窗口的请求是均匀分布的。然而，这个问题可能并不像它看起来那么糟糕。根据 Cloudflare 所做的实验，在 4 亿个请求中，只有 0.003%的请求被错误地允许或限流。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>高层结构&lt;/p>
&lt;p>限流算法的基本思想很简单。在高层次上，我们需要一个计数器来跟踪来自同一用户、IP 地址等的多少个请求。如果计数器大于限制值，请求就会被禁止。&lt;/p>
&lt;p>我们应该在哪里存储计数器呢？由于磁盘访问速度慢，使用数据库并不是一个好主意。选择内存缓存是因为它速度快且支持基于时间的过期策略。例如，Redis 是实现限流的一个流行选择。它是一个内存存储，提供两个命令。INCR 和 EXPIRE。&lt;/p>
&lt;ul>
&lt;li>INCR：它使存储的计数器增加 1。&lt;/li>
&lt;li>EXPIRE：它为计数器设置一个超时。如果超时过后，计数器会被自动删除。&lt;/li>
&lt;/ul>
&lt;p>图 4-12 显示了限流的高层结构，其工作原理如下。&lt;/p>
&lt;img src="../../system_design_interview/index-62_1.jpg" width="50%"/>
&lt;ul>
&lt;li>客户端向限流中间件发送一个请求。&lt;/li>
&lt;li>限流中间件从 Redis 的相应桶中获取计数器，并检查是否达到限制。&lt;/li>
&lt;li>如果达到了限制，请求被拒绝。&lt;/li>
&lt;li>如果没有达到限制，请求被发送到 API 服务器。同时，系统增加计数器并将其保存到 Redis。&lt;/li>
&lt;/ul>
&lt;h3 id="设计深究">设计深究&lt;/h3>
&lt;p>图 4-12 中的高层设计并没有回答以下问题。&lt;/p>
&lt;ul>
&lt;li>如何创建限流规则？规则存储在哪里？&lt;/li>
&lt;li>如何处理受到限流的请求？&lt;/li>
&lt;/ul>
&lt;p>在这一节中，我们将首先回答关于限流规则的问题，然后介绍处理限流请求的策略。最后，我们将讨论分布式环境中的限流，一个详细的设计，性能优化和监控。&lt;/p>
&lt;p>费率限制规则&lt;/p>
&lt;p>Lyft 开源了他们的限流组件。我们将窥视该组件的内部，并查看一些限流规则的例子。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">domain&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">messaging&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">descriptors&lt;/span>&lt;span style="color:#111">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">key&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">message_type&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">Value&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">marketing&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">rate_limit&lt;/span>&lt;span style="color:#111">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">unit&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">day&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests_per_unit&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在上述例子中，系统被配置为每天最多允许 5 条营销信息。下面是另一个例子。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">domain&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">auth&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">descriptors&lt;/span>&lt;span style="color:#111">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">key&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">auth_type&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">Value&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">login&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">rate_limit&lt;/span>&lt;span style="color:#111">:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">unit&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">minute&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">requests_per_unit&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个规则显示，客户不允许在 1 分钟内登录超过 5 次。规则一般写在配置文件中并保存在磁盘上。&lt;/p>
&lt;p>超出限流&lt;/p>
&lt;p>如果一个请求有限流，API 会向客户端返回一个 HTTP 响应代码 429（请求太多）。根据不同的使用情况，我们可能会排队等待限流的请求，以便以后处理。例如，如果一些订单由于系统过载而受到限流，我们可能会保留这些订单以便以后处理。&lt;/p>
&lt;p>限流器标题 客户端如何知道它是否被节流？客户端又如何知道在被节流前允许的剩余请求数？答案就在 HTTP 响应头中。限流器向客户端返回以下 HTTP 头。&lt;/p>
&lt;p>X-Ratelimit-Remaining：窗口内允许的剩余请求数。
X-Ratelimit-Limit：它表示客户端在每个时间窗口内可以进行多少次呼叫。
X-Ratelimit-Retry-After：等待的秒数，直到可以再次发出请求而不被节流。&lt;/p>
&lt;p>当用户发送了太多的请求时，会向客户端返回一个 429 太多请求的错误和 X-Ratelimit- Retry-After 标头。&lt;/p>
&lt;p>详细设计&lt;/p>
&lt;p>图 4-13 展示了系统的详细设计。&lt;/p>
&lt;img src="../../system_design_interview/index-65_1.jpg" width="66%"/>
&lt;ul>
&lt;li>规则被存储在磁盘上。工作者经常从磁盘中提取规则并将其存储在缓存中。&lt;/li>
&lt;li>当客户端向服务器发送请求时，该请求首先被发送到限流器中间件。&lt;/li>
&lt;li>限流器中间件从缓冲区加载规则。它从 Redis 缓存中获取计数器和最后一次请求的时间戳。根据响应，限流器决定。
&lt;ul>
&lt;li>如果请求没有限流，它将被转发到 API 服务器。&lt;/li>
&lt;li>如果请求有限流，限流器会向客户端返回 429 太多请求的错误。同时，该请求被放弃或转发到队列中。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>分布式环境中的限流器&lt;/p>
&lt;p>构建一个在单服务器环境下工作的限流器并不困难。然而，扩展系统以支持多个服务器和并发线程是一个不同的故事。这有两个挑战。&lt;/p>
&lt;ul>
&lt;li>竞态条件&lt;/li>
&lt;li>同步问题&lt;/li>
&lt;/ul>
&lt;p>竞态条件&lt;/p>
&lt;p>如前所述，限流器在高层工作如下。&lt;/p>
&lt;ul>
&lt;li>从 Redis 读取计数器的值。&lt;/li>
&lt;li>检查( counter + 1 )是否超过了阈值。&lt;/li>
&lt;li>如果没有，在 Redis 中把计数器的值增加 1。&lt;/li>
&lt;/ul>
&lt;p>如图 4-14 所示，在一个高度并发的环境中可能会发生竞态条件。&lt;/p>
&lt;img src="../../system_design_interview/index-66_1.jpg" width="66%"/>
&lt;p>假设 Redis 中的计数器值是 3。如果两个请求在其中一个写回计数器值之前同时读取该值，每个请求都会将计数器增量为 1，然后写回，而不检查其他线程。两个请求（线程）都认为他们有正确的计数器值 4。然而，正确的计数器值应该是 5。&lt;/p>
&lt;p>锁是解决竞赛条件的最明显的解决方案。然而，锁将大大降低系统的速度。有两种策略通常被用来解决这个问题：Lua 脚本和 Redis 中的排序集数据结构。对这些策略感兴趣的读者可以参考相应的参考资料。&lt;/p>
&lt;p>同步问题 同步是分布式环境中需要考虑的另一个重要因素。为了支持数以百万计的用户，一个限流器服务器可能不足以处理这些流量。当使用多个限流器服务器时，需要进行同步。例如，在图 4-15 的左边，客户 1 向限流器 1 发送请求，客户 2 向限流器 2 发送请求。由于网络层是无状态的，客户可以向不同的限流器发送请求，如图 4-15 的右侧所示。如果没有发生同步，限流器 1 不包含任何关于客户端 2 的数据。因此，限流器不能正常工作。&lt;/p>
&lt;img src="../../system_design_interview/index-67_1.jpg" width="66%"/>
一个可能的解决方案是使用粘性会话，允许客户发送流量到同一个限流器。这种解决方案是不可取的，因为它既不具备可扩展性，也不具备灵活性。一个更好的方法是使用集中式数据存储，如 Redis。该设计如图 4-16 所示。
&lt;img src="../../system_design_interview/index-67_2.jpg" width="50%"/>
&lt;p>性能优化&lt;/p>
&lt;p>性能优化是系统设计访谈中的一个常见话题。我们将涉及两个方面的改进。&lt;/p>
&lt;p>首先，多数据中心的设置对于限流器来说是至关重要的，因为对于远离数据中心的用户来说，延迟很高。大多数云服务提供商在世界各地建立了许多边缘服务器位置。例如，截至 2020 年 5 月 20 日，Cloudflare 有 194 个地理上分布的边缘服务器。流量被自动路由到最近的边缘服务器以减少延迟。&lt;/p>
&lt;img src="../../system_design_interview/index-68_1.jpg" width="50%"/>
&lt;p>第二，用最终的一致性模型来同步数据。如果你不清楚最终的一致性模型，请参考 &amp;ldquo;第 6 章：设计键值存储 &amp;ldquo;中的 &amp;ldquo;一致性 &amp;ldquo;部分。&lt;/p>
&lt;p>监控&lt;/p>
&lt;p>限流器投入使用后，收集分析数据以检查限流器是否有效是很重要的。主要的是，我们要确保&lt;/p>
&lt;ul>
&lt;li>限流算法是有效的。&lt;/li>
&lt;li>限流规则是有效的。&lt;/li>
&lt;/ul>
&lt;p>例如，如果限流规则过于严格，许多有效的请求会被放弃。在这种情况下，我们想把规则放宽一点。在另一个例子中，我们注意到当流量突然增加时，我们的限流器变得无效，比如闪购。在这种情况下，我们可以更换算法来支持突发流量。Token bucket 在这里很适合。&lt;/p>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在这一章中，我们讨论了限流的不同算法及其利弊。讨论的算法包括。&lt;/p>
&lt;ul>
&lt;li>Token bucket&lt;/li>
&lt;li>Leaking bucket&lt;/li>
&lt;li>Fixed window&lt;/li>
&lt;li>Sliding window log&lt;/li>
&lt;li>Sliding window counter&lt;/li>
&lt;/ul>
&lt;p>然后，我们讨论了系统架构、分布式环境下的限流器、性能优化和监控。与任何系统设计的面试问题类似，如果时间允许，你还可以提到一些额外的谈话要点。&lt;/p>
&lt;ul>
&lt;li>硬限流与软限流。
&lt;ul>
&lt;li>硬：请求的数量不能超过阈值。&lt;/li>
&lt;li>软：请求可以在短时间内超过阈值。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>不同级别的限流。在本章中，我们只谈到了应用层面的限流（HTTP：第 7 层）。也可以在其他层应用限流。例如，你可以使用 Iptables（IP：第 3 层）按 IP 地址应用限流。注意：开放系统互连模型（OSI 模型）有 7 层。第 1 层：物理层，第 2 层：数据链路层，第 3 层：网络层，第 4 层：传输层，第 5 层：会话层，第 6 层：表现层，第 7 层：应用层。&lt;/li>
&lt;li>避免被限流。用最佳实践设计你的客户端。
&lt;ul>
&lt;li>使用客户端缓存以避免频繁调用 API。&lt;/li>
&lt;li>理解限制，不要在短时间内发送太多的请求。&lt;/li>
&lt;li>包括捕捉异常或错误的代码，以便你的客户端可以从异常中优雅地恢复。&lt;/li>
&lt;li>添加足够的后退时间来重试逻辑。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>祝贺你走到了这一步! 现在给自己拍拍屁股吧。干得好!&lt;/p>
&lt;h3 id="参考资料">参考资料&lt;/h3>
&lt;p>[1]&lt;a href="https://cloud.google.com/solutions/rate-limitingstrategies-techniques">rate-limiting strategies and techniques&lt;/a>&lt;br>
[2]&lt;a href="https://developer.twitter.com/en/docs/basics/rate-limits">twitter rate limits&lt;/a>&lt;br>
[3]&lt;a href="https://developers.google.com/docs/api/limits">google docs usage limits&lt;/a>&lt;br>
[4]&lt;a href="https://www.ibm.com/cloud/learn/microservices">ibm microservices&lt;/a>&lt;br>
[5]&lt;a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-requestthrottling.html">throttle api requests for better throughput&lt;/a>&lt;br>
[6]&lt;a href="https://stripe.com/blog/rate-limiters">stripe rate limiters&lt;/a>&lt;br>
[7]&lt;a href="https://help.shopify.com/en/api/reference/restadmin-api-rate-limits">shopify rest admin api rate limits&lt;/a>&lt;br>
[8]&lt;a href="https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/">better rate limiting with redis sorted sets&lt;/a>&lt;br>
[9]&lt;a href="https://medium.com/@saisandeepmopuri/system-design-rate-limiter-and-data-modelling9304b0d18250">system design — rate limiter and data modelling&lt;/a>&lt;br>
[10]&lt;a href="https://blog.cloudflare.com/counting-things-a-lot-of-different-things/">how we built rate limiting capable of scaling to millions of domains&lt;/a>&lt;br>
[11]&lt;a href="https://redis.io/">redis website&lt;/a>&lt;br>
[12]&lt;a href="https://github.com/lyft/ratelimit">lyft rate limiting&lt;/a>&lt;br>
[13]&lt;a href="https://gist.github.com/ptarjan/e38f45f2dfe601419ca3af937fff574d#request-rate-limiter">scaling your api with rate limiters&lt;/a>&lt;br>
[14]&lt;a href="https://www.cloudflare.com/learning/serverless/glossary/whatis-edge-computing/">what is edge computing&lt;/a>&lt;br>
[15]&lt;a href="https://blog.programster.org/rate-limit-requests-withiptables">rate limit requests with iptables&lt;/a>&lt;br>
[16]&lt;a href="https://en.wikipedia.org/wiki/OSI_model#Layer_architecture">osi model&lt;/a>&lt;/p></description></item><item><title>系统设计::系统设计面试框架</title><link>/system_design/system_design_interview_03/</link><pubDate>Wed, 03 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_03/</guid><description>&lt;h2 id="系统设计面试框架">系统设计面试框架&lt;/h2>
&lt;p>你刚刚在你梦想中的公司获得了令人羡慕的现场面试机会。招聘协调员给你发了一份当天的时间表。扫视清单，你感觉很好，直到你的目光落在这个面试环节&amp;ndash;系统设计面试。&lt;/p>
&lt;p>系统设计面试往往令人生畏。它可能像 &amp;ldquo;设计一个众所周知的产品 X？&amp;ldquo;一样模糊。问题模棱两可，看起来不合理地宽泛。你的疲惫是可以理解的。毕竟，怎么可能有人在一个小时内设计出一个流行的产品，而这个产品是花了几百个甚至几千个工程师才建成的？&lt;/p>
&lt;p>好消息是，没有人期望你能做到。现实世界的系统设计是极其复杂的。例如，谷歌搜索具有欺骗性的简单性；然而，支撑这种简单性的技术数量确实令人吃惊。如果没有人期望你在一小时内设计出一个真实世界的系统，那么系统设计面试的好处是什么？&lt;/p>
&lt;p>系统设计面试模拟了现实生活中的问题解决，两个同事合作解决一个模糊的问题，并提出一个符合他们目标的解决方案。这个问题是开放式的，没有完美的答案。与你在设计过程中付出的努力相比，最终的设计并不那么重要。这使你能够展示你的设计技能，为你的设计选择辩护，并以建设性的方式回应反馈。&lt;/p>
&lt;p>让我们切换角度，考虑一下当面试官走进会议室与你见面时，她的脑子里在想什么。面试官的首要目标是准确评估你的能力。她最不希望的是，因为会议进行得不顺利，没有足够的信号，而给出一个没有结论的评价。面试官在系统设计面试中寻找的是什么？&lt;/p>
&lt;p>许多人认为，系统设计面试是关于一个人的技术设计能力。它远不止于此。一个有效的系统设计面试给人以强烈的信号，表明一个人的合作能力，在压力下工作的能力，以及建设性地解决模糊性的能力。提出好问题的能力也是一项重要的技能，许多面试官专门寻找这种技能。&lt;/p>
&lt;p>一个好的面试官也会寻找错误。过度工程化是许多工程师的一个真正的病症，因为他们喜欢设计的纯粹性，而忽视了权衡。他们往往没有意识到过度工程系统的复合成本，而许多公司为这种无知付出了高昂的代价。你当然不希望在系统设计面试中表现出这种倾向。其他的错误包括狭隘的心态、固执等等。&lt;/p>
&lt;p>在这一章中，我们将讲述一些有用的技巧，并介绍一个简单而有效的框架来解决系统设计面试问题。&lt;/p>
&lt;h3 id="有效的系统设计面试的-4-个流程">有效的系统设计面试的 4 个流程&lt;/h3>
&lt;p>每个系统设计面试都是不同的。一个好的系统设计面试是开放式的，没有一个放之四海而皆准的解决方案。然而，在每个系统设计面试中都有一些步骤和共同点。&lt;/p>
&lt;h3 id="理解问题并确定设计范围">理解问题并确定设计范围&lt;/h3>
&lt;p>&amp;ldquo;老虎为什么咆哮？&amp;rdquo;&lt;br>
班级后面有一只手举了起来。&lt;br>
&amp;ldquo;是的，吉米？&amp;quot;，老师回答。&lt;br>
&amp;ldquo;因为他很饿&amp;rdquo;。&lt;br>
&amp;ldquo;非常好，吉米&amp;rdquo;。&lt;br>
在整个童年时期，吉米一直是班上第一个回答问题的人。每当老师提出问题时，教室里总有一个孩子喜欢在问题上一试身手，不管他是否知道答案。这就是吉米。&lt;br>
吉米是一个王牌学生。他以能快速知道所有答案为荣。在考试中，他通常是第一个完成问题的人。在任何学术竞赛中，他都是老师的首选。&lt;br>
不要像吉米那样。&lt;/p>
&lt;p>在系统设计面试中，不加思索地迅速给出答案不会给你加分。在没有彻底理解需求的情况下回答问题是一个巨大的错误，因为面试不是一个小游戏比赛。没有正确的答案。&lt;/p>
&lt;p>所以，不要直接跳进去给出一个解决方案。慢下来。深入思考并提出问题以澄清需求和假设。这一点极为重要。&lt;/p>
&lt;p>作为一个工程师，我们喜欢解决困难的问题并跳入最终的设计；然而，这种方法很可能导致你设计出错误的系统。作为一个工程师，最重要的技能之一是提出正确的问题，做出适当的假设，并收集建立一个系统所需的所有信息。因此，不要害怕提出问题。&lt;/p>
&lt;p>当你提出问题时，面试官要么直接回答你的问题，要么要求你做出假设。如果是后者，请在白板或纸上写下你的假设。你以后可能会用到它们。&lt;/p>
&lt;ul>
&lt;li>要问什么样的问题？提出问题以了解确切的要求。这里有一个问题清单，可以帮助你开始工作。
&lt;ul>
&lt;li>我们要建立什么具体的功能？&lt;/li>
&lt;li>该产品有多少用户？&lt;/li>
&lt;li>公司预计扩大规模的速度如何？3 个月、6 个月和 1 年后的预期规模是什么？&lt;/li>
&lt;li>该公司的技术栈是什么？你可以利用哪些现有的服务来简化设计？&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>例子:&lt;br>
如果你被要求设计一个新闻源系统，你要问一些问题，帮助你澄清需求。你和面试官之间的对话可能是这样的。&lt;br>
候选人：这是一个移动应用程序吗？还是一个网络应用？或者两者都是？&lt;br>
面试官。都是。&lt;br>
应聘者：产品最重要的功能是什么？面试官。能够发帖并看到朋友的新闻提要。&lt;br>
应聘者：新闻源是按时间倒序还是按特定顺序排序的？特定顺序意味着每个帖子都有不同的权重。例如，来自你的亲密朋友的帖子比来自一个小组的帖子更重要。&lt;br>
采访者。为了简单起见，让我们假设 feed 是按逆时针顺序排序的。&lt;br>
候选人：一个用户可以有多少个朋友？面试官。5000&lt;br>
考生：流量是多少？面试官。1000 万日活跃用户（DAU）。&lt;br>
应聘者：饲料可以包含图片、视频，还是只有文字？&lt;br>
面试官：可以。它可以包含媒体文件，包括图片和视频。&lt;br>
以上是你可以问面试官的一些样本问题。理解要求并澄清含糊之处非常重要。&lt;/p>
&lt;h3 id="提出高层次的设计并获得认同">提出高层次的设计并获得认同&lt;/h3>
&lt;p>在这个步骤中，我们的目标是制定一个高层次的设计，并与面试官就设计达成一致。在这个过程中，与面试官合作是个好主意。&lt;/p>
&lt;ul>
&lt;li>想出一个初步的设计蓝图。征求反馈意见。把你的面试官当作队友，一起工作。许多优秀的面试官喜欢交谈和参与。&lt;/li>
&lt;li>在白板或纸上画出带有关键部件的方框图。这可能包括客户端（移动/网络）、API、网络服务器、数据存储、缓存、CDN、消息队列，等等。&lt;/li>
&lt;li>做事后计算，评估你的蓝图是否符合规模限制。努力思考。在深入研究之前，如果有必要进行逆向计算，请与你的面试官沟通。&lt;/li>
&lt;/ul>
&lt;p>如果可能的话，通过一些具体的使用案例。这将帮助你确定高级设计的框架。也有可能这些用例会帮助你发现你还没有考虑过的边缘案例。&lt;/p>
&lt;p>我们应该在这里包括 API 端点和数据库模式吗？这取决于问题的情况。对于像 &amp;ldquo;设计谷歌搜索引擎 &amp;ldquo;这样的大型设计问题，这有点太低级了。对于像为多人扑克游戏设计后端这样的问题，这是一个公平的游戏。与你的面试官沟通。&lt;/p>
&lt;p>例子:&lt;br>
让我们用 &amp;ldquo;设计一个新闻源系统 &amp;ldquo;来演示如何进行高层设计。这里不要求你了解系统的实际工作情况。所有的细节将在第 11 章解释。&lt;/p>
&lt;ul>
&lt;li>在高层次上，设计分为两个流程：Feed 发布和新闻源构建。
&lt;ul>
&lt;li>帖子发布：当用户发布帖子时，相应的数据被写入缓存/数据库，该帖子将被填充到朋友的新闻提要中。&lt;/li>
&lt;li>新闻源构建：新闻源是通过将朋友的帖子按照逆时针顺序聚合起来而构建的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>图 3-1 和图 3-2 分别展示了新闻发布和新闻源构建流程的高级设计。&lt;/p>
&lt;img src="../../system_design_interview/index-45_1.jpg" width="50%"/>
&lt;img src="../../system_design_interview/index-46_1.jpg" width="50%"/>
&lt;h3 id="设计深挖">设计深挖&lt;/h3>
&lt;p>在这一步，你和你的面试官应该已经实现了以下目标。&lt;/p>
&lt;ul>
&lt;li>就总体目标和功能范围达成一致&lt;/li>
&lt;li>为整体设计勾勒出一个高层次的蓝图&lt;/li>
&lt;li>从你的面试官那里获得关于高级设计的反馈。&lt;/li>
&lt;li>根据她的反馈，对深入研究的重点领域有了一些初步的想法&lt;/li>
&lt;/ul>
&lt;p>你应与面试官一起确定架构中的组件并确定其优先次序。值得强调的是，每次面试都是不同的。有时，面试官可能会发出暗示，她喜欢关注高层设计。有时，对于一个高级候选人的面试，讨论的可能是系统的性能特征，很可能集中在瓶颈和资源估计上。在大多数情况下，面试官可能希望你挖掘一些系统组件的细节。对于 URL 断链接生成器，深入研究将长 URL 转换为短 URL 的哈希函数设计是很有趣的。对于一个聊天系统，如何减少延迟和如何支持在线/离线状态是两个有趣的话题。&lt;/p>
&lt;p>时间管理是非常重要的，因为你很容易被一些细微的细节所迷惑，而这些细节并不能体现你的能力。尽量不要涉足不必要的细节。例如，在系统设计面试中，详细谈论 Facebook feed 排名的 EdgeRank 算法并不理想，因为这需要很多宝贵的时间，而且不能证明你有能力设计一个可扩展的系统。&lt;/p>
&lt;p>例子:&lt;br>
在这一点上，我们已经讨论了新闻源系统的高层次设计，面试官对你的提议感到满意。接下来，我们将调查两个最重要的用例。&lt;/p>
&lt;ol>
&lt;li>新闻发布&lt;/li>
&lt;li>新闻提要的检索&lt;/li>
&lt;/ol>
&lt;p>图 3-3 和图 3-4 显示了这两个用例的详细设计，这将在第 11 章中详细说明。&lt;/p>
&lt;img src="../../system_design_interview/index-48_1.jpg" width="75%"/>
&lt;img src="../../system_design_interview/index-49_1.jpg" width="75%"/>
&lt;h3 id="总结">总结&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>在这最后一步，面试官可能会问你一些后续问题，或者让你自由讨论其他的附加要点。这里有几个方向可以遵循。&lt;/p>
&lt;ul>
&lt;li>面试官可能希望你找出系统的瓶颈，并讨论潜在的改进。千万不要说你的设计是完美的，没有什么可以改进的。总有一些东西是可以改进的。这是一个展示你的批判性思维的好机会，并留下一个好的最终印象。&lt;/li>
&lt;li>给面试官一个关于你的设计的回顾可能是有用的。如果你提出了一些解决方案，这一点就特别重要。在漫长的会议之后，刷新你的面试官的记忆会很有帮助。&lt;/li>
&lt;li>错误案例（服务器故障、网络丢失等）是很有趣的话题。&lt;/li>
&lt;li>操作问题是值得一提的。你如何监控指标和错误日志？如何推广系统？&lt;/li>
&lt;li>如何处理下一个规模曲线也是一个有趣的话题。例如，如果你目前的设计支持 100 万用户，你需要做什么改变来支持 1000 万用户？&lt;/li>
&lt;li>如果你有更多的时间，提出你需要的其他细化措施。总结一下，我们总结了一份该做的和不该做的清单。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>去做&lt;/p>
&lt;ul>
&lt;li>总是要求澄清。不要假设你的假设是正确的。&lt;/li>
&lt;li>理解问题的要求。&lt;/li>
&lt;li>既没有正确的答案，也没有最好的答案。为解决一个年轻的初创公司的问题而设计的解决方案，与一个拥有数百万用户的成熟公司的解决方案是不同的。请确保你了解需求。&lt;/li>
&lt;li>让面试官知道你在想什么。与你的面试官进行沟通。&lt;/li>
&lt;li>如果可能的话，提出多种方法。&lt;/li>
&lt;li>一旦你与你的面试官就蓝图达成一致，就对每个组件进行详细了解。先设计最关键的部分。&lt;/li>
&lt;li>向面试官反映想法。一个好的面试官会像队友一样和你一起工作。&lt;/li>
&lt;li>永远不要放弃。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>不要去做&lt;/p>
&lt;ul>
&lt;li>不要对典型的面试问题毫无准备。&lt;/li>
&lt;li>不要在没有弄清要求和假设的情况下就跳进一个解决方案。&lt;/li>
&lt;li>不要在一开始就对一个单一的组件进行太多细节的研究。先给出高层次的设计，然后再往下钻研。&lt;/li>
&lt;li>如果你被卡住了，不要犹豫，向他们寻求提示。&lt;/li>
&lt;li>再一次，沟通。不要在沉默中思考。&lt;/li>
&lt;li>不要认为一旦你给出了设计，你的面试就结束了。直到你的面试官说你完成了，你才算完成。尽早、经常地征求反馈意见。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>每个步骤的时间分配&lt;br>
系统设计的面试问题通常非常广泛，45 分钟或一个小时不足以涵盖整个设计。时间管理是必不可少的。你应该在每个步骤上花多少时间？以下是一个非常粗略的指南，指导你在 45 分钟的面试中分配时间。请记住，这只是一个粗略的估计，实际的时间分配取决于问题的范围和面试官的要求。&lt;/p>
&lt;ul>
&lt;li>第 1 步 了解问题并确定设计范围。3 - 10 分钟&lt;/li>
&lt;li>第 2 步 提出高层次的设计并获得认同：10 - 15 分钟&lt;/li>
&lt;li>第 3 步 深入设计：10 - 25 分钟&lt;/li>
&lt;li>第 4 步 总结。3-5 分钟&lt;/li>
&lt;/ul></description></item><item><title>系统设计::粗略评估</title><link>/system_design/system_design_interview_02/</link><pubDate>Tue, 02 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_02/</guid><description>&lt;h2 id="粗略评估">粗略评估&lt;/h2>
&lt;p>在系统设计面试中，有时你会被要求用粗略评估系统容量或性能要求。根据 Google 高级研究员 Jeff Dean 的说法，&amp;ldquo;粗略计算是你使用思想实验和常见的性能数字的组合来创建的估计，以很好地感觉到哪些设计可以满足你的要求&amp;rdquo;&lt;/p>
&lt;p>你需要对可扩展性的基础知识有一个很好的感觉，以便有效地进行粗略计算。你需要好地理解以下概念：二的幂，每个程序员都应该知道的延迟数字，以及可用性数字。&lt;/p>
&lt;h3 id="2-的幂">2 的幂&lt;/h3>
&lt;p>尽管在处理分布式系统时，数据量可能变得巨大，但计算都可以归结为基础知识。为了获得正确的计算结果，关键是要知道使用 2 的幂的数据量单位。一个字节是一个 8 位的序列。一个 ASCII 字符使用一个字节的内存（8 比特）。下面是一个解释数据量单位的表格&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Power&lt;/th>
&lt;th>Approximate value&lt;/th>
&lt;th>Full name&lt;/th>
&lt;th>Short name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>10&lt;/td>
&lt;td>1 Thousand&lt;/td>
&lt;td>1 Kilobyte&lt;/td>
&lt;td>1 KB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>20&lt;/td>
&lt;td>1 Million&lt;/td>
&lt;td>1 Megabyte&lt;/td>
&lt;td>1 MB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>30&lt;/td>
&lt;td>1 Billion&lt;/td>
&lt;td>1 Gigabyte&lt;/td>
&lt;td>1 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>40&lt;/td>
&lt;td>1 Trillion&lt;/td>
&lt;td>1 Terabyte&lt;/td>
&lt;td>1 TB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>50&lt;/td>
&lt;td>1 Quadrillion&lt;/td>
&lt;td>1 Petabyte&lt;/td>
&lt;td>1 PB&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="每个程序都应该知道的延迟数字">每个程序都应该知道的延迟数字&lt;/h3>
&lt;p>来自谷歌的 Dr.Dean 展示了 2010 年典型计算机操作的时间长度。随着计算机变得更快、更强大，有些数字已经过时了。然而，这些数字应该仍然能够让我们了解不同计算机操作的快慢。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Operation name&lt;/th>
&lt;th>Time&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>L1 cache reference&lt;/td>
&lt;td>0.5 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Branch mispredict&lt;/td>
&lt;td>5 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>L2 cache reference&lt;/td>
&lt;td>7 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Mutex lock/unlock&lt;/td>
&lt;td>100 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Main memory reference&lt;/td>
&lt;td>100 ns&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Compress 1K bytes with Zippy&lt;/td>
&lt;td>10,000 ns = 10 us&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Send 2K bytes over 1 Gbps network&lt;/td>
&lt;td>20,000 ns = 20 us&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Read 1 MB sequentially from memory&lt;/td>
&lt;td>250,000 ns = 250 us&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Round trip within the same datacenter&lt;/td>
&lt;td>500,000 ns = 500 us&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Disk seek&lt;/td>
&lt;td>10,000,000 ns = 10 ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Read 1 MB sequentially from the network&lt;/td>
&lt;td>10,000,000 ns = 10 ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Read 1 MB sequentially from disk&lt;/td>
&lt;td>30,000,000 ns = 30 ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Send packet CA (California) -&amp;gt; Netherlands-&amp;gt; CA&lt;/td>
&lt;td>150,000,000 ns = 150 ms&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>一位谷歌软件工程师建立了一个工具，将 Dr.Dean 的数字可视化。该工具还将时间因素考虑在内。下图显示了截至 2020 年的可视化延迟数字&lt;/p>
&lt;img src="../../system_design_interview/index-37_1.jpg" width="100%"/>
&lt;ul>
&lt;li>内存很快，但磁盘很慢。&lt;/li>
&lt;li>如果可能的话，要避免磁盘搜索。&lt;/li>
&lt;li>简单的压缩算法是快速的。&lt;/li>
&lt;li>如果可能的话，在通过互联网发送数据之前先进行压缩。&lt;/li>
&lt;li>数据中心通常在不同地区，在它们之间发送数据需要时间。&lt;/li>
&lt;/ul>
&lt;h3 id="可用性">可用性&lt;/h3>
&lt;p>高可用性是指一个系统在一个理想的长时期内持续运行的能力。高可用性是以百分比来衡量的，100%意味着一个服务没有停机时间。大多数服务在 99%和 100%之间。&lt;/p>
&lt;p>服务水平协议（SLA）是服务提供者的一个常用术语。这是你（服务提供商）和你的客户之间的协议，这个协议正式定义了你的服务将提供的正常运行时间水平。云服务提供商亚马逊、谷歌和微软将其 SLA 设定为 99.9% 或以上。正常运行时间传统上是以 9 的个数为单位衡量的。9 个数多，越好。如下表所示，9 的个数与预期系统停机时间相关。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Availability %&lt;/th>
&lt;th>Downtime per day&lt;/th>
&lt;th>Downtime per year&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>99%&lt;/td>
&lt;td>14.40 minutes&lt;/td>
&lt;td>3.65 days&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.9%&lt;/td>
&lt;td>1.44 minutes&lt;/td>
&lt;td>8.77 hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.99%&lt;/td>
&lt;td>8.64 seconds&lt;/td>
&lt;td>52.60 minutes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.999%&lt;/td>
&lt;td>864.00 milliseconds&lt;/td>
&lt;td>5.26 minutes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>99.9999%&lt;/td>
&lt;td>86.40 milliseconds&lt;/td>
&lt;td>31.56 seconds&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="例子评估-twitter-的-qps-和存储需求">例子:评估 Twitter 的 QPS 和存储需求&lt;/h3>
&lt;p>请注意，以下数字仅用于本练习，因为它们不是 Twitter 的真实数字。&lt;/p>
&lt;ul>
&lt;li>假设。
&lt;ul>
&lt;li>每月有 3 亿活跃用户。&lt;/li>
&lt;li>50%的用户每天使用 Twitter。&lt;/li>
&lt;li>用户平均每天发布 2 条推文。&lt;/li>
&lt;li>10%的推文包含媒体。&lt;/li>
&lt;li>数据存储时间为 5 年。估算。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>每秒查询次数（QPS）估计。
&lt;ul>
&lt;li>日活跃用户（DAU）=3 亿*50%=1.5 亿&lt;/li>
&lt;li>推文 QPS = 1.5 亿 * 2 条推文/24 小时/3600 秒 = ~3500&lt;/li>
&lt;li>Peek QPS = 2 * QPS = ~7000&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>我们在此只估算媒体存储量。
&lt;ul>
&lt;li>平均推文大小。
&lt;ul>
&lt;li>tweet_id 64 bytes&lt;/li>
&lt;li>文本 140 字节&lt;/li>
&lt;li>媒体 1 MB&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>媒体存储。1.5 亿&lt;em>2&lt;/em>10%*1MB=30TB/天&lt;/li>
&lt;li>5 年的媒体存储。30 TB * 365 * 5 = ~55 PB&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="技巧">技巧&lt;/h3>
&lt;p>粗略估计是关于过程的。解决问题比获得结果更重要。面试官可能会测试你解决问题的能力。这里有几个技巧可以借鉴。&lt;/p>
&lt;ul>
&lt;li>四舍五入和近似。在面试中很难进行复杂的数学运算。例如，&amp;ldquo;99987 / 9.1 &amp;ldquo;的结果是什么？没有必要花费宝贵的时间来解决复杂的数学问题。精度不被期待。使用整数和近似值对你有利。这个除法问题可以简化如下。&amp;ldquo;100,000 / 10&amp;rdquo;.&lt;/li>
&lt;li>写下你的假设。写下你的假设是个好主意，以便以后参考。&lt;/li>
&lt;li>标记你的单位。当你写下 &amp;ldquo;5 &amp;ldquo;时，它是指 5KB 还是 5MB？你可能会因此而迷惑自己。写下单位，因为 &amp;ldquo;5 MB &amp;ldquo;有助于消除歧义。&lt;/li>
&lt;li>常见的粗略估算法。QPS，峰值 QPS，存储，缓存，服务器的数量，等等。你可以在准备面试的时候练习这些计算方法。实践出真知。&lt;/li>
&lt;/ul>
&lt;p>恭喜你走到这一步! 现在给自己拍拍背吧。干得好!&lt;/p></description></item><item><title>系统设计::从零到一百万</title><link>/system_design/system_design_interview_01/</link><pubDate>Mon, 01 Feb 2021 22:20:24 +0800</pubDate><guid>/system_design/system_design_interview_01/</guid><description>&lt;h2 id="从零到一百万">从零到一百万&lt;/h2>
&lt;p>设计一个支持数百万用户的系统是一个挑战，这是一个需要不断完善和无止境改进的历程。在本章中，我们将构建一个支持单个用户的系统，并逐步将其扩展到服务数百万用户。读完本章，你将掌握一手的技巧，帮助你破解系统设计的面试题。&lt;/p>
&lt;p>&lt;strong>单服务器设置&lt;/strong>&lt;/p>
&lt;p>千里之行始于足下，构建一个复杂的系统也不例外。先从简单的东西开始，所有的东西都运行在一台服务器上。图 1-1 是单服务器设置的说明，所有的东西都在一台服务器上运行：Web 应用、数据库、缓存等。&lt;/p>
&lt;img src="../../../system_design_interview/index-6_1.jpg" width="50%"/>
&lt;p>为了理解这种设置，研究一下请求流程和流量来源是很有帮助的。我们先来看看请求流程（图 1-2）。&lt;/p>
&lt;img src="../../../system_design_interview/index-6_2.jpg" width="50%"/>
&lt;ol>
&lt;li>用户通过域名访问网站，如 api.mysite.com。通常，域名系统（DNS）是由第三方提供的付费服务，而不是由我们的服务器托管。&lt;/li>
&lt;li>互联网协议（IP）地址返回给浏览器或移动应用。在本例中，返回的 IP 地址为 15.125.23.214。&lt;/li>
&lt;li>获得 IP 地址后，超文本传输协议（HTTP）[1]请求直接发送到您的网络服务器。&lt;/li>
&lt;li>Web 服务器返回 HTML 页面或 JSON 响应进行渲染。&lt;/li>
&lt;/ol>
&lt;p>接下来，我们来看看流量来源。你的 Web 服务器的流量来自两个方面：Web 应用和移动应用。&lt;/p>
&lt;ul>
&lt;li>Web 应用：它使用服务器端语言（Java、Python 等）组合来处理业务逻辑、存储等，使用客户端语言（HTML 和 JavaScript）来进行展示。&lt;/li>
&lt;li>移动应用。HTTP 协议是移动应用与 Web 服务器之间的通信协议。JavaScript 对象符号（JSON）由于其简单性，是常用的 API 响应格式来传输数据。JSON 格式的 API 响应示例如下所示。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;firstName&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;John&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;lastName&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;Smith&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;address&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#111">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;streetAddress&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;21 2nd street&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;city&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;New York&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;state&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;NY&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;postal Code&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#ae81ff">10021&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#111">},&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;phoneNumbers&amp;#34;&lt;/span>&lt;span style="color:#111">:&lt;/span> &lt;span style="color:#111">[&lt;/span>&lt;span style="color:#d88200">&amp;#34;212 555-1234&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span> &lt;span style="color:#d88200">&amp;#34;646 555-4567&amp;#34;&lt;/span>&lt;span style="color:#111">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>GET /users/12 – Retrieve user object for id = 12&lt;/code>&lt;/p>
&lt;p>&lt;strong>数据库&lt;/strong>&lt;/p>
&lt;p>随着用户群的增长，一台服务器是不够的，我们需要多台服务器：一台用于 web/移动流量，另一台用于数据库（图 1-3）。将 web/移动流量（web 层）和数据库（数据层）服务器分开，可以让它们独立扩展。&lt;/p>
&lt;img src="../../../system_design_interview/index-8_1.jpg" width="50%"/>
&lt;p>&lt;strong>使用哪种数据库?&lt;/strong>&lt;/p>
&lt;p>你可以选择传统的关系型数据库和非关系型数据库。让我们来看看它们的区别。&lt;/p>
&lt;p>关系型数据库也叫关系型数据库管理系统（RDBMS）或 SQL 数据库。最流行的有 MySQL、Oracle 数据库、PostgreSQL 等。关系型数据库以表和行来表示和存储数据。你可以在不同的数据库表之间使用 SQL 进行连接操作。&lt;/p>
&lt;p>非关系型数据库也叫 NoSQL 数据库。常用的有 CouchDB、Neo4j、Cassandra、HBase、Amazon DynamoDB 等。[2]. 这些数据库分为四类：键值存储、图存储、列存储和文档存储。在非关系型数据库中，一般不支持 Join 操作。&lt;/p>
&lt;p>对于大多数开发人员来说，关系型数据库是最好的选择，因为关系型数据库已经存在了 40 多年，而且从历史上看，关系型数据库运行良好。然而，如果关系型数据库不适合你的特定用例，那么探索关系型数据库之外的东西是至关重要的。在以下情况下，非关系型数据库可能是正确的选择。&lt;/p>
&lt;ul>
&lt;li>你的应用需要超低的延迟&lt;/li>
&lt;li>你的数据是非结构化的，或者你没有任何关系型数据。&lt;/li>
&lt;li>你只需要序列化和反序列化数据（JSON、XML、YAML 等）。&lt;/li>
&lt;li>你需要存储大量的数据。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>垂直扩展与水平扩展&lt;/strong>&lt;/p>
&lt;p>垂直扩展，简称为 &amp;ldquo;扩容&amp;rdquo;，指的是为服务器增加更多功率（CPU、RAM 等）的过程。&lt;/p>
&lt;p>水平扩展，称为 &amp;ldquo;scale-out&amp;rdquo;，允许您通过向资源池中添加更多的服务器来扩展。&lt;/p>
&lt;p>当流量较低时，垂直扩展是一个很好的选择，垂直扩展的简单性是其主要优势。不幸的是，它有严重的局限性。&lt;/p>
&lt;ul>
&lt;li>垂直扩展有一个硬件限制。不可能在一台服务器上增加无限的 CPU 和内存。&lt;/li>
&lt;li>垂直扩展没有故障转移和冗余。如果一台服务器出现故障，网站/应用也会随之完全瘫痪。&lt;/li>
&lt;/ul>
&lt;p>由于垂直扩展的局限性，水平扩展对于大规模的应用更为理想。
在之前的设计中，用户是直接连接到网站服务器的。如果 Web 服务器离线，用户将无法访问网站。在另一种情况下，如果很多用户同时访问 Web 服务器，达到了 Web 服务器的负载极限，用户一般会出现响应速度较慢或无法连接到服务器的情况。负载均衡是解决这些问题的最佳技术。&lt;/p>
&lt;p>&lt;strong>负载均衡&lt;/strong>&lt;/p>
&lt;p>负载均衡将传入的流量均匀地分配给定义在负载均衡集群中的 Web 服务器。图 1-4 显示了负载均衡器的工作原理。&lt;/p>
&lt;img src="../../../system_design_interview/index-10_1.jpg" width="50%"/>
&lt;p>如图 1-4 所示，用户直接连接到负载均衡器的公网 IP。通过这种设置，Web 服务器已经无法被客户端直接访问了。为了提高安全性，服务器之间的通信采用私有 IP。私有 IP 是指只有同一网络中的服务器之间才能到达的 IP 地址，但是，通过互联网是无法到达的。负载均衡器通过私有 IP 与 Web 服务器进行通信。&lt;/p>
&lt;p>在图 1-4 中，增加了一个负载均衡器和第二台 Web 服务器后，我们成功解决了无故障切换问题，提高了 Web 层的可用性。下面将详细说明。&lt;/p>
&lt;ul>
&lt;li>如果服务器 1 离线，所有的流量将被路由到服务器 2。这样可以防止网站离线。我们也会在服务器池中增加一个新的健康网站服务器来平衡负载。&lt;/li>
&lt;li>如果网站流量快速增长，两台服务器不足以处理流量，负载均衡器可以优雅地处理这个问题。你只需要向 Web 服务器池添加更多的服务器，负载平衡器就会自动开始向它们发送请求。&lt;/li>
&lt;/ul>
&lt;p>现在 web 层看起来不错，那数据层呢？目前的设计只有一个数据库，所以它不支持故障转移和冗余。数据库复制是解决这些问题的一个常用技术。让我们来看看。&lt;/p>
&lt;p>&lt;strong>数据库复制&lt;/strong>&lt;/p>
&lt;p>引自维基百科。&amp;ldquo;数据库复制可用于许多数据库管理系统，通常原始数据库(主数据库)和副本(从数据库)之间存在主/从关系&amp;rdquo;[3]。&lt;/p>
&lt;p>主数据库一般只支持写操作。从数据库从主数据库获取数据的副本，只支持读操作。所有的插入、删除、更新等数据修改命令都必须发送到主数据库。大多数应用对读与写的比例要求更高，因此，系统中从数据库的数量通常大于主数据库的数量。图 1-5 显示了一个主数据库与多个从数据库的情况。&lt;/p>
&lt;img src="../../../system_design_interview/index-12_1.jpg" width="50%"/>
&lt;p>&lt;strong>数据库复制的优势&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>性能更好。在主从模式中，所有写入和更新都发生在主节点上；而读操作则分布在从节点上。这种模式可以提高性能，因为它允许并行处理更多的查询。&lt;/li>
&lt;li>可靠性。如果你的一个数据库服务器被自然灾害摧毁，如台风或地震，数据仍然会被保存下来。您不必担心数据丢失，因为数据是在多个地点复制的。&lt;/li>
&lt;li>高可用性。通过在不同地点复制数据，即使数据库离线，您的网站仍然可以运行，因为您可以访问存储在另一个数据库服务器的数据。&lt;/li>
&lt;/ul>
&lt;p>在上一节中，我们讨论了负载均衡器如何帮助提高系统的可用性。我们在这里提出同样的问题：如果其中一个数据库离线了怎么办？图 1-5 中讨论的架构设计可以处理这种情况。&lt;/p>
&lt;ul>
&lt;li>如果只有一个从数据库可用，而它又脱机了，读操作将被暂时导向主数据库。一旦发现问题，新的从数据库将取代旧的数据库。如果有多个从数据库可用，读取操作将被重定向到其他健康的从数据库。新的数据库服务器将取代旧的数据库。&lt;/li>
&lt;li>如果主数据库下线，一个从数据库将被提升为新的主数据库。所有的数据库操作将暂时在新的主数据库上执行。新的从数据库将立即取代旧的数据库进行数据复制。在生产系统中，推广新的主数据库比较复杂，因为从数据库中的数据可能不是最新的。缺少的数据需要通过运行数据恢复脚本来更新。虽然其他一些复制方法，如多主站和循环复制可以帮助我们，但这些设置比较复杂；而且它们的讨论也超出了本书的范围。有兴趣的读者可以参考列出的参考资料[4][5]。&lt;/li>
&lt;/ul>
&lt;p>图 1-6 是增加负载均衡器和数据库复制后的系统设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-14_1.jpg" width="50%"/>
&lt;p>我们来看一下设计。&lt;/p>
&lt;ul>
&lt;li>用户从 DNS 获取负载均衡器的 IP 地址。&lt;/li>
&lt;li>用户用这个 IP 地址连接负载均衡器。&lt;/li>
&lt;li>HTTP 请求被路由到服务器 1 或服务器 2。&lt;/li>
&lt;li>Web 服务器从从属数据库读取用户数据。&lt;/li>
&lt;li>Web 服务器将任何数据修改操作路由到主数据库。这包括写入、更新和删除操作。&lt;/li>
&lt;/ul>
&lt;p>现在，你已经对网络和数据层有了坚实的了解，是时候提高加载/响应时间了。这可以通过添加缓存层和将静态内容（JavaScript/CSS/图片/视频文件）转移到内容传输网络（CDN）来实现。&lt;/p>
&lt;p>&lt;strong>缓存&lt;/strong>&lt;/p>
&lt;p>缓存是一个临时的存储区域，它将昂贵的响应结果或频繁访问的数据存储在内存中，以便后续的请求能够更快地得到服务。如图 1-6 所示，每次加载新的网页时，都会执行一次或多次数据库调用来获取数据。由于反复调用数据库，应用性能受到很大影响。缓存可以缓解这个问题。&lt;/p>
&lt;p>&lt;strong>缓存层&lt;/strong>&lt;/p>
&lt;p>缓存层是一个临时的数据存储层，比数据库快得多。单独设置缓存层的好处包括更好的系统性能，能够减少数据库的工作负载，以及能够独立地扩展缓存层。图 1-7 显示了一个缓存服务器的可能设置。&lt;/p>
&lt;img src="../../../system_design_interview/index-15_1.jpg" />
&lt;p>在收到请求后，Web 服务器首先检查缓存是否有可用的响应。如果有，它就把数据发回给客户端。如果没有，它就查询数据库，将响应存储在缓存中，然后再发回给客户端。这种缓存策略称为读通式缓存。根据数据类型、大小和访问模式，还有其他缓存策略可供选择。之前的一项研究解释了不同缓存策略的工作原理[6]。&lt;/p>
&lt;p>与缓存服务器的交互很简单，因为大多数缓存服务器都提供了通用编程语言的 API。下面的代码片段展示了典型的 Memcached API。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75af00">SECONDS&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#111">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75af00">cache&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">set&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#d88200">&amp;#34;myKey&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span> &lt;span style="color:#d88200">&amp;#34;hi there&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span> &lt;span style="color:#ae81ff">3600&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#75af00">SECONDS&lt;/span>&lt;span style="color:#111">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75af00">cache&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">get&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#d88200">&amp;#34;myKey&amp;#34;&lt;/span>&lt;span style="color:#111">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>使用缓存的注意事项&lt;/strong>&lt;/p>
&lt;p>以下是使用缓存系统的几个注意事项。&lt;/p>
&lt;ul>
&lt;li>决定何时使用缓存。当数据经常被读取但不经常被修改时，考虑使用缓存。由于缓存数据存储在易失性内存中，因此缓存服务器并不是持久化数据的理想选择。例如，如果缓存服务器重新启动，内存中的所有数据都会丢失。因此，重要的数据应该保存在持久化数据存储中。&lt;/li>
&lt;li>过期策略。实施过期策略是一个很好的做法。一旦缓存数据过期，它就会从缓存中删除。当没有过期策略时，缓存数据将永久保存在内存中。建议不要把过期日期定得太短，否则会导致系统过于频繁地从数据库中重新加载数据。同时，建议不要把有效期做得太长，因为数据会变得陈旧。&lt;/li>
&lt;li>一致性。这涉及到保持数据存储和缓存的同步。由于对数据存储和缓存的数据修改操作不在一个事务中，所以会发生不一致的情况。当跨多个区域扩展时，保持数据存储和缓存之间的一致性是一个挑战。更多细节，请参考 Facebook 发布的题为 &amp;ldquo;Scaling Memcache at Facebook &amp;ldquo;的论文[7]。&lt;/li>
&lt;li>缓解故障。单个缓存服务器代表了一个潜在的单点故障（SPOF），在维基百科中的定义如下。&amp;ldquo;单点故障(SPOF)是指系统的一部分，如果它发生故障，将使整个系统停止工作&amp;rdquo;[8]。因此，建议在不同的数据中心设置多台缓存服务器，以避免 SPOF 的发生。另一种推荐的方法是按一定的百分比超额提供所需的内存。这样可以在内存使用量增加时提供一个缓冲区。&lt;/li>
&lt;li>驱逐政策。一旦缓存满了，任何向缓存添加项目的请求都可能导致现有项目被删除。这就是所谓的缓存驱逐。最少最近使用（LRU）是最流行的缓存驱逐策略。其他的驱逐策略，如最不常用(LFU)或先进先出(FIFO)，可以满足不同的用例。&lt;/li>
&lt;/ul>
&lt;img src="../../../system_design_interview/index-16_1.jpg" width="50%"/>
&lt;p>&lt;strong>内容传输网络(CDN)&lt;/strong>&lt;/p>
&lt;p>CDN 是一个由地理上分散的服务器组成的网络，用于传输静态内容。CDN 服务器缓存静态内容，如图片、视频、CSS、JavaScript 文件等。&lt;/p>
&lt;p>动态内容缓存是一个比较新的概念，超出了本书的范围。它可以实现基于请求路径、查询字符串、Cookie 和请求头的 HTML 页面的缓存。关于这方面的内容，请参考参考资料[9]中提到的文章。本书主要介绍如何使用 CDN 来缓存静态内容。&lt;/p>
&lt;p>下面是 CDN 的顶层工作原理：当用户访问一个网站时，离用户最近的 CDN 服务器将提供静态内容。直观地说，用户离 CDN 服务器越远，网站的加载速度越慢。例如，如果 CDN 服务器在旧金山，那么洛杉矶的用户将比欧洲的用户更快地获得内容。图 1-9 是一个很好的例子，它显示了 CDN 如何改善加载时间。&lt;/p>
&lt;img src="../../../system_design_interview/index-17_1.jpg" width="50%"/>
&lt;p>图 1-10 展示了 CDN 的工作流程。&lt;/p>
&lt;img src="../../../system_design_interview/index-17_2.jpg" width="75%"/>
&lt;ol>
&lt;li>用户 A 试图通过图片 URL 获取 image.png。该 URL 的域名由 CDN 提供商提供。以下两个图片 URL 是用来演示 Amazon 和 Akamai CDN 上的图片 URL 的示例。
&lt;ul>
&lt;li>&lt;a href="https://mysite.cloudfront.net/logo.jpg">https://mysite.cloudfront.net/logo.jpg&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mysite.akamai.com/image-manager/img/logo.jpg">https://mysite.akamai.com/image-manager/img/logo.jpg&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>如果 CDN 服务器的缓存中没有 image.png，CDN 服务器就会向原点请求该文件，这个原点可以是 Web 服务器，也可以是 Amazon S3 等在线存储。&lt;/li>
&lt;li>原点将 image.png 返回给 CDN 服务器，其中包括可选的 HTTP 头 Time-to-Live（TTL），它描述了图像被缓存的时间。&lt;/li>
&lt;li>CDN 缓存图像并将其返回给用户 A，图像一直在 CDN 中缓存，直到 TTL 过期。&lt;/li>
&lt;li>用户 B 发送一个请求来获取相同的图像。&lt;/li>
&lt;li>只要 TTL 没有过期，图像就会从缓存中返回。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>使用 CDN 的注意事项&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>费用。CDN 由第三方供应商运营，您需要为进出 CDN 的数据传输付费。缓存不经常使用的资产并不能提供显著的好处，所以你应该考虑将它们移出 CDN。&lt;/li>
&lt;li>设置一个合适的缓存到期时间。对于时间敏感的内容，设置一个缓存到期时间很重要。缓存到期时间既不能太长也不能太短。如果太长，内容可能过期。如果太短，可能会导致从源服务器到 CDN 的内容重复重载。&lt;/li>
&lt;li>CDN 回源。你应该考虑你的网站/应用如何应对 CDN 故障。如果 CDN 出现临时中断，客户端应该能够检测到问题，并从源服务器请求资源。&lt;/li>
&lt;li>使文件无效。您可以通过执行以下操作之一，在文件过期前从 CDN 中删除文件。
&lt;ul>
&lt;li>使用 CDN 供应商提供的 API 使 CDN 对象无效。&lt;/li>
&lt;li>使用对象版本化来服务对象的不同版本。要对对象进行版本管理，可以在 URL 中添加一个参数，例如版本号。例如，在查询字符串中添加版本号 2：image.png?v=2。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>图 1-11 是添加 CDN 和缓存后的设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-19_1.jpg" width="75%"/>
&lt;ol>
&lt;li>静态资产（JS、CSS、图片等）不再由 Web 服务器提供服务。它们从 CDN 获取，以获得更好的性能。&lt;/li>
&lt;li>通过缓存数据，减轻了数据库的负载。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>无状态 Web 层&lt;/strong>&lt;/p>
&lt;p>现在是时候考虑横向扩展 Web 层了。为此，我们需要将状态（例如用户会话数据）移出 web 层。一个好的做法是将会话数据存储在持久性存储中，如关系型数据库或 NoSQL。集群中的每个 Web 服务器都可以从数据库中访问状态数据。这就是所谓的无状态 Web 层。&lt;/p>
&lt;p>&lt;strong>有状态架构&lt;/strong>&lt;/p>
&lt;p>有状态服务器和无状态服务器有一些关键的区别。有状态的服务器会记住客户的数据（状态），从一个请求到下一个请求。无状态服务器不保留状态信息。&lt;/p>
&lt;p>图 1-12 显示了一个有状态架构的例子。&lt;/p>
&lt;img src="../../../system_design_interview/index-20_1.jpg" width="75%"/>
&lt;p>在图 1-12 中，用户 A 的会话数据和配置文件图像存储在服务器 1 中。要对用户 A 进行身份验证，HTTP 请求必须路由到服务器 1。如果向服务器 2 等其他服务器发送请求，认证将失败，因为服务器 2 不包含用户 A 的会话数据。同样，所有来自用户 B 的 HTTP 请求必须路由到服务器 2；所有来自用户 C 的请求必须发送到服务器 3。&lt;/p>
&lt;p>问题是来自同一客户端的每个请求都必须路由到同一个服务器。这可以通过大多数负载均衡器中的粘性会话来实现[10]；然而，这增加了开销。使用这种方法增加或删除服务器要困难得多。处理服务器故障也是一个挑战。&lt;/p>
&lt;p>&lt;strong>无状态结构&lt;/strong>&lt;/p>
&lt;p>图 1-13 为无状态架构。&lt;/p>
&lt;img src="../../../system_design_interview/index-21_1.jpg" width="66%"/>
&lt;p>在这种无状态架构中，用户的 HTTP 请求可以发送到任何 Web 服务器上，服务器从共享数据存储中获取状态数据。状态数据存储在共享数据存储中，不受 Web 服务器的影响。无状态系统更简单、更健壮、可扩展。&lt;/p>
&lt;p>图 1-14 为无状态网络层的更新设计。&lt;/p>
&lt;img src="../../../system_design_interview/index-22_1.jpg" width="75%"/>
&lt;p>在图 1-14 中，我们将会话数据从 Web 层移出，并将其存储在持久化数据存储中。共享数据存储可以是关系型数据库、Memcached/Redis、NoSQL 等。选择 NoSQL 数据存储是因为它易于扩展。自动伸缩是指根据流量负载自动增加或删除 Web 服务器。当状态数据从 web 服务器中取出后，根据流量负载增加或删除服务器，就可以轻松实现 web 层的自动伸缩。&lt;/p>
&lt;p>您的网站发展迅速，在国际上吸引了大量的用户。为了提高可用性，并在更广泛的地域提供更好的用户体验，支持多个数据中心至关重要。&lt;/p>
&lt;p>&lt;strong>数据中心&lt;/strong>&lt;/p>
&lt;p>图 1-15 是一个有两个数据中心的设置实例。在正常运行中，用户会被 geoDNS-routed，也就是地理路由，到最近的数据中心，美东地区的流量分成 x%，美西地区的流量分成(100 - x)%，geoDNS 是一种 DNS 服务，可以根据用户的位置将域名解析到 IP 地址。&lt;/p>
&lt;img src="../../../system_design_interview/index-23_1.jpg" width="75%"/>
&lt;p>在任何重大的数据中心中断的情况下，我们将所有的流量引导到一个健康的数据中心。在图 1-16 中，数据中心 2（US-West）处于离线状态，100%的流量被引导到数据中心 1（US-East）。&lt;/p>
&lt;img src="../../../system_design_interview/index-24_1.jpg" width="75%"/>
&lt;p>要实现多数据中心的设置，必须解决几个技术难题。&lt;/p>
&lt;ul>
&lt;li>流量重定向。需要有效的工具来引导流量到正确的数据中心。GeoDNS 可以根据用户所在的位置，将流量引导到最近的数据中心。&lt;/li>
&lt;li>数据同步。来自不同地区的用户可能使用不同的本地数据库或缓存。在故障转移情况下，流量可能会被路由到数据不可用的数据中心。一个常见的策略是在多个数据中心之间复制数据。之前的一项研究展示了 Netflix 如何实现异步多数据中心复制[11]。&lt;/li>
&lt;li>测试和部署。对于多数据中心的设置，在不同的位置测试你的网站/应用是很重要的。自动部署工具对于在所有数据中心保持服务的一致性至关重要[11]。&lt;/li>
&lt;/ul>
&lt;p>为了进一步扩展我们的系统，我们需要对系统的不同组件进行解耦，以便它们可以独立地进行扩展。消息队列是许多现实世界的分布式系统采用的一个关键策略，以解决这个问题。&lt;/p>
&lt;p>&lt;strong>消息队列&lt;/strong>&lt;/p>
&lt;p>消息队列是一个持久的组件，存储在内存中，支持异步通信。它作为一个缓冲区，分发异步请求。消息队列的基本架构很简单。输入服务，称为生产者/发布者，创建消息，并将它们发布到消息队列中。其他服务或服务器，称为消费者/订阅者，连接到队列，并执行由消息定义的操作。该模型如图 1-17 所示。&lt;/p>
&lt;img src="../../../system_design_interview/index-25_1.jpg" width="66%"/>
&lt;p>解耦使得消息队列成为构建可扩展和可靠应用的首选架构。通过消息队列，当消费者无法处理消息时，生产者可以将消息发布到队列中。即使在生产者不可用时，消费者也可以从队列中读取消息。&lt;/p>
&lt;p>考虑以下用例：你的应用程序支持照片定制，包括裁剪、锐化、模糊等。这些定制任务需要时间来完成。在图 1-18 中，Web 服务器将照片处理作业发布到消息队列中。照片处理工作者从消息队列中接取作业，并异步执行照片定制任务。生产者和消费者可以独立伸缩。当队列的规模变大时，会增加更多的工人以减少处理时间。但是，如果队列大部分时间是空的，可以减少工人的数量。&lt;/p>
&lt;img src="../../../system_design_interview/index-25_2.jpg" width="66%"/>
&lt;p>&lt;strong>记录、指标、自动化&lt;/strong>&lt;/p>
&lt;p>当与一个在少数服务器上运行的小型网站合作时，日志，指标和自动化支持是良好的实践，但不是必需品。然而，现在你的网站已经成长为服务于一个大型企业，投资于这些工具是必不可少的。&lt;/p>
&lt;p>日志记录。监控错误日志很重要，因为它有助于识别系统中的错误和问题。您可以在每个服务器级别监控错误日志，或者使用工具将它们汇总到一个集中的服务，以便于搜索和查看。&lt;/p>
&lt;p>指标。收集不同类型的指标有助于我们获得业务洞察力，了解系统的健康状况。以下一些指标是有用的。&lt;/p>
&lt;ul>
&lt;li>主机级指标： CPU、内存、磁盘 I/O 等。&lt;/li>
&lt;li>汇总级指标：例如，整个数据库层、缓存层的性能等。&lt;/li>
&lt;li>关键业务指标：日活跃用户、留存率、收入等。&lt;/li>
&lt;/ul>
&lt;p>自动化。当一个系统变得庞大而复杂时，我们需要建立或利用自动化工具来提高生产力。持续集成是一个很好的实践，通过自动化来验证每一个代码的签入，让团队及早发现问题。此外，将构建、测试、部署等过程自动化，可以显著提高开发人员的生产力。&lt;/p>
&lt;p>&lt;strong>添加消息队列和不同的工具&lt;/strong>&lt;/p>
&lt;p>图 1-19 为更新后的设计。由于篇幅所限，图中只显示了一个数据中心。&lt;/p>
&lt;ol>
&lt;li>设计中加入了消息队列，这有助于使系统更加松散耦合和故障恢复能力。&lt;/li>
&lt;li>包含了日志、监控、指标和自动化工具。&lt;/li>
&lt;/ol>
&lt;img src="../../../system_design_interview/index-27_1.jpg" width="66%"/>
&lt;p>随着数据每天的增长，你的数据库会越来越过载。是时候扩大数据层的规模了。&lt;/p>
&lt;p>&lt;strong>数据库扩展&lt;/strong>&lt;/p>
&lt;p>数据库的扩展有两大方法：垂直扩展和水平扩展。&lt;/p>
&lt;p>&lt;strong>垂直扩展&lt;/strong>&lt;/p>
&lt;p>垂直扩展，也叫扩大规模，就是通过给现有的机器增加更多的功率（CPU、RAM、DISK 等）来进行扩展。有一些强大的数据库服务器。根据 Amazon Relational Database Service(RDS)[12]，你可以得到一个 24TB 内存的数据库服务器。这种强大的数据库服务器可以存储和处理大量的数据。例如，stackoverflow.com 在 2013 年有超过 1000 万的月度独立访客，但它只有 1 个主数据库[13]。然而，垂直扩展也有一些严重的缺点。&lt;/p>
&lt;ul>
&lt;li>你可以在数据库服务器上增加更多的 CPU、RAM 等，但有硬件限制。如果你有大量的用户群，单台服务器是不够的。&lt;/li>
&lt;li>单点故障的风险较大。&lt;/li>
&lt;li>垂直扩展的整体成本很高。强大的服务器要贵得多。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>水平扩展&lt;/strong>&lt;/p>
&lt;p>水平扩展，也称为 sharding，是增加更多服务器的做法。图 1- 20 比较了垂直扩展和水平扩展。&lt;/p>
&lt;img src="../../../system_design_interview/index-28_1.jpg" width="66%"/>
&lt;p>Sharding 将大型数据库分离成更小、更容易管理的部分，称为 shard。每个分片共享相同的模式，尽管每个分片上的实际数据对该分片来说是独一无二的。&lt;/p>
&lt;p>图 1-21 显示了一个分片数据库的例子。用户数据是根据用户 ID 分配到数据库服务器上的。任何时候访问数据时，都会使用一个哈希函数来找到相应的分片。在我们的例子中，user_id % 4 被用作哈希函数。如果结果等于 0，则 0 号分片被用来存储和获取数据。如果结果等于 1，则使用分片 1。同样的逻辑也适用于其他分片。&lt;/p>
&lt;img src="../../../system_design_interview/index-29_1.jpg" width="50%"/>
&lt;p>图 1-22 是分片数据库中的用户表。&lt;/p>
&lt;img src="../../../system_design_interview/index-29_2.jpg" width="50%"/>
&lt;p>在实施分区策略时，需要考虑的最重要因素是分区密钥的选择。分区键（称为分区键）由一列或多列组成，决定数据的分布方式。如图 1-22 所示，&amp;ldquo;user_id &amp;ldquo;就是 sharding 键。通过 sharding 键，可以将数据库查询路由到正确的数据库，从而有效地检索和修改数据。在选择 sharding 键时，最重要的一个标准是选择一个能够均匀分布数据的键。&lt;/p>
&lt;p>Sharding 是一种很好的扩展数据库的技术，但它远不是一个完美的解决方案。它给系统带来了复杂性和新的挑战。&lt;/p>
&lt;p>&lt;strong>重置数据&lt;/strong>&lt;/p>
&lt;p>在以下情况下需要重新 sharding 数据：&lt;/p>
&lt;ol>
&lt;li>由于快速增长，单个分片无法再容纳更多的数据。&lt;/li>
&lt;li>由于数据分布不均，某些分片可能比其他分片更快地出现分片耗尽。当分片耗尽时，需要更新 sharding 函数，并移动数据。&lt;/li>
&lt;/ol>
&lt;p>第 5 章将讨论的一致性哈希是解决这个问题的常用技术。&lt;/p>
&lt;p>&lt;strong>名人问题&lt;/strong>&lt;/p>
&lt;p>这也被称为热点问题。对特定分片的过度访问可能导致服务器过载。想象一下，Katy Perry、Justin Bieber 和 Lady Gaga 的数据最终都会出现在同一个分片上。对于社交应用来说，该分片将因读取操作而不堪重负。为了解决这个问题，我们可能需要为每个名人分配一个 shard。每个分片甚至可能需要进一步分区。&lt;/p>
&lt;p>&lt;strong>使用和去范式化&lt;/strong>&lt;/p>
&lt;p>一旦一个数据库被分片到多个服务器上 就很难在不同的数据库分片之间进行连接操作了一个常见的变通方法是对数据库进行去范式化，这样就可以在一张表中进行查询。&lt;/p>
&lt;p>在图 1-23 中，我们对数据库进行分片，以支持快速增加的数据流量。同时，将一些非关系型功能转移到 NoSQL 数据存储中，以减少数据库负载。这里有一篇文章，涵盖了 NoSQL 的很多用例[14]。&lt;/p>
&lt;img src="../../../system_design_interview/index-31_1.jpg" width="66%"/>
&lt;p>&lt;strong>数百万用户及以上&lt;/strong>&lt;/p>
&lt;p>扩展系统是一个迭代的过程。迭代我们在本章所学到的知识可以让我们走得更远。要想扩展到数百万用户以上，还需要更多的微调和新的策略。例如，你可能需要优化你的系统，并将系统解耦到更小的服务。本章所学到的所有技术都应该为应对新的挑战打下良好的基础。在本章的最后，我们将对我们如何扩展系统以支持数百万用户进行总结。&lt;/p>
&lt;ul>
&lt;li>保持网络层无状态&lt;/li>
&lt;li>在每一层建立冗余&lt;/li>
&lt;li>尽可能多地缓存数据&lt;/li>
&lt;li>支持多个数据中心&lt;/li>
&lt;li>在 CDN 中托管静态资产&lt;/li>
&lt;li>通过分区来扩展您的数据层&lt;/li>
&lt;li>将层级划分为个别服务&lt;/li>
&lt;li>监控您的系统并使用自动化工具&lt;/li>
&lt;/ul>
&lt;p>恭喜你走到这一步！现在给自己拍拍背。做得好！&lt;/p>
&lt;p>&lt;strong>参考资料&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">[1] Hypertext Transfer Protocol&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.teamtreehouse.com/should-you-go-beyond-relational-databases">[2] Should you go Beyond Relational Databases?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Replication_(computing)">[3] Replication&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication">[4] Multi-master replication&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dev.mysql.com/doc/refman/5.7/en/mysql-cluster-replication-multi-master.html">[5] NDB Cluster Replication: Multi-Master and Circular Replication&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://codeahoy.com/2017/08/11/caching-strategies-and-how-to-choose-the-right-one/">[6] Caching Strategies and How to Choose the Right One&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf">[7] Scaling Memcache at Facebook &lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Single_point_of_failure">[8] Single point of failure&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/cloudfront/dynamic-content/">[9] Amazon CloudFront Dynamic Content Delivery&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html">[10] Configure Sticky Sessions for Your Classic Load Balancer&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://netflixtechblog.com/active-active-for-multi-regional-resiliency-c47719f6685b">[11] Active-Active for Multi-Regional Resiliency&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aws.amazon.com/ec2/instance-types/high-memory/">[12] Amazon EC2 High Memory Instances&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://nickcraver.com/blog/2013/11/22/what-it-takes-to-run-stack-overflow">[13] What it takes to run Stack Overflow&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://highscalability.com/blog/2010/12/6/what-the-heck-are-you-actually-using-nosql-for.html">[14] What The Heck Are You Actually Using NoSQL For&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>