<!DOCTYPE html>
<html lang="en-us">
<head>
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Kafka::基础 | Y.CH.Y</title>
  <link rel = 'canonical' href = '/post/kafka_basic/'>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="Kafka::基础" />
<meta property="og:description" content="入门  定义  Apache Kafka 是一款开源的消息引擎系统。根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。   特点  消息引擎传输的对象是消息 传输消息属于消息引擎设计机制的一部分   消息编码格式  CSV XML JSON Google 的 Protocol Buffer Facebook 的 Thrift 结构化的二进制字节序列   消息传输协议  点对点模型 发布/订阅模型   功能  削峰填谷：缓冲上下游瞬时突发流量，使其更平滑过度给下游 发送方和接收方的松耦合：简化应用开发，减少了系统不必要的交互   术语  消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。 主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。 分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。 消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。 副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。 生产者：Producer。向主题发布新消息的应用程序。 消费者：Consumer。从主题订阅新消息的应用程序。 消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。   分布式流处理平台  研发背景  数据正确性不足，Polling 导致数据偏差 系统高度定制化，维护成本高   特性  提供一套 API 实现生产者和消费者 降低网络传输和磁盘存储开销 实现高伸缩性架构   优势  更容易实现端到端的正确性，Kafka 可以实现端到端的精确一次处理语义 更开放的流式计算定位，Kafka Streams 是一个用于搭建实时流处理的客户端库而非是一个完整的功能系统 用作分布式存储     版本选择  Apache Kafka，也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。 Confluent Kafka，Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。 CDH/HDP Kafka，大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。    基本使用  部署环境  操作系统  Linux：高效的 I/O 性能、Linux 实现了零拷贝的数据传输、Kafka 更重视 Linux 社区   磁盘  追求性价比的公司可以不搭建 RAID，使用普通磁盘组成存储空间即可 使用机械磁盘完全能够胜任 Kafka 线上环境   磁盘容量  新增消息数 消息留存时间 平均消息大小 备份数 是否启用压缩   带宽  预留三分一空闲带宽     重要的配置  Broker 端参数  log." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/kafka_basic/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-08-11T03:52:05+08:00" />
<meta property="article:modified_time" content="2021-08-11T03:52:05+08:00" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Kafka::基础"/>
<meta name="twitter:description" content="入门  定义  Apache Kafka 是一款开源的消息引擎系统。根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。   特点  消息引擎传输的对象是消息 传输消息属于消息引擎设计机制的一部分   消息编码格式  CSV XML JSON Google 的 Protocol Buffer Facebook 的 Thrift 结构化的二进制字节序列   消息传输协议  点对点模型 发布/订阅模型   功能  削峰填谷：缓冲上下游瞬时突发流量，使其更平滑过度给下游 发送方和接收方的松耦合：简化应用开发，减少了系统不必要的交互   术语  消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。 主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。 分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。 消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。 副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。 生产者：Producer。向主题发布新消息的应用程序。 消费者：Consumer。从主题订阅新消息的应用程序。 消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。   分布式流处理平台  研发背景  数据正确性不足，Polling 导致数据偏差 系统高度定制化，维护成本高   特性  提供一套 API 实现生产者和消费者 降低网络传输和磁盘存储开销 实现高伸缩性架构   优势  更容易实现端到端的正确性，Kafka 可以实现端到端的精确一次处理语义 更开放的流式计算定位，Kafka Streams 是一个用于搭建实时流处理的客户端库而非是一个完整的功能系统 用作分布式存储     版本选择  Apache Kafka，也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。 Confluent Kafka，Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。 CDH/HDP Kafka，大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。    基本使用  部署环境  操作系统  Linux：高效的 I/O 性能、Linux 实现了零拷贝的数据传输、Kafka 更重视 Linux 社区   磁盘  追求性价比的公司可以不搭建 RAID，使用普通磁盘组成存储空间即可 使用机械磁盘完全能够胜任 Kafka 线上环境   磁盘容量  新增消息数 消息留存时间 平均消息大小 备份数 是否启用压缩   带宽  预留三分一空闲带宽     重要的配置  Broker 端参数  log."/>

  
  
    
  
  
  <link rel="stylesheet" href="/css/styles.a1d8fc2f132c452937740993f66c1b7a35d39b0774f74823f917c8b66b7795716119b0af416457217bed8e35420077308b167d77d283c319f347c34500e4ca46.css" integrity="sha512-odj8LxMsRSk3dAmT9mwbejXTmwd090gj&#43;RfItmt3lXFhGbCvQWRXIXvtjjVCAHcwixZ9d9KDwxnzR8NFAOTKRg=="> 

  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="/images/favicon.ico" />

  
  
  
  
  
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-X1L70M4MM0', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  
  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

    <header id="header">
  <a href="/">
  
    <div id="logo" style="background-image: url(/images/logo.png)"></div>
  
  <div id="title">
    <h1>Y.CH.Y</h1>
  </div>
  </a>
  <div id="nav">
    <ul>
      <li class="icon">
        <a href="#" aria-label="Menu"><i class="fas fa-bars fa-2x" aria-hidden="true"></i></a>
      </li>
      
        <li><a href="/">Home</a></li>
      
    </ul>
  </div>
</header>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-X1L70M4MM0"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-X1L70M4MM0', { 'anonymize_ip': false });
}
</script>



    
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <div class="content" itemprop="articleBody">
  
    <h2 id="入门">入门</h2>
<ul>
<li>定义
<ul>
<li>Apache Kafka 是一款开源的消息引擎系统。根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。</li>
</ul>
</li>
<li>特点
<ul>
<li>消息引擎传输的对象是消息</li>
<li>传输消息属于消息引擎设计机制的一部分</li>
</ul>
</li>
<li>消息编码格式
<ul>
<li>CSV</li>
<li>XML</li>
<li>JSON</li>
<li>Google 的 Protocol Buffer</li>
<li>Facebook 的 Thrift</li>
<li>结构化的二进制字节序列</li>
</ul>
</li>
<li>消息传输协议
<ul>
<li>点对点模型</li>
<li>发布/订阅模型</li>
</ul>
</li>
<li>功能
<ul>
<li>削峰填谷：缓冲上下游瞬时突发流量，使其更平滑过度给下游</li>
<li>发送方和接收方的松耦合：简化应用开发，减少了系统不必要的交互</li>
</ul>
</li>
<li>术语
<ul>
<li>消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。</li>
<li>主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。</li>
<li>分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。</li>
<li>消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。</li>
<li>副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。</li>
<li>生产者：Producer。向主题发布新消息的应用程序。</li>
<li>消费者：Consumer。从主题订阅新消息的应用程序。</li>
<li>消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。</li>
<li>消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。</li>
<li>重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。</li>
</ul>
</li>
<li>分布式流处理平台
<ul>
<li>研发背景
<ul>
<li>数据正确性不足，Polling 导致数据偏差</li>
<li>系统高度定制化，维护成本高</li>
</ul>
</li>
<li>特性
<ul>
<li>提供一套 API 实现生产者和消费者</li>
<li>降低网络传输和磁盘存储开销</li>
<li>实现高伸缩性架构</li>
</ul>
</li>
<li>优势
<ul>
<li>更容易实现端到端的正确性，Kafka 可以实现端到端的精确一次处理语义</li>
<li>更开放的流式计算定位，Kafka Streams 是一个用于搭建实时流处理的客户端库而非是一个完整的功能系统</li>
<li>用作分布式存储</li>
</ul>
</li>
</ul>
</li>
<li>版本选择
<ul>
<li>Apache Kafka，也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。</li>
<li>Confluent Kafka，Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。</li>
<li>CDH/HDP Kafka，大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。</li>
</ul>
</li>
</ul>
<h2 id="基本使用">基本使用</h2>
<ul>
<li>部署环境
<ul>
<li>操作系统
<ul>
<li>Linux：高效的 I/O 性能、Linux 实现了零拷贝的数据传输、Kafka 更重视 Linux 社区</li>
</ul>
</li>
<li>磁盘
<ul>
<li>追求性价比的公司可以不搭建 RAID，使用普通磁盘组成存储空间即可</li>
<li>使用机械磁盘完全能够胜任 Kafka 线上环境</li>
</ul>
</li>
<li>磁盘容量
<ul>
<li>新增消息数</li>
<li>消息留存时间</li>
<li>平均消息大小</li>
<li>备份数</li>
<li>是否启用压缩</li>
</ul>
</li>
<li>带宽
<ul>
<li>预留三分一空闲带宽</li>
</ul>
</li>
</ul>
</li>
<li>重要的配置
<ul>
<li>Broker 端参数
<ul>
<li>log.dirs: Broker 需要使用的若干个文件目录路径，逗号分隔的多个路径</li>
<li>log.dir: 表示单个路径，它是补充上一个参数用的</li>
<li>zookeeper.connect: 负责协调管理并保存 Kafka 集群的所有元数据信息，逗号分隔，chroot 只写一次，添加到最后</li>
<li>listeners：学名叫监听器，其实就是告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka 服务。</li>
<li>advertised.listeners：和 listeners 相比多了个 advertised。Advertised 的含义表示宣称的、公布的，就是说这组监听器是 Broker 用于对外发布的。</li>
<li>listener.security.protocol.map：自定义协议声明</li>
<li>auto.create.topics.enable：是否允许自动创建 Topic。</li>
<li>unclean.leader.election.enable：是否允许 Unclean Leader 选举。</li>
<li>auto.leader.rebalance.enable：是否允许定期进行 Leader 选举。</li>
<li>log.retention.{hour|minutes|ms}：控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hour 最低。</li>
<li>log.retention.bytes：这是指定 Broker 为消息保存的总磁盘容量大小，-1 表示不限制。</li>
<li>message.max.bytes：控制 Broker 能够接收的最大消息大小。</li>
</ul>
</li>
<li>Topic 端参数
<ul>
<li>retention.ms：规定了该 Topic 消息被保存的时长</li>
<li>retention.bytes：规定了要为该 Topic 预留多大的磁盘空间</li>
</ul>
</li>
<li>JVM 参数
<ul>
<li>-XX:+UseParallelGC：启用 CMS 收集器</li>
<li>KAFKA_HEAP_OPTS：指定堆大小。</li>
<li>KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。</li>
</ul>
</li>
<li>操作系统参数
<ul>
<li>文件描述符限制：ulimit -n，每次连接会打开一个文件，可以设置大一点</li>
<li>文件系统选择：XFS 性能强于 ext3、ext4</li>
<li>SWAP：预留一些以免耗尽内存触发系统 OOM killer</li>
<li>调整 Flush 落盘时间：已经有了副本冗余，可以延长一点，换取性能</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="实践与原理">实践与原理</h2>
<ul>
<li>生产者消息分区原理
<ul>
<li>主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份。</li>
<li>分区的作用就是提供负载均衡的能力，实现系统的高伸缩性</li>
<li>分区策略
<ul>
<li>轮询策略：轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略</li>
<li>随机策略：从实际表现来看，它要逊于轮询策略，所以如果追求数据的均匀分布，还是使用轮询策略比较好</li>
<li>Key-ordering 策略：Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key 的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以用来表征消息元数据。特别是在 Kafka 不支持时间戳的年代，在一些场景中，工程师们都是直接将消息创建时间封装进 Key 里面的。一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为 Key-Ordering 保序策略</li>
<li>其他分区策略：基于地理位置的分区等</li>
</ul>
</li>
</ul>
</li>
<li>生产者压缩算法
<ul>
<li>V2 版本的 Kafka 提取了消息中的公共部分到外面消息集合里，对整个消息集合进行压缩，V1 版本压缩消息队列后再放入消息集合中，获得了更好的压缩效果。</li>
<li>何时压缩
<ul>
<li>在生产端和 Broker 端都可以压缩，一般在生产端压缩</li>
<li>Broker 端压缩的场景：
<ul>
<li>Broker 端指定了和 Producer 端不同的压缩算法</li>
<li>Broker 端发生了消息格式转换：出于兼容不同版本消费者程序，丧失了零拷贝抽象</li>
</ul>
</li>
</ul>
</li>
<li>何时解压缩
<ul>
<li>在 Consumer 和 Broker 都可以解压缩，每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证</li>
</ul>
</li>
<li>压缩算法
<ul>
<li>根据压缩比和压缩/解压吞吐量来选择压缩算法</li>
<li>如果 Producer 端服务器 CPU 资源充足，可以在 Producer 端开启压缩</li>
<li>尽量避免解压缩操作</li>
</ul>
</li>
</ul>
</li>
<li>无消息丢失配置
<ul>
<li>Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。
<ul>
<li>当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。</li>
<li>消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。</li>
</ul>
</li>
<li>消息丢失的场景
<ul>
<li>异步发送消息：丢包，队列阻塞，Broker 因为格式错误不接受，改正方法采用 callback</li>
<li>消费者丢失数据：先更新位移再消费，中间中断了消费，重新消费时从位移点开始，丢失了一部分数据。维持先消费消息（阅读），再更新位移（书签）的顺序即可。这样就能最大限度地保证消息不丢失。</li>
<li>多线程消费更新位移丢失消息。如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。</li>
</ul>
</li>
<li>最佳实践
<ul>
<li>不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。</li>
<li>设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li>
<li>设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。</li>
<li>设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。</li>
<li>设置 replication.factor &gt;= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。</li>
<li>设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li>
<li>确保 replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。</li>
<li>确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。</li>
</ul>
</li>
</ul>
</li>
<li>Kafka 拦截器
<ul>
<li>可以在消息处理的前后多个时点动态植入不同的处理逻辑，比如在消息发送前或者在消息被消费后。</li>
<li>Kafka 拦截器分为生产者拦截器和消费者拦截器。生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。</li>
<li>生产者拦截器继承<code>org.apache.kafka.clients.producer.ProducerInterceptor</code>
<ul>
<li><code>onSend</code>：该方法会在消息发送之前被调用</li>
<li><code>onAcknowledgement</code>：该方法会在消息成功提交或发送失败之后被调用</li>
</ul>
</li>
<li>消费者拦截器继承<code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code>
<ul>
<li><code>onConsume</code> ：该方法在消息返回给 Consumer 程序之前调用。</li>
<li><code>onCommit</code>：Consumer 在提交位移之后调用该方法。</li>
</ul>
</li>
<li>场景
<ul>
<li>客户端监控</li>
<li>端到端系统性能检测</li>
<li>消息审计</li>
</ul>
</li>
</ul>
</li>
<li>生产者 TCP 连接管理
<ul>
<li>KafkaProducer 实例创建时启动 Sender 线程，从而创建与 bootstrap.servers 中所有 Broker 的 TCP 连接。</li>
<li>KafkaProducer 实例首次更新元数据信息之后，还会再次创建与集群中所有 Broker 的 TCP 连接。</li>
<li>如果 Producer 端发送消息到某台 Broker 时发现没有与该 Broker 的 TCP 连接，那么也会立即创建连接。</li>
<li>如果设置 Producer 端 connections.max.idle.ms 参数大于 0，则步骤 1 中创建的 TCP 连接会被自动关闭；如果设置该参数 =-1，那么步骤 1 中创建的 TCP 连接将无法被关闭，从而成为“僵尸”连接。</li>
</ul>
</li>
<li>可靠性保障
<ul>
<li>处理消息常见承诺
<ul>
<li>最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。</li>
<li>至少一次（at least once）：消息不会丢失，但有可能被重复发送。</li>
<li>精确一次（exactly once）：消息不会丢失，也不会被重复发送。</li>
</ul>
</li>
<li>幂等 Producer:enable.idempotence 被设置成 true 后，Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要改变。Kafka 自动帮你做消息的重复去重。底层具体的原理很简单，就是经典的用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们“丢弃”掉。</li>
<li>事务 Producer：和普通 Producer 代码相比，事务型 Producer 的显著特点是调用了一些事务 API，如 initTransaction、beginTransaction、commitTransaction 和 abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。在 Consumer 端设置事务级别 read_committed，它只处理事务型 Producer 写入的消息。</li>
<li>幂等性 Producer 只能保证单分区、单会话上的消息幂等性；而事务能够保证跨分区、跨会话间的幂等性。从交付语义上来看，自然是事务型 Producer 能做的更多，但是性能更差。</li>
</ul>
</li>
<li>消费者组
<ul>
<li>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制</li>
<li>Consumer Group 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。在实际场景中，使用进程更为常见一些。</li>
<li>Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。</li>
<li>Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。</li>
<li>理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数。</li>
</ul>
</li>
<li>位移主题
<ul>
<li>新版本 Consumer 的位移管理机制将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。</li>
<li>位移主题的消息格式却是 Kafka 自己定义的</li>
<li>位移主题的 Key 中应该保存 3 部分内容：&lt;Group ID，主题名，分区号&gt;</li>
<li>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。</li>
<li>如果位移主题是 Kafka 自动创建的，那么该主题的分区数是 50，副本数是 3。</li>
<li>Consumer 提交位移的方式有两种：自动提交位移和手动提交位移。</li>
<li>Kafka 使用 Compact 策略来删除位移主题中的过期消息，避免该主题无限期膨胀。</li>
<li>Kafka 提供了专门的后台线程定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。这个后台线程叫 Log Cleaner。</li>
</ul>
</li>
<li>重平衡
<ul>
<li>Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。</li>
<li>在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。但是，在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。</li>
<li>缺点
<ul>
<li>Rebalance 影响 Consumer 端 TPS。</li>
<li>Rebalance 很慢。</li>
<li>Rebalance 效率不高。</li>
</ul>
</li>
<li>Rebalance 发生时机
<ul>
<li>组成员数量发生变化</li>
<li>订阅主题数量发生变化</li>
<li>订阅主题的分区数发生变化</li>
</ul>
</li>
<li>避免 Rebalance
<ul>
<li>第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被“踢出”Group 而引发的</li>
<li>第二类非必要 Rebalance 是 Consumer 消费时间过长导致的</li>
</ul>
</li>
</ul>
</li>
<li>位移提交
<ul>
<li>Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移</li>
<li>Consumer 需要为分配给它的每个分区提交各自的位移数据。</li>
<li>位移提交的语义保障是由开发者来负责的，Kafka 只会“无脑”地接受你提交的位移</li>
<li>从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。</li>
<li>手动提交也无法完全避免重复消费</li>
</ul>
</li>
<li>CommitFailedException
<ul>
<li>所谓 CommitFailedException，顾名思义就是 Consumer 客户端在提交位移时出现了错误或异常，而且还是那种不可恢复的严重异常</li>
<li>优化方法
<ul>
<li>缩短单条消息处理的时间</li>
<li>增加 Consumer 端允许下游系统消费一批消息的最大时长</li>
<li>减少下游系统一次性消费的消息总数</li>
<li>下游系统使用多线程来加速消费</li>
</ul>
</li>
</ul>
</li>
<li>消费者 TCP 管理
<ul>
<li>构建 KafkaConsumer 实例时是不会创建任何 TCP 连接的</li>
<li>TCP 连接是在调用 KafkaConsumer.poll 方法时被创建的
<ul>
<li>发起 FindCoordinator 请求时</li>
<li>连接协调者时</li>
<li>消费数据时</li>
</ul>
</li>
<li>3 类 TCP 连接
<ul>
<li>确定协调者和获取集群元数据。</li>
<li>连接协调者，令其执行组成员管理操作。</li>
<li>执行实际的消息获取。</li>
</ul>
</li>
</ul>
</li>
<li>消费进度监控
<ul>
<li>对于 Kafka 消费者来说，最重要的事情就是监控它们的消费进度了，或者说是监控它们消费的滞后程度。这个滞后程度有个专门的名称：消费者 Lag 或 Consumer Lag。</li>
<li>在实际业务场景中必须时刻关注消费者的消费进度。一旦出现 Lag 逐步增加的趋势，一定要定位问题，及时处理，避免造成业务损失。</li>
<li>几种监控方式
<ul>
<li>使用 Kafka 自带的命令行工具 kafka-consumer-groups 脚本。</li>
<li>使用 Kafka Java Consumer API 编程。</li>
<li>使用 Kafka 自带的 JMX 监控指标。</li>
</ul>
</li>
</ul>
</li>
</ul>

  
  </div>
</article>


    <footer id="footer">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
  <div class="footer-left">
    Copyright  &copy; 2021  Y.CH.Y 
    <span id="busuanzi_container_page_pv">Page PV : <span id="busuanzi_value_page_pv"></span></span>
    <span id="busuanzi_container_site_uv">Site UV : <span id="busuanzi_value_site_uv"></span></span>
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
</html>
